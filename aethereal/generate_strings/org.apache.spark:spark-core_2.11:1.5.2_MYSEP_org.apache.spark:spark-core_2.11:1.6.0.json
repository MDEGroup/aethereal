[
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2/apply(java.lang.Class)|",
    "called": "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/SetLike/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/MethodIdentifier/MethodIdentifier(java.lang.Class,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/Set/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/FieldAccessFinder$$anon$3/org$apache$spark$util$FieldAccessFinder$$anon$$$outer()|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Set/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/FieldAccessFinder/FieldAccessFinder(scala.collection.mutable.Map,boolean,scala.Option,scala.collection.mutable.Set)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader/accept(com.esotericsoftware.reflectasm.shaded.org.objectweb.asm.ClassVisitor,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/SetLike/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/MethodIdentifier/MethodIdentifier(java.lang.Class,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/Set/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/FieldAccessFinder$$anon$3/org$apache$spark$util$FieldAccessFinder$$anon$$$outer()|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/Set/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/FieldAccessFinder/FieldAccessFinder(scala.collection.mutable.Map,boolean,scala.Option,scala.collection.mutable.Set)|",
      "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15/apply(java.lang.Class)|",
    "called": "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/FieldAccessFinder$/$lessinit$greater$default$4()|",
      "|java+constructor:///org/apache/spark/util/FieldAccessFinder/FieldAccessFinder(scala.collection.mutable.Map,boolean,scala.Option,scala.collection.mutable.Set)|",
      "|java+method:///org/apache/spark/util/FieldAccessFinder$/$lessinit$greater$default$3()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader/accept(com.esotericsoftware.reflectasm.shaded.org.objectweb.asm.ClassVisitor,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/FieldAccessFinder$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/util/FieldAccessFinder/FieldAccessFinder(scala.collection.mutable.Map,boolean,scala.Option,scala.collection.mutable.Set)|",
      "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
      "|java+method:///org/apache/spark/util/FieldAccessFinder$/$lessinit$greater$default$3()|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/ReturnStatementFinder$$anon$2/ReturnStatementFinder$$anon$2(org.apache.spark.util.ReturnStatementFinder)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor/MethodVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/ReturnStatementFinder/ReturnStatementFinder()|",
    "called": "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor/ClassVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/InnerClosureFinder$$anon$4/InnerClosureFinder$$anon$4(org.apache.spark.util.InnerClosureFinder)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor/MethodVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/ClosureCleaner$/org$apache$spark$util$ClosureCleaner$$clean(java.lang.Object,boolean,boolean,scala.collection.mutable.Map)|",
    "called": "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/ClosureCleaner$/org$apache$spark$util$ClosureCleaner$$isClosure(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$5/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$5(java.lang.reflect.Method%5B%5D)|",
      "|java+method:///java/lang/reflect/Field/setAccessible(boolean)|",
      "|java+method:///java/lang/Class/getDeclaredMethods()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$1/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$1(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$2/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$2(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/org$apache$spark$util$ClosureCleaner$$getOuterClassesAndObjects(java.lang.Object)|",
      "|java+method:///scala/runtime/ObjectRef/create(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14(scala.collection.mutable.Map)|",
      "|java+method:///scala/collection/immutable/List/withFilter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16(scala.collection.mutable.Map)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/reverse()|",
      "|java+method:///scala/collection/SetLike/contains(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Class/getDeclaredField(java.lang.String)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/immutable/List/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Map/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$17/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$17()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$13/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$13()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$20/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$20()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$21/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$21()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$9/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$9(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/ensureSerializable(java.lang.Object)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$23/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$23(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8()|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$19/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$19(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$18/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$18(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$7/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$7(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22(boolean,scala.collection.mutable.Map,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/Map/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$11/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$11(scala.collection.immutable.List)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$3/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$3(java.lang.reflect.Field%5B%5D)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///java/lang/reflect/Field/set(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/size()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader/accept(com.esotericsoftware.reflectasm.shaded.org.objectweb.asm.ClassVisitor,int)|",
      "|java+method:///scala/collection/immutable/List/$colon$colon(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ReturnStatementFinder/ReturnStatementFinder()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/mutable/Map/isEmpty()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$24/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$24(java.lang.Object)|",
      "|java+method:///java/lang/Class/getDeclaredFields()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15(boolean,scala.collection.mutable.Map)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getInnerClosureClasses(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/ClosureCleaner$/org$apache$spark$util$ClosureCleaner$$isClosure(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$5/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$5(java.lang.reflect.Method%5B%5D)|",
      "|java+method:///java/lang/reflect/Field/setAccessible(boolean)|",
      "|java+method:///java/lang/Class/getDeclaredMethods()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$1/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$1(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$2/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$2(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/org$apache$spark$util$ClosureCleaner$$getOuterClassesAndObjects(java.lang.Object)|",
      "|java+method:///scala/runtime/ObjectRef/create(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14(scala.collection.mutable.Map)|",
      "|java+method:///scala/collection/immutable/List/withFilter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16(scala.collection.mutable.Map)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/reverse()|",
      "|java+method:///scala/collection/SetLike/contains(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Class/getDeclaredField(java.lang.String)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/immutable/List/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Map/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$17/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$17()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$13/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$13()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$20/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$20()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$21/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$21()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$9/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$9(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/ensureSerializable(java.lang.Object)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$23/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$23(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8()|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$19/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$19(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$18/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$18(scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$7/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$7(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22(boolean,scala.collection.mutable.Map,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/Map/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$11/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$11(scala.collection.immutable.List)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$3/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$3(java.lang.reflect.Field%5B%5D)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///java/lang/reflect/Field/set(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/size()|",
      "|java+method:///scala/collection/immutable/List/$colon$colon(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/ReturnStatementFinder/ReturnStatementFinder()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/mutable/Map/isEmpty()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$24/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$24(java.lang.Object)|",
      "|java+method:///java/lang/Class/getDeclaredFields()|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15/ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15(boolean,scala.collection.mutable.Map)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getInnerClosureClasses(java.lang.Object)|",
      "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/ClosureCleaner$/getInnerClosureClasses(java.lang.Object)|",
    "called": "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/Set/$minus$minus(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/mutable/Set/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$getInnerClosureClasses$1/ClosureCleaner$$anonfun$getInnerClosureClasses$1(scala.collection.mutable.Set,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///scala/collection/mutable/Set$/apply(scala.collection.Seq)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/util/InnerClosureFinder/InnerClosureFinder(scala.collection.mutable.Set)|",
      "|java+method:///scala/runtime/ObjectRef/create(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Set/$minus(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Set/toList()|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader/accept(com.esotericsoftware.reflectasm.shaded.org.objectweb.asm.ClassVisitor,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/Set/$minus$minus(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/mutable/Set/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/ClosureCleaner$$anonfun$getInnerClosureClasses$1/ClosureCleaner$$anonfun$getInnerClosureClasses$1(scala.collection.mutable.Set,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///scala/collection/mutable/Set$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/util/InnerClosureFinder/InnerClosureFinder(scala.collection.mutable.Set)|",
      "|java+method:///org/apache/xbean/asm5/ClassReader/accept(org.apache.xbean.asm5.ClassVisitor,int)|",
      "|java+method:///scala/runtime/ObjectRef/create(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Set/$minus(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Set/toList()|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/InnerClosureFinder/InnerClosureFinder(scala.collection.mutable.Set)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor/ClassVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/FieldAccessFinder/FieldAccessFinder(scala.collection.mutable.Map,boolean,scala.Option,scala.collection.mutable.Set)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassVisitor/ClassVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/ClassVisitor/ClassVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/ReturnStatementFinder$$anon$1/ReturnStatementFinder$$anon$1(org.apache.spark.util.ReturnStatementFinder)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor/MethodVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/FieldAccessFinder$$anon$3/FieldAccessFinder$$anon$3(org.apache.spark.util.FieldAccessFinder)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|",
    "v1Body": [
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/MethodVisitor/MethodVisitor(int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/xbean/asm5/MethodVisitor/MethodVisitor(int)|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/ClosureCleaner$/getClassReader(java.lang.Class)|",
    "called": "|java+constructor:///org/apache/xbean/asm5/ClassReader/ClassReader(java.io.InputStream)|",
    "v1Body": [
      "|java+method:///java/lang/Class/getResourceAsStream(java.lang.String)|",
      "|java+constructor:///java/io/ByteArrayOutputStream/ByteArrayOutputStream(int)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/lang/String/replaceFirst(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/copyStream(java.io.InputStream,java.io.OutputStream,boolean,boolean)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/util/Utils$/copyStream$default$4()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/ByteArrayOutputStream/toByteArray()|",
      "|java+constructor:///com/esotericsoftware/reflectasm/shaded/org/objectweb/asm/ClassReader/ClassReader(java.io.InputStream)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/getResourceAsStream(java.lang.String)|",
      "|java+constructor:///java/io/ByteArrayOutputStream/ByteArrayOutputStream(int)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///org/apache/xbean/asm5/ClassReader/ClassReader(java.io.InputStream)|",
      "|java+method:///java/lang/String/replaceFirst(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/copyStream(java.io.InputStream,java.io.OutputStream,boolean,boolean)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/util/Utils$/copyStream$default$4()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/ByteArrayOutputStream/toByteArray()|"
    ],
    "affectedLib": "org.apache.xbean:xbean-asm5-shaded:4.4",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/PythonRunner$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///py4j/GatewayServer/getListeningPort()|",
    "v1Body": [
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.util.List)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///java/lang/String/valueOf(java.lang.Object)|",
      "|java+method:///org/apache/spark/api/python/PythonUtils$/mergePythonPaths(scala.collection.Seq)|",
      "|java+method:///py4j/GatewayServer/shutdown()|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPath(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/api/python/PythonUtils$/sparkPythonPath()|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$main$1/PythonRunner$$anonfun$main$1()|",
      "|java+constructor:///org/apache/spark/util/RedirectThread/RedirectThread(java.io.InputStream,java.io.OutputStream,java.lang.String,boolean)|",
      "|java+method:///java/lang/Thread/join()|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPaths(java.lang.String,boolean)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/redirectErrorStream(boolean)|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPaths$default$2()|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/slice(int,int)|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+constructor:///org/apache/spark/SparkUserAppException/SparkUserAppException(int)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/util/RedirectThread$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/util/RedirectThread/start()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPath$default$2()|",
      "|java+constructor:///py4j/GatewayServer/GatewayServer(java.lang.Object,int)|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anon$1/PythonRunner$$anon$1(py4j.GatewayServer)|",
      "|java+method:///py4j/GatewayServer/getListeningPort()|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$1/PythonRunner$$anonfun$1()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.util.List)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///java/lang/String/valueOf(java.lang.Object)|",
      "|java+method:///org/apache/spark/api/python/PythonUtils$/mergePythonPaths(scala.collection.Seq)|",
      "|java+method:///py4j/GatewayServer/shutdown()|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPath(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/api/python/PythonUtils$/sparkPythonPath()|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$main$1/PythonRunner$$anonfun$main$1()|",
      "|java+constructor:///org/apache/spark/util/RedirectThread/RedirectThread(java.io.InputStream,java.io.OutputStream,java.lang.String,boolean)|",
      "|java+method:///java/lang/Thread/join()|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPaths(java.lang.String,boolean)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/redirectErrorStream(boolean)|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPaths$default$2()|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/slice(int,int)|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+constructor:///org/apache/spark/SparkUserAppException/SparkUserAppException(int)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/util/RedirectThread$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/util/RedirectThread/start()|",
      "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPath$default$2()|",
      "|java+constructor:///py4j/GatewayServer/GatewayServer(java.lang.Object,int)|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anon$1/PythonRunner$$anon$1(py4j.GatewayServer)|",
      "|java+method:///py4j/GatewayServer/getListeningPort()|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$1/PythonRunner$$anonfun$1()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "net.sf.py4j:py4j:0.9",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer)|",
    "called": "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
    "v1Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$putBytes$1/TachyonBlockManager$$anonfun$putBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///tachyon/client/OutStream/cancel()|",
      "|java+method:///tachyon/client/OutStream/write(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///tachyon/client/OutStream/close()|",
      "|java+method:///java/nio/ByteBuffer/array()|"
    ],
    "v2Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/file/FileOutStream/cancel()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$putBytes$1/TachyonBlockManager$$anonfun$putBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/array()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///tachyon/client/file/FileOutStream/write(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///tachyon/client/file/FileOutStream/close()|"
    ],
    "affectedLib": "org.tachyonproject:tachyon-client:0.8.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/getBytes(org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///tachyon/client/TachyonFile/length()|",
    "v1Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/InStream/close()|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$getBytes$1/TachyonBlockManager$$anonfun$getBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///tachyon/client/file/FileInStream/close()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$getBytes$1/TachyonBlockManager$$anonfun$getBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "affectedLib": "org.tachyonproject:tachyon-client:0.8.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/putValues(org.apache.spark.storage.BlockId,scala.collection.Iterator)|",
    "called": "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/blockManager()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerializeStream(org.apache.spark.storage.BlockId,java.io.OutputStream,scala.collection.Iterator,org.apache.spark.serializer.Serializer)|",
      "|java+method:///tachyon/client/OutStream/close()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerializeStream$default$4()|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$putValues$1/TachyonBlockManager$$anonfun$putValues$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///tachyon/client/OutStream/cancel()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/blockManager()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerializeStream(org.apache.spark.storage.BlockId,java.io.OutputStream,scala.collection.Iterator)|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/file/FileOutStream/cancel()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$putValues$1/TachyonBlockManager$$anonfun$putValues$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getOutStream(tachyon.client.WriteType)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///tachyon/client/file/FileOutStream/close()|"
    ],
    "affectedLib": "org.tachyonproject:tachyon-client:0.8.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(java.lang.String)|",
    "called": "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/nonNegativeHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/tachyonDirs()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(tachyon.TachyonURI)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/subDirs()|",
      "|java+method:///tachyon/client/TachyonFS/createFile(tachyon.TachyonURI)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(tachyon.TachyonURI)|",
      "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///tachyon/client/TachyonFS/exist(tachyon.TachyonURI)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$subDirsPerTachyonDir()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/nonNegativeHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/tachyonDirs()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(tachyon.TachyonURI)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/subDirs()|",
      "|java+method:///tachyon/client/TachyonFS/createFile(tachyon.TachyonURI)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(tachyon.TachyonURI)|",
      "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///tachyon/client/TachyonFS/exist(tachyon.TachyonURI)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$subDirsPerTachyonDir()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "affectedLib": "org.tachyonproject:tachyon-client:0.8.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/launcher/WorkerCommandBuilder/WorkerCommandBuilder(java.lang.String,int,org.apache.spark.deploy.Command)|",
    "called": "|java+constructor:///org/apache/spark/launcher/AbstractCommandBuilder/AbstractCommandBuilder()|",
    "v1Body": [
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/JavaConversions$/mapAsJavaMap(scala.collection.Map)|",
      "|java+method:///org/apache/spark/deploy/Command/environment()|",
      "|java+method:///java/util/Map/putAll(java.util.Map)|",
      "|java+constructor:///org/apache/spark/launcher/AbstractCommandBuilder/AbstractCommandBuilder()|"
    ],
    "v2Body": [
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///scala/collection/JavaConverters$/mapAsJavaMapConverter(scala.collection.Map)|",
      "|java+method:///org/apache/spark/deploy/Command/environment()|",
      "|java+method:///java/util/Map/putAll(java.util.Map)|",
      "|java+constructor:///org/apache/spark/launcher/AbstractCommandBuilder/AbstractCommandBuilder()|"
    ],
    "affectedLib": "org.apache.spark:spark-launcher_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/buildCommand(java.util.Map)|",
    "called": "|java+method:///org/apache/spark/launcher/CommandBuilderUtils/addPermGenSizeOpt(java.util.List)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/Command/javaOpts()|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/getenv(java.lang.String)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/Command/classPathEntries()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/launcher/WorkerCommandBuilder$$anonfun$buildCommand$1/WorkerCommandBuilder$$anonfun$buildCommand$1(org.apache.spark.launcher.WorkerCommandBuilder,java.util.List)|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/addOptionString(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/buildJavaCommand(java.lang.String)|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/addPermGenSizeOpt(java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/Command/javaOpts()|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/getenv(java.lang.String)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/Command/classPathEntries()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/launcher/WorkerCommandBuilder$$anonfun$buildCommand$1/WorkerCommandBuilder$$anonfun$buildCommand$1(org.apache.spark.launcher.WorkerCommandBuilder,java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/launcher/CommandBuilderUtils/addPermGenSizeOpt(java.util.List)|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/addOptionString(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/buildJavaCommand(java.lang.String)|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.apache.spark:spark-launcher_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/HighlyCompressedMapStatus$/apply(org.apache.spark.storage.BlockManagerId,long%5B%5D)|",
    "called": "|java+method:///org/roaringbitmap/RoaringBitmap/runOptimize()|",
    "v1Body": [
      "|java+constructor:///org/roaringbitmap/RoaringBitmap/RoaringBitmap()|",
      "|java+constructor:///org/apache/spark/scheduler/HighlyCompressedMapStatus/HighlyCompressedMapStatus(org.apache.spark.storage.BlockManagerId,int,org.roaringbitmap.RoaringBitmap,long)|",
      "|java+method:///org/roaringbitmap/RoaringBitmap/add(int)|"
    ],
    "v2Body": [
      "|java+method:///org/roaringbitmap/RoaringBitmap/runOptimize()|",
      "|java+constructor:///org/roaringbitmap/RoaringBitmap/RoaringBitmap()|",
      "|java+constructor:///org/apache/spark/scheduler/HighlyCompressedMapStatus/HighlyCompressedMapStatus(org.apache.spark.storage.BlockManagerId,int,org.roaringbitmap.RoaringBitmap,long)|",
      "|java+method:///org/roaringbitmap/RoaringBitmap/add(int)|",
      "|java+method:///org/roaringbitmap/RoaringBitmap/trim()|"
    ],
    "affectedLib": "org.roaringbitmap:RoaringBitmap:0.5.11",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/api/python/SerDeUtil$$anonfun$pairRDDToPython$1$$anonfun$apply$2/apply(scala.collection.Seq)|",
    "called": "|java+method:///net/razorvine/pickle/Pickler/dumps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///net/razorvine/pickle/Pickler/dumps(java.lang.Object)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///net/razorvine/pickle/Pickler/dumps(java.lang.Object)|"
    ],
    "affectedLib": "net.razorvine:pyrolite:4.9",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/MesosExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|",
    "called": "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf,java.io.File)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf,java.io.File)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String,org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/MesosExternalShuffleClient(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder,boolean,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/create()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///java/util/concurrent/locks/ReentrantLock/ReentrantLock()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,int)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/MesosExternalShuffleClient(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder,boolean,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf$default$2()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/parseConstraintString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/create()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///java/util/concurrent/locks/ReentrantLock/ReentrantLock()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/MesosExternalShuffleClient(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder,boolean,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf$default$3()|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,java.lang.String,int)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/parseConstraintString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getRejectOfferDurationForUnmetConstraints(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/ExternalShuffleService/newShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|",
    "called": "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf,java.io.File)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/ExternalShuffleBlockHandler(org.apache.spark.network.util.TransportConf,java.io.File)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
    "called": "|java+method:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/connectedApps()|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/RegisterDriverParam()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/RpcResponseCallback/onSuccess(byte%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/getSocketAddress()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$RegisterDriverParam$/unapply(org.apache.spark.network.shuffle.protocol.mesos.RegisterDriver)|",
      "|java+method:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/applicationRemoved(java.lang.String,boolean)|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/connectedApps()|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/RegisterDriverParam()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/RpcResponseCallback/onSuccess(java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/getSocketAddress()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$RegisterDriverParam$/unapply(org.apache.spark.network.shuffle.protocol.mesos.RegisterDriver)|",
      "|java+method:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/applicationRemoved(java.lang.String,boolean)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/statusUpdate(org.apache.mesos.SchedulerDriver,org.apache.mesos.Protos$TaskStatus)|",
    "called": "|java+method:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/registerDriverWithShuffleService(java.lang.String,int)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/registerDriverWithShuffleService(java.lang.String,int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/Map/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///scala/Enumeration$Value/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorTerminated(org.apache.mesos.SchedulerDriver,java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosExternalShuffleClient()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getSlaveId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/assume(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/registerDriverWithShuffleService(java.lang.String,int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///scala/Enumeration$Value/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/get(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorTerminated(org.apache.mesos.SchedulerDriver,java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosExternalShuffleClient()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getSlaveId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/assume(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/uploadBlock(java.lang.String,int,java.lang.String,org.apache.spark.storage.BlockId,org.apache.spark.network.buffer.ManagedBuffer,org.apache.spark.storage.StorageLevel)|",
    "called": "|java+constructor:///org/apache/spark/network/shuffle/protocol/UploadBlock/UploadBlock(java.lang.String,java.lang.String,java.lang.String,byte%5B%5D,byte%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anon$2/NettyBlockTransferService$$anon$2(org.apache.spark.network.netty.NettyBlockTransferService,org.apache.spark.storage.BlockId,scala.concurrent.Promise)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/UploadBlock/UploadBlock(java.lang.String,java.lang.String,java.lang.String,byte%5B%5D,byte%5B%5D)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+method:///org/apache/spark/network/shuffle/protocol/UploadBlock/toByteArray()|",
      "|java+method:///java/nio/ByteBuffer/hasArray()|",
      "|java+method:///org/apache/spark/network/client/TransportClientFactory/createClient(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/buffer/ManagedBuffer/nioByteBuffer()|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/serializer/JavaSerializer/newInstance()|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/Promise$/apply()|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///org/apache/spark/network/client/TransportClient/sendRpc(byte%5B%5D,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///java/nio/ByteBuffer/array()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anon$2/NettyBlockTransferService$$anon$2(org.apache.spark.network.netty.NettyBlockTransferService,org.apache.spark.storage.BlockId,scala.concurrent.Promise)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/UploadBlock/UploadBlock(java.lang.String,java.lang.String,java.lang.String,byte%5B%5D,byte%5B%5D)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/sendRpc(java.nio.ByteBuffer,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+method:///java/nio/ByteBuffer/array()|",
      "|java+method:///org/apache/spark/network/client/TransportClientFactory/createClient(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/buffer/ManagedBuffer/nioByteBuffer()|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/serializer/JavaSerializer/newInstance()|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/Promise$/apply()|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///org/apache/spark/network/shuffle/protocol/UploadBlock/toByteBuffer()|",
      "|java+method:///java/nio/ByteBuffer/hasArray()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillReader/UnsafeSorterSpillReader(org.apache.spark.storage.BlockManager,java.io.File,org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///java/io/DataInputStream/readInt()|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///java/io/File/length()|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+constructor:///org/apache/spark/util/collection/unsafe/sort/UnsafeSorterIterator/UnsafeSorterIterator()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+method:///java/io/DataInputStream/readInt()|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///java/io/File/length()|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+constructor:///org/apache/spark/util/collection/unsafe/sort/UnsafeSorterIterator/UnsafeSorterIterator()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorTerminated(org.apache.mesos.SchedulerDriver,java.lang.String,java.lang.String)|",
    "called": "|java+method:///org/spark-project/guava/collect/HashBiMap/inverse()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/removeExecutor(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$pendingRemovedSlaveIds()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/remove(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/sparkExecutorId(java.lang.String,java.lang.String)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/inverse()|",
      "|java+method:///org/spark-project/guava/collect/BiMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$pendingRemovedSlaveIds()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/scheduler/SlaveLost/SlaveLost(java.lang.String)|",
      "|java+method:///org/spark-project/guava/collect/BiMap/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/removeExecutor(java.lang.String,org.apache.spark.scheduler.ExecutorLossReason)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/remove(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/sparkExecutorId(java.lang.String,java.lang.String)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/inverse()|",
      "|java+method:///org/spark-project/guava/collect/BiMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$initialize$1(java.lang.Process,java.lang.ProcessBuilder,java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/redirectStream(java.io.InputStream,java.io.File)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/redirectStream(java.io.InputStream,java.io.File)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/parseConstraintString(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils,java.lang.String)|",
    "called": "|java+method:///org/spark-project/guava/base/Splitter/withKeyValueSeparator(char)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/spark-project/guava/base/Splitter/trimResults()|",
      "|java+method:///org/spark-project/guava/base/Splitter/withKeyValueSeparator(char)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/spark-project/guava/base/Splitter/on(char)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$$anonfun$parseConstraintString$1/MesosSchedulerUtils$$anonfun$parseConstraintString$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+method:///scala/collection/mutable/Map$/canBuildFrom()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///scala/collection/mutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/MapLike/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///org/spark-project/guava/base/Splitter$MapSplitter/split(java.lang.CharSequence)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/spark-project/guava/base/Splitter/trimResults()|",
      "|java+method:///scala/collection/immutable/Map/mapValues(scala.Function1)|",
      "|java+method:///org/spark-project/guava/base/Splitter/withKeyValueSeparator(char)|",
      "|java+method:///scala/collection/JavaConverters$/mapAsScalaMapConverter(java.util.Map)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///org/spark-project/guava/base/Splitter/on(char)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Predef$/$conforms()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$$anonfun$parseConstraintString$1/MesosSchedulerUtils$$anonfun$parseConstraintString$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+method:///org/spark-project/guava/base/Splitter$MapSplitter/split(java.lang.CharSequence)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String,org.apache.spark.SecurityManager)|",
    "called": "|java+method:///org/spark-project/guava/collect/HashBiMap/create()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/create()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///java/util/concurrent/locks/ReentrantLock/ReentrantLock()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,int)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/MesosExternalShuffleClient(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder,boolean,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf$default$2()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/parseConstraintString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/create()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///java/util/concurrent/locks/ReentrantLock/ReentrantLock()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/MesosExternalShuffleClient(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder,boolean,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf$default$3()|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,java.lang.String,int)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/parseConstraintString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getRejectOfferDurationForUnmetConstraints(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/init(org.apache.spark.network.BlockDataManager)|",
    "called": "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///scala/Option/toList()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/createServer(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///scala/Option/toList()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/createServer(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(java.lang.String,org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/getBytes(org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/InStream/close()|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$getBytes$1/TachyonBlockManager$$anonfun$getBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///tachyon/client/file/FileInStream/close()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$getBytes$1/TachyonBlockManager$$anonfun$getBytes$1(org.apache.spark.storage.TachyonBlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/org$apache$spark$network$netty$NettyBlockTransferService$$startService$1(int,scala.collection.immutable.List)|",
    "called": "|java+method:///org/apache/spark/network/TransportContext/createServer(int,java.util.List)|",
    "v1Body": [
      "|java+method:///org/apache/spark/network/server/TransportServer/getPort()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int,java.util.List)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///org/apache/spark/network/server/TransportServer/getPort()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int,java.util.List)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/TestUtils$/createCompiledClass(java.lang.String,java.io.File,org.apache.spark.TestUtils$JavaSourceFromString,scala.collection.Seq)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
    "v1Body": [
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///javax/tools/ToolProvider/getSystemJavaCompiler()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$5/TestUtils$$anonfun$5()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///javax/tools/JavaCompiler/getTask(java.io.Writer,javax.tools.JavaFileManager,javax.tools.DiagnosticListener,java.lang.Iterable,java.lang.Iterable,java.lang.Iterable)|",
      "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///javax/tools/JavaCompiler$CompilationTask/call()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$1/TestUtils$$anonfun$createCompiledClass$1(java.io.File)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$2/TestUtils$$anonfun$createCompiledClass$2(java.io.File)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///javax/tools/ToolProvider/getSystemJavaCompiler()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$6/TestUtils$$anonfun$6()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Arrays/asList(java.lang.Object%5B%5D)|",
      "|java+method:///javax/tools/JavaCompiler/getTask(java.io.Writer,javax.tools.JavaFileManager,javax.tools.DiagnosticListener,java.lang.Iterable,java.lang.Iterable,java.lang.Iterable)|",
      "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///javax/tools/JavaCompiler$CompilationTask/call()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$1/TestUtils$$anonfun$createCompiledClass$1(java.io.File)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$2/TestUtils$$anonfun$createCompiledClass$2(java.io.File)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/SecurityManager/generateSecretKey()|",
    "called": "|java+method:///org/spark-project/guava/hash/HashCode/toString()|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///akka/util/Crypt$/generateSecureCookie()|",
      "|java+method:///org/apache/spark/SecurityManager$/SPARK_AUTH_SECRET_CONF()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|",
      "|java+method:///org/apache/hadoop/io/Text/toString()|",
      "|java+method:///org/apache/spark/SecurityManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/getSecretKeyFromUserCredentials(java.lang.String)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/addSecretKeyToUserCredentials(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/SecurityManager$/ENV_AUTH_SECRET()|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$9/SecurityManager$$anonfun$9(org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$8/SecurityManager$$anonfun$8(org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$7/SecurityManager$$anonfun$7(org.apache.spark.SecurityManager)|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/isYarnMode()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/SecurityManager/sparkSecretLookupKey()|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$10/SecurityManager$$anonfun$10(org.apache.spark.SecurityManager)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SecurityManager$/SPARK_AUTH_SECRET_CONF()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+constructor:///java/security/SecureRandom/SecureRandom()|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|",
      "|java+method:///org/apache/hadoop/io/Text/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/getSecretKeyFromUserCredentials(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/addSecretKeyToUserCredentials(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/SecurityManager$/ENV_AUTH_SECRET()|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$7/SecurityManager$$anonfun$7(org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SecurityManager$$anonfun$generateSecretKey$1/SecurityManager$$anonfun$generateSecretKey$1(org.apache.spark.SecurityManager)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SecurityManager$/SECRET_LOOKUP_KEY()|",
      "|java+method:///java/security/SecureRandom/nextBytes(byte%5B%5D)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/isYarnMode()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/spark-project/guava/hash/HashCode/toString()|",
      "|java+method:///org/spark-project/guava/hash/HashCodes/fromBytes(byte%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
    "called": "|java+constructor:///org/apache/spark/network/buffer/FileSegmentManagedBuffer/FileSegmentManagedBuffer(org.apache.spark.network.util.TransportConf,java.io.File,long,long)|",
    "v1Body": [
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver$ShuffleFileGroup/getFileSegmentFor(int,int)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/transportConf()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/mapId()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/org$apache$spark$shuffle$FileShuffleBlockResolver$$shuffleStates()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/storage/FileSegment/length()|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/FileSegment/offset()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver$ShuffleState/allFileGroups()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/shuffleId()|",
      "|java+method:///org/apache/spark/storage/FileSegment/file()|",
      "|java+constructor:///org/apache/spark/network/buffer/FileSegmentManagedBuffer/FileSegmentManagedBuffer(org.apache.spark.network.util.TransportConf,java.io.File,long,long)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/util/concurrent/ConcurrentLinkedQueue/iterator()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/org$apache$spark$shuffle$FileShuffleBlockResolver$$consolidateShuffleFiles()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/org$apache$spark$shuffle$FileShuffleBlockResolver$$blockManager()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/reduceId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/transportConf()|",
      "|java+constructor:///org/apache/spark/network/buffer/FileSegmentManagedBuffer/FileSegmentManagedBuffer(org.apache.spark.network.util.TransportConf,java.io.File,long,long)|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///org/apache/spark/shuffle/FileShuffleBlockResolver/org$apache$spark$shuffle$FileShuffleBlockResolver$$blockManager()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/statusUpdate(org.apache.mesos.SchedulerDriver,org.apache.mesos.Protos$TaskStatus)|",
    "called": "|java+method:///org/spark-project/guava/collect/HashBiMap/get(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/registerDriverWithShuffleService(java.lang.String,int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/Map/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///scala/Enumeration$Value/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorTerminated(org.apache.mesos.SchedulerDriver,java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosExternalShuffleClient()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getSlaveId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/assume(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/shuffleServiceEnabled()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/shuffle/mesos/MesosExternalShuffleClient/registerDriverWithShuffleService(java.lang.String,int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///scala/Enumeration$Value/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stateLock()|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/get(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$6(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorTerminated(org.apache.mesos.SchedulerDriver,java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosExternalShuffleClient()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getSlaveId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/assume(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/HttpFileServer/addFileToDir(java.io.File,java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/copy(java.io.File,java.io.File)|",
    "v1Body": [
      "|java+method:///java/io/File/getName()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+method:///org/spark-project/guava/io/Files/copy(java.io.File,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/io/File/getName()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+method:///org/apache/spark/util/Utils$/encodeFileNameToURIRawPath(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/copy(java.io.File,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/util/SizeEstimator$/SizeEstimator$()|",
    "called": "|java+constructor:///org/spark-project/guava/collect/MapMaker/MapMaker()|",
    "v1Body": [
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/initialize()|",
      "|java+method:///scala/Predef$/wrapIntArray(int%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/spark-project/guava/collect/MapMaker/MapMaker()|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/spark-project/guava/collect/MapMaker/weakKeys()|",
      "|java+method:///org/spark-project/guava/collect/MapMaker/makeMap()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/initialize()|",
      "|java+method:///scala/Predef$/wrapIntArray(int%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/input/WholeTextFileRecordReader/nextKeyValue()|",
    "called": "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodecFactory/getCodec(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodec/createInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+constructor:///org/apache/hadoop/io/compress/CompressionCodecFactory/CompressionCodecFactory(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/io/Text/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodecFactory/getCodec(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodec/createInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+constructor:///org/apache/hadoop/io/compress/CompressionCodecFactory/CompressionCodecFactory(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/TestUtils$$anonfun$createJar$1/apply(java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
    "v1Body": [
      "|java+method:///org/spark-project/guava/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///java/util/jar/JarOutputStream/putNextEntry(java.util.zip.ZipEntry)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+constructor:///java/util/jar/JarEntry/JarEntry(java.lang.String)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/guava/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
      "|java+method:///java/nio/file/Paths/get(java.lang.String,java.lang.String%5B%5D)|",
      "|java+method:///java/util/jar/JarOutputStream/putNextEntry(java.util.zip.ZipEntry)|",
      "|java+constructor:///java/util/jar/JarEntry/JarEntry(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/io/File/getName()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createJar$1$$anonfun$5/TestUtils$$anonfun$createJar$1$$anonfun$5(org.apache.spark.TestUtils$$anonfun$createJar$1)|",
      "|java+method:///java/io/FileInputStream/close()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/uploadBlock(java.lang.String,int,java.lang.String,org.apache.spark.storage.BlockId,org.apache.spark.network.buffer.ManagedBuffer,org.apache.spark.storage.StorageLevel)|",
    "called": "|java+method:///org/apache/spark/network/client/TransportClient/sendRpc(java.nio.ByteBuffer,org.apache.spark.network.client.RpcResponseCallback)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anon$2/NettyBlockTransferService$$anon$2(org.apache.spark.network.netty.NettyBlockTransferService,org.apache.spark.storage.BlockId,scala.concurrent.Promise)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/UploadBlock/UploadBlock(java.lang.String,java.lang.String,java.lang.String,byte%5B%5D,byte%5B%5D)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+method:///org/apache/spark/network/shuffle/protocol/UploadBlock/toByteArray()|",
      "|java+method:///java/nio/ByteBuffer/hasArray()|",
      "|java+method:///org/apache/spark/network/client/TransportClientFactory/createClient(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/buffer/ManagedBuffer/nioByteBuffer()|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/serializer/JavaSerializer/newInstance()|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/Promise$/apply()|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///org/apache/spark/network/client/TransportClient/sendRpc(byte%5B%5D,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///java/nio/ByteBuffer/array()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anon$2/NettyBlockTransferService$$anon$2(org.apache.spark.network.netty.NettyBlockTransferService,org.apache.spark.storage.BlockId,scala.concurrent.Promise)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/UploadBlock/UploadBlock(java.lang.String,java.lang.String,java.lang.String,byte%5B%5D,byte%5B%5D)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/sendRpc(java.nio.ByteBuffer,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+method:///java/nio/ByteBuffer/array()|",
      "|java+method:///org/apache/spark/network/client/TransportClientFactory/createClient(java.lang.String,int)|",
      "|java+method:///org/apache/spark/network/buffer/ManagedBuffer/nioByteBuffer()|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/serializer/JavaSerializer/newInstance()|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/Promise$/apply()|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///org/apache/spark/network/shuffle/protocol/UploadBlock/toByteBuffer()|",
      "|java+method:///java/nio/ByteBuffer/hasArray()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService/ExternalShuffleService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/blockHandler()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/newShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportConf()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,int)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/blockHandler()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/newShuffleBlockHandler(org.apache.spark.network.util.TransportConf)|",
      "|java+method:///org/apache/spark/network/netty/SparkTransportConf$/fromSparkConf(org.apache.spark.SparkConf,java.lang.String,int)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportConf()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler,boolean)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///org/spark-project/guava/collect/HashBiMap/put(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+method:///scala/collection/mutable/Map/update(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/toAttributeMap(java.util.List)|",
      "|java+method:///org/apache/mesos/Protos$OfferID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getAttributesList()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addAllResources(java.lang.Iterable)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/size()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,org.apache.mesos.Protos$TaskInfo$Builder)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$3/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,double,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/declineOffer(org.apache.mesos.Protos$OfferID)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$4/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,double,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveOfferConstraints()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/partitionResources(java.util.List,java.lang.String,double)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int,int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorLimit()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/matchesAttributeRequirements(scala.collection.immutable.Map,scala.collection.immutable.Map)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/toAttributeMap(java.util.List)|",
      "|java+method:///org/apache/mesos/Protos$OfferID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getAttributesList()|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$rejectOfferDurationForUnmetConstraints()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addAllResources(java.lang.Iterable)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/size()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,org.apache.mesos.Protos$TaskInfo$Builder)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$3/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,double,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$5/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,double,int,java.lang.String)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/declineOffer(org.apache.mesos.Protos$OfferID)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$4/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,double,int,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveOfferConstraints()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$slaveIdToHost()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/declineOffer(org.apache.mesos.Protos$OfferID,org.apache.mesos.Protos$Filters)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/partitionResources(java.util.List,java.lang.String,double)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int,int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/executorLimit()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/matchesAttributeRequirements(scala.collection.immutable.Map,scala.collection.immutable.Map)|",
      "|java+method:///org/spark-project/guava/collect/HashBiMap/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
    "called": "|java+method:///org/apache/spark/network/client/TransportClient/getSocketAddress()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/connectedApps()|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/RegisterDriverParam()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/RpcResponseCallback/onSuccess(byte%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/getSocketAddress()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$RegisterDriverParam$/unapply(org.apache.spark.network.shuffle.protocol.mesos.RegisterDriver)|",
      "|java+method:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/applicationRemoved(java.lang.String,boolean)|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/connectedApps()|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$1(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/RegisterDriverParam()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/RpcResponseCallback/onSuccess(java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2/MesosExternalShuffleBlockHandler$$anonfun$handleMessage$2(org.apache.spark.deploy.mesos.MesosExternalShuffleBlockHandler,java.lang.String,java.net.SocketAddress,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/client/TransportClient/getSocketAddress()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler$RegisterDriverParam$/unapply(org.apache.spark.network.shuffle.protocol.mesos.RegisterDriver)|",
      "|java+method:///org/apache/spark/network/shuffle/ExternalShuffleBlockHandler/handleMessage(org.apache.spark.network.shuffle.protocol.BlockTransferMessage,org.apache.spark.network.client.TransportClient,org.apache.spark.network.client.RpcResponseCallback)|",
      "|java+method:///org/apache/spark/deploy/mesos/MesosExternalShuffleBlockHandler/applicationRemoved(java.lang.String,boolean)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/input/PortableDataStream/toArray()|",
    "called": "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/input/PortableDataStream/open()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/spark/input/PortableDataStream/close()|",
      "|java+method:///org/apache/spark/input/PortableDataStream/fileIn()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/input/PortableDataStream/open()|",
      "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonSingleThreadScheduledExecutor(java.lang.String)|",
    "called": "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
    "v1Body": [
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/concurrent/Executors/newSingleThreadScheduledExecutor(java.util.concurrent.ThreadFactory)|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|"
    ],
    "v2Body": [
      "|java+constructor:///java/util/concurrent/ScheduledThreadPoolExecutor/ScheduledThreadPoolExecutor(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+method:///java/util/concurrent/ScheduledThreadPoolExecutor/setRemoveOnCancelPolicy(boolean)|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor()|",
    "called": "|java+method:///org/spark-project/guava/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$1/ExecutorRunner$$anonfun$1(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$1/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$1(org.apache.spark.deploy.worker.ExecutorRunner,java.util.List)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/publicAddress()|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///org/apache/spark/util/logging/FileAppender$/apply(java.io.InputStream,java.io.File,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stderrAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/executorDir()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/ProcessBuilder/directory(java.io.File)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$killProcess(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stdoutAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/EXITED()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$2/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$2(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/KILLED()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$3/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$3(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$7()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logInfo(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appLocalDirs()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/webUiPort()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process_$eq(java.lang.Process)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,org.apache.spark.SecurityManager,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/worker()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/send(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appDesc()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appId()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/sparkHome()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$1/ExecutorRunner$$anonfun$1(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/publicAddress()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stderrAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/executorDir()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/ProcessBuilder/directory(java.io.File)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$killProcess(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/execId()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$1/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$1(org.apache.spark.deploy.worker.ExecutorRunner,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stdoutAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/EXITED()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$2/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$2(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/KILLED()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$3/ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$3(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$7()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logInfo(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appLocalDirs()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/webUiPort()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process_$eq(java.lang.Process)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,org.apache.spark.SecurityManager,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///org/apache/spark/util/logging/FileAppender$/apply(java.io.InputStream,java.io.File,org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/worker()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/send(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appDesc()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appId()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/sparkHome()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/Utils$/takeOrdered(scala.collection.Iterator,int,scala.math.Ordering)|",
    "called": "|java+method:///org/spark-project/guava/collect/Ordering/leastOf(java.util.Iterator,int)|",
    "v1Body": [
      "|java+method:///org/spark-project/guava/collect/Ordering/leastOf(java.util.Iterator,int)|",
      "|java+method:///scala/collection/JavaConversions$/asJavaIterator(scala.collection.Iterator)|",
      "|java+method:///scala/collection/Iterable/iterator()|",
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+constructor:///org/apache/spark/util/collection/Utils$$anon$1/Utils$$anon$1(scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConverters$/asJavaIteratorConverter(scala.collection.Iterator)|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+constructor:///org/apache/spark/util/collection/Utils$$anon$1/Utils$$anon$1(scala.math.Ordering)|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///scala/collection/JavaConverters$/asScalaIteratorConverter(java.util.Iterator)|",
      "|java+method:///org/spark-project/guava/collect/Ordering/leastOf(java.util.Iterator,int)|",
      "|java+method:///java/util/List/iterator()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/deploy/ExternalShuffleService/start()|",
    "called": "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/server_$eq(org.apache.spark.network.server.TransportServer)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/server()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportContext()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/org$apache$spark$deploy$ExternalShuffleService$$port()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/org$apache$spark$deploy$ExternalShuffleService$$useSasl()|",
      "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService$$anonfun$start$1/ExternalShuffleService$$anonfun$start$1(org.apache.spark.deploy.ExternalShuffleService)|",
      "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService$$anonfun$start$2/ExternalShuffleService$$anonfun$start$2(org.apache.spark.deploy.ExternalShuffleService)|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int,java.util.List)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportConf()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/server_$eq(org.apache.spark.network.server.TransportServer)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/server()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportContext()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/org$apache$spark$deploy$ExternalShuffleService$$port()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/org$apache$spark$deploy$ExternalShuffleService$$useSasl()|",
      "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService$$anonfun$start$1/ExternalShuffleService$$anonfun$start$1(org.apache.spark.deploy.ExternalShuffleService)|",
      "|java+method:///scala/collection/JavaConverters$/seqAsJavaListConverter(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService$$anonfun$start$2/ExternalShuffleService$$anonfun$start$2(org.apache.spark.deploy.ExternalShuffleService)|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int,java.util.List)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/transportConf()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillReader/loadNext()|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D,int,int)|",
    "v1Body": [
      "|java+method:///java/io/DataInputStream/readInt()|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D,int,int)|",
      "|java+method:///java/io/DataInputStream/readLong()|",
      "|java+method:///java/io/File/delete()|"
    ],
    "v2Body": [
      "|java+method:///java/io/DataInputStream/readInt()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillReader/close()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D,int,int)|",
      "|java+method:///java/io/DataInputStream/readLong()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/allocate(int)|",
    "called": "|java+method:///org/apache/spark/unsafe/array/LongArray/zeroOut()|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/nextPowerOf2(long)|",
      "|java+method:///java/lang/Math/min(long,long)|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/fromLongArray(long%5B%5D)|",
      "|java+constructor:///org/apache/spark/unsafe/array/LongArray/LongArray(org.apache.spark.unsafe.memory.MemoryBlock)|",
      "|java+constructor:///org/apache/spark/unsafe/bitset/BitSet/BitSet(org.apache.spark.unsafe.memory.MemoryBlock)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/nextPowerOf2(long)|",
      "|java+method:///java/lang/Math/min(long,long)|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/allocateArray(long)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/zeroOut()|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter$SortedIterator/loadNext()|",
    "called": "|java+method:///org/apache/spark/unsafe/Platform/getInt(java.lang.Object,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/Platform/getInt(java.lang.Object,long)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/getOffsetInPage(long)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/getPage(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/Platform/getInt(java.lang.Object,long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/access$100(org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter)|",
      "|java+method:///org/apache/spark/memory/TaskMemoryManager/getOffsetInPage(long)|",
      "|java+method:///org/apache/spark/memory/TaskMemoryManager/getPage(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/access$000(org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/safeLookup(java.lang.Object,long,int,org.apache.spark.unsafe.map.BytesToBytesMap$Location)|",
    "called": "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/memory/MemoryLocation/getBaseOffset()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/getKeyAddress()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/access$400(org.apache.spark.unsafe.map.BytesToBytesMap$Location,int,int,boolean)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryLocation/getBaseObject()|",
      "|java+method:///org/apache/spark/unsafe/hash/Murmur3_x86_32/hashUnsafeWords(java.lang.Object,long,int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/isSet(int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/getKeyLength()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/getKeyLength()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/access$1000(org.apache.spark.unsafe.map.BytesToBytesMap$Location,int,int,boolean)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryLocation/getBaseOffset()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/getKeyAddress()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryLocation/getBaseObject()|",
      "|java+method:///org/apache/spark/unsafe/hash/Murmur3_x86_32/hashUnsafeWords(java.lang.Object,long,int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/insertRecord(long,long)|",
    "called": "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/expandPointerArray()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/hasSpaceForAnotherRecord()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/array/LongArray/size()|",
      "|java+method:///org/apache/spark/memory/MemoryConsumer/allocateArray(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/expandPointerArray(org.apache.spark.unsafe.array.LongArray)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/hasSpaceForAnotherRecord()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/putNewKey(java.lang.Object,long,int,java.lang.Object,long,int)|",
    "called": "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/allocatePage(long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$700(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$600(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/release(long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$000(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1400(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1200(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1100(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1000(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/growAndRehash()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/updateAddressesAndSizes(long)|",
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/set(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$900(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$800(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseOffset()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/size()|",
      "|java+method:///java/lang/Long/valueOf(long)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$500(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$100(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1214(org.apache.spark.unsafe.map.BytesToBytesMap,long)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1300(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/tryToAcquire(long)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$708(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/Platform/getInt(java.lang.Object,long)|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1308(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1700(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1500(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1400(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1100(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1800(org.apache.spark.unsafe.map.BytesToBytesMap,long)|",
      "|java+method:///org/apache/spark/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/updateAddressesAndSizes(long)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseOffset()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/size()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/size()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1600(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1300(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1402(org.apache.spark.unsafe.map.BytesToBytesMap,boolean)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1200(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1714(org.apache.spark.unsafe.map.BytesToBytesMap,long)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/growAndRehash()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/with(int,int,boolean)|",
    "called": "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$500(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/updateAddressesAndSizes(long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/access$1200(org.apache.spark.unsafe.map.BytesToBytesMap)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap$Location/updateAddressesAndSizes(long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeSortDataFormat/allocate(int)|",
    "called": "|java+constructor:///org/apache/spark/unsafe/array/LongArray/LongArray(org.apache.spark.unsafe.memory.MemoryBlock)|",
    "v1Body": [
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError(java.lang.Object)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeSortDataFormat/allocate(int)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError(java.lang.Object)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/unsafe/array/LongArray/LongArray(org.apache.spark.unsafe.memory.MemoryBlock)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeSortDataFormat/allocate(int)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/fromLongArray(long%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/insertRecord(java.lang.Object,long,int,long)|",
    "called": "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/growPointerArrayIfNecessary()|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/insertRecord(long,long)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/tryToAcquire(long)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/acquireNewPageIfNecessary(int)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/allocatePage(long)|",
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/roundNumberOfBytesToNearestWord(int)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseOffset()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/release(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/spill()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///java/util/LinkedList/add(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/growPointerArrayIfNecessary()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/acquireNewPageIfNecessary(int)|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/insertRecord(long,long)|",
      "|java+method:///org/apache/spark/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/growAndRehash()|",
    "called": "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/isSet(int)|",
      "|java+method:///java/lang/System/nanoTime()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/allocate(int)|",
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/set(int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
      "|java+method:///org/apache/spark/unsafe/map/HashMapGrowthStrategy/nextCapacity(int)|",
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/capacity()|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/spark/unsafe/bitset/BitSet/nextSetBit(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/freeArray(org.apache.spark.unsafe.array.LongArray)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/size()|",
      "|java+method:///java/lang/System/nanoTime()|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/get(int)|",
      "|java+method:///org/apache/spark/unsafe/map/BytesToBytesMap/allocate(int)|",
      "|java+method:///org/apache/spark/unsafe/map/HashMapGrowthStrategy/nextCapacity(int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///org/apache/spark/unsafe/array/LongArray/set(int,long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/PrefixComparators$BinaryPrefixComparator/computePrefix(byte%5B%5D)|",
    "called": "|java+method:///org/apache/spark/unsafe/types/ByteArray/getPrefix(byte%5B%5D)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/Platform/getByte(java.lang.Object,long)|",
      "|java+method:///java/lang/Math/min(int,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/unsafe/types/ByteArray/getPrefix(byte%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.11:1.5.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.11:1.6.0",
    "caller": "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/insertKVRecord(java.lang.Object,long,int,java.lang.Object,long,int,long)|",
    "called": "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/growPointerArrayIfNecessary()|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/insertRecord(long,long)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/tryToAcquire(long)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/acquireNewPageIfNecessary(int)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/allocatePage(long)|",
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/roundNumberOfBytesToNearestWord(int)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseOffset()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/release(long)|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/spill()|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///java/util/LinkedList/add(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/growPointerArrayIfNecessary()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter/acquireNewPageIfNecessary(int)|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///org/apache/spark/unsafe/memory/MemoryBlock/getBaseObject()|",
      "|java+method:///org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter/insertRecord(long,long)|",
      "|java+method:///org/apache/spark/memory/TaskMemoryManager/encodePageNumberAndOffset(org.apache.spark.unsafe.memory.MemoryBlock,long)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putInt(java.lang.Object,long,int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.11:1.6.0",
    "change": "UPDATED"
  }
]