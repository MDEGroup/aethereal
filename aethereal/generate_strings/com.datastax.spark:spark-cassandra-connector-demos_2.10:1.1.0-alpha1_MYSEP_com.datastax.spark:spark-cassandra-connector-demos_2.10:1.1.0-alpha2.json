[
  {
    "coordinatesV1": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha1",
    "coordinatesV2": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha2",
    "caller": "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///org/apache/spark/SparkEnv$/get()|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.Manifest,scala.reflect.Manifest)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.1.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha1",
    "coordinatesV2": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha2",
    "caller": "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/main(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.Manifest,scala.reflect.Manifest)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "affectedLib": "org.apache.spark:spark-streaming_2.10:1.1.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha1",
    "coordinatesV2": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha2",
    "caller": "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.Manifest,scala.reflect.Manifest)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "affectedLib": "org.apache.spark:spark-streaming-kafka_2.10:1.1.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha1",
    "coordinatesV2": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha2",
    "caller": "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.Manifest,scala.reflect.Manifest)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "affectedLib": "com.datastax.spark:spark-cassandra-connector_2.10:1.1.0-alpha2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha1",
    "coordinatesV2": "com.datastax.spark:spark-cassandra-connector-demos_2.10:1.1.0-alpha2",
    "caller": "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.Manifest,scala.reflect.Manifest)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/createTopic(java.lang.String)|",
      "|java+constructor:///org/apache/spark/streaming/StreamingContext/StreamingContext(org.apache.spark.SparkConf,org.apache.spark.streaming.Duration)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/registerOnTermination(scala.Function0)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/kafka()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/topic()|",
      "|java+method:///org/apache/spark/streaming/dstream/ReceiverInputDStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond(scala.Function0,scala.concurrent.duration.Duration,scala.concurrent.duration.Duration,java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/kafkaParams()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$6/KafkaStreamingDemo$$anonfun$main$6(com.datastax.spark.connector.CassandraRow%5B%5D)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/streaming/kafka/KafkaUtils$/createStream(org.apache.spark.streaming.StreamingContext,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.spark.storage.StorageLevel,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext$/toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toStreamingContextFunctions(org.apache.spark.streaming.StreamingContext)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///com/datastax/spark/connector/streaming/package$/toDStreamFunctions(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$2/KafkaStreamingDemo$$anonfun$main$2()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$4/KafkaStreamingDemo$$anonfun$main$4()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$5/KafkaStreamingDemo$$anonfun$main$5()|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$1/KafkaStreamingDemo$$anonfun$main$1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///com/datastax/spark/connector/SparkContextFunctions/cassandraTable(java.lang.String,java.lang.String,scala.reflect.ClassTag,com.datastax.spark.connector.rdd.reader.RowReaderFactory)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/log()|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$3()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/awaitCond$default$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/collect()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/start()|",
      "|java+method:///com/datastax/spark/connector/rdd/CassandraRDD/select(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/streaming/dstream/PairDStreamFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_ONLY()|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/awaitTermination()|",
      "|java+method:///org/apache/spark/streaming/dstream/DStream/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///com/datastax/spark/connector/embedded/EmbeddedKafka/produceAndSendMessage(java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///com/datastax/spark/connector/mapper/ColumnMapper$/tuple2ColumnMapper()|",
      "|java+method:///scala/collection/immutable/Map/forall(scala.Function1)|",
      "|java+method:///org/apache/spark/streaming/Seconds$/apply(long)|",
      "|java+constructor:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$$anonfun$main$3/KafkaStreamingDemo$$anonfun$main$3(scala.collection.immutable.Map,com.datastax.spark.connector.rdd.CassandraRDD)|",
      "|java+method:///org/apache/spark/streaming/StreamingContext/stop(boolean,boolean)|",
      "|java+method:///com/datastax/spark/connector/writer/RowWriterFactory$/defaultRowWriterFactory(scala.reflect.ClassTag,com.datastax.spark.connector.mapper.ColumnMapper)|",
      "|java+method:///com/datastax/spark/connector/streaming/DStreamFunctions/saveToCassandra(java.lang.String,java.lang.String,com.datastax.spark.connector.SomeColumns,int,com.datastax.spark.connector.writer.RowWriterFactory)|",
      "|java+constructor:///com/datastax/spark/connector/SomeColumns/SomeColumns(scala.collection.Seq)|",
      "|java+method:///com/datastax/spark/connector/demo/streaming/KafkaStreamingDemo$/sc()|"
    ],
    "affectedLib": "com.datastax.spark:spark-cassandra-connector-embedded_2.10:1.1.0-alpha2",
    "change": "UPDATED"
  }
]