[
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/ScalaUDF/eval(org.apache.spark.sql.catalyst.InternalRow)|",
    "called": "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
    "v1Body": [
      "|java+method:///scala/Function1/apply(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/ScalaUDF/udfErrorMessage()|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-core_2.11:2.0.2.3",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/trees/TreeNode/org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson(java.lang.Object)|",
    "called": "|java+method:///org/apache/spark/storage/StorageLevel/replication()|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$8/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$8(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/math/BigInt$/long2bigInt(long)|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/json4s/JsonDSL$/list2jvalue(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$3/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$3(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$4/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$4(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/json4s/JsonAST$JBool/JsonAST$JBool(boolean)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$5/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$5(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///org/apache/spark/sql/types/Metadata/jsonValue()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$11/TreeNode$$anonfun$11(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$6/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$6(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+constructor:///org/json4s/JsonAST$JDouble/JsonAST$JDouble(double)|",
      "|java+method:///scala/collection/Iterator/toSeq()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$7/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$7(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/deserialized()|",
      "|java+method:///scala/Predef$/ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$9/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$9(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+constructor:///org/json4s/JsonAST$JObject/JsonAST$JObject(scala.collection.immutable.List)|",
      "|java+constructor:///org/json4s/JsonAST$JArray/JsonAST$JArray(scala.collection.immutable.List)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/collection/Map/toList()|",
      "|java+method:///scala/Product/productIterator()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/math/BigInt$/int2bigInt(int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///org/json4s/JsonAST$JString/JsonAST$JString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameterNames(java.lang.Class)|",
      "|java+constructor:///org/json4s/JsonAST$JInt/JsonAST$JInt(scala.math.BigInt)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/$conforms()|",
      "|java+method:///scala/collection/immutable/List/$colon$colon(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/DataType/jsonValue()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/json4s/JsonDSL$/option2jvalue(scala.Option,scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/trees/TreeNode/jsonValue()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$1/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$1(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$2/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$2(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/replication()|",
      "|java+method:///scala/collection/TraversableOnce/toList()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$8/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$8(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/math/BigInt$/long2bigInt(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/json4s/JsonDSL$/list2jvalue(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$3/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$3(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$4/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$4(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/json4s/JsonAST$JBool/JsonAST$JBool(boolean)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$5/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$5(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///org/apache/spark/sql/types/Metadata/jsonValue()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$11/TreeNode$$anonfun$11(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$6/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$6(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+constructor:///org/json4s/JsonAST$JDouble/JsonAST$JDouble(double)|",
      "|java+method:///scala/collection/Iterator/toSeq()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$7/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$7(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/deserialized()|",
      "|java+method:///scala/Predef$/ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$9/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$9(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///org/apache/spark/sql/types/Metadata$/empty()|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/json4s/JsonAST$JObject/JsonAST$JObject(scala.collection.immutable.List)|",
      "|java+constructor:///org/json4s/JsonAST$JArray/JsonAST$JArray(scala.collection.immutable.List)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/collection/Map/toList()|",
      "|java+method:///scala/Product/productIterator()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/math/BigInt$/int2bigInt(int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///org/json4s/JsonAST$JString/JsonAST$JString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/ScalaReflection$/getConstructorParameterNames(java.lang.Class)|",
      "|java+constructor:///org/json4s/JsonAST$JInt/JsonAST$JInt(scala.math.BigInt)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/$conforms()|",
      "|java+method:///scala/collection/immutable/List/$colon$colon(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/DataType/jsonValue()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/json4s/JsonDSL$/option2jvalue(scala.Option,scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/trees/TreeNode/jsonValue()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$1/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$1(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/trees/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$2/TreeNode$$anonfun$org$apache$spark$sql$catalyst$trees$TreeNode$$parseToJson$2(org.apache.spark.sql.catalyst.trees.TreeNode)|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/replication()|",
      "|java+method:///scala/collection/TraversableOnce/toList()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-core_2.11:2.0.2.3",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2/apply(scala.Tuple2)|",
    "called": "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
    "v1Body": [
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/getPartition(java.lang.String,java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy$default$2()|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/org$apache$spark$sql$catalyst$catalog$InMemoryCatalog$$catalog()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$5/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$5(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$renamePartitions$2,scala.collection.immutable.Map)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$6/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$6(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$renamePartitions$2,scala.collection.immutable.Map)|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/storage()|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy(scala.collection.immutable.Map,org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/locationUri()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/getPartition(java.lang.String,java.lang.String,scala.collection.immutable.Map)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$TableDesc/partitions()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy$default$2()|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/storage()|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog/org$apache$spark$sql$catalyst$catalog$InMemoryCatalog$$catalog()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$DatabaseDesc/tables()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$5/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$5(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$renamePartitions$2,scala.collection.immutable.Map)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/catalog/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$6/InMemoryCatalog$$anonfun$renamePartitions$2$$anonfun$6(org.apache.spark.sql.catalyst.catalog.InMemoryCatalog$$anonfun$renamePartitions$2,scala.collection.immutable.Map)|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy$default$3()|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogTablePartition/copy(scala.collection.immutable.Map,org.apache.spark.sql.catalyst.catalog.CatalogStorageFormat,scala.collection.immutable.Map)|",
      "|java+method:///org/apache/spark/sql/catalyst/catalog/CatalogStorageFormat/locationUri()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-core_2.11:2.0.2.3",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1/apply(scala.Tuple2)|",
    "called": "|java+constructor:///org/codehaus/janino/util/ClassFile/ClassFile(java.io.InputStream)|",
    "v1Body": [
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)|",
      "|java+method:///com/codahale/metrics/Histogram/update(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/codehaus/janino/util/ClassFile/ClassFile(java.io.InputStream)|",
      "|java+method:///org/apache/spark/metrics/source/CodegenMetrics$/METRIC_GENERATED_CLASS_BYTECODE_SIZE()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$3/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$3(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1)|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/JavaConverters$/asScalaBufferConverter(java.util.List)|",
      "|java+method:///com/codahale/metrics/Histogram/update(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/codehaus/janino/util/ClassFile/ClassFile(java.io.InputStream)|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/metrics/source/CodegenMetrics$/METRIC_GENERATED_CLASS_BYTECODE_SIZE()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$5/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$5(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$3/CodeGenerator$$anonfun$recordCompilationStats$1$$anonfun$apply$3(org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/collection/convert/Decorators$AsScala/asScala()|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|"
    ],
    "affectedLib": "org.codehaus.janino:janino:3.0.6",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1/apply()|",
    "called": "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromDayTimeString(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromSingleUnitString(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$54/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$54(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/ParseException/ParseException(java.lang.String,org.antlr.v4.runtime.ParserRuleContext)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/ParserUtils$/assert(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalValueContext/getText()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$apply$4/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$apply$4(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1,org.apache.spark.unsafe.types.CalendarInterval)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromYearMonthString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///java/lang/IllegalArgumentException/getMessage()|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/ParseException/setStackTrace(java.lang.StackTraceElement%5B%5D)|",
      "|java+method:///java/lang/IllegalArgumentException/getStackTrace()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromDayTimeString(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1/apply()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$49/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$49(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/ParseException/ParseException(java.lang.String,org.antlr.v4.runtime.ParserRuleContext)|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/ParserUtils$/validate(scala.Function0,java.lang.String,org.antlr.v4.runtime.ParserRuleContext)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/SqlBaseParser$IntervalValueContext/getText()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromSingleUnitString(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$apply$3/AstBuilder$$anonfun$visitIntervalField$1$$anonfun$apply$3(org.apache.spark.sql.catalyst.parser.AstBuilder$$anonfun$visitIntervalField$1,org.apache.spark.unsafe.types.CalendarInterval)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromYearMonthString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/SqlBaseParser$IdentifierContext/getText()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///java/lang/IllegalArgumentException/getMessage()|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/ParseException/setStackTrace(java.lang.StackTraceElement%5B%5D)|",
      "|java+method:///java/lang/IllegalArgumentException/getStackTrace()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/types/CalendarInterval/fromDayTimeString(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/parser/AstBuilder$$anonfun$visitIntervalField$1/apply()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/UnsafeRow/equals(java.lang.Object)|",
    "called": "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/spark/unsafe/array/ByteArrayMethods/arrayEquals(java.lang.Object,long,java.lang.Object,long,long)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/StringBuilder/toString()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal/sql()|",
    "called": "|java+method:///org/apache/spark/unsafe/types/UTF8String/toString()|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/DecimalType/sql()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaDate(int)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(byte)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/FloatType$/sql()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToFloat(float)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal/value()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(double)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(short)|",
      "|java+method:///org/apache/spark/sql/types/DataType/sql()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/toString()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal/dataType()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/lang/Double/isNaN()|",
      "|java+method:///java/lang/Float/isNaN()|",
      "|java+method:///scala/Predef$/double2Double(double)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Predef$any2stringadd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaDate(int)|",
      "|java+method:///org/apache/spark/sql/types/DoubleType$/sql()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/toJavaTimestamp(long)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(byte)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/FloatType$/sql()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToFloat(float)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal/value()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(double)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/sql/types/DataType/sql()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/toString()|",
      "|java+method:///scala/Predef$/float2Float(float)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(short)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal/dataType()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/Ascii/nullSafeEval(java.lang.Object)|",
    "called": "|java+method:///org/apache/spark/unsafe/types/UTF8String/getByte(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/getBytes()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/getByte(int)|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/numBytes()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object)|",
    "called": "|java+method:///org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/sql/types/Decimal$/apply(java.math.BigDecimal)|",
      "|java+method:///scala/math/BigDecimal/scale()|",
      "|java+method:///org/apache/spark/sql/types/Decimal/scale()|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+method:///org/apache/spark/sql/types/Decimal$/apply(scala.math.BigDecimal)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaDate(java.sql.Date)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/math/BigDecimal/scale()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToShort(short)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToFloat(float)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/Literal$/apply(java.lang.Object,org.apache.spark.sql.types.DataType)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///java/math/BigDecimal/precision()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/sql/types/DecimalType/DecimalType(int,int)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///scala/math/BigDecimal/precision()|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaTimestamp(java.sql.Timestamp)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/Decimal/precision()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/sql/types/Decimal$/apply(java.math.BigDecimal)|",
      "|java+method:///scala/math/BigDecimal/scale()|",
      "|java+method:///org/apache/spark/sql/types/Decimal/scale()|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToByte(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaDate(java.sql.Date)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/math/BigDecimal/scale()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToShort(java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/types/UTF8String/fromString(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToShort(short)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToFloat(float)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToFloat(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/sql/catalyst/expressions/Literal/Literal(java.lang.Object,org.apache.spark.sql.types.DataType)|",
      "|java+method:///org/apache/spark/sql/types/Decimal$/apply(scala.math.BigDecimal)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///java/math/BigDecimal/precision()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/sql/types/DecimalType/DecimalType(int,int)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///scala/math/BigDecimal/precision()|",
      "|java+method:///org/apache/spark/sql/catalyst/util/DateTimeUtils$/fromJavaTimestamp(java.sql.Timestamp)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/sql/types/Decimal/precision()|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "io.snappydata:snappy-spark-catalyst_2.11:2.0.1-3",
    "coordinatesV2": "io.snappydata:snappy-spark-catalyst_2.11:2.0.2.3",
    "caller": "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/UnsafeArrayWriter/write(int,org.apache.spark.sql.types.Decimal,int,int)|",
    "called": "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/sql/types/Decimal/toJavaBigDecimal()|",
      "|java+method:///org/apache/spark/sql/types/Decimal/changePrecision(int,int)|",
      "|java+method:///org/apache/spark/sql/types/Decimal/MAX_LONG_DIGITS()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/BufferHolder/grow(int)|",
      "|java+method:///java/math/BigDecimal/unscaledValue()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/UnsafeArrayWriter/setNullAt(int)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putLong(java.lang.Object,long,long)|",
      "|java+method:///java/math/BigInteger/toByteArray()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/UnsafeArrayWriter/setOffset(int)|",
      "|java+method:///org/apache/spark/sql/types/Decimal/toUnscaledLong()|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/sql/types/Decimal/toJavaBigDecimal()|",
      "|java+method:///org/apache/spark/sql/types/Decimal/changePrecision(int,int)|",
      "|java+method:///org/apache/spark/sql/types/Decimal/MAX_LONG_DIGITS()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/BufferHolder/grow(int)|",
      "|java+method:///java/math/BigDecimal/unscaledValue()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/UnsafeArrayWriter/setNullAt(int)|",
      "|java+method:///org/apache/spark/unsafe/Platform/putLong(java.lang.Object,long,long)|",
      "|java+method:///java/math/BigInteger/toByteArray()|",
      "|java+method:///org/apache/spark/sql/catalyst/expressions/codegen/UnsafeArrayWriter/setOffset(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/spark/sql/types/Decimal/toUnscaledLong()|",
      "|java+method:///org/apache/spark/unsafe/Platform/copyMemory(java.lang.Object,long,java.lang.Object,long,long)|"
    ],
    "affectedLib": "io.snappydata:snappy-spark-unsafe_2.11:2.0.2.3",
    "change": "UPDATED"
  }
]