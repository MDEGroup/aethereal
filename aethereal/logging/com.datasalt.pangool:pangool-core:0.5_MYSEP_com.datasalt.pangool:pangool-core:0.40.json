[
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/utils/DCUtils/loadSerializedObjectInDC(org.apache.hadoop.conf.Configuration,java.lang.Class,java.lang.String,boolean)|",
    "called": "|java+method:///org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/io/ObjectInput/readObject()|",
      "|java+method:///java/lang/Class/cast(java.lang.Object)|",
      "|java+method:///java/io/ObjectInput/close()|",
      "|java+constructor:///java/io/ObjectInputStream/ObjectInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/locateFileInDC(org.apache.hadoop.conf.Configuration,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/io/ObjectInput/readObject()|",
      "|java+method:///java/lang/Class/cast(java.lang.Object)|",
      "|java+method:///java/io/ObjectInput/close()|",
      "|java+constructor:///java/io/ObjectInputStream/ObjectInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/locateFileInDC(org.apache.hadoop.conf.Configuration,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder/createJob()|",
    "called": "|java+method:///org/apache/hadoop/mapreduce/Job/setPartitionerClass(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapreduce/Job/setMapOutputKeyClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/MultipleInputsInterface/getMultiInputs()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setReducerClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/set(com.datasalt.pangool.tuplemr.TupleMRConfig,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setGroupingComparatorClass(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/serializeToDC(java.lang.Object,java.lang.String,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/getRollupFrom()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRException/failIfEmpty(java.util.Collection,java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/TupleMRException/TupleMRException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRException/failIfNull(java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleSerialization/enableSerialization(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setCombinerClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setSortComparatorClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setMapOutputValueClass(java.lang.Class)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/tuplemr/MultipleInputsInterface/configureJob(org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///com/datasalt/pangool/tuplemr/NamedOutputsInterface/configureJob(org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setPartitionerClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(char)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder/buildConf()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapreduce/Job/setMapOutputKeyClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/input/PangoolMultipleInputs/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.InputFormat,org.apache.hadoop.mapreduce.Mapper)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/PangoolMultipleOutputs/addNamedOutputContext(org.apache.hadoop.mapreduce.Job,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setPartitionerClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setGroupingComparatorClass(java.lang.Class)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/getRollupFrom()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRException/failIfEmpty(java.util.Collection,java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/TupleMRException/TupleMRException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setReducerClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Input/access$400(com.datasalt.pangool.tuplemr.TupleMRBuilder$Input)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Input/access$300(com.datasalt.pangool.tuplemr.TupleMRBuilder$Input)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Output/access$100(com.datasalt.pangool.tuplemr.TupleMRBuilder$Output)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Input/access$200(com.datasalt.pangool.tuplemr.TupleMRBuilder$Input)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRException/failIfNull(java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/set(com.datasalt.pangool.tuplemr.TupleMRConfig,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Output/access$500(com.datasalt.pangool.tuplemr.TupleMRBuilder$Output)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Output/access$600(com.datasalt.pangool.tuplemr.TupleMRBuilder$Output)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Output/access$700(com.datasalt.pangool.tuplemr.TupleMRBuilder$Output)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleSerialization/enableSerialization(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setCombinerClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setSortComparatorClass(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setMapOutputValueClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder$Output/access$800(com.datasalt.pangool.tuplemr.TupleMRBuilder$Output)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(char)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRBuilder/buildConf()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/PangoolMultipleOutputs/addNamedOutput(org.apache.hadoop.mapreduce.Job,java.lang.String,org.apache.hadoop.mapreduce.OutputFormat,java.lang.Class,java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/serializeToDC(java.lang.Object,java.lang.String,org.apache.hadoop.conf.Configuration)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/utils/test/AbstractBaseTest/createNewConfiguration()|",
    "called": "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleSerialization/enableSchemaValidation(org.apache.hadoop.conf.Configuration)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/mapred/SortComparator/compare(byte%5B%5D,int,byte%5B%5D,int,com.datasalt.pangool.io.Schema,com.datasalt.pangool.tuplemr.Criteria,com.datasalt.pangool.tuplemr.mapred.SortComparator$Offsets)|",
    "called": "|java+method:///org/apache/hadoop/io/WritableComparator/readVLong(byte%5B%5D,int)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/io/WritableComparator/readVInt(byte%5B%5D,int)|",
      "|java+method:///org/apache/hadoop/io/RawComparator/compare(byte%5B%5D,int,int,byte%5B%5D,int,int)|",
      "|java+method:///com/datasalt/pangool/io/Schema/getField(int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readVLong(byte%5B%5D,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria/getElements()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field$Type/ordinal()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getType()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///org/apache/hadoop/io/WritableUtils/decodeVIntSize(byte)|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readFloat(byte%5B%5D,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria$SortElement/getCustomComparator()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/compareBytes(byte%5B%5D,int,int,byte%5B%5D,int,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria$SortElement/getOrder()|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readDouble(byte%5B%5D,int)|",
      "|java+method:///java/util/List/get(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/io/WritableComparator/readVInt(byte%5B%5D,int)|",
      "|java+method:///org/apache/hadoop/io/RawComparator/compare(byte%5B%5D,int,int,byte%5B%5D,int,int)|",
      "|java+method:///com/datasalt/pangool/io/Schema/getField(int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readVLong(byte%5B%5D,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria/getElements()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getType()|",
      "|java+method:///org/apache/hadoop/io/WritableUtils/decodeVIntSize(byte)|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readFloat(byte%5B%5D,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria$SortElement/getCustomComparator()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/compareBytes(byte%5B%5D,int,int,byte%5B%5D,int,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/SortComparator/getHeaderLengthAndFieldLength(byte%5B%5D,int,com.datasalt.pangool.io.Schema$Field$Type)|",
      "|java+method:///com/datasalt/pangool/tuplemr/Criteria$SortElement/getOrder()|",
      "|java+method:///org/apache/hadoop/io/WritableComparator/readDouble(byte%5B%5D,int)|",
      "|java+method:///java/util/List/get(int)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/MapOnlyJobBuilder/createJob()|",
    "called": "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)|",
    "v1Body": [
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///com/datasalt/pangool/tuplemr/MultipleInputsInterface/getMultiInputs()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setNumReduceTasks(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/serializeToDC(java.lang.Object,java.lang.String,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/TupleMRException/TupleMRException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/tuplemr/MultipleInputsInterface/configureJob(org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///com/datasalt/pangool/tuplemr/NamedOutputsInterface/configureJob(org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(char)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/TupleMRException/TupleMRException(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/input/PangoolMultipleInputs/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.InputFormat,org.apache.hadoop.mapreduce.Mapper)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setNumReduceTasks(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/utils/DCUtils/serializeToDC(java.lang.Object,java.lang.String,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/TupleMRException/TupleMRException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(char)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+constructor:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/TupleOutputFormat(java.lang.String)|",
    "called": "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/FileOutputFormat()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/FileOutputFormat()|",
      "|java+method:///com/datasalt/pangool/io/Schema/parse(java.lang.String)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/FileOutputFormat()|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer/deserializeMultipleSources()|",
    "called": "|java+method:///org/apache/hadoop/io/WritableUtils/readVInt(java.io.DataInput)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/io/WritableUtils/readVInt(java.io.DataInput)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/SimpleTupleDeserializer/getInput()|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer/mixIntermediateIntoResult(com.datasalt.pangool.io.ITuple,com.datasalt.pangool.io.ITuple,com.datasalt.pangool.io.ITuple,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$300(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$200(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$100(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchemaDeserializers()|",
      "|java+method:///com/datasalt/pangool/io/DatumWrapper/datum()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getCommonSchemaDeserializers()|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/SimpleTupleDeserializer/readFields(com.datasalt.pangool.io.ITuple,org.apache.hadoop.io.serializer.Deserializer%5B%5D)|",
      "|java+method:///java/util/List/get(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/io/WritableUtils/readVInt(java.io.DataInput)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer/mixIntermediateIntoResult(com.datasalt.pangool.io.ITuple,com.datasalt.pangool.io.ITuple,com.datasalt.pangool.io.ITuple,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$300(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$200(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer$CachedTuples/access$100(com.datasalt.pangool.tuplemr.serialization.TupleDeserializer$CachedTuples)|",
      "|java+method:///java/util/List/get(int)|",
      "|java+method:///com/datasalt/pangool/io/DatumWrapper/datum()|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleDeserializer/readFields(com.datasalt.pangool.io.ITuple,java.io.DataInput)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleSerializer/multipleSourcesSerialization(com.datasalt.pangool.io.ITuple)|",
    "called": "|java+method:///org/apache/hadoop/io/WritableUtils/writeVInt(java.io.DataOutput,int)|",
    "v1Body": [
      "|java+method:///java/lang/Integer/intValue()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/SimpleTupleSerializer/getOut()|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/SimpleTupleSerializer/write(com.datasalt.pangool.io.Schema,com.datasalt.pangool.io.ITuple,int%5B%5D,org.apache.hadoop.io.serializer.Serializer%5B%5D)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchemaIndexTranslation(int)|",
      "|java+method:///java/util/List/get(int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/getSchemaIdByName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/Schema/equals(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/io/Schema/getName()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchemaSerializers()|",
      "|java+method:///org/apache/hadoop/io/WritableUtils/writeVInt(java.io.DataOutput,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchema(int)|",
      "|java+method:///com/datasalt/pangool/io/ITuple/getSchema()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getCommonSchemaSerializers()|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/getIntermediateSchema(int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getCommonSchemaIndexTranslation(int)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Integer/intValue()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/tuplemr/serialization/TupleSerializer/write(com.datasalt.pangool.io.Schema,com.datasalt.pangool.io.ITuple,int%5B%5D,java.io.DataOutput)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchemaIndexTranslation(int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/TupleMRConfig/getSchemaIdByName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/ITuple/getSchema()|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getCommonSchemaIndexTranslation(int)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///com/datasalt/pangool/io/Schema/getName()|",
      "|java+method:///org/apache/hadoop/io/WritableUtils/writeVInt(java.io.DataOutput,int)|",
      "|java+method:///com/datasalt/pangool/tuplemr/SerializationInfo/getSpecificSchema(int)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/getBoolean(java.lang.String,boolean)|",
    "v1Body": [
      "|java+constructor:///com/datasalt/pangool/io/TupleFile$Writer/TupleFile$Writer(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,com.datasalt.pangool.io.Schema,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat/getOutputCompressorClass(org.apache.hadoop.mapreduce.JobContext,java.lang.Class)|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat/getOutputCompressionType(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat$1/TupleOutputFormat$1(com.datasalt.pangool.tuplemr.mapred.lib.output.TupleOutputFormat,com.datasalt.pangool.io.TupleFile$Writer)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getCompressOutput(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getDefaultWorkFile(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/utils/AvroUtils/toAvroSchema(com.datasalt.pangool.io.Schema)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/setCodec(org.apache.avro.file.CodecFactory)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/Schema/parse(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat$TupleRecordWriter/TupleOutputFormat$TupleRecordWriter(org.apache.avro.Schema,com.datasalt.pangool.io.Schema,org.apache.avro.file.DataFileWriter,com.datasalt.pangool.serialization.HadoopSerialization)|",
      "|java+constructor:///org/apache/avro/reflect/ReflectDatumWriter/ReflectDatumWriter()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/serialization/HadoopSerialization/HadoopSerialization(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getDefaultWorkFile(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)|",
      "|java+method:///org/apache/avro/file/CodecFactory/fromString(java.lang.String)|",
      "|java+method:///org/apache/avro/file/CodecFactory/deflateCodec(int)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/setSyncInterval(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()|",
      "|java+constructor:///org/apache/avro/file/DataFileWriter/DataFileWriter(org.apache.avro.io.DatumWriter)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/create(org.apache.avro.Schema,java.io.OutputStream)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/getInt(java.lang.String,int)|"
    ],
    "affectedLib": "org.apache.hadoop:hadoop-core:0.20.2",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
    "called": "|java+method:///org/apache/avro/file/DataFileWriter/setCodec(org.apache.avro.file.CodecFactory)|",
    "v1Body": [
      "|java+constructor:///com/datasalt/pangool/io/TupleFile$Writer/TupleFile$Writer(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,com.datasalt.pangool.io.Schema,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat/getOutputCompressorClass(org.apache.hadoop.mapreduce.JobContext,java.lang.Class)|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat/getOutputCompressionType(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat$1/TupleOutputFormat$1(com.datasalt.pangool.tuplemr.mapred.lib.output.TupleOutputFormat,com.datasalt.pangool.io.TupleFile$Writer)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getCompressOutput(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getDefaultWorkFile(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)|",
      "|java+method:///com/datasalt/pangool/utils/AvroUtils/toAvroSchema(com.datasalt.pangool.io.Schema)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/setCodec(org.apache.avro.file.CodecFactory)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/Schema/parse(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat$TupleRecordWriter/TupleOutputFormat$TupleRecordWriter(org.apache.avro.Schema,com.datasalt.pangool.io.Schema,org.apache.avro.file.DataFileWriter,com.datasalt.pangool.serialization.HadoopSerialization)|",
      "|java+constructor:///org/apache/avro/reflect/ReflectDatumWriter/ReflectDatumWriter()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/serialization/HadoopSerialization/HadoopSerialization(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///com/datasalt/pangool/tuplemr/mapred/lib/output/TupleOutputFormat/getDefaultWorkFile(org.apache.hadoop.mapreduce.TaskAttemptContext,java.lang.String)|",
      "|java+method:///org/apache/avro/file/CodecFactory/fromString(java.lang.String)|",
      "|java+method:///org/apache/avro/file/CodecFactory/deflateCodec(int)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/setSyncInterval(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getConfiguration()|",
      "|java+constructor:///org/apache/avro/file/DataFileWriter/DataFileWriter(org.apache.avro.io.DatumWriter)|",
      "|java+method:///org/apache/avro/file/DataFileWriter/create(org.apache.avro.Schema,java.io.OutputStream)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/getInt(java.lang.String,int)|"
    ],
    "affectedLib": "org.apache.avro:avro:1.6.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/utils/AvroUtils/toAvroSchema(com.datasalt.pangool.io.Schema)|",
    "called": "|java+constructor:///org/apache/avro/Schema$Field/Schema$Field(java.lang.String,org.apache.avro.Schema,java.lang.String,org.codehaus.jackson.JsonNode)|",
    "v1Body": [
      "|java+method:///org/apache/avro/Schema/createEnum(java.lang.String,java.lang.String,java.lang.String,java.util.List)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field$Type/toString()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field$Type/ordinal()|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getProps()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///com/datasalt/pangool/io/Schema/getFields()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getObjectClass()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getName()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/avro/Schema$Type/valueOf(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///com/datasalt/pangool/io/Schema/getName()|",
      "|java+method:///org/apache/avro/Schema$Field/addProp(java.lang.String,java.lang.String)|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getType()|",
      "|java+method:///org/apache/avro/Schema/createRecord(java.lang.String,java.lang.String,java.lang.String,boolean)|",
      "|java+constructor:///org/apache/avro/Schema$Field/Schema$Field(java.lang.String,org.apache.avro.Schema,java.lang.String,org.codehaus.jackson.JsonNode)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/avro/Schema/setFields(java.util.List)|",
      "|java+method:///org/apache/avro/Schema/create(org.apache.avro.Schema$Type)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getObjectSerialization()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///java/lang/Class/getEnumConstants()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/avro/Schema/createEnum(java.lang.String,java.lang.String,java.lang.String,java.util.List)|",
      "|java+method:///org/apache/avro/Schema/addProp(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field$Type/ordinal()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getType()|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///com/datasalt/pangool/io/Schema/getFields()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getObjectClass()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/getName()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///com/datasalt/pangool/io/Schema/getName()|",
      "|java+method:///org/apache/avro/Schema/createRecord(java.lang.String,java.lang.String,java.lang.String,boolean)|",
      "|java+constructor:///org/apache/avro/Schema$Field/Schema$Field(java.lang.String,org.apache.avro.Schema,java.lang.String,org.codehaus.jackson.JsonNode)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///java/util/HashMap/HashMap()|",
      "|java+method:///org/apache/avro/Schema/setFields(java.util.List)|",
      "|java+method:///org/apache/avro/Schema/create(org.apache.avro.Schema$Type)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///java/lang/Class/getEnumConstants()|"
    ],
    "affectedLib": "org.apache.avro:avro:1.6.2",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "com.datasalt.pangool:pangool-core:0.5",
    "coordinatesV2": "com.datasalt.pangool:pangool-core:0.40",
    "caller": "|java+method:///com/datasalt/pangool/utils/AvroUtils/toPangoolSchema(org.apache.avro.Schema)|",
    "called": "|java+method:///org/apache/avro/Schema/getFields()|",
    "v1Body": [
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/avro/Schema$Field/schema()|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.Throwable)|",
      "|java+method:///java/util/Set/contains(java.lang.Object)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/avro/Schema/getFields()|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///org/apache/avro/Schema/getFullName()|",
      "|java+method:///org/apache/avro/Schema/getType()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/create(java.lang.String,com.datasalt.pangool.io.Schema$Field$Type)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/avro/Schema$Type/ordinal()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/createObject(java.lang.String,java.lang.Class)|",
      "|java+method:///org/apache/avro/Schema$Field/name()|",
      "|java+constructor:///com/datasalt/pangool/io/Schema/Schema(java.lang.String,java.util.List)|",
      "|java+method:///org/apache/avro/Schema$Field/props()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/createEnum(java.lang.String,java.lang.Class)|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/addProp(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/setObjectSerialization(java.lang.Class)|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/avro/Schema$Field/getProp(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/avro/Schema/getProp(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/avro/Schema$Field/schema()|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.String)|",
      "|java+constructor:///com/datasalt/pangool/PangoolRuntimeException/PangoolRuntimeException(java.lang.Throwable)|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/createEnum(java.lang.String,java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/avro/Schema/getFields()|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///org/apache/avro/Schema/getFullName()|",
      "|java+method:///org/apache/avro/Schema/getType()|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/create(java.lang.String,com.datasalt.pangool.io.Schema$Field$Type)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/avro/Schema$Type/ordinal()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+method:///com/datasalt/pangool/io/Schema$Field/createObject(java.lang.String,java.lang.Class)|",
      "|java+method:///org/apache/avro/Schema$Field/name()|",
      "|java+constructor:///com/datasalt/pangool/io/Schema/Schema(java.lang.String,java.util.List)|"
    ],
    "affectedLib": "org.apache.avro:avro:1.6.2",
    "change": "UPDATED"
  }
]