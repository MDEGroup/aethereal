[
  {
    "coordinatesV1": "org.spark-project.hive:hive-contrib:0.12.0-protobuf-2.5",
    "coordinatesV2": "org.spark-project.hive:hive-contrib:0.13.1",
    "caller": "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/next(org.apache.hadoop.io.Writable)|",
    "called": "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters/getConverter(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readTypeCode()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readByte(org.apache.hadoop.hive.serde2.io.ByteWritable)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils/getTypeEntryFromTypeName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/writeEndOfRecord()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/write(int,org.apache.hadoop.io.Writable)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/reset()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/name()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/allocateWritable(org.apache.hadoop.hive.contrib.util.typedbytes.Type)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readInt(org.apache.hadoop.io.IntWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readFloat(org.apache.hadoop.io.FloatWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readBoolean(org.apache.hadoop.io.BooleanWritable)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readShort(org.apache.hadoop.hive.serde2.io.ShortWritable)|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/io/BytesWritable/set(byte%5B%5D,int,int)|",
      "|java+method:///java/util/ArrayList/size()|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeSpec)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readDouble(org.apache.hadoop.hive.serde2.io.DoubleWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/ordinal()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getLength()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readText(org.apache.hadoop.io.Text)|",
      "|java+method:///java/util/ArrayList/get(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getData()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readLong(org.apache.hadoop.io.LongWritable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readTypeCode()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readByte(org.apache.hadoop.hive.serde2.io.ByteWritable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/writeEndOfRecord()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/write(int,org.apache.hadoop.io.Writable)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/reset()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/name()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/allocateWritable(org.apache.hadoop.hive.contrib.util.typedbytes.Type)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters/getConverter(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readInt(org.apache.hadoop.io.IntWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readFloat(org.apache.hadoop.io.FloatWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readBoolean(org.apache.hadoop.io.BooleanWritable)|",
      "|java+method:///org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory/getPrimitiveTypeInfo(java.lang.String)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readShort(org.apache.hadoop.hive.serde2.io.ShortWritable)|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/io/BytesWritable/set(byte%5B%5D,int,int)|",
      "|java+method:///java/util/ArrayList/size()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readDouble(org.apache.hadoop.hive.serde2.io.DoubleWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/ordinal()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getLength()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readText(org.apache.hadoop.io.Text)|",
      "|java+method:///java/util/ArrayList/get(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getData()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readLong(org.apache.hadoop.io.LongWritable)|"
    ],
    "affectedLib": "org.spark-project.hive:hive-serde:0.13.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.spark-project.hive:hive-contrib:0.12.0-protobuf-2.5",
    "coordinatesV2": "org.spark-project.hive:hive-contrib:0.13.1",
    "caller": "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/initialize(java.io.InputStream,org.apache.hadoop.conf.Configuration,java.util.Properties)|",
    "called": "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo)|",
    "v1Body": [
      "|java+method:///java/util/Properties/getProperty(java.lang.String)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/util/Arrays/asList(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeSpec)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/TypedBytesWritableOutput(java.io.DataOutput)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils/getTypeEntryFromTypeName(java.lang.String)|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+constructor:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/TypedBytesWritableInput(java.io.DataInput)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo)|",
      "|java+method:///java/util/Properties/getProperty(java.lang.String)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+constructor:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/TypedBytesWritableOutput(java.io.DataOutput)|",
      "|java+method:///java/util/Arrays/asList(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory/getPrimitiveTypeInfo(java.lang.String)|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+constructor:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/TypedBytesWritableInput(java.io.DataInput)|"
    ],
    "affectedLib": "org.spark-project.hive:hive-serde:0.13.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.spark-project.hive:hive-contrib:0.12.0-protobuf-2.5",
    "coordinatesV2": "org.spark-project.hive:hive-contrib:0.13.1",
    "caller": "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/next(org.apache.hadoop.io.Writable)|",
    "called": "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getData()|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters/getConverter(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readTypeCode()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readByte(org.apache.hadoop.hive.serde2.io.ByteWritable)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils/getTypeEntryFromTypeName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/writeEndOfRecord()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/write(int,org.apache.hadoop.io.Writable)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/reset()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/name()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/allocateWritable(org.apache.hadoop.hive.contrib.util.typedbytes.Type)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readInt(org.apache.hadoop.io.IntWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readFloat(org.apache.hadoop.io.FloatWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readBoolean(org.apache.hadoop.io.BooleanWritable)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readShort(org.apache.hadoop.hive.serde2.io.ShortWritable)|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/io/BytesWritable/set(byte%5B%5D,int,int)|",
      "|java+method:///java/util/ArrayList/size()|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeSpec)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readDouble(org.apache.hadoop.hive.serde2.io.DoubleWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/ordinal()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getLength()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readText(org.apache.hadoop.io.Text)|",
      "|java+method:///java/util/ArrayList/get(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getData()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readLong(org.apache.hadoop.io.LongWritable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readTypeCode()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readByte(org.apache.hadoop.hive.serde2.io.ByteWritable)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableOutput/writeEndOfRecord()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/write(int,org.apache.hadoop.io.Writable)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/reset()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/name()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader/allocateWritable(org.apache.hadoop.hive.contrib.util.typedbytes.Type)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters/getConverter(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)|",
      "|java+method:///org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory/getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readInt(org.apache.hadoop.io.IntWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readFloat(org.apache.hadoop.io.FloatWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readBoolean(org.apache.hadoop.io.BooleanWritable)|",
      "|java+method:///org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory/getPrimitiveTypeInfo(java.lang.String)|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readShort(org.apache.hadoop.hive.serde2.io.ShortWritable)|",
      "|java+method:///java/util/ArrayList/add(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/io/BytesWritable/set(byte%5B%5D,int,int)|",
      "|java+method:///java/util/ArrayList/size()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readDouble(org.apache.hadoop.hive.serde2.io.DoubleWritable)|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/Type/ordinal()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getLength()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readText(org.apache.hadoop.io.Text)|",
      "|java+method:///java/util/ArrayList/get(int)|",
      "|java+constructor:///java/lang/AssertionError/AssertionError()|",
      "|java+method:///org/apache/hadoop/hive/ql/io/NonSyncDataOutputBuffer/getData()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesWritableInput/readLong(org.apache.hadoop.io.LongWritable)|"
    ],
    "affectedLib": "org.spark-project.hive:hive-exec:0.13.1",
    "change": "UPDATED"
  }
]