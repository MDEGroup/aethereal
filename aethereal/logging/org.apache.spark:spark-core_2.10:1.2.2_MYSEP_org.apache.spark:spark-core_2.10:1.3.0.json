[
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///org/eclipse/jetty/security/HashLoginService/HashLoginService()|",
    "v1Body": [
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setDataConstraint(int)|",
      "|java+constructor:///org/eclipse/jetty/security/ConstraintSecurityHandler/ConstraintSecurityHandler()|",
      "|java+constructor:///org/eclipse/jetty/security/HashLoginService/HashLoginService()|",
      "|java+constructor:///org/eclipse/jetty/security/authentication/DigestAuthenticator/DigestAuthenticator()|",
      "|java+constructor:///org/eclipse/jetty/util/security/Password/Password(java.lang.String)|",
      "|java+constructor:///org/eclipse/jetty/security/ConstraintMapping/ConstraintMapping()|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setConstraintMappings(org.eclipse.jetty.security.ConstraintMapping%5B%5D)|",
      "|java+constructor:///org/eclipse/jetty/util/security/Constraint/Constraint()|",
      "|java+method:///org/eclipse/jetty/security/ConstraintMapping/setPathSpec(java.lang.String)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintMapping/setConstraint(org.eclipse.jetty.util.security.Constraint)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setLoginService(org.eclipse.jetty.security.LoginService)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setAuthenticator(org.eclipse.jetty.security.Authenticator)|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setName(java.lang.String)|",
      "|java+method:///org/eclipse/jetty/security/HashLoginService/putUser(java.lang.String,org.eclipse.jetty.util.security.Credential,java.lang.String%5B%5D)|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setRoles(java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/getHttpUser()|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setAuthenticate(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setDataConstraint(int)|",
      "|java+constructor:///org/spark-project/jetty/security/HashLoginService/HashLoginService()|",
      "|java+constructor:///org/spark-project/jetty/security/ConstraintMapping/ConstraintMapping()|",
      "|java+constructor:///org/spark-project/jetty/security/authentication/DigestAuthenticator/DigestAuthenticator()|",
      "|java+constructor:///org/spark-project/jetty/util/security/Password/Password(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setConstraintMappings(org.spark-project.jetty.security.ConstraintMapping%5B%5D)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintMapping/setPathSpec(java.lang.String)|",
      "|java+constructor:///org/spark-project/jetty/util/security/Constraint/Constraint()|",
      "|java+method:///org/spark-project/jetty/security/ConstraintMapping/setConstraint(org.spark-project.jetty.util.security.Constraint)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setLoginService(org.spark-project.jetty.security.LoginService)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setName(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setAuthenticator(org.spark-project.jetty.security.Authenticator)|",
      "|java+method:///org/spark-project/jetty/security/HashLoginService/putUser(java.lang.String,org.spark-project.jetty.util.security.Credential,java.lang.String%5B%5D)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setAuthenticate(boolean)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setRoles(java.lang.String%5B%5D)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/getHttpUser()|",
      "|java+constructor:///org/spark-project/jetty/security/ConstraintSecurityHandler/ConstraintSecurityHandler()|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-security:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink/GraphiteSink(java.util.Properties,com.codahale.metrics.MetricRegistry,org.apache.spark.SecurityManager)|",
    "called": "|java+method:///com/codahale/metrics/graphite/GraphiteReporter/forRegistry(com.codahale.metrics.MetricRegistry)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertDurationsTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_UNIT()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/host()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/graphite()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PREFIX()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/checkMinimalPollingPeriod(java.util.concurrent.TimeUnit,int)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_PERIOD()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/propertyToOption(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollPeriod()|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/port()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PORT()|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$1/GraphiteSink$$anonfun$1(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PERIOD()|",
      "|java+method:///java/lang/String/toUpperCase()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollUnit()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/prefixedWith(java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertRatesTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_HOST()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/build(com.codahale.metrics.graphite.Graphite)|",
      "|java+constructor:///com/codahale/metrics/graphite/Graphite/Graphite(java.net.InetSocketAddress)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/prefix()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///java/util/concurrent/TimeUnit/valueOf(java.lang.String)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter/forRegistry(com.codahale.metrics.MetricRegistry)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertDurationsTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/host()|",
      "|java+constructor:///com/codahale/metrics/graphite/Graphite/Graphite(java.net.InetSocketAddress)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PREFIX()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/build(com.codahale.metrics.graphite.GraphiteSender)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_PERIOD()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/propertyToOption(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollPeriod()|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/port()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PORT()|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$1/GraphiteSink$$anonfun$1(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PERIOD()|",
      "|java+method:///java/lang/String/toUpperCase()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollUnit()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/prefixedWith(java.lang.String)|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$2/GraphiteSink$$anonfun$2(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertRatesTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_HOST()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/graphite()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/prefix()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///java/util/concurrent/TimeUnit/valueOf(java.lang.String)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter/forRegistry(com.codahale.metrics.MetricRegistry)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/checkMinimalPollingPeriod(java.util.concurrent.TimeUnit,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PROTOCOL()|",
      "|java+constructor:///com/codahale/metrics/graphite/GraphiteUDP/GraphiteUDP(java.net.InetSocketAddress)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "com.codahale.metrics:metrics-graphite:3.0.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/HttpServer/org$apache$spark$HttpServer$$doStart(int)|",
    "called": "|java+constructor:///org/eclipse/jetty/server/handler/ResourceHandler/ResourceHandler()|",
    "v1Body": [
      "|java+method:///org/eclipse/jetty/server/Server/setThreadPool(org.eclipse.jetty.util.thread.ThreadPool)|",
      "|java+constructor:///org/eclipse/jetty/server/handler/DefaultHandler/DefaultHandler()|",
      "|java+method:///org/eclipse/jetty/server/Server/setHandler(org.eclipse.jetty.server.Handler)|",
      "|java+method:///org/eclipse/jetty/server/Server/addConnector(org.eclipse.jetty.server.Connector)|",
      "|java+constructor:///org/eclipse/jetty/server/Server/Server()|",
      "|java+constructor:///org/eclipse/jetty/server/bio/SocketConnector/SocketConnector()|",
      "|java+method:///org/eclipse/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+method:///org/eclipse/jetty/server/Connector/getLocalPort()|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setPort(int)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/eclipse/jetty/server/handler/HandlerList/setHandlers(org.eclipse.jetty.server.Handler%5B%5D)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setHandler(org.eclipse.jetty.server.Handler)|",
      "|java+method:///org/apache/spark/HttpServer/logDebug(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setSoLingerTime(int)|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setMaxIdleTime(int)|",
      "|java+method:///org/eclipse/jetty/server/Server/getConnectors()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/eclipse/jetty/server/handler/HandlerList/HandlerList()|",
      "|java+method:///org/eclipse/jetty/server/handler/ResourceHandler/setResourceBase(java.lang.String)|",
      "|java+constructor:///org/eclipse/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1(org.apache.spark.HttpServer)|",
      "|java+method:///org/eclipse/jetty/server/Server/start()|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2(org.apache.spark.HttpServer)|",
      "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/eclipse/jetty/server/handler/ResourceHandler/ResourceHandler()|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setPort(int)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/DefaultHandler/DefaultHandler()|",
      "|java+method:///org/spark-project/jetty/server/Server/setThreadPool(org.spark-project.jetty.util.thread.ThreadPool)|",
      "|java+method:///org/spark-project/jetty/server/Server/addConnector(org.spark-project.jetty.server.Connector)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$3/HttpServer$$anonfun$3(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$2/HttpServer$$anonfun$2(org.apache.spark.HttpServer)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/HttpServer/logDebug(scala.Function0)|",
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setMaxIdleTime(int)|",
      "|java+method:///org/spark-project/jetty/server/Server/getConnectors()|",
      "|java+method:///org/apache/spark/SecurityManager/fileServerSSLOptions()|",
      "|java+constructor:///org/spark-project/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+method:///org/spark-project/jetty/server/Server/start()|",
      "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
      "|java+method:///org/spark-project/jetty/server/Connector/getLocalPort()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/spark-project/jetty/server/Server/Server()|",
      "|java+method:///org/spark-project/jetty/server/Server/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///org/spark-project/jetty/server/handler/HandlerList/setHandlers(org.spark-project.jetty.server.Handler%5B%5D)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/HandlerList/HandlerList()|",
      "|java+method:///org/apache/spark/SSLOptions/createJettySslContextFactory()|",
      "|java+method:///org/spark-project/jetty/server/handler/ResourceHandler/setResourceBase(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setSoLingerTime(int)|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/ResourceHandler/ResourceHandler()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-server:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/ui/JettyUtils$/startJettyServer(java.lang.String,int,scala.collection.Seq,org.apache.spark.SparkConf,java.lang.String)|",
    "called": "|java+constructor:///org/eclipse/jetty/server/handler/ContextHandlerCollection/ContextHandlerCollection()|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/Utils$/startServiceOnPort(int,scala.Function1,org.apache.spark.SparkConf,java.lang.String)|",
      "|java+constructor:///org/eclipse/jetty/server/handler/ContextHandlerCollection/ContextHandlerCollection()|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/addFilters(scala.collection.Seq,org.apache.spark.SparkConf)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/eclipse/jetty/server/handler/ContextHandlerCollection/setHandlers(org.eclipse.jetty.server.Handler%5B%5D)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/ui/ServerInfo/ServerInfo(org.eclipse.jetty.server.Server,int,org.eclipse.jetty.server.handler.ContextHandlerCollection)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+constructor:///org/apache/spark/ui/JettyUtils$$anonfun$2/JettyUtils$$anonfun$2(java.lang.String,org.eclipse.jetty.server.handler.ContextHandlerCollection)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/ui/ServerInfo/ServerInfo(org.spark-project.jetty.server.Server,int,org.spark-project.jetty.server.handler.ContextHandlerCollection)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/addFilters(scala.collection.Seq,org.apache.spark.SparkConf)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/JettyUtils$$anonfun$2/JettyUtils$$anonfun$2(java.lang.String,org.spark-project.jetty.server.handler.ContextHandlerCollection)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/spark-project/jetty/server/handler/ContextHandlerCollection/setHandlers(org.spark-project.jetty.server.Handler%5B%5D)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/ContextHandlerCollection/ContextHandlerCollection()|",
      "|java+method:///org/apache/spark/util/Utils$/startServiceOnPort(int,scala.Function1,org.apache.spark.SparkConf,java.lang.String)|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-server:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/HttpServer/org$apache$spark$HttpServer$$doStart(int)|",
    "called": "|java+constructor:///org/eclipse/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
    "v1Body": [
      "|java+method:///org/eclipse/jetty/server/Server/setThreadPool(org.eclipse.jetty.util.thread.ThreadPool)|",
      "|java+constructor:///org/eclipse/jetty/server/handler/DefaultHandler/DefaultHandler()|",
      "|java+method:///org/eclipse/jetty/server/Server/setHandler(org.eclipse.jetty.server.Handler)|",
      "|java+method:///org/eclipse/jetty/server/Server/addConnector(org.eclipse.jetty.server.Connector)|",
      "|java+constructor:///org/eclipse/jetty/server/Server/Server()|",
      "|java+constructor:///org/eclipse/jetty/server/bio/SocketConnector/SocketConnector()|",
      "|java+method:///org/eclipse/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+method:///org/eclipse/jetty/server/Connector/getLocalPort()|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setPort(int)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/eclipse/jetty/server/handler/HandlerList/setHandlers(org.eclipse.jetty.server.Handler%5B%5D)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setHandler(org.eclipse.jetty.server.Handler)|",
      "|java+method:///org/apache/spark/HttpServer/logDebug(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setSoLingerTime(int)|",
      "|java+method:///org/eclipse/jetty/server/bio/SocketConnector/setMaxIdleTime(int)|",
      "|java+method:///org/eclipse/jetty/server/Server/getConnectors()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/eclipse/jetty/server/handler/HandlerList/HandlerList()|",
      "|java+method:///org/eclipse/jetty/server/handler/ResourceHandler/setResourceBase(java.lang.String)|",
      "|java+constructor:///org/eclipse/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1(org.apache.spark.HttpServer)|",
      "|java+method:///org/eclipse/jetty/server/Server/start()|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2(org.apache.spark.HttpServer)|",
      "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/eclipse/jetty/server/handler/ResourceHandler/ResourceHandler()|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setPort(int)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/DefaultHandler/DefaultHandler()|",
      "|java+method:///org/spark-project/jetty/server/Server/setThreadPool(org.spark-project.jetty.util.thread.ThreadPool)|",
      "|java+method:///org/spark-project/jetty/server/Server/addConnector(org.spark-project.jetty.server.Connector)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$3/HttpServer$$anonfun$3(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$2/HttpServer$$anonfun$2(org.apache.spark.HttpServer)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/HttpServer/logDebug(scala.Function0)|",
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setMaxIdleTime(int)|",
      "|java+method:///org/spark-project/jetty/server/Server/getConnectors()|",
      "|java+method:///org/apache/spark/SecurityManager/fileServerSSLOptions()|",
      "|java+constructor:///org/spark-project/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+method:///org/spark-project/jetty/server/Server/start()|",
      "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
      "|java+method:///org/spark-project/jetty/server/Connector/getLocalPort()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/spark-project/jetty/server/Server/Server()|",
      "|java+method:///org/spark-project/jetty/server/Server/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///org/spark-project/jetty/server/handler/HandlerList/setHandlers(org.spark-project.jetty.server.Handler%5B%5D)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/HandlerList/HandlerList()|",
      "|java+method:///org/apache/spark/SSLOptions/createJettySslContextFactory()|",
      "|java+method:///org/spark-project/jetty/server/handler/ResourceHandler/setResourceBase(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/spark-project/jetty/server/bio/SocketConnector/setSoLingerTime(int)|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$1(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/apache/spark/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2/HttpServer$$anonfun$org$apache$spark$HttpServer$$doStart$2(org.apache.spark.HttpServer)|",
      "|java+constructor:///org/spark-project/jetty/server/handler/ResourceHandler/ResourceHandler()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-util:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/util/Utils$/isBindCollision(java.lang.Throwable)|",
    "called": "|java+method:///org/eclipse/jetty/util/MultiException/getThrowables()|",
    "v1Body": [
      "|java+method:///java/net/BindException/getMessage()|",
      "|java+method:///java/net/BindException/getCause()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$isBindCollision$1/Utils$$anonfun$isBindCollision$1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/eclipse/jetty/util/MultiException/getThrowables()|",
      "|java+method:///java/lang/Exception/getCause()|",
      "|java+method:///scala/collection/mutable/Buffer/exists(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///java/net/BindException/getMessage()|",
      "|java+method:///java/net/BindException/getCause()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$isBindCollision$1/Utils$$anonfun$isBindCollision$1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/spark-project/jetty/util/MultiException/getThrowables()|",
      "|java+method:///java/lang/Exception/getCause()|",
      "|java+method:///scala/collection/mutable/Buffer/exists(scala.Function1)|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-util:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.2.2",
    "caller": "|java+method:///org/apache/spark/HttpServer/setupSecurityHandler(org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///org/eclipse/jetty/util/security/Constraint/Constraint()|",
    "v1Body": [
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setDataConstraint(int)|",
      "|java+constructor:///org/eclipse/jetty/security/ConstraintSecurityHandler/ConstraintSecurityHandler()|",
      "|java+constructor:///org/eclipse/jetty/security/HashLoginService/HashLoginService()|",
      "|java+constructor:///org/eclipse/jetty/security/authentication/DigestAuthenticator/DigestAuthenticator()|",
      "|java+constructor:///org/eclipse/jetty/util/security/Password/Password(java.lang.String)|",
      "|java+constructor:///org/eclipse/jetty/security/ConstraintMapping/ConstraintMapping()|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setConstraintMappings(org.eclipse.jetty.security.ConstraintMapping%5B%5D)|",
      "|java+constructor:///org/eclipse/jetty/util/security/Constraint/Constraint()|",
      "|java+method:///org/eclipse/jetty/security/ConstraintMapping/setPathSpec(java.lang.String)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintMapping/setConstraint(org.eclipse.jetty.util.security.Constraint)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setLoginService(org.eclipse.jetty.security.LoginService)|",
      "|java+method:///org/eclipse/jetty/security/ConstraintSecurityHandler/setAuthenticator(org.eclipse.jetty.security.Authenticator)|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setName(java.lang.String)|",
      "|java+method:///org/eclipse/jetty/security/HashLoginService/putUser(java.lang.String,org.eclipse.jetty.util.security.Credential,java.lang.String%5B%5D)|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setRoles(java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/getHttpUser()|",
      "|java+method:///org/eclipse/jetty/util/security/Constraint/setAuthenticate(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setDataConstraint(int)|",
      "|java+constructor:///org/spark-project/jetty/security/HashLoginService/HashLoginService()|",
      "|java+constructor:///org/spark-project/jetty/security/ConstraintMapping/ConstraintMapping()|",
      "|java+constructor:///org/spark-project/jetty/security/authentication/DigestAuthenticator/DigestAuthenticator()|",
      "|java+constructor:///org/spark-project/jetty/util/security/Password/Password(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setConstraintMappings(org.spark-project.jetty.security.ConstraintMapping%5B%5D)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintMapping/setPathSpec(java.lang.String)|",
      "|java+constructor:///org/spark-project/jetty/util/security/Constraint/Constraint()|",
      "|java+method:///org/spark-project/jetty/security/ConstraintMapping/setConstraint(org.spark-project.jetty.util.security.Constraint)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setLoginService(org.spark-project.jetty.security.LoginService)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setName(java.lang.String)|",
      "|java+method:///org/spark-project/jetty/security/ConstraintSecurityHandler/setAuthenticator(org.spark-project.jetty.security.Authenticator)|",
      "|java+method:///org/spark-project/jetty/security/HashLoginService/putUser(java.lang.String,org.spark-project.jetty.util.security.Credential,java.lang.String%5B%5D)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setAuthenticate(boolean)|",
      "|java+method:///org/spark-project/jetty/util/security/Constraint/setRoles(java.lang.String%5B%5D)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/getHttpUser()|",
      "|java+constructor:///org/spark-project/jetty/security/ConstraintSecurityHandler/ConstraintSecurityHandler()|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|"
    ],
    "affectedLib": "org.eclipse.jetty:jetty-util:8.1.14.v20131031",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink/GraphiteSink(java.util.Properties,com.codahale.metrics.MetricRegistry,org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///com/codahale/metrics/graphite/GraphiteUDP/GraphiteUDP(java.net.InetSocketAddress)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertDurationsTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_UNIT()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/host()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/graphite()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PREFIX()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/checkMinimalPollingPeriod(java.util.concurrent.TimeUnit,int)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_PERIOD()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/propertyToOption(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollPeriod()|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/port()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PORT()|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$1/GraphiteSink$$anonfun$1(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PERIOD()|",
      "|java+method:///java/lang/String/toUpperCase()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollUnit()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/prefixedWith(java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertRatesTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_HOST()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/build(com.codahale.metrics.graphite.Graphite)|",
      "|java+constructor:///com/codahale/metrics/graphite/Graphite/Graphite(java.net.InetSocketAddress)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/prefix()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///java/util/concurrent/TimeUnit/valueOf(java.lang.String)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter/forRegistry(com.codahale.metrics.MetricRegistry)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertDurationsTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/host()|",
      "|java+constructor:///com/codahale/metrics/graphite/Graphite/Graphite(java.net.InetSocketAddress)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PREFIX()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/build(com.codahale.metrics.graphite.GraphiteSender)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_PERIOD()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/propertyToOption(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollPeriod()|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/port()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PORT()|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$1/GraphiteSink$$anonfun$1(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PERIOD()|",
      "|java+method:///java/lang/String/toUpperCase()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_DEFAULT_UNIT()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/pollUnit()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/prefixedWith(java.lang.String)|",
      "|java+constructor:///org/apache/spark/metrics/sink/GraphiteSink$$anonfun$2/GraphiteSink$$anonfun$2(org.apache.spark.metrics.sink.GraphiteSink)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter$Builder/convertRatesTo(java.util.concurrent.TimeUnit)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_HOST()|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/graphite()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/prefix()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///java/util/concurrent/TimeUnit/valueOf(java.lang.String)|",
      "|java+method:///com/codahale/metrics/graphite/GraphiteReporter/forRegistry(com.codahale.metrics.MetricRegistry)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/checkMinimalPollingPeriod(java.util.concurrent.TimeUnit,int)|",
      "|java+method:///org/apache/spark/metrics/sink/GraphiteSink/GRAPHITE_KEY_PROTOCOL()|",
      "|java+constructor:///com/codahale/metrics/graphite/GraphiteUDP/GraphiteUDP(java.net.InetSocketAddress)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "io.dropwizard.metrics:metrics-graphite:3.1.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+constructor:///org/apache/spark/util/collection/Utils$$anon$1/Utils$$anon$1(scala.math.Ordering)|",
    "called": "|java+constructor:///org/spark-project/guava/collect/Ordering/Ordering()|",
    "v1Body": [
      "|java+constructor:///com/google/common/collect/Ordering/Ordering()|"
    ],
    "v2Body": [
      "|java+constructor:///org/spark-project/guava/collect/Ordering/Ordering()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/storage/TachyonStore/getBytes(org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
    "v1Body": [
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/InStream/close()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonStore$$anonfun$getBytes$1/TachyonStore$$anonfun$getBytes$1(org.apache.spark.storage.TachyonStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///com/google/common/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///tachyon/client/TachyonFile/getLocationHosts()|",
      "|java+method:///tachyon/client/InStream/close()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///tachyon/client/TachyonFile/length()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/storage/TachyonStore$$anonfun$getBytes$1/TachyonStore$$anonfun$getBytes$1(org.apache.spark.storage.TachyonStore,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///tachyon/client/TachyonFile/getInStream(tachyon.client.ReadType)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/fetchAndRunExecutor()|",
    "called": "|java+method:///org/spark-project/guava/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$1/ExecutorRunner$$anonfun$1(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$3/ExecutorRunner$$anonfun$fetchAndRunExecutor$3(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///org/apache/spark/util/logging/FileAppender$/apply(java.io.InputStream,java.io.File,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stderrAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/executorDir()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/ProcessBuilder/directory(java.io.File)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$killProcess(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$5()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stdoutAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/EXITED()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/KILLED()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logInfo(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appLocalDirs()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process_$eq(java.lang.Process)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$2/ExecutorRunner$$anonfun$fetchAndRunExecutor$2(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/worker()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appDesc()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/conf()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang$default$2(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appId()|",
      "|java+method:///com/google/common/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/sparkHome()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$1/ExecutorRunner$$anonfun$fetchAndRunExecutor$1(org.apache.spark.deploy.worker.ExecutorRunner,java.util.List)|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$1/ExecutorRunner$$anonfun$1(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$3/ExecutorRunner$$anonfun$fetchAndRunExecutor$3(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/publicAddress()|",
      "|java+method:///org/apache/spark/util/logging/FileAppender$/apply(java.io.InputStream,java.io.File,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stderrAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/executorDir()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/ProcessBuilder/directory(java.io.File)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$killProcess(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$5()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/stdoutAppender_$eq(org.apache.spark.util.logging.FileAppender)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/EXITED()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/KILLED()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/write(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logInfo(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appLocalDirs()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/webUiPort()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process_$eq(java.lang.Process)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$2/ExecutorRunner$$anonfun$fetchAndRunExecutor$2(org.apache.spark.deploy.worker.ExecutorRunner)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/process()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/worker()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appDesc()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/conf()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang$default$2(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/appId()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/sparkHome()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anonfun$fetchAndRunExecutor$1/ExecutorRunner$$anonfun$fetchAndRunExecutor$1(org.apache.spark.deploy.worker.ExecutorRunner,java.util.List)|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/skipFully(java.io.InputStream,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getDataFile(int,int)|",
      "|java+method:///java/io/DataInputStream/close()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/shuffleId()|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/mapId()|",
      "|java+constructor:///org/apache/spark/network/buffer/FileSegmentManagedBuffer/FileSegmentManagedBuffer(org.apache.spark.network.util.TransportConf,java.io.File,long,long)|",
      "|java+method:///java/io/DataInputStream/readLong()|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getIndexFile(int,int)|",
      "|java+method:///com/google/common/io/ByteStreams/skipFully(java.io.InputStream,long)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/transportConf()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/reduceId()|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/guava/io/ByteStreams/skipFully(java.io.InputStream,long)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getDataFile(int,int)|",
      "|java+method:///java/io/DataInputStream/close()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/shuffleId()|",
      "|java+constructor:///java/io/DataInputStream/DataInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/mapId()|",
      "|java+constructor:///org/apache/spark/network/buffer/FileSegmentManagedBuffer/FileSegmentManagedBuffer(org.apache.spark.network.util.TransportConf,java.io.File,long,long)|",
      "|java+method:///java/io/DataInputStream/readLong()|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getIndexFile(int,int)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/transportConf()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockId/reduceId()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/nextBatchStream()|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/limit(java.io.InputStream,long)|",
    "v1Body": [
      "|java+method:///java/nio/channels/FileChannel/position(long)|",
      "|java+method:///com/google/common/io/ByteStreams/limit(java.io.InputStream,long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/batchIndex_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/org$apache$spark$util$collection$ExternalAppendOnlyMap$DiskMapIterator$$$outer()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/apply(int)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$ser()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/fileStream_$eq(java.io.FileInputStream)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///java/io/FileInputStream/getChannel()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/length()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/deserializeStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/cleanup()|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator$$anonfun$nextBatchStream$1/ExternalAppendOnlyMap$DiskMapIterator$$anonfun$nextBatchStream$1(org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator,long,long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/batchIndex()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/org$apache$spark$util$collection$ExternalAppendOnlyMap$DiskMapIterator$$batchOffsets()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/fileStream()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|"
    ],
    "v2Body": [
      "|java+method:///java/nio/channels/FileChannel/position(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/batchIndex_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/org$apache$spark$util$collection$ExternalAppendOnlyMap$DiskMapIterator$$$outer()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/limit(java.io.InputStream,long)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/apply(int)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$ser()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/fileStream_$eq(java.io.FileInputStream)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///java/io/FileInputStream/getChannel()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/length()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/deserializeStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/cleanup()|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator$$anonfun$nextBatchStream$1/ExternalAppendOnlyMap$DiskMapIterator$$anonfun$nextBatchStream$1(org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator,long,long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/batchIndex()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/org$apache$spark$util$collection$ExternalAppendOnlyMap$DiskMapIterator$$batchOffsets()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/fileStream()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+constructor:///org/apache/spark/util/Utils$/Utils$()|",
    "called": "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
    "v1Body": [
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Runtime/getRuntime()|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///java/lang/Runtime/addShutdownHook(java.lang.Thread)|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anon$4/Utils$$anon$4()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|"
    ],
    "v2Body": [
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Runtime/getRuntime()|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///java/lang/Runtime/addShutdownHook(java.lang.Thread)|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anon$4/Utils$$anon$4()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$initialize$1(java.lang.Process,java.lang.ProcessBuilder,java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///com/google/common/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/redirectStream(java.io.InputStream,java.io.File)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/redirectStream(java.io.InputStream,java.io.File)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/spark-project/guava/io/Files/append(java.lang.CharSequence,java.io.File,java.nio.charset.Charset)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///scala/collection/mutable/Buffer/mkString(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/ProcessBuilder/command()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/Utils$/offsetBytes(java.lang.String,long,long)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/skipFully(java.io.InputStream,long)|",
    "v1Body": [
      "|java+method:///scala/io/Codec$/fallbackSystemCodec()|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///com/google/common/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+method:///com/google/common/io/ByteStreams/skipFully(java.io.InputStream,long)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///scala/io/Source/mkString()|",
      "|java+method:///scala/math/package$/min(long,long)|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///scala/io/Source$/fromBytes(byte%5B%5D,scala.io.Codec)|"
    ],
    "v2Body": [
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/readFully(java.io.InputStream,byte%5B%5D)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///scala/io/Source/mkString()|",
      "|java+method:///scala/math/package$/min(long,long)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/skipFully(java.io.InputStream,long)|",
      "|java+method:///scala/io/Codec$/fallbackSystemCodec()|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///scala/io/Source$/fromBytes(byte%5B%5D,scala.io.Codec)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/logging/RollingFileAppender/moveFile()|",
    "called": "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
    "v1Body": [
      "|java+method:///java/io/File/getParent()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/io/File/getAbsoluteFile()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logDebug(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/io/File/getParentFile()|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logInfo(scala.Function0)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logWarning(scala.Function0)|",
      "|java+method:///com/google/common/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$3/RollingFileAppender$$anonfun$moveFile$3(org.apache.spark.util.logging.RollingFileAppender,java.io.File,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$1/RollingFileAppender$$anonfun$moveFile$1(org.apache.spark.util.logging.RollingFileAppender,java.io.File)|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$4/RollingFileAppender$$anonfun$moveFile$4(org.apache.spark.util.logging.RollingFileAppender)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$2/RollingFileAppender$$anonfun$moveFile$2(org.apache.spark.util.logging.RollingFileAppender,java.io.File)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/rollingPolicy()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/logging/RollingPolicy/generateRolledOverFileSuffix()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/io/File/getParent()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logWarning(scala.Function0)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/io/File/getAbsoluteFile()|",
      "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logDebug(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/io/File/getParentFile()|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/logInfo(scala.Function0)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$3/RollingFileAppender$$anonfun$moveFile$3(org.apache.spark.util.logging.RollingFileAppender,java.io.File,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$1/RollingFileAppender$$anonfun$moveFile$1(org.apache.spark.util.logging.RollingFileAppender,java.io.File)|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$4/RollingFileAppender$$anonfun$moveFile$4(org.apache.spark.util.logging.RollingFileAppender)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/logging/RollingFileAppender$$anonfun$moveFile$2/RollingFileAppender$$anonfun$moveFile$2(org.apache.spark.util.logging.RollingFileAppender,java.io.File)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender/rollingPolicy()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/logging/RollingPolicy/generateRolledOverFileSuffix()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/HttpFileServer/addFileToDir(java.io.File,java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/copy(java.io.File,java.io.File)|",
    "v1Body": [
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/copy(java.io.File,java.io.File)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///scala/runtime/StringAdd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/io/File/getName()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+method:///org/spark-project/guava/io/Files/copy(java.io.File,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+method:///scala/runtime/StringAdd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/Utils$/copyFile(java.lang.String,java.io.File,java.io.File,boolean,boolean)|",
    "called": "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+method:///com/google/common/io/Files/copy(java.io.File,java.io.File)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$1/Utils$$anonfun$copyFile$1(java.lang.String,java.io.File)|",
      "|java+method:///com/google/common/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///com/google/common/io/Files/equal(java.io.File,java.io.File)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$2/Utils$$anonfun$copyFile$2(java.io.File,java.io.File)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$3/Utils$$anonfun$copyFile$3(java.io.File,java.io.File)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/File/delete()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$1/Utils$$anonfun$copyFile$1(java.lang.String,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/org$apache$spark$util$Utils$$copyRecursive(java.io.File,java.io.File)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$2/Utils$$anonfun$copyFile$2(java.io.File,java.io.File)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyFile$3/Utils$$anonfun$copyFile$3(java.io.File,java.io.File)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/org$apache$spark$util$Utils$$filesEqualRecursive(java.io.File,java.io.File)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/File/delete()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/input/WholeTextFileRecordReader/nextKeyValue()|",
    "called": "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
    "v1Body": [
      "|java+method:///com/google/common/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodecFactory/getCodec(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/io/Text/toString()|",
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodec/createInputStream(java.io.InputStream)|",
      "|java+constructor:///org/apache/hadoop/io/compress/CompressionCodecFactory/CompressionCodecFactory(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|",
      "|java+method:///com/google/common/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodecFactory/getCodec(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/io/compress/CompressionCodec/createInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/spark-project/guava/io/Closeables/close(java.io.Closeable,boolean)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+constructor:///org/apache/hadoop/io/compress/CompressionCodecFactory/CompressionCodecFactory(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/io/Text/Text(byte%5B%5D)|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/hadoop/io/Text/toString()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$3/HistoryServer$$anon$3(org.apache.spark.deploy.history.HistoryServer)|",
    "called": "|java+constructor:///org/spark-project/guava/cache/CacheLoader/CacheLoader()|",
    "v1Body": [
      "|java+constructor:///com/google/common/cache/CacheLoader/CacheLoader()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///org/spark-project/guava/cache/CacheLoader/CacheLoader()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/collection/Utils$/takeOrdered(scala.collection.Iterator,int,scala.math.Ordering)|",
    "called": "|java+method:///org/spark-project/guava/collect/Ordering/leastOf(java.util.Iterator,int)|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Ordering/leastOf(java.util.Iterator,int)|",
      "|java+method:///scala/collection/JavaConversions$/asJavaIterator(scala.collection.Iterator)|",
      "|java+method:///scala/collection/Iterable/iterator()|",
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+constructor:///org/apache/spark/util/collection/Utils$$anon$1/Utils$$anon$1(scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/guava/collect/Ordering/leastOf(java.util.Iterator,int)|",
      "|java+method:///scala/collection/JavaConversions$/asJavaIterator(scala.collection.Iterator)|",
      "|java+method:///scala/collection/Iterable/iterator()|",
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+constructor:///org/apache/spark/util/collection/Utils$$anon$1/Utils$$anon$1(scala.math.Ordering)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/TestUtils$$anonfun$createJar$1/apply(java.io.File)|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
    "v1Body": [
      "|java+method:///java/io/File/getName()|",
      "|java+method:///com/google/common/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
      "|java+method:///java/util/jar/JarOutputStream/putNextEntry(java.util.zip.ZipEntry)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+constructor:///java/util/jar/JarEntry/JarEntry(java.lang.String)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/guava/io/ByteStreams/copy(java.io.InputStream,java.io.OutputStream)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///java/util/jar/JarOutputStream/putNextEntry(java.util.zip.ZipEntry)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+constructor:///java/util/jar/JarEntry/JarEntry(java.lang.String)|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryServer/HistoryServer(org.apache.spark.SparkConf,org.apache.spark.deploy.history.ApplicationHistoryProvider,org.apache.spark.SecurityManager,int)|",
    "called": "|java+method:///org/spark-project/guava/cache/CacheBuilder/build(org.spark-project.guava.cache.CacheLoader)|",
    "v1Body": [
      "|java+method:///com/google/common/cache/CacheBuilder/removalListener(com.google.common.cache.RemovalListener)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///com/google/common/cache/CacheBuilder/newBuilder()|",
      "|java+constructor:///org/apache/spark/ui/WebUI/WebUI(org.apache.spark.SecurityManager,int,org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$5()|",
      "|java+method:///com/google/common/cache/CacheBuilder/maximumSize(long)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/retainedApplications()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$4/HistoryServer$$anon$4(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$3/HistoryServer$$anon$3(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1/HistoryServer$$anon$1(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///com/google/common/cache/CacheBuilder/build(com.google.common.cache.CacheLoader)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/initialize()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/appLoader()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/ui/WebUI/WebUI(org.apache.spark.SecurityManager,int,org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$5()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/retainedApplications()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$3/HistoryServer$$anon$3(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/build(org.spark-project.guava.cache.CacheLoader)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$4/HistoryServer$$anon$4(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/maximumSize(long)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/initialize()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/appLoader()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1/HistoryServer$$anon$1(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/removalListener(org.spark-project.guava.cache.RemovalListener)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/newBuilder()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/input/PortableDataStream/toArray()|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
    "v1Body": [
      "|java+method:///org/apache/spark/input/PortableDataStream/open()|",
      "|java+method:///org/apache/spark/input/PortableDataStream/close()|",
      "|java+method:///org/apache/spark/input/PortableDataStream/fileIn()|",
      "|java+method:///com/google/common/io/ByteStreams/toByteArray(java.io.InputStream)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/input/PortableDataStream/open()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/toByteArray(java.io.InputStream)|",
      "|java+method:///org/apache/spark/input/PortableDataStream/close()|",
      "|java+method:///org/apache/spark/input/PortableDataStream/fileIn()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/nextBatchStream()|",
    "called": "|java+method:///org/spark-project/guava/io/ByteStreams/limit(java.io.InputStream,long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpilledFile/file()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///com/google/common/io/ByteStreams/limit(java.io.InputStream,long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/fileStream_$eq(java.io.FileInputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchId()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/org$apache$spark$util$collection$ExternalSorter$SpillReader$$$outer()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpilledFile/blockId()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchOffsets()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///java/io/FileInputStream/getChannel()|",
      "|java+method:///java/nio/channels/FileChannel/position(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchId_$eq(int)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/fileStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/cleanup()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$SpillReader$$anonfun$nextBatchStream$1/ExternalSorter$SpillReader$$anonfun$nextBatchStream$1(org.apache.spark.util.collection.ExternalSorter$SpillReader,long,long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpilledFile/file()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/fileStream_$eq(java.io.FileInputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchId()|",
      "|java+method:///org/spark-project/guava/io/ByteStreams/limit(java.io.InputStream,long)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/org$apache$spark$util$collection$ExternalSorter$SpillReader$$$outer()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpilledFile/blockId()|",
      "|java+constructor:///java/io/FileInputStream/FileInputStream(java.io.File)|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchOffsets()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/wrapForCompression(org.apache.spark.storage.BlockId,java.io.InputStream)|",
      "|java+method:///java/io/FileInputStream/getChannel()|",
      "|java+method:///java/nio/channels/FileChannel/position(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/batchId_$eq(int)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/fileStream()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/cleanup()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$SpillReader$$anonfun$nextBatchStream$1/ExternalSorter$SpillReader$$anonfun$nextBatchStream$1(org.apache.spark.util.collection.ExternalSorter$SpillReader,long,long)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/util/Utils$/namedThreadFactory(java.lang.String)|",
    "called": "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/build()|",
    "v1Body": [
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/daemonThreadFactoryBuilder()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/daemonThreadFactoryBuilder()|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.3.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/executor/MesosExecutorBackend/launchTask(org.apache.mesos.ExecutorDriver,org.apache.mesos.Protos$TaskInfo)|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/runAsSparkUser(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getTaskId()|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$launchTask$2/MesosExecutorBackend$$anonfun$launchTask$2(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$launchTask$1/MesosExecutorBackend$$anonfun$launchTask$1(org.apache.spark.executor.MesosExecutorBackend,org.apache.mesos.Protos$TaskInfo,long)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/runAsSparkUser(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getTaskId()|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$launchTask$2/MesosExecutorBackend$$anonfun$launchTask$2(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getData()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosTaskLaunchData$/fromByteString(org.apache.mesos.protobuf.ByteString)|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$launchTask$1/MesosExecutorBackend$$anonfun$launchTask$1(org.apache.spark.executor.MesosExecutorBackend,org.apache.mesos.Protos$TaskInfo,long,org.apache.spark.scheduler.cluster.mesos.MesosTaskLaunchData)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$launchTask$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskInfo/getName()|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/asReadOnlyByteBuffer()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getData()|",
      "|java+method:///org/apache/spark/executor/Executor/launchTask(org.apache.spark.executor.ExecutorBackend,long,java.lang.String,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosTaskLaunchData/attemptNumber()|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/getName()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosTaskLaunchData/serializedTask()|",
      "|java+method:///org/apache/spark/executor/Executor/launchTask(org.apache.spark.executor.ExecutorBackend,long,int,java.lang.String,java.nio.ByteBuffer)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
    "called": "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$recordSlaveLost$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$recordSlaveLost$1$$anonfun$apply$mcV$sp$8/MesosSchedulerBackend$$anonfun$recordSlaveLost$1$$anonfun$apply$mcV$sp$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$recordSlaveLost$1)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/executorLost(java.lang.String,org.apache.spark.scheduler.ExecutorLossReason)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$removeExecutor(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$recordSlaveLost$1$$anonfun$apply$mcV$sp$8/MesosSchedulerBackend$$anonfun$recordSlaveLost$1$$anonfun$apply$mcV$sp$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$recordSlaveLost$1)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/executorLost(java.lang.String,org.apache.spark.scheduler.ExecutorLossReason)|",
      "|java+method:///org/apache/spark/scheduler/ExecutorLossReason/toString()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$createTaskScheduler(org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
    "v1Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$34/SparkContext$$anonfun$34()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$41/SparkContext$$anonfun$41()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/executor/MesosExecutorBackend/registered(org.apache.mesos.ExecutorDriver,org.apache.mesos.Protos$ExecutorInfo,org.apache.mesos.Protos$FrameworkInfo,org.apache.mesos.Protos$SlaveInfo)|",
    "called": "|java+method:///org/apache/mesos/Protos$ExecutorID/getValue()|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/getValue()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$3/MesosExecutorBackend$$anonfun$3(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor_$eq(org.apache.spark.executor.Executor)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo/getId()|",
      "|java+method:///org/apache/spark/executor/Executor$/$lessinit$greater$default$6()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getExecutorId()|",
      "|java+constructor:///org/apache/spark/executor/Executor/Executor(java.lang.String,java.lang.String,scala.collection.Seq,int,boolean,akka.actor.ActorSystem)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/Buffer/find(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getResourcesList()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$1/MesosExecutorBackend$$anonfun$1(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$2/MesosExecutorBackend$$anonfun$2(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///org/apache/mesos/Protos$SlaveInfo/getHostname()|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/driver_$eq(org.apache.mesos.ExecutorDriver)|",
      "|java+method:///org/apache/spark/util/Utils$/deserialize(byte%5B%5D)|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/toByteArray()|",
      "|java+method:///org/apache/spark/executor/Executor$/$lessinit$greater$default$5()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$registered$1/MesosExecutorBackend$$anonfun$registered$1(org.apache.spark.executor.MesosExecutorBackend,int,java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getData()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$ExecutorID/getValue()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$3/MesosExecutorBackend$$anonfun$3(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/setAll(scala.collection.Traversable)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/executor_$eq(org.apache.spark.executor.Executor)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+constructor:///org/apache/spark/executor/Executor/Executor(java.lang.String,java.lang.String,org.apache.spark.SparkEnv,scala.collection.Seq,boolean)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo/getId()|",
      "|java+method:///org/apache/spark/SparkEnv$/createExecutorEnv(org.apache.spark.SparkConf,java.lang.String,java.lang.String,int,int,boolean)|",
      "|java+method:///org/apache/spark/executor/Executor$/$lessinit$greater$default$4()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf(boolean)|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getExecutorId()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/Buffer/find(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getResourcesList()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$1/MesosExecutorBackend$$anonfun$1(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$2/MesosExecutorBackend$$anonfun$2(org.apache.spark.executor.MesosExecutorBackend)|",
      "|java+method:///org/apache/mesos/Protos$SlaveInfo/getHostname()|",
      "|java+method:///org/apache/spark/executor/MesosExecutorBackend/driver_$eq(org.apache.mesos.ExecutorDriver)|",
      "|java+method:///org/apache/spark/util/Utils$/deserialize(byte%5B%5D)|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/toByteArray()|",
      "|java+method:///org/apache/spark/executor/Executor$/$lessinit$greater$default$5()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|",
      "|java+constructor:///org/apache/spark/executor/MesosExecutorBackend$$anonfun$registered$1/MesosExecutorBackend$$anonfun$registered$1(org.apache.spark.executor.MesosExecutorBackend,int,java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/getData()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$statusUpdate$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getData()|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/isFinished(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/asReadOnlyByteBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getData()|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/isFinished(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$removeExecutor(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/asReadOnlyByteBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createMesosTask(org.apache.spark.scheduler.TaskDescription,java.lang.String)|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setExecutor(org.apache.mesos.Protos$ExecutorInfo)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setExecutor(org.apache.mesos.Protos$ExecutorInfo)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecutorInfo(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/serializedTask()|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/name()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/newBuilder()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/taskId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setExecutor(org.apache.mesos.Protos$ExecutorInfo)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecutorInfo(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/serializedTask()|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/name()|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/attemptNumber()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosTaskLaunchData/toByteString()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/TaskDescription/taskId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosTaskLaunchData/MesosTaskLaunchData(java.nio.ByteBuffer,int)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.2.2",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecutorInfo(java.lang.String)|",
    "called": "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.0",
    "change": "UPDATED"
  }
]