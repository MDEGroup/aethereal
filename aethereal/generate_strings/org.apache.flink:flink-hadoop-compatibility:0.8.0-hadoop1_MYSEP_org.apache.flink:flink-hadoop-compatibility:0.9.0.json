[
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordOutputFormat/close()|",
    "called": "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/commitTask(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/commitTask(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount/main(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$Tokenizer/WordCount$Tokenizer()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapreduce.OutputFormat,org.apache.hadoop.mapreduce.Job)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$HadoopDatatypeMapper/WordCount$HadoopDatatypeMapper()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopOutputFormat/getConfiguration()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/aggregate(org.apache.flink.api.java.aggregation.Aggregations,int)|",
      "|java+method:///org/apache/flink/api/java/DataSet/map(org.apache.flink.api.common.functions.MapFunction)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/TextOutputFormat()|",
      "|java+method:///org/apache/flink/api/java/DataSet/groupBy(int%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getInstance()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$Tokenizer/WordCount$Tokenizer()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$HadoopDatatypeMapper/WordCount$HadoopDatatypeMapper()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/aggregate(org.apache.flink.api.java.aggregation.Aggregations,int)|",
      "|java+method:///org/apache/flink/api/java/DataSet/map(org.apache.flink.api.common.functions.MapFunction)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapreduce.OutputFormat,org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormat/getConfiguration()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/TextOutputFormat()|",
      "|java+method:///org/apache/flink/api/java/DataSet/groupBy(int%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getInstance()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordOutputFormat/open(int,int)|",
    "called": "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/getTempTaskOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/getTempTaskOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount/main(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Counter/HadoopMapredCompatWordCount$Counter()|",
      "|java+method:///org/apache/flink/api/java/operators/DataSink/setParallelism(int)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/HadoopReduceCombineFunction(org.apache.hadoop.mapred.Reducer,org.apache.hadoop.mapred.Reducer)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Tokenizer/HadoopMapredCompatWordCount$Tokenizer()|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/reduceGroup(org.apache.flink.api.common.functions.GroupReduceFunction)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapred.OutputFormat,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopOutputFormat/getJobConf()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextInputFormat/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopInputFormat/getJobConf()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/hadoop/mapred/TextOutputFormat/TextOutputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/HadoopMapFunction(org.apache.hadoop.mapred.Mapper)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+constructor:///org/apache/hadoop/mapred/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/operators/FlatMapOperator/groupBy(int%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Counter/HadoopMapredCompatWordCount$Counter()|",
      "|java+method:///org/apache/flink/api/java/operators/DataSink/setParallelism(int)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapred.OutputFormat,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/HadoopReduceCombineFunction(org.apache.hadoop.mapred.Reducer,org.apache.hadoop.mapred.Reducer)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/reduceGroup(org.apache.flink.api.common.functions.GroupReduceFunction)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormat/getJobConf()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextInputFormat/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/hadoop/mapred/TextOutputFormat/TextOutputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/HadoopMapFunction(org.apache.hadoop.mapred.Mapper)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+constructor:///org/apache/hadoop/mapred/TextInputFormat/TextInputFormat()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormat/getJobConf()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Tokenizer/HadoopMapredCompatWordCount$Tokenizer()|",
      "|java+method:///org/apache/hadoop/mapred/TextOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/operators/FlatMapOperator/groupBy(int%5B%5D)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceFunction/getProducedType()|",
    "called": "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/api/java/typeutils/WritableTypeInfo/WritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getForClass(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordInputFormat/HadoopRecordInputFormat(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.mapred.JobConf,org.apache.flink.hadoopcompatibility.mapred.record.datatypes.HadoopTypeConverter)|",
    "called": "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
    "v1Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordInputFormat/createInputSplits(int)|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf)|",
    "v1Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordInputFormat/createInputSplits(int)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopInputSplit/HadoopInputSplit(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/InputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordInputFormat/createInputSplits(int)|",
      "|java+method:///org/apache/hadoop/mapred/InputFormat/getSplits(org.apache.hadoop.mapred.JobConf,int)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordOutputFormat/HadoopRecordOutputFormat(org.apache.hadoop.mapred.OutputFormat,org.apache.hadoop.mapred.JobConf,org.apache.flink.hadoopcompatibility.mapred.record.datatypes.FlinkTypeConverter)|",
    "called": "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
    "v1Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/HadoopFileOutputCommitter()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/getName()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/HadoopFileOutputCommitter()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordOutputFormat/close()|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
    "v1Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/commitTask(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/commitTask(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
    "v1Body": [
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$Tokenizer/WordCount$Tokenizer()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapreduce.OutputFormat,org.apache.hadoop.mapreduce.Job)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$HadoopDatatypeMapper/WordCount$HadoopDatatypeMapper()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopOutputFormat/getConfiguration()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/aggregate(org.apache.flink.api.java.aggregation.Aggregations,int)|",
      "|java+method:///org/apache/flink/api/java/DataSet/map(org.apache.flink.api.common.functions.MapFunction)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/TextOutputFormat()|",
      "|java+method:///org/apache/flink/api/java/DataSet/groupBy(int%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getInstance()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$Tokenizer/WordCount$Tokenizer()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapreduce/example/WordCount$HadoopDatatypeMapper/WordCount$HadoopDatatypeMapper()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/aggregate(org.apache.flink.api.java.aggregation.Aggregations,int)|",
      "|java+method:///org/apache/flink/api/java/DataSet/map(org.apache.flink.api.common.functions.MapFunction)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapreduce.OutputFormat,org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormat/getConfiguration()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/TextOutputFormat/TextOutputFormat()|",
      "|java+method:///org/apache/flink/api/java/DataSet/groupBy(int%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/input/TextInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getInstance()|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/HadoopRecordOutputFormat/open(int,int)|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/getTempTaskOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/record/datatypes/HadoopFileOutputCommitter/getTempTaskOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/get(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/open(org.apache.flink.configuration.Configuration)|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/api/common/functions/RichFlatMapFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+method:///org/apache/hadoop/mapred/Mapper/configure(org.apache.hadoop.mapred.JobConf)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/api/common/functions/RichFlatMapFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/hadoop/mapred/Mapper/configure(org.apache.hadoop.mapred.JobConf)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Counter/HadoopMapredCompatWordCount$Counter()|",
      "|java+method:///org/apache/flink/api/java/operators/DataSink/setParallelism(int)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/HadoopReduceCombineFunction(org.apache.hadoop.mapred.Reducer,org.apache.hadoop.mapred.Reducer)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Tokenizer/HadoopMapredCompatWordCount$Tokenizer()|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/reduceGroup(org.apache.flink.api.common.functions.GroupReduceFunction)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapred.OutputFormat,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopOutputFormat/getJobConf()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextInputFormat/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopInputFormat/getJobConf()|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/hadoop/mapred/TextOutputFormat/TextOutputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/HadoopMapFunction(org.apache.hadoop.mapred.Mapper)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+constructor:///org/apache/hadoop/mapred/TextInputFormat/TextInputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/operators/FlatMapOperator/groupBy(int%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Counter/HadoopMapredCompatWordCount$Counter()|",
      "|java+method:///org/apache/flink/api/java/operators/DataSink/setParallelism(int)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/createInput(org.apache.flink.api.common.io.InputFormat)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormat/HadoopOutputFormat(org.apache.hadoop.mapred.OutputFormat,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/HadoopReduceCombineFunction(org.apache.hadoop.mapred.Reducer,org.apache.hadoop.mapred.Reducer)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormat/HadoopInputFormat(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/UnsortedGrouping/reduceGroup(org.apache.flink.api.common.functions.GroupReduceFunction)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormat/getJobConf()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TextInputFormat/addInputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/execute(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/ExecutionEnvironment/getExecutionEnvironment()|",
      "|java+constructor:///org/apache/hadoop/mapred/TextOutputFormat/TextOutputFormat()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/HadoopMapFunction(org.apache.hadoop.mapred.Mapper)|",
      "|java+method:///org/apache/flink/api/java/DataSet/output(org.apache.flink.api.common.io.OutputFormat)|",
      "|java+method:///org/apache/flink/api/java/DataSet/flatMap(org.apache.flink.api.common.functions.FlatMapFunction)|",
      "|java+constructor:///org/apache/hadoop/mapred/TextInputFormat/TextInputFormat()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormat/getJobConf()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/example/HadoopMapredCompatWordCount$Tokenizer/HadoopMapredCompatWordCount$Tokenizer()|",
      "|java+method:///org/apache/hadoop/mapred/TextOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/flink/api/java/operators/FlatMapOperator/groupBy(int%5B%5D)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopMapFunction/getProducedType()|",
    "called": "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/api/java/typeutils/WritableTypeInfo/WritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getForClass(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/getProducedType()|",
    "called": "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/api/java/typeutils/WritableTypeInfo/WritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getForClass(java.lang.Class)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/TupleTypeInfo/TupleTypeInfo(org.apache.flink.api.common.typeinfo.TypeInformation%5B%5D)|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceFunction/open(org.apache.flink.configuration.Configuration)|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/api/common/functions/RichGroupReduceFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/hadoop/mapred/Reducer/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopTupleUnwrappingIterator/HadoopTupleUnwrappingIterator(java.lang.Class)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopTupleUnwrappingIterator/HadoopTupleUnwrappingIterator(org.apache.flink.api.common.typeutils.TypeSerializer)|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceFunction/getRuntimeContext()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getForClass(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/createSerializer(org.apache.flink.api.common.ExecutionConfig)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/api/common/functions/RichGroupReduceFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+method:///org/apache/hadoop/mapred/Reducer/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/common/functions/RuntimeContext/getExecutionConfig()|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-hadoop-compatibility:0.8.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-hadoop-compatibility:0.9.0",
    "caller": "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/open(org.apache.flink.configuration.Configuration)|",
    "called": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
    "v1Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/api/common/functions/RichGroupReduceFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/hadoop/mapred/Reducer/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopTupleUnwrappingIterator/HadoopTupleUnwrappingIterator(java.lang.Class)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopTupleUnwrappingIterator/HadoopTupleUnwrappingIterator(org.apache.flink.api.common.typeutils.TypeSerializer)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getParameterType(java.lang.Class,java.lang.Class,int)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/getForClass(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/createSerializer(org.apache.flink.api.common.ExecutionConfig)|",
      "|java+method:///org/apache/flink/api/common/functions/RichGroupReduceFunction/open(org.apache.flink.configuration.Configuration)|",
      "|java+method:///org/apache/hadoop/mapred/Reducer/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|",
      "|java+constructor:///org/apache/flink/hadoopcompatibility/mapred/wrapper/HadoopOutputCollector/HadoopOutputCollector()|",
      "|java+method:///org/apache/flink/hadoopcompatibility/mapred/HadoopReduceCombineFunction/getRuntimeContext()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/common/functions/RuntimeContext/getExecutionConfig()|"
    ],
    "affectedLib": "org.apache.flink:flink-java:0.9.0",
    "change": "UPDATED"
  }
]