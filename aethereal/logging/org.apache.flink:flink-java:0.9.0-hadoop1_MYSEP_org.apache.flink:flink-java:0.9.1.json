[
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
    "v1Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopInputSplit/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/InputSplit/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
      "|java+method:///java/io/ObjectInputStream/defaultReadObject()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/InputSplit/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapred/JobConfigurable/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
      "|java+method:///java/io/ObjectInputStream/defaultReadObject()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
    "v1Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/finalizeGlobal(int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapred/FileOutputCommitter/FileOutputCommitter()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/commitJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/getOutputCommitter()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/commitJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/HadoopInputFormatBase(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
    "called": "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/HadoopInputFormatCommonBase(org.apache.hadoop.security.Credentials)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/close()|",
    "called": "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/commitTask(org.apache.hadoop.mapred.TaskAttemptContext)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/commitTask(org.apache.hadoop.mapred.TaskAttemptContext)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/RecordWriter/close(org.apache.hadoop.mapred.Reporter)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/needsTaskCommit(org.apache.hadoop.mapred.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/commitTask(org.apache.hadoop.mapred.TaskAttemptContext)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyReporter/HadoopDummyReporter()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/open(int,int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/getWorkPath()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/setupJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/toString()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/getWorkPath()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/setupJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/toString()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getCredentials()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/open(int,int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/mapred/FileOutputCommitter/FileOutputCommitter()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setInt(java.lang.String,int)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/toString()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/getOutputCommitter()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/setupJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setInt(java.lang.String,int)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/toString()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/writeObject(java.io.ObjectOutputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/write(java.io.ObjectOutputStream)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/InputFormat/getSplits(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/get(int)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/InputFormat/getSplits(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/JobContext/getCredentials()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///java/util/List/get(int)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/finalizeGlobal(int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/commitJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/commitJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/JobContext/getCredentials()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/close()|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/Path/toUri()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/RecordWriter/close(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/Path/toUri()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/RecordWriter/close(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/writeObject(java.io.ObjectOutputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/write(java.io.ObjectOutputStream)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-hadoop1:0.9.0-hadoop1",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/finalizeGlobal(int)|",
    "called": "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/commitJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/commitJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/JobContext/getCredentials()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/writeObject(java.io.ObjectOutputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/write(java.io.ObjectOutputStream)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/open(int,int)|",
    "called": "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/getWorkPath()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/setupJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/toString()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+constructor:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/FileOutputCommitter(org.apache.hadoop.fs.Path,org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/getWorkPath()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.TaskAttemptID)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/setupJob(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/toString()|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getRecordWriter(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptID/forName(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///org/apache/hadoop/mapreduce/TaskAttemptContext/getCredentials()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputFormat/getOutputCommitter(org.apache.hadoop.mapreduce.TaskAttemptContext)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/privateGetForClass(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
    "called": "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/WritableTypeInfo/getWritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/typeutils/ObjectArrayTypeInfo/getInfoFor(java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/analyzePojo(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/isDebugEnabled()|",
      "|java+method:///java/util/Set/add(java.lang.Object)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/reflect/Modifier/isInterface(int)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+constructor:///java/util/ArrayList/ArrayList(java.util.Collection)|",
      "|java+method:///org/apache/flink/api/java/typeutils/ValueTypeInfo/getValueTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/EnumTypeInfo/EnumTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/AvroTypeInfo/AvroTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/GenericTypeInfo/GenericTypeInfo(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/functions/InvalidTypesException/getMessage()|",
      "|java+constructor:///org/apache/flink/api/common/functions/InvalidTypesException/InvalidTypesException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/PrimitiveArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///java/lang/Class/getModifiers()|",
      "|java+method:///java/lang/Class/asSubclass(java.lang.Class)|",
      "|java+method:///java/util/Set/contains(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/WritableTypeInfo/getWritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/Class/asSubclass(java.lang.Class)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/typeutils/ObjectArrayTypeInfo/getInfoFor(java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/analyzePojo(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/isDebugEnabled()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/countTypeInHierarchy(java.util.ArrayList,java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/reflect/Modifier/isInterface(int)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+constructor:///java/util/ArrayList/ArrayList(java.util.Collection)|",
      "|java+method:///org/apache/flink/api/java/typeutils/ValueTypeInfo/getValueTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/EnumTypeInfo/EnumTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/AvroTypeInfo/AvroTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/GenericTypeInfo/GenericTypeInfo(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/functions/InvalidTypesException/getMessage()|",
      "|java+constructor:///org/apache/flink/api/common/functions/InvalidTypesException/InvalidTypesException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/PrimitiveArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///java/lang/Class/getModifiers()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+constructor:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/Keys$ExpressionKeys(int%5B%5D,org.apache.flink.api.common.typeinfo.TypeInformation,boolean)|",
    "called": "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///java/util/ArrayList/ArrayList(int)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+constructor:///org/apache/flink/api/common/InvalidProgramException/InvalidProgramException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/removeNullElementsFromList(java.util.List)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TupleTypeInfoBase/addAllFields(int,java.util.List)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/countNestedElementsBefore(org.apache.flink.api.common.typeutils.CompositeType,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getTypeAt(int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/common/typeutils/CompositeType$FlatFieldDescriptor/CompositeType$FlatFieldDescriptor(int,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/isTupleType()|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getTotalFields()|",
      "|java+method:///org/apache/flink/api/java/operators/Keys/access$100(int%5B%5D,int)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getArity()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///org/apache/flink/api/java/operators/Keys/Keys()|"
    ],
    "v2Body": [
      "|java+constructor:///java/util/ArrayList/ArrayList(int)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+constructor:///org/apache/flink/api/common/InvalidProgramException/InvalidProgramException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/removeNullElementsFromList(java.util.List)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getFlatFields(java.lang.String,int,java.util.List)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getTypeAt(int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/common/typeutils/CompositeType$FlatFieldDescriptor/CompositeType$FlatFieldDescriptor(int,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/isTupleType()|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getTotalFields()|",
      "|java+method:///org/apache/flink/api/java/operators/Keys/access$100(int%5B%5D,int)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getArity()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///org/apache/flink/api/java/operators/Keys/Keys()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/finalizeGlobal(int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapred/FileOutputCommitter/FileOutputCommitter()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/commitJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/getOutputCommitter()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/commitJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
    "called": "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
    "v1Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/InputFormat/getSplits(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/get(int)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hadoop/mapreduce/JobID/JobID()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/mapreduce/InputFormat/getSplits(org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///java/util/List/size()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/wrapper/HadoopInputSplit/HadoopInputSplit(int,org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.JobContext)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/createInputSplits(int)|",
      "|java+method:///org/apache/hadoop/mapreduce/JobContext/getCredentials()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapreduce.JobID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///java/util/List/get(int)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
    "v1Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
    "v1Body": [
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/conf/Configuration/readFields(java.io.DataInput)|",
      "|java+constructor:///org/apache/hadoop/conf/Configuration/Configuration()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/writeObject(java.io.ObjectOutputStream)|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/conf/Configuration/write(java.io.DataOutput)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopOutputFormatCommonBase/write(java.io.ObjectOutputStream)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///java/io/ObjectOutputStream/writeUTF(java.lang.String)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/HadoopInputFormatBase(org.apache.hadoop.mapred.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)|",
    "called": "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/HadoopInputFormatCommonBase(org.apache.hadoop.security.Credentials)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopOutputFormatBase/open(int,int)|",
    "called": "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/mapred/FileOutputCommitter/FileOutputCommitter()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setInt(java.lang.String,int)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/toString()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputCommitter/setupJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/getOutputCommitter()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/OutputCommitter/setupJob(org.apache.hadoop.mapred.JobContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopDummyProgressable/HadoopDummyProgressable()|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setInt(java.lang.String,int)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/forName(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapred/TaskAttemptID/toString()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobID/JobID()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.Throwable)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///org/apache/hadoop/mapred/OutputFormat/getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateTaskAttemptContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.TaskAttemptID)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/utils/HadoopUtils/instantiateJobContext(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.JobID)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getCurrentUser()|",
      "|java+method:///java/lang/Class/newInstance()|",
      "|java+method:///org/apache/hadoop/security/Credentials/addAll(org.apache.hadoop.security.Credentials)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/io/ObjectInputStream/readUTF()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/util/ReflectionUtils/setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapred/HadoopInputFormatBase/getCredentialsFromUGI(org.apache.hadoop.security.UserGroupInformation)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getCredentials()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/read(java.io.ObjectInputStream)|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/HadoopOutputFormatBase/close()|",
    "called": "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/Path/toUri()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/RecordWriter/close(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter/needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "v2Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/Path/toUri()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/get(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/hadoop/mapreduce/RecordWriter/close(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hadoop/mapreduce/OutputCommitter/needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)|",
      "|java+method:///java/lang/Integer/toString(int)|",
      "|java+method:///java/lang/String/length()|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/HadoopInputFormatBase(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
    "called": "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getCredentials()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/HadoopInputFormatCommonBase(org.apache.hadoop.security.Credentials)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/hadoop/mapred/wrapper/HadoopInputSplit/readObject(java.io.ObjectInputStream)|",
    "called": "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/InputSplit/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
      "|java+method:///java/io/ObjectInputStream/defaultReadObject()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/mapred/InputSplit/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/readFields(java.io.DataInput)|",
      "|java+method:///org/apache/hadoop/conf/Configurable/setConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/mapred/JobConfigurable/configure(org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf()|",
      "|java+method:///org/apache/hadoop/io/WritableFactories/newInstance(java.lang.Class)|",
      "|java+method:///java/io/ObjectInputStream/defaultReadObject()|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String,java.lang.Throwable)|"
    ],
    "affectedLib": "org.apache.flink:flink-shaded-include-yarn:0.9.1",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/privateGetForClass(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
    "called": "|java+method:///org/apache/flink/api/common/typeinfo/BasicTypeInfo/getInfoFor(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/WritableTypeInfo/getWritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/typeutils/ObjectArrayTypeInfo/getInfoFor(java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/analyzePojo(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/isDebugEnabled()|",
      "|java+method:///java/util/Set/add(java.lang.Object)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/reflect/Modifier/isInterface(int)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+constructor:///java/util/ArrayList/ArrayList(java.util.Collection)|",
      "|java+method:///org/apache/flink/api/java/typeutils/ValueTypeInfo/getValueTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/EnumTypeInfo/EnumTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/AvroTypeInfo/AvroTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/GenericTypeInfo/GenericTypeInfo(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/functions/InvalidTypesException/getMessage()|",
      "|java+constructor:///org/apache/flink/api/common/functions/InvalidTypesException/InvalidTypesException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/PrimitiveArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///java/lang/Class/getModifiers()|",
      "|java+method:///java/lang/Class/asSubclass(java.lang.Class)|",
      "|java+method:///java/util/Set/contains(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/api/java/typeutils/WritableTypeInfo/getWritableTypeInfo(java.lang.Class)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/lang/Class/asSubclass(java.lang.Class)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/flink/api/java/typeutils/ObjectArrayTypeInfo/getInfoFor(java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/analyzePojo(java.lang.Class,java.util.ArrayList,java.lang.reflect.ParameterizedType,org.apache.flink.api.common.typeinfo.TypeInformation,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/isDebugEnabled()|",
      "|java+method:///org/apache/flink/api/java/typeutils/TypeExtractor/countTypeInHierarchy(java.util.ArrayList,java.lang.reflect.Type)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/reflect/Modifier/isInterface(int)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+constructor:///java/util/ArrayList/ArrayList(java.util.Collection)|",
      "|java+method:///org/apache/flink/api/java/typeutils/ValueTypeInfo/getValueTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/EnumTypeInfo/EnumTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/AvroTypeInfo/AvroTypeInfo(java.lang.Class)|",
      "|java+constructor:///org/apache/flink/api/java/typeutils/GenericTypeInfo/GenericTypeInfo(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/functions/InvalidTypesException/getMessage()|",
      "|java+constructor:///org/apache/flink/api/common/functions/InvalidTypesException/InvalidTypesException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/BasicTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/PrimitiveArrayTypeInfo/getInfoFor(java.lang.Class)|",
      "|java+method:///java/lang/Class/getModifiers()|"
    ],
    "affectedLib": "org.apache.flink:flink-core:0.9.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+constructor:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/Keys$ExpressionKeys(int%5B%5D,org.apache.flink.api.common.typeinfo.TypeInformation,boolean)|",
    "called": "|java+constructor:///org/apache/flink/api/common/typeutils/CompositeType$FlatFieldDescriptor/CompositeType$FlatFieldDescriptor(int,org.apache.flink.api.common.typeinfo.TypeInformation)|",
    "v1Body": [
      "|java+constructor:///java/util/ArrayList/ArrayList(int)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+constructor:///org/apache/flink/api/common/InvalidProgramException/InvalidProgramException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/removeNullElementsFromList(java.util.List)|",
      "|java+method:///org/apache/flink/api/java/typeutils/TupleTypeInfoBase/addAllFields(int,java.util.List)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/countNestedElementsBefore(org.apache.flink.api.common.typeutils.CompositeType,int)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getTypeAt(int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/common/typeutils/CompositeType$FlatFieldDescriptor/CompositeType$FlatFieldDescriptor(int,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/isTupleType()|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getTotalFields()|",
      "|java+method:///org/apache/flink/api/java/operators/Keys/access$100(int%5B%5D,int)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getArity()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///org/apache/flink/api/java/operators/Keys/Keys()|"
    ],
    "v2Body": [
      "|java+constructor:///java/util/ArrayList/ArrayList(int)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+constructor:///org/apache/flink/api/common/InvalidProgramException/InvalidProgramException(java.lang.String)|",
      "|java+method:///org/apache/flink/api/java/operators/Keys$ExpressionKeys/removeNullElementsFromList(java.util.List)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getFlatFields(java.lang.String,int,java.util.List)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/flink/api/common/typeutils/CompositeType/getTypeAt(int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+constructor:///org/apache/flink/api/common/typeutils/CompositeType$FlatFieldDescriptor/CompositeType$FlatFieldDescriptor(int,org.apache.flink.api.common.typeinfo.TypeInformation)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/isTupleType()|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getTotalFields()|",
      "|java+method:///org/apache/flink/api/java/operators/Keys/access$100(int%5B%5D,int)|",
      "|java+method:///org/apache/flink/api/common/typeinfo/TypeInformation/getArity()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+constructor:///org/apache/flink/api/java/operators/Keys/Keys()|"
    ],
    "affectedLib": "org.apache.flink:flink-core:0.9.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.flink:flink-java:0.9.0-hadoop1",
    "coordinatesV2": "org.apache.flink:flink-java:0.9.1",
    "caller": "|java+constructor:///org/apache/flink/api/java/hadoop/mapreduce/HadoopInputFormatBase/HadoopInputFormatBase(org.apache.hadoop.mapreduce.InputFormat,java.lang.Class,java.lang.Class,org.apache.hadoop.mapreduce.Job)|",
    "called": "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getConfiguration()|",
      "|java+method:///org/apache/hadoop/mapreduce/Job/getCredentials()|",
      "|java+constructor:///org/apache/flink/api/java/hadoop/common/HadoopInputFormatCommonBase/HadoopInputFormatCommonBase(org.apache.hadoop.security.Credentials)|",
      "|java+method:///org/apache/flink/api/java/hadoop/mapreduce/utils/HadoopUtils/mergeHadoopConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/flink/shaded/com/google/common/base/Preconditions/checkNotNull(java.lang.Object)|"
    ],
    "affectedLib": "org.apache.flink:flink-core:0.9.1",
    "change": "UPDATED"
  }
]