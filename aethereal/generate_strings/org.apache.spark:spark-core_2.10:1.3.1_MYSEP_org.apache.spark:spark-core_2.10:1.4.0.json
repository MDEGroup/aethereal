[
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/start()|",
    "called": "|java+constructor:///org/apache/curator/framework/recipes/leader/LeaderLatch/LeaderLatch(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
    "v1Body": [
      "|java+constructor:///org/apache/curator/framework/recipes/leader/LeaderLatch/LeaderLatch(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///org/apache/curator/framework/recipes/leader/LeaderLatch/start()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/WORKING_DIR()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/logInfo(scala.Function0)|",
      "|java+method:///org/apache/curator/framework/recipes/leader/LeaderLatch/addListener(org.apache.curator.framework.recipes.leader.LeaderLatchListener)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/zk()|",
      "|java+method:///org/apache/spark/deploy/master/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/zk_$eq(org.apache.curator.framework.CuratorFramework)|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent$$anonfun$start$1/ZooKeeperLeaderElectionAgent$$anonfun$start$1(org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/leaderLatch()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/leaderLatch_$eq(org.apache.curator.framework.recipes.leader.LeaderLatch)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/curator/framework/recipes/leader/LeaderLatch/LeaderLatch(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/WORKING_DIR()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/logInfo(scala.Function0)|",
      "|java+method:///org/apache/curator/framework/recipes/leader/LeaderLatch/addListener(org.apache.curator.framework.recipes.leader.LeaderLatchListener)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/zk()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/zk_$eq(org.apache.curator.framework.CuratorFramework)|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent$$anonfun$start$1/ZooKeeperLeaderElectionAgent$$anonfun$start$1(org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/leaderLatch_$eq(org.apache.curator.framework.recipes.leader.LeaderLatch)|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient$default$2()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent/leaderLatch()|",
      "|java+method:///org/apache/curator/framework/recipes/leader/LeaderLatch/start()|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf,java.lang.String)|"
    ],
    "affectedLib": "org.apache.curator:curator-recipes:2.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/io/SnappyCompressionCodec/compressedOutputStream(java.io.OutputStream)|",
    "called": "|java+constructor:///org/xerial/snappy/SnappyOutputStream/SnappyOutputStream(java.io.OutputStream,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/xerial/snappy/SnappyOutputStream/SnappyOutputStream(java.io.OutputStream,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getSizeAsBytes(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/xerial/snappy/SnappyOutputStream/SnappyOutputStream(java.io.OutputStream,int)|",
      "|java+constructor:///org/apache/spark/io/SnappyOutputStreamWrapper/SnappyOutputStreamWrapper(org.xerial.snappy.SnappyOutputStream)|"
    ],
    "affectedLib": "org.xerial.snappy:snappy-java:1.1.1.6",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/ShuffledRDD/ShuffledRDD(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///org/apache/spark/rdd/ShuffledRDD/setAggregator(org.apache.spark.Aggregator)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$combineByKey$2/PairRDDFunctions$$anonfun$combineByKey$2(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.Aggregator)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$combineByKey$1/PairRDDFunctions$$anonfun$combineByKey$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/ShuffledRDD/setMapSideCombine(boolean)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+constructor:///org/apache/spark/Aggregator/Aggregator(scala.Function1,scala.Function2,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/ShuffledRDD/setSerializer(org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$combineByKey$1/PairRDDFunctions$$anonfun$combineByKey$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleExecutorLost$3/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/Stage/removeOutputsOnExecutor(java.lang.String)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/registerMapOutputs(int,org.apache.spark.scheduler.MapStatus%5B%5D,boolean)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleExecutorLost$3$$anonfun$16/DAGScheduler$$anonfun$handleExecutorLost$3$$anonfun$16(org.apache.spark.scheduler.DAGScheduler$$anonfun$handleExecutorLost$3)|",
      "|java+method:///org/apache/spark/scheduler/Stage/outputLocs()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/removeOutputsOnExecutor(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/registerMapOutputs(int,org.apache.spark.scheduler.MapStatus%5B%5D,boolean)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/outputLocs()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleExecutorLost$3$$anonfun$18/DAGScheduler$$anonfun$handleExecutorLost$3$$anonfun$18(org.apache.spark.scheduler.DAGScheduler$$anonfun$handleExecutorLost$3)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4/apply()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsPending()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4/apply()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/getThreadDump()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$11/Utils$$anonfun$11()|",
      "|java+method:///java/lang/management/ManagementFactory/getThreadMXBean()|",
      "|java+method:///java/lang/management/ThreadMXBean/dumpAllThreads(boolean,boolean)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$2/Utils$$anonfun$getThreadDump$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$1/Utils$$anonfun$getThreadDump$1()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/lang/management/ManagementFactory/getThreadMXBean()|",
      "|java+method:///java/lang/management/ThreadMXBean/dumpAllThreads(boolean,boolean)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$2/Utils$$anonfun$getThreadDump$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$1/Utils$$anonfun$getThreadDump$1()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$15/Utils$$anonfun$15()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$glom$1/RDD$$anonfun$glom$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/sampleByKeyExact(boolean,scala.collection.Map,long)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Iterable/forall(scala.Function1)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/util/random/StratifiedSamplingUtils$/getBernoulliSamplingFunction(org.apache.spark.rdd.RDD,scala.collection.Map,boolean,long)|",
      "|java+method:///org/apache/spark/util/random/StratifiedSamplingUtils$/getPoissonSamplingFunction(org.apache.spark.rdd.RDD,scala.collection.Map,boolean,long,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Map/values()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKeyExact$2/PairRDDFunctions$$anonfun$sampleByKeyExact$2(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKeyExact$1/PairRDDFunctions$$anonfun$sampleByKeyExact$1(org.apache.spark.rdd.PairRDDFunctions)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKeyExact$1/PairRDDFunctions$$anonfun$sampleByKeyExact$1(org.apache.spark.rdd.PairRDDFunctions,boolean,scala.collection.Map,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/fetchHcfsFile(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.FileSystem,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration,boolean,scala.Option)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchHcfsFile$1/Utils$$anonfun$fetchHcfsFile$1(org.apache.hadoop.fs.FileSystem,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration,boolean,java.io.File)|",
      "|java+method:///org/apache/hadoop/fs/FSDataInputStream/close()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/io/File/mkdir()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/downloadFile(java.lang.String,java.io.InputStream,java.io.File,boolean)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$4/Utils$$anonfun$4(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/isFile(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/File/getPath()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchHcfsFile$1/Utils$$anonfun$fetchHcfsFile$1(org.apache.hadoop.fs.FileSystem,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration,boolean,java.io.File)|",
      "|java+method:///org/apache/hadoop/fs/FSDataInputStream/close()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/io/File/mkdir()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/downloadFile(java.lang.String,java.io.InputStream,java.io.File,boolean)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$5/Utils$$anonfun$5(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/isFile(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/File/getPath()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskBlockManager/stop()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///java/lang/Runtime/removeShutdownHook(java.lang.Thread)|",
      "|java+method:///java/lang/Runtime/getRuntime()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/shutdownHook()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/org$apache$spark$storage$DiskBlockManager$$doStop()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskBlockManager/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/org$apache$spark$storage$DiskBlockManager$$doStop()|",
      "|java+method:///org/apache/spark/util/Utils$/removeShutdownHook(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/shutdownHook()|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$stop$1/DiskBlockManager$$anonfun$stop$1(org.apache.spark.storage.DiskBlockManager)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/collection/ExternalSorter/ExternalSorter(scala.Option,scala.Option,scala.Option,scala.Option)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingPairBuffer/SizeTrackingPairBuffer(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/conf()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/util/collection/Spillable$class/$init$(org.apache.spark.util.collection.Spillable)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$1/ExternalSorter$$anonfun$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/SizeTrackingAppendOnlyMap()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/bypassMergeThreshold()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anon$8/ExternalSorter$$anon$8(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anon$7/ExternalSorter$$anon$7(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionComparator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$ser()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$4/ExternalSorter$$anonfun$4(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$3/ExternalSorter$$anonfun$3(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/serializer/Serializer$/getSerializer(scala.Option)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingPairBuffer$/$lessinit$greater$default$1()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/bypassMergeThreshold()|",
      "|java+constructor:///org/apache/spark/util/collection/PartitionedAppendOnlyMap/PartitionedAppendOnlyMap()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/conf()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/ser()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/useSerializedPairBuffer()|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsKb(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/util/collection/PartitionedPairBuffer$/$lessinit$greater$default$1()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/metaInitialRecords()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///org/apache/spark/util/collection/Spillable$class/$init$(org.apache.spark.util.collection.Spillable)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/kvChunkSize()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$4/ExternalSorter$$anonfun$4(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$3/ExternalSorter$$anonfun$3(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/serializer/Serializer$/getSerializer(scala.Option)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+constructor:///org/apache/spark/util/collection/PartitionedPairBuffer/PartitionedPairBuffer(int)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$1/ExternalSorter$$anonfun$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/collection/PartitionedSerializedPairBuffer/PartitionedSerializedPairBuffer(int,int,org.apache.spark.serializer.SerializerInstance)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+method:///org/apache/spark/serializer/Serializer/supportsRelocationOfSerializedObjects()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/UIUtils$$anonfun$2/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/UIUtils$/tooltip(java.lang.String,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1/apply(java.lang.StackTraceElement)|",
    "called": "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$4/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$4(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$5/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$5(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$6/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$6(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/lang/StackTraceElement/getFileName()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///java/lang/StackTraceElement/getLineNumber()|",
      "|java+method:///java/lang/StackTraceElement/getClassName()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///java/lang/StackTraceElement/getMethodName()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$5/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$5(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$6/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$6(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$8/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$8(org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/lang/StackTraceElement/getFileName()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///java/lang/StackTraceElement/getLineNumber()|",
      "|java+method:///java/lang/StackTraceElement/getClassName()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///java/lang/StackTraceElement/getMethodName()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$13/MasterPage$$anonfun$13(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7(org.apache.spark.SparkConf$$anonfun$validateSettings$6,java.lang.String)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/exec/ExecutorsPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$11/ExecutorsPage$$anonfun$11(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/collection/TraversableOnce/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$13/ExecutorsPage$$anonfun$13(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/INPUT()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$10/ExecutorsPage$$anonfun$10(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$9/ExecutorsPage$$anonfun$9(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$8/ExecutorsPage$$anonfun$8(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$12/ExecutorsPage$$anonfun$12(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/TABLE_CLASS_STRIPED()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_WRITE()|",
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///scala/collection/immutable/IndexedSeq/size()|",
      "|java+constructor:///scala/xml/Comment/Comment(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$14/ExecutorsPage$$anonfun$14(org.apache.spark.ui.exec.ExecutorsPage,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsPage/listener()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$render$1/ExecutorsPage$$anonfun$render$1(org.apache.spark.ui.exec.ExecutorsPage,scala.xml.NodeBuffer)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/storageStatusList()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$11/ExecutorsPage$$anonfun$11(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/collection/TraversableOnce/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$13/ExecutorsPage$$anonfun$13(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsPage/org$apache$spark$ui$exec$ExecutorsPage$$listener()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/collection/immutable/IndexedSeq/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/INPUT()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$10/ExecutorsPage$$anonfun$10(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$9/ExecutorsPage$$anonfun$9(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$8/ExecutorsPage$$anonfun$8(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$12/ExecutorsPage$$anonfun$12(org.apache.spark.ui.exec.ExecutorsPage)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/TABLE_CLASS_STRIPED()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_WRITE()|",
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///scala/collection/immutable/IndexedSeq/size()|",
      "|java+constructor:///scala/xml/Comment/Comment(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$14/ExecutorsPage$$anonfun$14(org.apache.spark.ui.exec.ExecutorsPage,boolean)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$render$1/ExecutorsPage$$anonfun$render$1(org.apache.spark.ui.exec.ExecutorsPage,scala.xml.NodeBuffer)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/storageStatusList()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getMissingParentStages(org.apache.spark.scheduler.Stage)|",
    "called": "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashSet/toList()|",
      "|java+method:///scala/collection/mutable/Stack/isEmpty()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$3(org.apache.spark.rdd.RDD,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashSet/toList()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/nonEmpty()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$3(org.apache.spark.rdd.RDD,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/apply()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/apply$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$41/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$41/apply(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$41/apply(scala.Tuple2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/union(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/Option/isDefined()|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD/PartitionerAwareUnionRDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/UnionRDD/UnionRDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$union$1/RDD$$anonfun$union$1(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1/apply$mcV$sp()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registrationRetryTimer()|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workerId()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/connectionAttemptCount()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$1/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$1(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$4/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$4(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registrationRetryTimer_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/webUi()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/publicAddress()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/PROLONGED_REGISTRATION_RETRY_INTERVAL()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/connectionAttemptCount_$eq(int)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/TOTAL_REGISTRATION_RETRIES()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/INITIAL_REGISTRATION_RETRIES()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/master()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registered()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisterWorker/DeployMessages$RegisterWorker(java.lang.String,java.lang.String,int,int,int,int,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$3/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$3(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$connectionAttemptCount()|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registrationRetryTimer_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/boundPort()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$workerId()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$webUi()|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$4/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$4(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$PROLONGED_REGISTRATION_RETRY_INTERVAL()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$publicAddress()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$master()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registered()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$connectionAttemptCount_$eq(int)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registrationRetryTimer()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$INITIAL_REGISTRATION_RETRIES()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$TOTAL_REGISTRATION_RETRIES()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$1/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$1(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisterWorker/DeployMessages$RegisterWorker(java.lang.String,java.lang.String,int,int,int,int,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$3/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$3(org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$11/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$11/apply(java.lang.management.ThreadInfo)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$11/apply(java.io.File)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$20/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$20$$anonfun$apply$3/StagePage$$anonfun$20$$anonfun$apply$3(org.apache.spark.ui.jobs.StagePage$$anonfun$20)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$20$$anonfun$apply$13/StagePage$$anonfun$20$$anonfun$apply$13(org.apache.spark.ui.jobs.StagePage$$anonfun$20)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/jvmGCTime()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/toLocalIterator()|",
    "called": "|java+method:///scala/collection/immutable/Range/iterator()|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/collection/Iterator/flatMap(scala.Function1)|",
      "|java+method:///scala/collection/immutable/Range/iterator()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$toLocalIterator$1/RDD$$anonfun$toLocalIterator$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$toLocalIterator$1/RDD$$anonfun$toLocalIterator$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeout()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1/apply()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeoutS()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DirectTaskResult$$anonfun$readExternal$1/apply$mcV$sp()|",
    "called": "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
    "v1Body": [
      "|java+method:///java/io/ObjectInput/readFully(byte%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/valueBytes_$eq(java.nio.ByteBuffer)|",
      "|java+method:///java/io/ObjectInput/readObject()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/metrics_$eq(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/io/ObjectInput/readInt()|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/accumUpdates_$eq(scala.collection.mutable.Map)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$1/DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1)|",
      "|java+method:///scala/collection/mutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///java/io/ObjectInput/readFully(byte%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/org$apache$spark$scheduler$DirectTaskResult$$valueObjectDeserialized_$eq(boolean)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/valueBytes_$eq(java.nio.ByteBuffer)|",
      "|java+method:///java/io/ObjectInput/readObject()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/metrics_$eq(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/io/ObjectInput/readInt()|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/accumUpdates_$eq(scala.collection.mutable.Map)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$1/DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1)|",
      "|java+method:///scala/collection/mutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/JsonProtocol$/writeApplicationDescription(org.apache.spark.deploy.ApplicationDescription)|",
    "called": "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$2/JsonProtocol$$anonfun$writeApplicationDescription$2()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$3/JsonProtocol$$anonfun$writeApplicationDescription$3()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$4/JsonProtocol$$anonfun$writeApplicationDescription$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$1/JsonProtocol$$anonfun$writeApplicationDescription$1()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/Command/toString()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$5/JsonProtocol$$anonfun$writeApplicationDescription$5()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerSlave()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$2/JsonProtocol$$anonfun$writeApplicationDescription$2()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$3/JsonProtocol$$anonfun$writeApplicationDescription$3()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$4/JsonProtocol$$anonfun$writeApplicationDescription$4()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerExecutorMB()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$1/JsonProtocol$$anonfun$writeApplicationDescription$1()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/Command/toString()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationDescription$5/JsonProtocol$$anonfun$writeApplicationDescription$5()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/ZippedPartitionsBaseRDD$$anonfun$getPartitions$1/apply(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/HistoryPage/org$apache$spark$deploy$history$HistoryPage$$appRow(org.apache.spark.deploy.history.ApplicationHistoryInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/startTime()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDate(long)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/lastUpdated()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/endTime()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/sparkUser()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/UI_PATH_PREFIX()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/attempts()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/org$apache$spark$deploy$history$HistoryPage$$attemptRow(boolean,org.apache.spark.deploy.history.ApplicationHistoryInfo,org.apache.spark.deploy.history.ApplicationAttemptInfo,boolean)|",
      "|java+method:///scala/collection/immutable/List/head()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$15/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$15/apply(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$15/apply(scala.util.Try)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD/PartitionerAwareUnionRDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$3/PartitionerAwareUnionRDD$$anonfun$3(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$$init$$1/PartitionerAwareUnionRDD$$anonfun$$init$$1()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$2/PartitionerAwareUnionRDD$$anonfun$2(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/Predef$/require(boolean)|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/toSet()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/rdds()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/Set/size()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$4/PartitionerAwareUnionRDD$$anonfun$4(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/collection/Seq/forall(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$3/PartitionerAwareUnionRDD$$anonfun$3(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$$init$$1/PartitionerAwareUnionRDD$$anonfun$$init$$1()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$2/PartitionerAwareUnionRDD$$anonfun$2(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/Predef$/require(boolean)|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/toSet()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/rdds()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/Set/size()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/getPos$mcJ$sp(long)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$_mask()|",
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/_data()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/hasher()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash$mcJ$sp(long)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$_mask()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/_data()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/hasher()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash$mcJ$sp(long)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcJ$sp/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/text/SimpleDateFormat/format(java.util.Date)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logInfo(scala.Function0)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$3/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$3(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/util/Random/nextInt(int)|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$MAX_DIR_CREATION_ATTEMPTS()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logError(scala.Function0)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+constructor:///java/util/Date/Date()|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///tachyon/client/TachyonFS/exist(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$1/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$1(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,scala.runtime.ObjectRef,scala.runtime.IntRef)|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/TACHYON_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(tachyon.TachyonURI)|",
      "|java+method:///java/text/SimpleDateFormat/format(java.util.Date)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$1/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$1(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,scala.runtime.ObjectRef,scala.runtime.IntRef)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(tachyon.TachyonURI)|",
      "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$3/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$3(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///tachyon/client/TachyonFS/exist(tachyon.TachyonURI)|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore$/MAX_DIR_CREATION_ATTEMPTS()|",
      "|java+method:///java/util/Random/nextInt(int)|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/EXTERNAL_BLOCK_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logError(scala.Function0)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+constructor:///java/util/Date/Date()|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$50/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$50/apply(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$50/apply(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo$/unapply(org.apache.spark.storage.BlockManagerMessages$UpdateBlockInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/tachyonSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|",
      "|java+constructor:///scala/Tuple6/Tuple6(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/externalBlockStoreSize()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|",
      "|java+constructor:///scala/Tuple6/Tuple6(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$28/JsonProtocol$$anonfun$28()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$4/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$4/apply(org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$4/apply(char)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToChar(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/stop()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Map/clear()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/authorizedCommittersByStage()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorActor()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorActor_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/scheduler/OutputCommitCoordinator$$anonfun$stop$1/OutputCommitCoordinator$$anonfun$stop$1(org.apache.spark.scheduler.OutputCommitCoordinator)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Map/clear()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorRef_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/scheduler/OutputCommitCoordinator$$anonfun$stop$1/OutputCommitCoordinator$$anonfun$stop$1(org.apache.spark.scheduler.OutputCommitCoordinator)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/authorizedCommittersByStage()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorRef()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/removeExecutor(java.lang.String,java.lang.String)|",
    "called": "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RemoveExecutor/CoarseGrainedClusterMessages$RemoveExecutor(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverActor()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/timeout()|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RemoveExecutor/CoarseGrainedClusterMessages$RemoveExecutor(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverEndpoint()|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/WebUI/WebUI(org.apache.spark.SecurityManager,int,org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$1/WebUI$$anonfun$1(org.apache.spark.ui.WebUI)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$1/WebUI$$anonfun$1(org.apache.spark.ui.WebUI)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostNameForURI()|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/submitTasks(org.apache.spark.scheduler.TaskSet)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/activeTaskSets()|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/taskSet()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/tasks()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/properties()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/logInfo(scala.Function0)|",
      "|java+method:///java/util/Timer/scheduleAtFixedRate(java.util.TimerTask,long,long)|",
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend/reviveOffers()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/schedulableBuilder()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/STARVATION_TIMEOUT()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/id()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/hasReceivedTask()|",
      "|java+method:///org/apache/spark/scheduler/SchedulableBuilder/addTaskSetManager(org.apache.spark.scheduler.Schedulable,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/hasReceivedTask_$eq(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/createTaskSetManager(org.apache.spark.scheduler.TaskSet,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/maxTaskFailures()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anon$1/TaskSchedulerImpl$$anon$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$submitTasks$1/TaskSchedulerImpl$$anonfun$submitTasks$1(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.scheduler.TaskSet,org.apache.spark.scheduler.Task%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/backend()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/starvationTimer()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/schedulableBuilder()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/activeTaskSets()|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/taskSet()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/tasks()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/properties()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/logInfo(scala.Function0)|",
      "|java+method:///java/util/Timer/scheduleAtFixedRate(java.util.TimerTask,long,long)|",
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend/reviveOffers()|",
      "|java+method:///org/apache/spark/scheduler/TaskSet/id()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/hasReceivedTask()|",
      "|java+method:///org/apache/spark/scheduler/SchedulableBuilder/addTaskSetManager(org.apache.spark.scheduler.Schedulable,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/hasReceivedTask_$eq(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/STARVATION_TIMEOUT_MS()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/createTaskSetManager(org.apache.spark.scheduler.TaskSet,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/maxTaskFailures()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anon$1/TaskSchedulerImpl$$anon$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$submitTasks$1/TaskSchedulerImpl$$anonfun$submitTasks$1(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.scheduler.TaskSet,org.apache.spark.scheduler.Task%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/backend()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/starvationTimer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/YarnSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend$$anonfun$1/YarnSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.YarnSchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/minRegisteredRatio_$eq(double)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,akka.actor.ActorSystem)|",
      "|java+method:///akka/actor/Props$/apply(scala.Function0,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/actorSystem()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/rpcEnv()|",
      "|java+method:///org/apache/spark/util/RpcUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/minRegisteredRatio_$eq(double)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend$YarnSchedulerEndpoint/YarnSchedulerBackend$YarnSchedulerEndpoint(org.apache.spark.scheduler.cluster.YarnSchedulerBackend,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/conf()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/apply()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/apply$mcJ$sp()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/SizeEstimator$/getClassInfo(java.lang.Class)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/util/concurrent/ConcurrentHashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Class/getSuperclass()|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$getClassInfo$1/SizeEstimator$$anonfun$getClassInfo$1(scala.runtime.LongRef,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/classInfos()|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$ClassInfo/SizeEstimator$ClassInfo(long,scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/getClassInfo(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/shellSize()|",
      "|java+method:///java/lang/Class/getDeclaredFields()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/pointerFields()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/alignSize(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///java/lang/Class/getSuperclass()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$pointerSize()|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$getClassInfo$3/SizeEstimator$$anonfun$getClassInfo$3(scala.runtime.ObjectRef,int%5B%5D)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/classInfos()|",
      "|java+method:///scala/collection/immutable/List/max(scala.math.Ordering)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/getClassInfo(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/fieldSizes()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$getClassInfo$2/SizeEstimator$$anonfun$getClassInfo$2(scala.runtime.LongRef,int%5B%5D,scala.runtime.LongRef)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/pointerFields()|",
      "|java+method:///scala/collection/immutable/List/withFilter(scala.Function1)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Array$/fill(int,scala.Function0,scala.reflect.ClassTag)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$alignSizeUp(long,int)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$1/SizeEstimator$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$ClassInfo/SizeEstimator$ClassInfo(long,scala.collection.immutable.List)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$getClassInfo$1/SizeEstimator$$anonfun$getClassInfo$1(int%5B%5D)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/shellSize()|",
      "|java+method:///java/lang/Class/getDeclaredFields()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$removeExecutor$4/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$removeExecutor$4/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeout()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$removeExecutor$4/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeoutS()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/saveAsTextFile(java.lang.String,java.lang.Class)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$36/RDD$$anonfun$36(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,java.lang.Class,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/implicitly(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$saveAsTextFile$2/RDD$$anonfun$saveAsTextFile$2(org.apache.spark.rdd.RDD,java.lang.String,java.lang.Class)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/apply(org.apache.spark.deploy.master.DriverInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/apply(org.apache.spark.deploy.master.DriverInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CoGroupedRDD/getPartitions()|",
    "called": "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/Partitioner/numPartitions()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1/CoGroupedRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/Partitioner/numPartitions()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1/CoGroupedRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore/unrollSafely(org.apache.spark.storage.BlockId,scala.collection.Iterator,scala.collection.mutable.ArrayBuffer)|",
    "called": "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+method:///scala/collection/Iterator/$plus$plus(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$unrollSafely$2/MemoryStore$$anonfun$unrollSafely$2(org.apache.spark.storage.MemoryStore,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/accountingLock()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemoryForThisThread()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/maxUnrollMemory()|",
      "|java+method:///scala/package$/Right()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/toArray()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/ResultWithDroppedBlocks/droppedBlocks()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/ensureFreeSpace(org.apache.spark.storage.BlockId,long)|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logUnrollFailureMessage(org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/reserveUnrollMemoryForThisThread(long)|",
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingVector/SizeTrackingVector(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$unrollMemoryThreshold()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/estimateSize()|",
      "|java+method:///scala/package$/Left()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/iterator()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$unrollSafely$1/MemoryStore$$anonfun$unrollSafely$1(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///scala/util/Left$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemory()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+method:///scala/collection/Iterator/$plus$plus(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$unrollSafely$2/MemoryStore$$anonfun$unrollSafely$2(org.apache.spark.storage.MemoryStore,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/accountingLock()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemoryForThisThread()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/maxUnrollMemory()|",
      "|java+method:///scala/package$/Right()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/ResultWithDroppedBlocks/droppedBlocks()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/ensureFreeSpace(org.apache.spark.storage.BlockId,long)|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logUnrollFailureMessage(org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/reserveUnrollMemoryForThisThread(long)|",
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingVector/SizeTrackingVector(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$unrollMemoryThreshold()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/estimateSize()|",
      "|java+method:///scala/package$/Left()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/iterator()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/reservePendingUnrollMemoryForThisThread(long)|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingVector/toArray()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$unrollSafely$1/MemoryStore$$anonfun$unrollSafely$1(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///scala/util/Left$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemory()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$46/StagePage$$anonfun$46(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/blockStatusToJson(org.apache.spark.storage.BlockStatus)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$1/JsonProtocol$$anonfun$blockStatusToJson$1()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$2/JsonProtocol$$anonfun$blockStatusToJson$2()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelToJson(org.apache.spark.storage.StorageLevel)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$3/JsonProtocol$$anonfun$blockStatusToJson$3()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$1/JsonProtocol$$anonfun$blockStatusToJson$1()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$2/JsonProtocol$$anonfun$blockStatusToJson$2()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelToJson(org.apache.spark.storage.StorageLevel)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$blockStatusToJson$3/JsonProtocol$$anonfun$blockStatusToJson$3()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$1/FsHistoryProvider$$anonfun$checkForLogs$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$48/StagePage$$anonfun$48(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/loadDefaultSparkProperties(org.apache.spark.SparkConf,java.lang.String)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$10/Utils$$anonfun$10()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1/Utils$$anonfun$loadDefaultSparkProperties$1(org.apache.spark.SparkConf)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$14/Utils$$anonfun$14()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1/Utils$$anonfun$loadDefaultSparkProperties$1(org.apache.spark.SparkConf)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/hasRootAsShutdownDeleteDir(java.io.File)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$1/Utils$$anonfun$1(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/collection/mutable/HashSet/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$hasRootAsShutdownDeleteDir$1/Utils$$anonfun$hasRootAsShutdownDeleteDir$1(java.io.File)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/org$apache$spark$util$Utils$$shutdownDeletePaths()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$2/Utils$$anonfun$2(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/collection/mutable/HashSet/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$hasRootAsShutdownDeleteDir$1/Utils$$anonfun$hasRootAsShutdownDeleteDir$1(java.io.File)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/org$apache$spark$util$Utils$$shutdownDeletePaths()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$4/ApplicationPage$$anonfun$4(org.apache.spark.deploy.master.ui.ApplicationPage,java.lang.String,org.apache.spark.deploy.DeployMessages$MasterStateResponse)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresLeft()|",
      "|java+method:///scala/collection/TraversableOnce/toSet()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$3/ApplicationPage$$anonfun$3(org.apache.spark.deploy.master.ui.ApplicationPage,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeApps()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+constructor:///scala/xml/Comment/Comment(java.lang.String)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///akka/pattern/AskableActorRef$/$qmark$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$render$1/ApplicationPage$$anonfun$render$1(org.apache.spark.deploy.master.ui.ApplicationPage,scala.xml.NodeBuffer)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///scala/collection/Iterable/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/diff(scala.collection.GenSeq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerSlave()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/removedExecutors()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage/master()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/collection/immutable/Set/toSeq()|",
      "|java+method:///scala/collection/mutable/ArrayOps/find(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/ApplicationPage$$anonfun$5(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage/timeout()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$6/ApplicationPage$$anonfun$6(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$7/ApplicationPage$$anonfun$7(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$2/ApplicationPage$$anonfun$2(org.apache.spark.deploy.master.ui.ApplicationPage,java.lang.String,org.apache.spark.deploy.DeployMessages$MasterStateResponse)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$render$2/ApplicationPage$$anonfun$render$2(org.apache.spark.deploy.master.ui.ApplicationPage,scala.xml.NodeBuffer)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresLeft()|",
      "|java+method:///scala/collection/TraversableOnce/toSet()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$render$1/ApplicationPage$$anonfun$render$1(org.apache.spark.deploy.master.ui.ApplicationPage,scala.xml.Elem)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$1/ApplicationPage$$anonfun$1(org.apache.spark.deploy.master.ui.ApplicationPage,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeApps()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+constructor:///scala/xml/Comment/Comment(java.lang.String)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///akka/pattern/AskableActorRef$/$qmark$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///scala/collection/Iterable/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/diff(scala.collection.GenSeq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/removedExecutors()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage/master()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerExecutorMB()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/collection/immutable/Set/toSeq()|",
      "|java+method:///scala/collection/mutable/ArrayOps/find(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$4/ApplicationPage$$anonfun$4(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/ApplicationPage$$anonfun$5(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage/timeout()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$3/ApplicationPage$$anonfun$3(org.apache.spark.deploy.master.ui.ApplicationPage)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$11/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$11/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$11/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/apply()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master/preStart()|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/RECOVERY_MODE()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterMetricsSystem()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/bind()|",
      "|java+method:///org/apache/spark/deploy/master/StandaloneRecoveryModeFactory/createPersistenceEngine()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///org/apache/spark/deploy/master/Master/applicationMetricsSystem()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$4/Master$$anonfun$preStart$4(org.apache.spark.deploy.master.Master)|",
      "|java+method:///akka/serialization/SerializationExtension$/apply(akka.actor.ActorSystem)|",
      "|java+constructor:///org/apache/spark/deploy/master/BlackHolePersistenceEngine/BlackHolePersistenceEngine()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$2/Master$$anonfun$2(org.apache.spark.deploy.master.Master)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$2/Master$$anonfun$preStart$2(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$3/Master$$anonfun$preStart$3(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$1/Master$$anonfun$preStart$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/webUi()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterPublicAddress()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/createPersistenceEngine()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/createPersistenceEngine()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+constructor:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/FileSystemRecoveryModeFactory(org.apache.spark.SparkConf,akka.serialization.Serialization)|",
      "|java+method:///org/apache/spark/deploy/master/Master/context()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterWebUiUrl_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterSource()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/persistenceEngine_$eq(org.apache.spark.deploy.master.PersistenceEngine)|",
      "|java+method:///org/apache/spark/deploy/master/Master/leaderElectionAgent_$eq(org.apache.spark.deploy.master.LeaderElectionAgent)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/spark/deploy/master/Master/WORKER_TIMEOUT()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/ZooKeeperRecoveryModeFactory(org.apache.spark.SparkConf,akka.serialization.Serialization)|",
      "|java+constructor:///org/apache/spark/deploy/master/MonarchyLeaderAgent/MonarchyLeaderAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/master/StandaloneRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/millis()|",
      "|java+method:///org/apache/spark/deploy/master/Master/conf()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$applicationMetricsSystem()|",
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/RECOVERY_MODE()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterMetricsSystem()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/bind()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///org/apache/spark/deploy/master/StandaloneRecoveryModeFactory/createPersistenceEngine()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$WORKER_TIMEOUT()|",
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$3/Master$$anonfun$3(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$4/Master$$anonfun$preStart$4(org.apache.spark.deploy.master.Master)|",
      "|java+method:///akka/serialization/SerializationExtension$/apply(akka.actor.ActorSystem)|",
      "|java+constructor:///org/apache/spark/deploy/master/BlackHolePersistenceEngine/BlackHolePersistenceEngine()|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$2/Master$$anonfun$preStart$2(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$3/Master$$anonfun$preStart$3(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$preStart$1/Master$$anonfun$preStart$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/boundPort()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterPublicAddress()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/createPersistenceEngine()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/createPersistenceEngine()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+constructor:///org/apache/spark/deploy/master/FileSystemRecoveryModeFactory/FileSystemRecoveryModeFactory(org.apache.spark.SparkConf,akka.serialization.Serialization)|",
      "|java+method:///org/apache/spark/deploy/master/Master/context()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$persistenceEngine_$eq(org.apache.spark.deploy.master.PersistenceEngine)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$masterWebUiUrl_$eq(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterSource()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/leaderElectionAgent_$eq(org.apache.spark.deploy.master.LeaderElectionAgent)|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperRecoveryModeFactory/ZooKeeperRecoveryModeFactory(org.apache.spark.SparkConf,akka.serialization.Serialization)|",
      "|java+constructor:///org/apache/spark/deploy/master/MonarchyLeaderAgent/MonarchyLeaderAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/master/StandaloneRecoveryModeFactory/createLeaderElectionAgent(org.apache.spark.deploy.master.LeaderElectable)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/millis()|",
      "|java+method:///org/apache/spark/deploy/master/Master/conf()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$webUi()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobIds()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$apply$5/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$apply$5(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3,int)|",
      "|java+method:///scala/collection/mutable/HashSet/isEmpty()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/removeStage$1(int)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobIds()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/removeStage$1(int)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$apply$4/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$apply$4(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3,int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,java.lang.Class)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf,scala.Option)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopFile$3/PairRDDFunctions$$anonfun$saveAsHadoopFile$3(org.apache.spark.rdd.PairRDDFunctions,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/ApplicationPage$$anonfun$5(org.apache.spark.deploy.master.ui.ApplicationPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/countApproxDistinct(int,int)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/aggregate(java.lang.Object,scala.Function2,scala.Function2,scala.reflect.ClassTag)|",
      "|java+constructor:///com/clearspring/analytics/stream/cardinality/HyperLogLogPlus/HyperLogLogPlus(int,int)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$3/RDD$$anonfun$countApproxDistinct$3(org.apache.spark.rdd.RDD,int,int)|",
      "|java+method:///com/clearspring/analytics/stream/cardinality/HyperLogLogPlus/cardinality()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/RDD$$anonfun$countApproxDistinct$1(org.apache.spark.rdd.RDD,int)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/RDD$$anonfun$countApproxDistinct$2(org.apache.spark.rdd.RDD,int)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$4/RDD$$anonfun$countApproxDistinct$4(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$5/RDD$$anonfun$countApproxDistinct$5(org.apache.spark.rdd.RDD)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$1/RDD$$anonfun$countApproxDistinct$1(org.apache.spark.rdd.RDD,int,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master/removeApplication(org.apache.spark.deploy.master.ApplicationInfo,scala.Enumeration$Value)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/actorToApp()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$2/Master$$anonfun$removeApplication$2(org.apache.spark.deploy.master.Master)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$schedule()|",
      "|java+method:///org/apache/spark/deploy/master/Master/RETAINED_APPLICATIONS()|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingApps()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///org/apache/spark/deploy/master/Master/rebuildSparkUI(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$1/Master$$anonfun$removeApplication$1(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/markFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/driver()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/size()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/trimStart(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/FINISHED()|",
      "|java+method:///org/apache/spark/deploy/master/Master/idToApp()|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$4/Master$$anonfun$removeApplication$4(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/math/package$/max(int,int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+method:///org/apache/spark/deploy/master/Master/addressToApp()|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/take(int)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///akka/actor/ActorPath/address()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ApplicationRemoved/DeployMessages$ApplicationRemoved(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$3/Master$$anonfun$removeApplication$3(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/completedApps()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/removeApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/persistenceEngine()|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ResizableArray/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/actorToApp()|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$addressToApp()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/master/Master/RETAINED_APPLICATIONS()|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingApps()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/rebuildSparkUI(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$1/Master$$anonfun$removeApplication$1(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/markFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/driver()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/size()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/trimStart(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/FINISHED()|",
      "|java+method:///org/apache/spark/deploy/master/Master/idToApp()|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$4/Master$$anonfun$removeApplication$4(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/math/package$/max(int,int)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/take(int)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///akka/actor/ActorPath/address()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ApplicationRemoved/DeployMessages$ApplicationRemoved(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$3/Master$$anonfun$removeApplication$3(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$2/Master$$anonfun$removeApplication$2(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$completedApps()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$persistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$schedule()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/removeApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ResizableArray/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/ClientArguments/parse(scala.collection.immutable.List)|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments$/isValidJarUrl(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverId_$eq(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/MemoryParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cores_$eq(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/memory_$eq(int)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/master_$eq(java.lang.String)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/_driverOptions()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/supervise_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/logLevel_$eq(org.apache.log4j.Level)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/printUsageAndExit(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cmd_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/jarUrl_$eq(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments$/isValidJarUrl(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverId_$eq(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/masters_$eq(java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/util/MemoryParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cores_$eq(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/parseStandaloneMasterUrls(java.lang.String)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/memory_$eq(int)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/_driverOptions()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/supervise_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/logLevel_$eq(org.apache.log4j.Level)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/printUsageAndExit(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cmd_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/jarUrl_$eq(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$2/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$2/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$2/apply()|",
      "|java+method:///org/apache/spark/serializer/SerializationStream/writeAll(scala.collection.Iterator,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$3/SparkContext$$anonfun$3(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcV$sp/AbstractFunction0$mcV$sp()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/rest/CreateSubmissionRequest$$anonfun$assertPropertyIsNumeric$1/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/rest/CreateSubmissionRequest$$anonfun$assertPropertyIsNumeric$1/apply(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/rest/CreateSubmissionRequest$$anonfun$assertPropertyIsNumeric$1/apply(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/registerWithMaster()|",
    "called": "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
    "v1Body": [
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/context()|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1/AppClient$ClientActor$$anonfun$registerWithMaster$1(org.apache.spark.deploy.client.AppClient$ClientActor,scala.runtime.IntRef)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/REGISTRATION_TIMEOUT()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/registrationRetryTimer_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|"
    ],
    "v2Body": [
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/context()|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/registrationRetryTimer_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1/AppClient$ClientActor$$anonfun$registerWithMaster$1(org.apache.spark.deploy.client.AppClient$ClientActor,scala.runtime.IntRef)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$REGISTRATION_TIMEOUT()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$6/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$6/apply(scala.Tuple2)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$6/apply(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/createTachyonDirs()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$1/TachyonBlockManager$$anonfun$createTachyonDirs$1(org.apache.spark.storage.TachyonBlockManager)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2/TachyonBlockManager$$anonfun$createTachyonDirs$2(org.apache.spark.storage.TachyonBlockManager,java.text.SimpleDateFormat)|",
      "|java+constructor:///java/text/SimpleDateFormat/SimpleDateFormat(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$1/TachyonBlockManager$$anonfun$createTachyonDirs$1(org.apache.spark.storage.TachyonBlockManager)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/rootDirs()|",
      "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2/TachyonBlockManager$$anonfun$createTachyonDirs$2(org.apache.spark.storage.TachyonBlockManager,java.text.SimpleDateFormat)|",
      "|java+constructor:///java/text/SimpleDateFormat/SimpleDateFormat(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitStage(org.apache.spark.scheduler.Stage)|",
    "called": "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/collection/mutable/HashSet/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$activeJobForStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks(org.apache.spark.scheduler.Stage,int)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$2(org.apache.spark.scheduler.DAGScheduler,scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/DAGScheduler$$anonfun$12(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getMissingParentStages(org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/collection/mutable/HashSet/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$activeJobForStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/collection/immutable/List/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks(org.apache.spark.scheduler.Stage,int)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$2(org.apache.spark.scheduler.DAGScheduler,scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$13/DAGScheduler$$anonfun$13(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getMissingParentStages(org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$9/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$9/apply(org.apache.spark.scheduler.ActiveJob)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$9/apply(org.apache.spark.scheduler.ActiveJob)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/taskInfoFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$54/JsonProtocol$$anonfun$54()|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/finishTime_$eq(long)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$8/JsonProtocol$$anonfun$8()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extractOpt(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/failed_$eq(boolean)|",
      "|java+method:///scala/reflect/ManifestFactory$/Boolean()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/withName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskInfoFromJson$1/JsonProtocol$$anonfun$taskInfoFromJson$1(org.apache.spark.scheduler.TaskInfo)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskInfo/TaskInfo(long,int,int,long,java.lang.String,java.lang.String,scala.Enumeration$Value,boolean)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$9/JsonProtocol$$anonfun$9()|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/gettingResultTime_$eq(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$59/JsonProtocol$$anonfun$59()|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/finishTime_$eq(long)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$8/JsonProtocol$$anonfun$8()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extractOpt(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/failed_$eq(boolean)|",
      "|java+method:///scala/reflect/ManifestFactory$/Boolean()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/withName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskInfoFromJson$1/JsonProtocol$$anonfun$taskInfoFromJson$1(org.apache.spark.scheduler.TaskInfo)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskInfo/TaskInfo(long,int,int,long,java.lang.String,java.lang.String,scala.Enumeration$Value,boolean)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$9/JsonProtocol$$anonfun$9()|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/gettingResultTime_$eq(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster$$anonfun$updateBlockInfo$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster$$anonfun$updateBlockInfo$1/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster$$anonfun$updateBlockInfo$1/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/deleteRecursively(tachyon.client.TachyonFile,tachyon.client.TachyonFS)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFile/getPath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///tachyon/client/TachyonFS/delete(java.lang.String,boolean)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFile/getPath()|",
      "|java+method:///tachyon/client/TachyonFS/delete(tachyon.TachyonURI,boolean)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/apply()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/jvmGCTime()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/TaskInfo/finished()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/applicationStartToJson(org.apache.spark.scheduler.SparkListenerApplicationStart)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$6/JsonProtocol$$anonfun$applicationStartToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$4/JsonProtocol$$anonfun$applicationStartToJson$4()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$2/JsonProtocol$$anonfun$applicationStartToJson$2()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$5/JsonProtocol$$anonfun$applicationStartToJson$5()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$3/JsonProtocol$$anonfun$applicationStartToJson$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$1/JsonProtocol$$anonfun$applicationStartToJson$1()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$8/JsonProtocol$$anonfun$applicationStartToJson$8()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$6/JsonProtocol$$anonfun$applicationStartToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$4/JsonProtocol$$anonfun$applicationStartToJson$4()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$2/JsonProtocol$$anonfun$applicationStartToJson$2()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$7/JsonProtocol$$anonfun$applicationStartToJson$7()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$5/JsonProtocol$$anonfun$applicationStartToJson$5()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$3/JsonProtocol$$anonfun$applicationStartToJson$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$applicationStartToJson$1/JsonProtocol$$anonfun$applicationStartToJson$1()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$max$1/RDD$$anonfun$max$1(org.apache.spark.rdd.RDD,scala.math.Ordering)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$defaultSparkProperties$1$$anonfun$apply$1/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$defaultSparkProperties$1/org$apache$spark$deploy$SparkSubmitArguments$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printWarning(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printStream()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/verbose()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$defaultSparkProperties$1/org$apache$spark$deploy$SparkSubmitArguments$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printStream()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/verbose()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$4/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$4/apply()|",
      "|java+method:///org/apache/spark/SparkConf/toDebugString()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$4/apply()|",
      "|java+method:///org/apache/spark/package$/SPARK_VERSION()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/TestClient$/main(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+constructor:///org/apache/spark/deploy/client/TestClient$TestListener/TestClient$TestListener()|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription$/$lessinit$greater$default$6()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription$/$lessinit$greater$default$7()|",
      "|java+method:///akka/actor/ActorSystem/awaitTermination()|",
      "|java+constructor:///org/apache/spark/deploy/ApplicationDescription/ApplicationDescription(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient/AppClient(akka.actor.ActorSystem,java.lang.String%5B%5D,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.client.AppClientListener,org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/util/Utils$/localIpAddress()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/start()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+constructor:///org/apache/spark/deploy/ApplicationDescription/ApplicationDescription(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient/AppClient(akka.actor.ActorSystem,java.lang.String%5B%5D,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.client.AppClientListener,org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/deploy/client/TestClient$TestListener/TestClient$TestListener()|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/start()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription$/$lessinit$greater$default$6()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription$/$lessinit$greater$default$7()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription$/$lessinit$greater$default$8()|",
      "|java+method:///akka/actor/ActorSystem/awaitTermination()|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$13/AllJobsPage$$anonfun$13(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$/fetch(int,int,org.apache.spark.TaskContext,org.apache.spark.serializer.Serializer)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$4/BlockStoreShuffleFetcher$$anonfun$fetch$4(scala.collection.mutable.HashMap)|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockFetcherIterator/flatMap(scala.Function1)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$2/BlockStoreShuffleFetcher$$anonfun$fetch$2(int,int,long)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$1/BlockStoreShuffleFetcher$$anonfun$fetch$1(int,int)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$1/BlockStoreShuffleFetcher$$anonfun$1(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/MapOutputTracker/getServerStatuses(int,int)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$2/BlockStoreShuffleFetcher$$anonfun$2(int,int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/withFilter(scala.Function1)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/spark/storage/ShuffleBlockFetcherIterator/ShuffleBlockFetcherIterator(org.apache.spark.TaskContext,org.apache.spark.network.shuffle.ShuffleClient,org.apache.spark.storage.BlockManager,scala.collection.Seq,org.apache.spark.serializer.Serializer,long)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$3/BlockStoreShuffleFetcher$$anonfun$3(int,scala.Tuple2%5B%5D)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+method:///scala/collection/mutable/HashMap/toSeq()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anon$1/BlockStoreShuffleFetcher$$anon$1(org.apache.spark.TaskContext,org.apache.spark.util.CompletionIterator)|",
      "|java+method:///org/apache/spark/storage/BlockManager/shuffleClient()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/util/CompletionIterator$/apply(scala.collection.Iterator,scala.Function0)|",
      "|java+method:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$/logDebug(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$3/BlockStoreShuffleFetcher$$anonfun$fetch$3()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$4/BlockStoreShuffleFetcher$$anonfun$fetch$4(scala.collection.mutable.HashMap)|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockFetcherIterator/flatMap(scala.Function1)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$2/BlockStoreShuffleFetcher$$anonfun$fetch$2(int,int,long)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$1/BlockStoreShuffleFetcher$$anonfun$fetch$1(int,int)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$1/BlockStoreShuffleFetcher$$anonfun$1(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/MapOutputTracker/getServerStatuses(int,int)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$2/BlockStoreShuffleFetcher$$anonfun$2(int,int)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/spark/storage/ShuffleBlockFetcherIterator/ShuffleBlockFetcherIterator(org.apache.spark.TaskContext,org.apache.spark.network.shuffle.ShuffleClient,org.apache.spark.storage.BlockManager,scala.collection.Seq,org.apache.spark.serializer.Serializer,long)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$3/BlockStoreShuffleFetcher$$anonfun$3(int,scala.Tuple2%5B%5D)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+method:///scala/collection/mutable/HashMap/toSeq()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anon$1/BlockStoreShuffleFetcher$$anon$1(org.apache.spark.TaskContext,org.apache.spark.util.CompletionIterator)|",
      "|java+method:///org/apache/spark/storage/BlockManager/shuffleClient()|",
      "|java+method:///scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsMb(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/withFilter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/util/CompletionIterator$/apply(scala.collection.Iterator,scala.Function0)|",
      "|java+method:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$/logDebug(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/shuffle/hash/BlockStoreShuffleFetcher$$anonfun$fetch$3/BlockStoreShuffleFetcher$$anonfun$fetch$3()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$54/JsonProtocol$$anonfun$54()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/MapOutputTracker/MapOutputTracker(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/retryWaitMs(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/numRetries(org.apache.spark.SparkConf)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/treeAggregate(java.lang.Object,scala.Function2,scala.Function2,int,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$29/RDD$$anonfun$29(org.apache.spark.rdd.RDD,scala.Function1)|",
      "|java+method:///org/apache/spark/util/Utils$/clone(java.lang.Object,org.apache.spark.serializer.SerializerInstance,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///scala/math/package$/ceil(double)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(org.apache.spark.Partitioner,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/values()|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/math/package$/max(int,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$28/RDD$$anonfun$28(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2,scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1/RDD$$anonfun$treeAggregate$1(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///scala/math/package$/pow(double,double)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$30/RDD$$anonfun$30(org.apache.spark.rdd.RDD,int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1/RDD$$anonfun$treeAggregate$1(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2,scala.Function2,int,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$5/apply()|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$5$$anonfun$apply$4/Utils$$anonfun$5$$anonfun$apply$4(org.apache.spark.util.Utils$$anonfun$5)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$5/apply()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$5/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/init(org.apache.spark.network.BlockDataManager)|",
    "called": "|java+method:///scala/Option/toList()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///scala/Option/toList()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslRpcHandler/SaslRpcHandler(org.apache.spark.network.server.RpcHandler,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///scala/Option/toList()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/createServer(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions/countAsync()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/AsyncRDDActions$$anonfun$countAsync$1(org.apache.spark.rdd.AsyncRDDActions,java.util.concurrent.atomic.AtomicLong)|",
      "|java+method:///scala/package$/Range()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$3/AsyncRDDActions$$anonfun$countAsync$3(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$2/AsyncRDDActions$$anonfun$countAsync$2(org.apache.spark.rdd.AsyncRDDActions,java.util.concurrent.atomic.AtomicLong)|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicLong/AtomicLong()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/AsyncRDDActions$$anonfun$countAsync$1(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/MapOutputTracker/sendTracker(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/MapOutputTracker/askTracker(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/MapOutputTracker/askTracker(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/sampleByKey(boolean,scala.collection.Map,long)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Iterable/forall(scala.Function1)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKey$2/PairRDDFunctions$$anonfun$sampleByKey$2(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/util/random/StratifiedSamplingUtils$/getPoissonSamplingFunction(org.apache.spark.rdd.RDD,scala.collection.Map,boolean,long,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Map/values()|",
      "|java+method:///org/apache/spark/util/random/StratifiedSamplingUtils$/getBernoulliSamplingFunction(org.apache.spark.rdd.RDD,scala.collection.Map,boolean,long)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKey$1/PairRDDFunctions$$anonfun$sampleByKey$1(org.apache.spark.rdd.PairRDDFunctions)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$sampleByKey$1/PairRDDFunctions$$anonfun$sampleByKey$1(org.apache.spark.rdd.PairRDDFunctions,boolean,scala.collection.Map,long)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter/writePartitionedFile(org.apache.spark.storage.BlockId,org.apache.spark.TaskContext,java.io.File)|",
    "called": "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionedIterator()|",
      "|java+method:///scala/Option/filter(scala.Function1)|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incDiskBytesSpilled(long)|",
      "|java+method:///java/io/FileInputStream/close()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incMemoryBytesSpilled(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File,boolean)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/collection/Iterator/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/diskBytesSpilled()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$1/ExternalSorter$$anonfun$writePartitionedFile$1(org.apache.spark.util.collection.ExternalSorter,long%5B%5D,scala.runtime.ObjectRef,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spillToPartitionFiles(org.apache.spark.util.collection.SizeTrackingPairCollection)|",
      "|java+method:///scala/collection/Iterator/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/memoryBytesSpilled()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/lang/System/nanoTime()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$7/ExternalSorter$$anonfun$writePartitionedFile$7(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$2/ExternalSorter$$anonfun$writePartitionedFile$2(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$4/ExternalSorter$$anonfun$writePartitionedFile$4(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$6/ExternalSorter$$anonfun$writePartitionedFile$6(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$5/ExternalSorter$$anonfun$writePartitionedFile$5(org.apache.spark.util.collection.ExternalSorter,org.apache.spark.storage.BlockId,org.apache.spark.TaskContext,java.io.File,long%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$partitionWriters()|",
      "|java+method:///java/io/FileOutputStream/close()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$3/ExternalSorter$$anonfun$writePartitionedFile$3(org.apache.spark.util.collection.ExternalSorter,long)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/commitAndClose()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///java/lang/System/nanoTime()|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spills()|",
      "|java+method:///scala/Option/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedPairCollection/destructiveSortedWritablePartitionedIterator(scala.Option)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$2/ExternalSorter$$anonfun$writePartitionedFile$2(org.apache.spark.util.collection.ExternalSorter,org.apache.spark.TaskContext,java.io.FileOutputStream,long)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incMemoryBytesSpilled(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$partitionWriters()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File,boolean)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedIterator/hasNext()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$fileBufferSize()|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedIterator/writeNext(org.apache.spark.storage.BlockObjectWriter)|",
      "|java+method:///scala/collection/Iterator/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/diskBytesSpilled()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/fileSegment()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionedIterator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///scala/collection/Iterator/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/memoryBytesSpilled()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedIterator/nextPartition()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spillToPartitionFiles(org.apache.spark.util.collection.WritablePartitionedPairCollection)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$7/ExternalSorter$$anonfun$writePartitionedFile$7(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$4/ExternalSorter$$anonfun$writePartitionedFile$4(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$6/ExternalSorter$$anonfun$writePartitionedFile$6(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$3/ExternalSorter$$anonfun$writePartitionedFile$3(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$5/ExternalSorter$$anonfun$writePartitionedFile$5(org.apache.spark.util.collection.ExternalSorter,org.apache.spark.storage.BlockId,org.apache.spark.TaskContext,java.io.File,long%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$1/ExternalSorter$$anonfun$writePartitionedFile$1(org.apache.spark.util.collection.ExternalSorter,long%5B%5D,java.io.FileOutputStream)|",
      "|java+method:///org/apache/spark/storage/FileSegment/length()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incDiskBytesSpilled(long)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/isEmpty()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/comparator()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.SerializerInstance,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$34/StagePage$$anonfun$34(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$10/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$10/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$10/apply(org.apache.spark.scheduler.ActiveJob)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ExecutorAllocationManager/ExecutorAllocationManager(org.apache.spark.ExecutorAllocationClient,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///java/util/concurrent/Executors/newSingleThreadScheduledExecutor(java.util.concurrent.ThreadFactory)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/validateSettings()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeout()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/util/SystemClock/SystemClock()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$ExecutorAllocationListener/ExecutorAllocationManager$ExecutorAllocationListener(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$/NOT_SET()|",
      "|java+method:///org/apache/spark/util/Utils$/namedThreadFactory(java.lang.String)|"
    ],
    "v2Body": [
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeoutS()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$minNumExecutors()|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonSingleThreadScheduledExecutor(java.lang.String)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/validateSettings()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$ExecutorAllocationManagerSource/ExecutorAllocationManager$ExecutorAllocationManagerSource(org.apache.spark.ExecutorAllocationManager)|",
      "|java+constructor:///org/apache/spark/util/SystemClock/SystemClock()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$ExecutorAllocationListener/ExecutorAllocationManager$ExecutorAllocationListener(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$/NOT_SET()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsSeconds(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$3/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$3/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/sparkHome()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$3/apply()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$sparkHome()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/listener()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$11/StagePage$$anonfun$11(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$22/StagePage$$anonfun$22(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadRecords()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/TASK_DESERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/jobs/ExecutorTable/toNodeSeq()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$7/StagePage$$anonfun$7(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/GETTING_RESULT_TIME()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$12/StagePage$$anonfun$12(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$23/StagePage$$anonfun$23(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$9/StagePage$$anonfun$9(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasShuffleRead()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$8/StagePage$$anonfun$8(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasBytesSpilled()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SHUFFLE_READ_REMOTE_SIZE()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasOutput()|",
      "|java+method:///scala/collection/Seq/count(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/StagePage$$anonfun$13(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24/StagePage$$anonfun$24(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ()|",
      "|java+method:///scala/collection/IndexedSeq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteRecords()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/TASK_DESERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputRecords()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/StagePage$$anonfun$14(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25/StagePage$$anonfun$25(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$1/StagePage$$anonfun$render$1(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/RESULT_SERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/StagePage$$anonfun$15(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$2/StagePage$$anonfun$render$2(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26/StagePage$$anonfun$26(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedTimeQuantiles$1(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasShuffleWrite()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SCHEDULER_DELAY()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputRecords()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/StagePage$$anonfun$16(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/diskBytesSpilled()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27/StagePage$$anonfun$27(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/isEmpty()|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/unzip(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/RESULT_SERIALIZATION_TIME()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/StagePage$$anonfun$17(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$28/StagePage$$anonfun$28(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/ExecutorTable/ExecutorTable(int,int,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SHUFFLE_READ_BLOCKED_TIME()|",
      "|java+method:///scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SCHEDULER_DELAY()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/executorRunTime()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$18/StagePage$$anonfun$18(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteBytes()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$29/StagePage$$anonfun$29(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/memoryBytesSpilled()|",
      "|java+method:///scala/collection/IndexedSeq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/HashMap/size()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$3/StagePage$$anonfun$render$3(org.apache.spark.ui.jobs.StagePage,scala.xml.Elem)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$19/StagePage$$anonfun$19(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ_BLOCKED_TIME()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedSizeQuantiles$1(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/accumulables()|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$10/StagePage$$anonfun$10(org.apache.spark.ui.jobs.StagePage,boolean,boolean,boolean,boolean,boolean,boolean)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedSizeQuantilesWithRecords$1(scala.collection.Seq,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$30/StagePage$$anonfun$30(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$4/StagePage$$anonfun$render$4(org.apache.spark.ui.jobs.StagePage,scala.xml.NodeSeq)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$20/StagePage$$anonfun$20(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$31/StagePage$$anonfun$31(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/taskData()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasInput()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/GETTING_RESULT_TIME()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$21/StagePage$$anonfun$21(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/GC_TIME()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ_REMOTE_SIZE()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadTotalBytes()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$22/StagePage$$anonfun$22(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$33/StagePage$$anonfun$33(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadRecords()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/TASK_DESERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/jobs/ExecutorTable/toNodeSeq()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/GETTING_RESULT_TIME()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$23/StagePage$$anonfun$23(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$34/StagePage$$anonfun$34(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasShuffleRead()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/makeTimeline(scala.collection.Seq,long)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasBytesSpilled()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SHUFFLE_READ_REMOTE_SIZE()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasOutput()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/StagePage$$anonfun$13(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24/StagePage$$anonfun$24(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$35/StagePage$$anonfun$35(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ()|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///scala/collection/Seq/count(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/progressListener()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteRecords()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/TASK_DESERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputRecords()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/StagePage$$anonfun$14(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25/StagePage$$anonfun$25(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$36/StagePage$$anonfun$36(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$1/StagePage$$anonfun$render$1(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/showDagVizForStage(int,scala.Option)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/RESULT_SERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/StagePage$$anonfun$15(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$37/StagePage$$anonfun$37(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$2/StagePage$$anonfun$render$2(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26/StagePage$$anonfun$26(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedTimeQuantiles$1(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasShuffleWrite()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SCHEDULER_DELAY()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputRecords()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/diskBytesSpilled()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27/StagePage$$anonfun$27(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/isEmpty()|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/unzip(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/RESULT_SERIALIZATION_TIME()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/StagePage$$anonfun$17(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$28/StagePage$$anonfun$28(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/ExecutorTable/ExecutorTable(int,int,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/SHUFFLE_READ_BLOCKED_TIME()|",
      "|java+method:///scala/collection/Seq/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SCHEDULER_DELAY()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$4/StagePage$$anonfun$render$4(org.apache.spark.ui.jobs.StagePage,scala.xml.Elem)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/executorRunTime()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$18/StagePage$$anonfun$18(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteBytes()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$29/StagePage$$anonfun$29(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/memoryBytesSpilled()|",
      "|java+method:///scala/collection/mutable/HashMap/size()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$3/StagePage$$anonfun$render$3(org.apache.spark.ui.jobs.StagePage,scala.xml.Elem)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$19/StagePage$$anonfun$19(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/expandDagVizOnLoad(boolean)|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ_BLOCKED_TIME()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/StagePage$$anonfun$16(org.apache.spark.ui.jobs.StagePage,boolean,long,boolean,boolean,boolean,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedSizeQuantiles$1(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/accumulables()|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/scope/RDDOperationGraphListener/getOperationGraphForStage(int)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/getFormattedSizeQuantilesWithRecords$1(scala.collection.Seq,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$30/StagePage$$anonfun$30(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$20/StagePage$$anonfun$20(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$31/StagePage$$anonfun$31(org.apache.spark.ui.jobs.StagePage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$render$5/StagePage$$anonfun$render$5(org.apache.spark.ui.jobs.StagePage,scala.xml.NodeSeq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/taskData()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/hasInput()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$32/StagePage$$anonfun$32(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/spark/ui/jobs/TaskDetailsClassNames$/GETTING_RESULT_TIME()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$21/StagePage$$anonfun$21(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/GC_TIME()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///org/apache/spark/ui/ToolTips$/SHUFFLE_READ_REMOTE_SIZE()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadTotalBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/operationGraphListener()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/intersection(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$10/RDD$$anonfun$10(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions$default$4(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keys()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$9/RDD$$anonfun$9(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$8/RDD$$anonfun$8(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/filter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$1/RDD$$anonfun$intersection$1(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter/insertAll(scala.collection.Iterator)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/changeValue(java.lang.Object,scala.Function2)|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spillToPartitionFiles(scala.collection.Iterator)|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///scala/Product2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/maybeSpillCollection(boolean)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$5/ExternalSorter$$anonfun$5(org.apache.spark.util.collection.ExternalSorter,scala.Function2,scala.Function1,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/addElementsRead()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$getPartition(java.lang.Object)|",
      "|java+method:///org/apache/spark/Aggregator/createCombiner()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///scala/Product2/_1()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$insertAll$1/ExternalSorter$$anonfun$insertAll$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/Aggregator/mergeValue()|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingPairBuffer/insert(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+method:///org/apache/spark/util/collection/PartitionedAppendOnlyMap/changeValue(java.lang.Object,scala.Function2)|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///scala/Product2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/maybeSpillCollection(boolean)|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spillToPartitionFiles(org.apache.spark.util.collection.WritablePartitionedIterator)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$5/ExternalSorter$$anonfun$5(org.apache.spark.util.collection.ExternalSorter,scala.Function2,scala.Function1,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/addElementsRead()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$getPartition(java.lang.Object)|",
      "|java+method:///org/apache/spark/Aggregator/createCombiner()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedIterator$/fromIterator(scala.collection.Iterator)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedPairCollection/insert(int,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Product2/_1()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$insertAll$1/ExternalSorter$$anonfun$insertAll$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/Aggregator/mergeValue()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/offsetBytes(scala.collection.Seq,long,long)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$1/Utils$$anonfun$offsetBytes$1(scala.collection.immutable.Map)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+constructor:///java/lang/StringBuffer/StringBuffer(int)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2/Utils$$anonfun$offsetBytes$2(long,long,scala.collection.immutable.Map,java.lang.StringBuffer,scala.runtime.LongRef)|",
      "|java+method:///java/lang/StringBuffer/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/Seq/sum(scala.math.Numeric)|",
      "|java+method:///scala/math/package$/min(long,long)|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$7/Utils$$anonfun$7()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$1/Utils$$anonfun$offsetBytes$1(scala.collection.immutable.Map)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+constructor:///java/lang/StringBuffer/StringBuffer(int)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2/Utils$$anonfun$offsetBytes$2(long,long,scala.collection.immutable.Map,java.lang.StringBuffer,scala.runtime.LongRef)|",
      "|java+method:///java/lang/StringBuffer/toString()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$11/Utils$$anonfun$11()|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/Seq/sum(scala.math.Numeric)|",
      "|java+method:///scala/math/package$/min(long,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$1/MemoryStore$$anonfun$1(org.apache.spark.storage.MemoryStore)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcJ$sp/AbstractFunction0$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/ClientActor/pollAndReportStatus(java.lang.String)|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/exception()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RequestDriverStatus/DeployMessages$RequestDriverStatus(java.lang.String)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/RUNNING()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/workerHostPort()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/masterActor()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/state()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorSelection)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/workerId()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/timeout()|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$pollAndReportStatus$1/ClientActor$$anonfun$pollAndReportStatus$1(org.apache.spark.deploy.ClientActor)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/found()|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///akka/pattern/AskableActorSelection$/$qmark$extension(akka.actor.ActorSelection,java.lang.Object,akka.util.Timeout)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/exception()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RequestDriverStatus/DeployMessages$RequestDriverStatus(java.lang.String)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/RUNNING()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/org$apache$spark$deploy$ClientActor$$activeMasterActor()|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/workerHostPort()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/state()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorSelection)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/workerId()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/timeout()|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$pollAndReportStatus$1/ClientActor$$anonfun$pollAndReportStatus$1(org.apache.spark.deploy.ClientActor)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/found()|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///akka/pattern/AskableActorSelection$/$qmark$extension(akka.actor.ActorSelection,java.lang.Object,akka.util.Timeout)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/JobsTab/isFairScheduler()|",
    "called": "|java+method:///scala/Option/exists(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/listener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/Option/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobsTab$$anonfun$isFairScheduler$1/JobsTab$$anonfun$isFairScheduler$1(org.apache.spark.ui.jobs.JobsTab)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/jobProgresslistener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/Option/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobsTab$$anonfun$isFairScheduler$1/JobsTab$$anonfun$isFairScheduler$1(org.apache.spark.ui.jobs.JobsTab)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/actorSystem()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverActor_$eq(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$start$1/CoarseGrainedSchedulerBackend$$anonfun$start$1(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/withFilter(scala.Function1)|",
      "|java+method:///akka/actor/Props$/apply(scala.Function0,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/sc()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$start$2/CoarseGrainedSchedulerBackend$$anonfun$start$2(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend,scala.collection.mutable.ArrayBuffer)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$start$3/CoarseGrainedSchedulerBackend$$anonfun$start$3(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/rpcEnv()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/sc()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$start$1/CoarseGrainedSchedulerBackend$$anonfun$start$1(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$DriverEndpoint/CoarseGrainedSchedulerBackend$DriverEndpoint(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend,org.apache.spark.rpc.RpcEnv,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$start$2/CoarseGrainedSchedulerBackend$$anonfun$start$2(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverEndpoint_$eq(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+method:///scala/collection/mutable/ArrayOps/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/union(scala.collection.Seq,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/collection/Seq$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$29/SparkContext$$anonfun$29(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/toSet()|",
      "|java+method:///scala/collection/immutable/Set/size()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD/PartitionerAwareUnionRDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/UnionRDD/UnionRDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$union$1/SparkContext$$anonfun$union$1(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/isEmpty()|",
    "called": "|java+method:///scala/runtime/ScalaRunTime$/array_length(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/runtime/ScalaRunTime$/array_length(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/take(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$isEmpty$1/RDD$$anonfun$isEmpty$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$85/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$85/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$85/apply(org.apache.spark.executor.TaskMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$copyStream$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$copyStream$1/apply()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$copyStream$1/apply$mcJ$sp()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$copyStream$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$2/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$2/apply()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$unrollMemoryThreshold()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$2/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$31/StagePage$$anonfun$31(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$11/MasterPage$$anonfun$11(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend$class/$init$(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/SparkConf/getDouble(java.lang.String,double)|",
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend$class/$init$(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3$$anonfun$apply$2/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3$$anonfun$apply$2(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3,java.lang.String,long)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$currentFiles()|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$hadoopConf$1(scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$currentFiles()|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3$$anonfun$apply$3/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3$$anonfun$apply$3(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3,java.lang.String,long)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$hadoopConf$1(scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$44/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$44/apply(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$44/apply(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/AkkaUtils$/makeExecutorRef(java.lang.String,org.apache.spark.SparkConf,java.lang.String,int,akka.actor.ActorSystem)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/actorSelection(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/lookupTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///akka/actor/ActorSelection/resolveOne(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$makeExecutorRef$1/AkkaUtils$$anonfun$makeExecutorRef$1(java.lang.String,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/actorSelection(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/RpcUtils$/lookupTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///akka/actor/ActorSelection/resolveOne(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$makeExecutorRef$1/AkkaUtils$$anonfun$makeExecutorRef$1(java.lang.String,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/apply(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/apply(org.apache.spark.deploy.master.WorkerInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopDataset$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///java/lang/Class/getSimpleName()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopDataset$1/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopDataset$1/apply$mcV$sp()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopDataset$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1/apply()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1/apply()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$5/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$5(org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+method:///org/apache/spark/ComplexFutureAction/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer(int)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$3/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$3(org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1,int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toSeq()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$2/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$2(org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$4/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$4(org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1,java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/size()|",
      "|java+method:///scala/collection/immutable/Range/size()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$/futureExecutionContext()|",
      "|java+method:///org/apache/spark/ComplexFutureAction/run(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/ComplexFutureAction/ComplexFutureAction()|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1/apply()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$10/AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$10(org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1,org.apache.spark.ComplexFutureAction)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/DAGScheduler$$anonfun$handleTaskCompletion$14(org.apache.spark.scheduler.DAGScheduler)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/getLog(java.lang.String,java.lang.String,scala.Option,int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$2/LogPage$$anonfun$getLog$2(org.apache.spark.deploy.worker.ui.LogPage,long,long)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$8/LogPage$$anonfun$8(org.apache.spark.deploy.worker.ui.LogPage)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$1/LogPage$$anonfun$getLog$1(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String,java.lang.String,scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$4/LogPage$$anonfun$getLog$4(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$3/LogPage$$anonfun$getLog$3(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/offsetBytes(scala.collection.Seq,long,long)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$3/LogPage$$anonfun$3(org.apache.spark.deploy.worker.ui.LogPage,int,long)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender$/getSortedRolledOverFiles(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Exception/getMessage()|",
      "|java+method:///scala/math/package$/min(long,long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$2/LogPage$$anonfun$getLog$2(org.apache.spark.deploy.worker.ui.LogPage,long,long)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$8/LogPage$$anonfun$8(org.apache.spark.deploy.worker.ui.LogPage)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/immutable/Set/mkString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/Set/contains(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$1/LogPage$$anonfun$getLog$1(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String,java.lang.String,scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$4/LogPage$$anonfun$getLog$4(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$getLog$3/LogPage$$anonfun$getLog$3(org.apache.spark.deploy.worker.ui.LogPage,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/offsetBytes(scala.collection.Seq,long,long)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/LogPage$$anonfun$3/LogPage$$anonfun$3(org.apache.spark.deploy.worker.ui.LogPage,int,long)|",
      "|java+method:///org/apache/spark/util/logging/RollingFileAppender$/getSortedRolledOverFiles(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/LogPage/supportedLogTypes()|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Exception/getMessage()|",
      "|java+method:///scala/math/package$/min(long,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/sumApprox(long,double)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/partial/SumEvaluator/SumEvaluator(int,double)|",
      "|java+method:///org/apache/spark/SparkContext/runApproximateJob(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$2/DoubleRDDFunctions$$anonfun$2(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$sumApprox$1/DoubleRDDFunctions$$anonfun$sumApprox$1(org.apache.spark.rdd.DoubleRDDFunctions,long,double)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$17/JsonProtocol$$anonfun$17()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionedIterator()|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/isEmpty()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/SizeTrackingPairCollection/destructiveSortedIterator(java.util.Comparator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/merge(scala.collection.Seq,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spills()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionComparator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/partitionKeyComparator()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$partitionedIterator$1/ExternalSorter$$anonfun$partitionedIterator$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/groupByPartition(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$partitionWriters()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/isEmpty()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$keyComparator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/merge(scala.collection.Seq,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/buffer()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/map()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/spills()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$partitionedIterator$1/ExternalSorter$$anonfun$partitionedIterator$1(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/groupByPartition(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$partitionWriters()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$bypassMergeSort()|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/isEmpty()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/comparator()|",
      "|java+method:///org/apache/spark/util/collection/WritablePartitionedPairCollection/partitionedDestructiveSortedIterator(scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ContextCleaner/doCleanupBroadcast(long,boolean)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/unbroadcast(long,boolean,boolean)|",
      "|java+method:///org/apache/spark/ContextCleaner/broadcastManager()|",
      "|java+method:///org/apache/spark/ContextCleaner/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/ContextCleaner/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/ContextCleaner/listeners()|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$1/ContextCleaner$$anonfun$doCleanupBroadcast$1(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$4/ContextCleaner$$anonfun$doCleanupBroadcast$4(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$2/ContextCleaner$$anonfun$doCleanupBroadcast$2(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$3/ContextCleaner$$anonfun$doCleanupBroadcast$3(org.apache.spark.ContextCleaner,long)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ContextCleaner/logError(scala.Function0,java.lang.Throwable)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/unbroadcast(long,boolean,boolean)|",
      "|java+method:///org/apache/spark/ContextCleaner/broadcastManager()|",
      "|java+method:///org/apache/spark/ContextCleaner/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/ContextCleaner/listeners()|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$1/ContextCleaner$$anonfun$doCleanupBroadcast$1(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$4/ContextCleaner$$anonfun$doCleanupBroadcast$4(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$2/ContextCleaner$$anonfun$doCleanupBroadcast$2(org.apache.spark.ContextCleaner,long)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$3/ContextCleaner$$anonfun$doCleanupBroadcast$3(org.apache.spark.ContextCleaner,long)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ContextCleaner/logError(scala.Function0,java.lang.Throwable)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/ZippedPartitionsBaseRDD/getPartitions()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/ZippedPartitionsBaseRDD$$anonfun$getPartitions$1/ZippedPartitionsBaseRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.ZippedPartitionsBaseRDD,int)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedPartitionsBaseRDD$$anonfun$getPartitions$2/ZippedPartitionsBaseRDD$$anonfun$getPartitions$2(org.apache.spark.rdd.ZippedPartitionsBaseRDD)|",
      "|java+method:///scala/collection/Seq/forall(scala.Function1)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/ZippedPartitionsBaseRDD/rdds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedPartitionsBaseRDD$$anonfun$getPartitions$1/ZippedPartitionsBaseRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.ZippedPartitionsBaseRDD,int)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedPartitionsBaseRDD$$anonfun$getPartitions$2/ZippedPartitionsBaseRDD$$anonfun$getPartitions$2(org.apache.spark.rdd.ZippedPartitionsBaseRDD)|",
      "|java+method:///scala/collection/Seq/forall(scala.Function1)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/ZippedPartitionsBaseRDD/rdds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/sum()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$sum$1/DoubleRDDFunctions$$anonfun$sum$1(org.apache.spark.rdd.DoubleRDDFunctions)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$sum$1/DoubleRDDFunctions$$anonfun$sum$1(org.apache.spark.rdd.DoubleRDDFunctions)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1/applyOrElse(java.lang.Object,scala.Function1)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/keys()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$1()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$3()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchDriver/driverId()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/appId()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/CLEANUP_INTERVAL_MILLIS()|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/masterWebUiUrl()|",
      "|java+method:///scala/collection/mutable/HashMap/keys()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/CLEANUP_ENABLED()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$5()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/HEARTBEAT_MILLIS()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/start()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorkerFailed/message()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/activeMasterUrl()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy(java.lang.String,int,int,boolean,org.apache.spark.deploy.Command)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/appDirectories()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$7()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/webUi()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/connected()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registerWithMaster()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner/DriverRunner(org.apache.spark.SparkConf,java.lang.String,java.io.File,java.io.File,org.apache.spark.deploy.DriverDescription,akka.actor.ActorRef,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner/ExecutorRunner(java.lang.String,int,org.apache.spark.deploy.ApplicationDescription,int,int,akka.actor.ActorRef,java.lang.String,java.lang.String,int,java.lang.String,java.io.File,java.io.File,java.lang.String,org.apache.spark.SparkConf,scala.collection.Seq,scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/publicAddress()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/drivers()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/Iterable/toList()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/activeMasterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedExecutors()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/akkaUrl()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$WorkerStateResponse/DeployMessages$WorkerStateResponse(java.lang.String,int,java.lang.String,scala.collection.immutable.List,scala.collection.immutable.List,scala.collection.immutable.List,scala.collection.immutable.List,java.lang.String,int,int,int,int,java.lang.String)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$Heartbeat/DeployMessages$Heartbeat(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/LOADING()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/coresUsed()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/changeMaster(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/memoryUsed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/masterAddress()|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/sender()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/appId()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,scala.Option,scala.Option,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,scala.Option,scala.Option,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/driverId()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registered_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/exitStatus()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2/Worker$$anonfun$receiveWithLogging$1$$anonfun$2(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workerId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/kill()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/memory()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,akka.remote.DisassociatedEvent)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$2()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/cores()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriver/driverId()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedDrivers()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/cores()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ApplicationFinished/id()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$3()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchDriver/driverDesc()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/appDesc()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$4()|",
      "|java+method:///java/io/File/mkdirs()|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workDir()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/exception()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/memoryUsed()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/cores()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/start()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/sparkHome()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$/maybeUpdateSSLSettings(org.apache.spark.deploy.Command,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterUrl()|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/coresUsed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/state()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/message()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ReconnectWorker/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/master()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/DeployMessages$WorkerSchedulerStateResponse(java.lang.String,scala.collection.immutable.List,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registered()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/masterUrl()|",
      "|java+method:///scala/concurrent/package$/future(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$masterDisconnected()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$1()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$reregisterWithMaster()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/millis()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedApps()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/conf()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/kill()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$2()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$3()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchDriver/driverId()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/appId()|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/masterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$publicAddress()|",
      "|java+method:///scala/collection/mutable/HashMap/keys()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/command()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$master()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registered()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$5()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/FAILED()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorkerFailed/message()|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/start()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy(java.lang.String,int,int,boolean,org.apache.spark.deploy.Command)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/appDirectories()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$7()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$akkaUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner/ExecutorRunner(java.lang.String,int,org.apache.spark.deploy.ApplicationDescription,int,int,akka.actor.ActorRef,java.lang.String,java.lang.String,int,java.lang.String,java.io.File,java.io.File,java.lang.String,org.apache.spark.SparkConf,scala.collection.Seq,scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/drivers()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/Iterable/toList()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$changeMaster(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$masterAddress()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/activeMasterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$HEARTBEAT_MILLIS()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedExecutors()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registerWithMaster()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registered_$eq(boolean)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$Heartbeat/DeployMessages$Heartbeat(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/LOADING()|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/coresUsed()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$WorkerStateResponse/DeployMessages$WorkerStateResponse(java.lang.String,int,java.lang.String,scala.collection.immutable.List,scala.collection.immutable.List,scala.collection.immutable.List,scala.collection.immutable.List,java.lang.String,int,int,int,int,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/memoryUsed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/execId()|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/sender()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/driverId()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,scala.Option,scala.Option,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,scala.Option,scala.Option,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,scala.Enumeration$Value)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/state()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$sparkHome()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/exitStatus()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2/Worker$$anonfun$receiveWithLogging$1$$anonfun$2(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/execId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/kill()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/memory()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/securityMgr()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$1()|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,int,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/cores()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriver/driverId()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$2()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,akka.remote.DisassociatedEvent)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedDrivers()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/cores()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ApplicationFinished/id()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$3()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchDriver/driverDesc()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/memory()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/appDesc()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/copy$default$4()|",
      "|java+method:///java/io/File/mkdirs()|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workDir()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/exception()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/memoryUsed()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/cores()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/start()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$/maybeUpdateSSLSettings(org.apache.spark.deploy.Command,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterUrl()|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$workerId()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/coresUsed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/state()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///java/lang/Exception/toString()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/message()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$CLEANUP_INTERVAL_MILLIS()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$CLEANUP_ENABLED()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ReconnectWorker/masterUrl()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/DeployMessages$WorkerSchedulerStateResponse(java.lang.String,scala.collection.immutable.List,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillExecutor/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner/DriverRunner(org.apache.spark.SparkConf,java.lang.String,java.io.File,java.io.File,org.apache.spark.deploy.DriverDescription,akka.actor.ActorRef,java.lang.String,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/concurrent/package$/future(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$masterDisconnected()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$activeMasterUrl()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$1()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$reregisterWithMaster()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/millis()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/finishedApps()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$LaunchExecutor/execId()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/conf()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/kill()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$webUi()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/copy$default$2()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$connected()|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$66/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$66/apply(org.apache.spark.executor.ShuffleReadMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$66/apply(org.apache.spark.executor.OutputMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$7/apply(java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$7$$anonfun$apply$1/SparkContext$$anonfun$7$$anonfun$apply$1(org.apache.spark.SparkContext$$anonfun$7)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$6/RDDPage$$anonfun$6(org.apache.spark.ui.storage.RDDPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/apply(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/jobsTable(scala.collection.Seq)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/exists(scala.Function1)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$4/AllJobsPage$$anonfun$4(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$jobsTable$1/AllJobsPage$$anonfun$jobsTable$1(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$jobsTable$1/AllJobsPage$$anonfun$jobsTable$1(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$13/AllJobsPage$$anonfun$13(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/FileSystemPersistenceEngine/serializeIntoFile(java.io.File,java.lang.Object)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/FileSystemPersistenceEngine/serialization()|",
      "|java+method:///akka/serialization/Serializer/toBinary(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///akka/serialization/Serialization/findSerializerFor(java.lang.Object)|",
      "|java+method:///java/io/FileOutputStream/close()|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///java/io/File/createNewFile()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/FileOutputStream/write(byte%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/FileSystemPersistenceEngine/serialization()|",
      "|java+method:///akka/serialization/Serializer/toBinary(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/deploy/master/FileSystemPersistenceEngine$$anonfun$serializeIntoFile$2/FileSystemPersistenceEngine$$anonfun$serializeIntoFile$2(org.apache.spark.deploy.master.FileSystemPersistenceEngine,java.io.FileOutputStream)|",
      "|java+method:///akka/serialization/Serialization/findSerializerFor(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///java/io/File/createNewFile()|",
      "|java+constructor:///org/apache/spark/deploy/master/FileSystemPersistenceEngine$$anonfun$serializeIntoFile$1/FileSystemPersistenceEngine$$anonfun$serializeIntoFile$1(org.apache.spark.deploy.master.FileSystemPersistenceEngine,byte%5B%5D,java.io.FileOutputStream)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$toLocalIterator$1/RDD$$anonfun$toLocalIterator$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/createDirectory(java.lang.String,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/io/File/mkdirs()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/MAX_DIR_CREATION_ATTEMPTS()|"
    ],
    "v2Body": [
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/io/File/getCanonicalFile()|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/io/File/mkdirs()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/MAX_DIR_CREATION_ATTEMPTS()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$sum$1/DoubleRDDFunctions$$anonfun$sum$1(org.apache.spark.rdd.DoubleRDDFunctions)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2$mcDDD$sp/AbstractFunction2$mcDDD$sp()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2$mcDDD$sp/AbstractFunction2$mcDDD$sp()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcD$sp/AbstractFunction0$mcD$sp()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/collectPartitions()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$collectPartitions$1/RDD$$anonfun$collectPartitions$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$collectPartitions$1/RDD$$anonfun$collectPartitions$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecutorInfo(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$3/MesosSchedulerBackend$$anonfun$createExecutorInfo$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$ExecutorInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$6/MesosSchedulerBackend$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/getYarnLocalDirs(org.apache.spark.SparkConf)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$5/Utils$$anonfun$5(org.apache.spark.SparkConf)|",
      "|java+method:///java/lang/String/isEmpty()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$6/Utils$$anonfun$6(org.apache.spark.SparkConf)|",
      "|java+method:///java/lang/String/isEmpty()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4/apply()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/Stage/isAvailable()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/numAvailableOutputs()|",
      "|java+method:///org/apache/spark/scheduler/Stage/numPartitions()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmit$/prepareSubmitEnvironment(org.apache.spark.deploy.SparkSubmitArguments)|",
    "called": "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/YARN()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/classIsLoadable(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$5/SparkSubmit$$anonfun$prepareSubmitEnvironment$5(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/STANDALONE()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$1/SparkSubmit$$anonfun$prepareSubmitEnvironment$1()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isSqlShell(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/files()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/LOCAL()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/childArgs()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/mergeFileLists(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printWarning(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores()|",
      "|java+constructor:///org/apache/spark/deploy/OptionAssigner/OptionAssigner(java.lang.String,int,int,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/CLIENT()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/useRest()|",
      "|java+method:///scala/collection/mutable/HashMap/withFilter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/mkString(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/isTesting()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$6/SparkSubmit$$anonfun$prepareSubmitEnvironment$6()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/supervise()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/childArgs_$eq(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars_$eq(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/ivyRepoPath()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/files_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveMavenCoordinates(java.lang.String,scala.Option,scala.Option,boolean)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$7/SparkSubmit$$anonfun$prepareSubmitEnvironment$7(scala.collection.mutable.HashMap)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/ALL_DEPLOY_MODES()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$8/SparkSubmit$$anonfun$prepareSubmitEnvironment$8(scala.collection.mutable.HashMap)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$3/SparkSubmit$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$2/SparkSubmit$$anonfun$2()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/repositories()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$4/SparkSubmit$$anonfun$4()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/CLUSTER()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$9/SparkSubmit$$anonfun$prepareSubmitEnvironment$9(scala.collection.mutable.HashMap)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/packages()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isStandaloneCluster()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master_$eq(java.lang.String)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/MESOS()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$2/SparkSubmit$$anonfun$prepareSubmitEnvironment$2(scala.collection.mutable.ArrayBuffer,scala.collection.mutable.HashMap,int,scala.runtime.IntRef)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/ALL_CLUSTER_MGRS()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/archives()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/SPARK_INTERNAL()|",
      "|java+method:///org/apache/spark/deploy/OptionAssigner$/apply$default$4()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isUserJar(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isShell(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/sparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/OptionAssigner$/apply$default$5()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isThriftServer(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/queue()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$3/SparkSubmit$$anonfun$prepareSubmitEnvironment$3(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory()|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths$default$2()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object,java.lang.Object,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveMavenCoordinates$default$4()|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+method:///scala/collection/mutable/ArrayOps/nonEmpty()|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/BufferLike/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$4/SparkSubmit$$anonfun$prepareSubmitEnvironment$4(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/PYSPARK_SHELL()|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/keytab()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/YARN()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/classIsLoadable(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$5/SparkSubmit$$anonfun$prepareSubmitEnvironment$5(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/STANDALONE()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/SPARKR_SHELL()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$1/SparkSubmit$$anonfun$prepareSubmitEnvironment$1()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$6/SparkSubmit$$anonfun$prepareSubmitEnvironment$6(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isSqlShell(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/files()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$7/SparkSubmit$$anonfun$prepareSubmitEnvironment$7(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/LOCAL()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/childArgs()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$3/SparkSubmit$$anonfun$prepareSubmitEnvironment$3(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printWarning(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores()|",
      "|java+constructor:///org/apache/spark/deploy/OptionAssigner/OptionAssigner(java.lang.String,int,int,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/CLIENT()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/useRest()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/collection/mutable/HashMap/withFilter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/mkString(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/isTesting()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/supervise()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/childArgs_$eq(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/mkString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars_$eq(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/ivyRepoPath()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/files_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveMavenCoordinates(java.lang.String,scala.Option,scala.Option,boolean)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$8/SparkSubmit$$anonfun$prepareSubmitEnvironment$8()|",
      "|java+method:///scala/collection/immutable/Map/contains(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$9/SparkSubmit$$anonfun$prepareSubmitEnvironment$9()|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/ALL_DEPLOY_MODES()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$3/SparkSubmit$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$2/SparkSubmit$$anonfun$2()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/repositories()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$4/SparkSubmit$$anonfun$4()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/CLUSTER()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isR()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$11/SparkSubmit$$anonfun$prepareSubmitEnvironment$11(scala.collection.mutable.HashMap)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$10/SparkSubmit$$anonfun$prepareSubmitEnvironment$10(scala.collection.mutable.HashMap)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$12/SparkSubmit$$anonfun$prepareSubmitEnvironment$12(scala.collection.mutable.HashMap)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/packages()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isStandaloneCluster()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master_$eq(java.lang.String)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/org$apache$spark$deploy$SparkSubmit$$mergeFileLists(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/MESOS()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/ALL_CLUSTER_MGRS()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/principal()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/archives()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/SPARK_INTERNAL()|",
      "|java+method:///org/apache/spark/deploy/OptionAssigner$/apply$default$4()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isUserJar(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$2/SparkSubmit$$anonfun$prepareSubmitEnvironment$2(scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isShell(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/sparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/OptionAssigner$/apply$default$5()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isThriftServer(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/queue()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmit$$anonfun$prepareSubmitEnvironment$4/SparkSubmit$$anonfun$prepareSubmitEnvironment$4(scala.collection.mutable.ArrayBuffer,scala.collection.mutable.HashMap,int,scala.runtime.IntRef)|",
      "|java+method:///scala/collection/Seq/mkString(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths$default$2()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object,java.lang.Object,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveMavenCoordinates$default$4()|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+method:///scala/collection/mutable/ArrayOps/nonEmpty()|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/collection/mutable/BufferLike/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/PYSPARK_SHELL()|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$6/AllJobsPage$$anonfun$6(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1/apply()|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatten(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1/apply()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$1/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$1(org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toSeq()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1/apply()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///scala/package$/Range()|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$7/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$7(org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1)|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$6/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$6(org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1,java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$8/AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$8(org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1,java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/applicationStartFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerApplicationStart/SparkListenerApplicationStart(java.lang.String,scala.Option,long,java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$47/JsonProtocol$$anonfun$47()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerApplicationStart/SparkListenerApplicationStart(java.lang.String,scala.Option,long,java.lang.String,scala.Option)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$50/JsonProtocol$$anonfun$50()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$49/JsonProtocol$$anonfun$49()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1/apply$mcVI$sp(int)|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/getLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/collection/mutable/ListBuffer/head()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue$default$2()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addMasters(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/masters()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$killLeader()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$getLeader()|",
      "|java+method:///scala/collection/mutable/ListBuffer/head()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue$default$2()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$masters()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addMasters(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/MasterPage$$anonfun$5(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/uri()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/hasDrivers$1(org.apache.spark.deploy.master.DriverInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$render$1/MasterPage$$anonfun$render$1(org.apache.spark.deploy.master.ui.MasterPage,scala.xml.NodeBuffer)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/restUri()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeApps()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$16/MasterPage$$anonfun$16(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$12/MasterPage$$anonfun$12(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$15/MasterPage$$anonfun$15(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$11/MasterPage$$anonfun$11(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$14/MasterPage$$anonfun$14(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$10/MasterPage$$anonfun$10(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$1/MasterPage$$anonfun$1(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$13/MasterPage$$anonfun$13(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/completedApps()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$2/MasterPage$$anonfun$2(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/MasterPage$$anonfun$3(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$4/MasterPage$$anonfun$4(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/timeout()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/completedDrivers()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///akka/pattern/AskableActorRef$/$qmark$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/master()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$6/MasterPage$$anonfun$6(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeDrivers()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/MasterPage$$anonfun$7(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$8/MasterPage$$anonfun$8(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/MasterPage$$anonfun$9(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/reverse()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/status()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/workers()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/MasterPage$$anonfun$5(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/uri()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/hasDrivers$1(org.apache.spark.deploy.master.DriverInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$render$1/MasterPage$$anonfun$render$1(org.apache.spark.deploy.master.ui.MasterPage,scala.xml.NodeBuffer)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/restUri()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeApps()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$16/MasterPage$$anonfun$16(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$12/MasterPage$$anonfun$12(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$15/MasterPage$$anonfun$15(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$11/MasterPage$$anonfun$11(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$14/MasterPage$$anonfun$14(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$10/MasterPage$$anonfun$10(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$17/MasterPage$$anonfun$17(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/getMasterState()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$13/MasterPage$$anonfun$13(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/completedApps()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$2/MasterPage$$anonfun$2(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/MasterPage$$anonfun$3(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$4/MasterPage$$anonfun$4(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/completedDrivers()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$6/MasterPage$$anonfun$6(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/activeDrivers()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/MasterPage$$anonfun$7(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$8/MasterPage$$anonfun$8(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/MasterPage$$anonfun$9(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/reverse()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/status()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/workers()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$9/AllJobsPage$$anonfun$9(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore/getBytes(java.io.File,long,long)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/channels/FileChannel/map(java.nio.channels.FileChannel$MapMode,long,long)|",
      "|java+method:///java/nio/channels/FileChannel/read(java.nio.ByteBuffer)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///java/io/RandomAccessFile/RandomAccessFile(java.io.File,java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/nio/channels/FileChannel/position(long)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/apache/spark/storage/DiskStore/minMemoryMapBytes()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/nio/channels/FileChannel/close()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/RandomAccessFile/getChannel()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///java/io/RandomAccessFile/RandomAccessFile(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$getBytes$2/DiskStore$$anonfun$getBytes$2(org.apache.spark.storage.DiskStore,java.io.File,long,long,java.nio.channels.FileChannel)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$getBytes$1/DiskStore$$anonfun$getBytes$1(org.apache.spark.storage.DiskStore,java.nio.channels.FileChannel)|",
      "|java+method:///java/io/RandomAccessFile/getChannel()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4(org.apache.spark.SparkConf$$anonfun$validateSettings$5,java.lang.String)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/makeRDD(scala.collection.Seq,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/collection/Seq$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///org/apache/spark/rdd/ParallelCollectionRDD/ParallelCollectionRDD(org.apache.spark.SparkContext,scala.collection.Seq,int,scala.collection.Map,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$26/SparkContext$$anonfun$26(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$makeRDD$1/SparkContext$$anonfun$makeRDD$1(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/Seq/size()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$makeRDD$2/SparkContext$$anonfun$makeRDD$2(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$19/JsonProtocol$$anonfun$19()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/RDDInfo$$anonfun$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/storage/RDDInfo$$anonfun$1/apply()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/RDDInfo$$anonfun$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/EventLoggingListener/start()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///java/io/OutputStream/close()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/IN_PROGRESS()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/hadoopDataStream()|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getDefaultUri(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$4/EventLoggingListener$$anonfun$4(org.apache.spark.scheduler.EventLoggingListener,java.io.OutputStream)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/hadoopDataStream_$eq(scala.Option)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/compressionCodec()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logWarning(scala.Function0)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/isDirectory(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logPath()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.net.URI)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/org$apache$spark$scheduler$EventLoggingListener$$LOG_FILE_PERMISSIONS()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$5/EventLoggingListener$$anonfun$5(org.apache.spark.scheduler.EventLoggingListener,java.io.OutputStream)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/outputBufferSize()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///java/io/BufferedOutputStream/BufferedOutputStream(java.io.OutputStream,int)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/initEventLog(java.io.OutputStream)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$start$1/EventLoggingListener$$anonfun$start$1(org.apache.spark.scheduler.EventLoggingListener,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/shouldOverwrite()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/writer_$eq(scala.Option)|",
      "|java+constructor:///java/io/PrintWriter/PrintWriter(java.io.OutputStream)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$start$2/EventLoggingListener$$anonfun$start$2(org.apache.spark.scheduler.EventLoggingListener)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/fileSystem()|"
    ],
    "v2Body": [
      "|java+method:///java/io/OutputStream/close()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/IN_PROGRESS()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/hadoopDataStream()|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getDefaultUri(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getFileStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logWarning(scala.Function0)|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/isDir()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$4/EventLoggingListener$$anonfun$4(org.apache.spark.scheduler.EventLoggingListener,java.io.OutputStream)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/hadoopDataStream_$eq(scala.Option)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/compressionCodec()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/logPath()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.net.URI)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/org$apache$spark$scheduler$EventLoggingListener$$LOG_FILE_PERMISSIONS()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$5/EventLoggingListener$$anonfun$5(org.apache.spark.scheduler.EventLoggingListener,java.io.OutputStream)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/outputBufferSize()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///java/io/BufferedOutputStream/BufferedOutputStream(java.io.OutputStream,int)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/initEventLog(java.io.OutputStream)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$start$1/EventLoggingListener$$anonfun$start$1(org.apache.spark.scheduler.EventLoggingListener,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/shouldOverwrite()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/writer_$eq(scala.Option)|",
      "|java+constructor:///java/io/PrintWriter/PrintWriter(java.io.OutputStream)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener$$anonfun$start$2/EventLoggingListener$$anonfun$start$2(org.apache.spark.scheduler.EventLoggingListener)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/fileSystem()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/afterEach()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/ZK_DIR()|",
      "|java+method:///org/apache/spark/deploy/master/SparkCuratorUtil$/deleteRecursive(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/sc_$eq(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/sc()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/zk()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/terminateCluster()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/ZK_DIR()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$sc_$eq(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$sc()|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/deleteRecursive(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/zk()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$terminateCluster()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/JettyUtils$/org$apache$spark$ui$JettyUtils$$connect$1(int,java.lang.String,org.spark-project.jetty.server.handler.ContextHandlerCollection)|",
    "called": "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/spark-project/jetty/server/Server/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/spark-project/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+method:///org/spark-project/jetty/server/Server/start()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/spark-project/jetty/server/Server/setThreadPool(org.spark-project.jetty.util.thread.ThreadPool)|",
      "|java+method:///org/spark-project/jetty/server/Server/getConnectors()|",
      "|java+constructor:///org/spark-project/jetty/server/Server/Server(java.net.InetSocketAddress)|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/stop()|",
      "|java+method:///org/spark-project/jetty/server/Connector/getLocalPort()|",
      "|java+method:///org/spark-project/jetty/server/Server/stop()|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/spark-project/jetty/server/handler/ErrorHandler/ErrorHandler()|",
      "|java+method:///org/spark-project/jetty/server/Server/setHandler(org.spark-project.jetty.server.Handler)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/spark-project/jetty/server/Server/start()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///java/net/InetSocketAddress/InetSocketAddress(java.lang.String,int)|",
      "|java+method:///org/spark-project/jetty/server/Server/setThreadPool(org.spark-project.jetty.util.thread.ThreadPool)|",
      "|java+method:///org/spark-project/jetty/server/Server/getConnectors()|",
      "|java+method:///org/spark-project/jetty/server/handler/ErrorHandler/setShowStacks(boolean)|",
      "|java+constructor:///org/spark-project/jetty/server/Server/Server(java.net.InetSocketAddress)|",
      "|java+method:///org/spark-project/jetty/server/Server/addBean(java.lang.Object)|",
      "|java+constructor:///org/spark-project/jetty/util/thread/QueuedThreadPool/QueuedThreadPool()|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/setDaemon(boolean)|",
      "|java+method:///org/spark-project/jetty/util/thread/QueuedThreadPool/stop()|",
      "|java+method:///org/spark-project/jetty/server/Connector/getLocalPort()|",
      "|java+method:///org/spark-project/jetty/server/Server/stop()|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$44/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$44$$anonfun$apply$9/JsonProtocol$$anonfun$44$$anonfun$apply$9(org.apache.spark.util.JsonProtocol$$anonfun$44)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$3/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$3/apply()|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$3/apply()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/name()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$51/StagePage$$anonfun$51(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/checkForLogs()|",
    "called": "|java+constructor:///scala/collection/mutable/LinkedHashMap/LinkedHashMap()|",
    "v1Body": [
      "|java+method:///scala/collection/Seq/iterator()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///scala/collection/BufferedIterator/next()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$1/FsHistoryProvider$$anonfun$checkForLogs$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$3/FsHistoryProvider$$anonfun$checkForLogs$3(org.apache.spark.deploy.history.FsHistoryProvider,scala.collection.mutable.LinkedHashMap)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$getMonotonicTimeMs()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$addIfAbsent$1(org.apache.spark.deploy.history.FsApplicationHistoryInfo,scala.collection.mutable.LinkedHashMap)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/BufferedIterator/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/LinkedHashMap/values()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$4/FsHistoryProvider$$anonfun$checkForLogs$4(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///scala/collection/mutable/LinkedHashMap/LinkedHashMap()|",
      "|java+method:///scala/collection/BufferedIterator/hasNext()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/applications()|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Iterator/buffered()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$5/FsHistoryProvider$$anonfun$5(org.apache.spark.deploy.history.FsHistoryProvider,scala.runtime.LongRef)|",
      "|java+method:///scala/collection/SeqLike/sortWith(scala.Function2)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$lastModifiedTime_$eq(long)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$lastLogCheckTimeMs_$eq(long)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$2/FsHistoryProvider$$anonfun$checkForLogs$2(org.apache.spark.deploy.history.FsHistoryProvider,scala.collection.mutable.LinkedHashMap)|",
      "|java+method:///scala/collection/BufferedIterator/head()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/applications_$eq(scala.collection.mutable.LinkedHashMap)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Iterable/iterator()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$lastModifiedTime()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$compareAppInfo(org.apache.spark.deploy.history.FsApplicationHistoryInfo,org.apache.spark.deploy.history.FsApplicationHistoryInfo)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$3/FsHistoryProvider$$anonfun$3(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$4/FsHistoryProvider$$anonfun$4(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$6/FsHistoryProvider$$anonfun$6(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$7/FsHistoryProvider$$anonfun$7(org.apache.spark.deploy.history.FsHistoryProvider)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Iterator/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$2/FsHistoryProvider$$anonfun$checkForLogs$2(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$checkForLogs$1/FsHistoryProvider$$anonfun$checkForLogs$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$7/FsHistoryProvider$$anonfun$7(org.apache.spark.deploy.history.FsHistoryProvider,scala.runtime.LongRef)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$lastModifiedTime()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/Seq/sliding(int,int)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/SeqLike/sortWith(scala.Function2)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$lastModifiedTime_$eq(long)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$5/FsHistoryProvider$$anonfun$5(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$6/FsHistoryProvider$$anonfun$6(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$8/FsHistoryProvider$$anonfun$8(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$9/FsHistoryProvider$$anonfun$9(org.apache.spark.deploy.history.FsHistoryProvider)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$7/apply(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$17/AllJobsPage$$anonfun$17(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/doPut(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockValues,org.apache.spark.storage.StorageLevel,boolean,scala.Option)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockInfo/markFailure()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$7/BlockManager$$anonfun$doPut$7(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/concurrent/duration/Duration$/Inf()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///java/nio/ByteBuffer/rewind()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/util/Left/a()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$3/BlockManager$$anonfun$doPut$3(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$6/BlockManager$$anonfun$doPut$6(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/PutResult/droppedBlocks()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$3/BlockManager$$anonfun$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel,java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$2/BlockManager$$anonfun$doPut$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$5/BlockManager$$anonfun$doPut$5(org.apache.spark.storage.BlockManager,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/storage/ByteBufferValues/buffer()|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/markReady(long)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/isValid()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$1/BlockManager$$anonfun$doPut$1(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/storage/PutResult/data()|",
      "|java+method:///scala/util/Right/b()|",
      "|java+method:///org/apache/spark/storage/BlockManager$/dispose(java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$9/BlockManager$$anonfun$9(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$9/BlockManager$$anonfun$doPut$9(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$8/BlockManager$$anonfun$doPut$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockManager/tachyonStore()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logTrace(scala.Function0)|",
      "|java+method:///java/nio/ByteBuffer/duplicate()|",
      "|java+constructor:///org/apache/spark/storage/BlockInfo/BlockInfo(org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$replicate(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/storage/IteratorValues/iterator()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerialize$default$3()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerialize(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/storage/ArrayValues/buffer()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/putIfAbsent(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Tuple2/_1$mcZ$sp()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$10/BlockManager$$anonfun$10(org.apache.spark.storage.BlockManager,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putIterator(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$4/BlockManager$$anonfun$doPut$4(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///scala/concurrent/Future$/apply(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$10/BlockManager$$anonfun$doPut$10(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/waitForReady()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/PutResult/size()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+constructor:///org/apache/spark/storage/BlockException/BlockException(org.apache.spark.storage.BlockId,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putArray(org.apache.spark.storage.BlockId,java.lang.Object%5B%5D,org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/replication()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/remove(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$7/BlockManager$$anonfun$doPut$7(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/concurrent/duration/Duration$/Inf()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///java/nio/ByteBuffer/rewind()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/util/Left/a()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$3/BlockManager$$anonfun$doPut$3(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$6/BlockManager$$anonfun$doPut$6(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/PutResult/droppedBlocks()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$3/BlockManager$$anonfun$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel,java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$2/BlockManager$$anonfun$doPut$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$5/BlockManager$$anonfun$doPut$5(org.apache.spark.storage.BlockManager,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/storage/ByteBufferValues/buffer()|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/markReady(long)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/isValid()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$1/BlockManager$$anonfun$doPut$1(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$8/BlockManager$$anonfun$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/PutResult/data()|",
      "|java+method:///scala/util/Right/b()|",
      "|java+method:///org/apache/spark/storage/BlockManager$/dispose(java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$9/BlockManager$$anonfun$doPut$9(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/markFailure()|",
      "|java+method:///org/apache/spark/storage/BlockManager/futureExecutionContext()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$8/BlockManager$$anonfun$doPut$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logTrace(scala.Function0)|",
      "|java+method:///java/nio/ByteBuffer/duplicate()|",
      "|java+constructor:///org/apache/spark/storage/BlockInfo/BlockInfo(org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$replicate(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/storage/IteratorValues/iterator()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerialize$default$3()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerialize(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/storage/ArrayValues/buffer()|",
      "|java+method:///org/apache/spark/storage/BlockManager/externalBlockStore()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/putIfAbsent(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Tuple2/_1$mcZ$sp()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putIterator(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$4/BlockManager$$anonfun$doPut$4(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///scala/concurrent/Future$/apply(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doPut$10/BlockManager$$anonfun$doPut$10(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,long)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/waitForReady()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/PutResult/size()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+constructor:///org/apache/spark/storage/BlockException/BlockException(org.apache.spark.storage.BlockId,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockStore/putArray(org.apache.spark.storage.BlockId,java.lang.Object%5B%5D,org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$9/BlockManager$$anonfun$9(org.apache.spark.storage.BlockManager,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/replication()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/remove(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master/rebuildSparkUI(org.apache.spark.deploy.master.ApplicationInfo)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/ReplayListenerBus/ReplayListenerBus()|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/replay(java.io.InputStream,java.lang.String)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/spark/ui/SparkUI$/createHistoryUI(org.apache.spark.SparkConf,org.apache.spark.scheduler.SparkListenerBus,org.apache.spark.SecurityManager,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/openEventLog(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)|",
      "|java+method:///org/apache/spark/deploy/master/Master/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/eventLogDir()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/IN_PROGRESS()|",
      "|java+method:///org/apache/spark/ui/SparkUI/basePath()|",
      "|java+method:///org/apache/spark/deploy/master/Master/hadoopConf()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/UI_PATH_PREFIX()|",
      "|java+method:///org/apache/spark/deploy/master/Master/webUi()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$13/Master$$anonfun$13(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo,java.lang.String,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/appIdToUI()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///java/net/URLEncoder/encode(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcZ$sp()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$12/Master$$anonfun$12(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///org/apache/spark/util/Utils$/getHadoopFileSystem(java.lang.String,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/util/Utils$/exceptionString(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/attachSparkUI(org.apache.spark.ui.SparkUI)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$3/Master$$anonfun$rebuildSparkUI$3(org.apache.spark.deploy.master.Master,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$2/Master$$anonfun$rebuildSparkUI$2(org.apache.spark.deploy.master.Master,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$1/Master$$anonfun$rebuildSparkUI$1(org.apache.spark.deploy.master.Master,scala.runtime.ObjectRef)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/master/Master/conf()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value()|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/eventLogDir()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$1/Master$$anonfun$rebuildSparkUI$1(org.apache.spark.deploy.master.Master,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/ReplayListenerBus/ReplayListenerBus()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$appIdToUI()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/IN_PROGRESS()|",
      "|java+method:///org/apache/spark/ui/SparkUI/basePath()|",
      "|java+method:///org/apache/spark/util/Utils$/getHadoopFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/deploy/master/Master/hadoopConf()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/eventLogCodec()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/UI_PATH_PREFIX()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$12/Master$$anonfun$12(org.apache.spark.deploy.master.Master,org.apache.spark.deploy.master.ApplicationInfo,java.lang.String,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl_$eq(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///java/net/URLEncoder/encode(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/replay(java.io.InputStream,java.lang.String,boolean)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/startTime()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/ui/SparkUI$/createHistoryUI(org.apache.spark.SparkConf,org.apache.spark.scheduler.SparkListenerBus,org.apache.spark.SecurityManager,java.lang.String,java.lang.String,long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/getLogPath(java.net.URI,java.lang.String,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/openEventLog(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)|",
      "|java+method:///org/apache/spark/util/Utils$/exceptionString(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/attachSparkUI(org.apache.spark.ui.SparkUI)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$3/Master$$anonfun$rebuildSparkUI$3(org.apache.spark.deploy.master.Master,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$rebuildSparkUI$2/Master$$anonfun$rebuildSparkUI$2(org.apache.spark.deploy.master.Master,scala.runtime.ObjectRef)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/master/Master/conf()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$webUi()|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$3/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$3/apply(org.apache.spark.deploy.master.ApplicationInfo)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$3/apply(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/AkkaUtils$/makeDriverRef(java.lang.String,org.apache.spark.SparkConf,akka.actor.ActorSystem)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/actorSelection(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/lookupTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///akka/actor/ActorSelection/resolveOne(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$makeDriverRef$1/AkkaUtils$$anonfun$makeDriverRef$1(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/actorSelection(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/RpcUtils$/lookupTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///akka/actor/ActorSelection/resolveOne(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$makeDriverRef$1/AkkaUtils$$anonfun$makeDriverRef$1(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$20/JsonProtocol$$anonfun$20()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$10/apply(java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$10$$anonfun$apply$2/SparkContext$$anonfun$10$$anonfun$apply$2(org.apache.spark.SparkContext$$anonfun$10)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$15/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$15/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$15/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/sample(boolean,double,long)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$sample$1/RDD$$anonfun$sample$1(org.apache.spark.rdd.RDD,double)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionwiseSampledRDD/PartitionwiseSampledRDD(org.apache.spark.rdd.RDD,org.apache.spark.util.random.RandomSampler,boolean,long,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/random/BernoulliSampler/BernoulliSampler(double,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/util/random/PoissonSampler/PoissonSampler(double,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$sample$1/RDD$$anonfun$sample$1(org.apache.spark.rdd.RDD,boolean,double,long)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/sortBy$default$3()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/HadoopRDD/HadoopRDD(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast,scala.Option,java.lang.Class,java.lang.Class,java.lang.Class,int)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///java/util/Date/Date()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/id()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///java/util/Date/Date()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$22/JsonProtocol$$anonfun$22()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner/kill()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$kill$1/DriverRunner$$anonfun$kill$1(org.apache.spark.deploy.worker.DriverRunner)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/killed_$eq(boolean)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$kill$1/DriverRunner$$anonfun$kill$1(org.apache.spark.deploy.worker.DriverRunner)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$killed_$eq(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$34/JsonProtocol$$anonfun$34()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$12/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$12/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$12/apply(scala.Tuple2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2/apply(java.io.File)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$10/Utils$$anonfun$offsetBytes$2$$anonfun$apply$10(org.apache.spark.util.Utils$$anonfun$offsetBytes$2,java.io.File)|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/apache/spark/util/Utils$/offsetBytes(java.lang.String,long,long)|",
      "|java+method:///java/lang/StringBuffer/append(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9(org.apache.spark.util.Utils$$anonfun$offsetBytes$2,java.io.File,long)|",
      "|java+method:///scala/math/package$/min(long,long)|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///scala/collection/immutable/Map/apply(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9(org.apache.spark.util.Utils$$anonfun$offsetBytes$2,java.io.File)|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/apache/spark/util/Utils$/offsetBytes(java.lang.String,long,long)|",
      "|java+method:///java/lang/StringBuffer/append(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$8/Utils$$anonfun$offsetBytes$2$$anonfun$apply$8(org.apache.spark.util.Utils$$anonfun$offsetBytes$2,java.io.File,long)|",
      "|java+method:///scala/math/package$/min(long,long)|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///scala/collection/immutable/Map/apply(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$93/StagePage$$anonfun$93(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/doCheckpoint()|",
    "called": "|java+method:///scala/Option/isDefined()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1/RDD$$anonfun$doCheckpoint$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/doCheckpointCalled()|",
      "|java+method:///org/apache/spark/rdd/RDD/checkpointData()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/rdd/RDD/doCheckpointCalled_$eq(boolean)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/doCheckpoint()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1/RDD$$anonfun$doCheckpoint$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDDOperationScope$/withScope(org.apache.spark.SparkContext,java.lang.String,boolean,boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/org$apache$spark$rdd$RDD$$sc()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$1/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$1(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5)|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/getURLs()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$urlClassLoader()|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/addURL(java.net.URL)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.net.URL)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$3/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$3(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.lang.String,long)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$hadoopConf$1(scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$9/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$9(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$currentJars()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$1/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$1(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/getURLs()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$urlClassLoader()|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/addURL(java.net.URL)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$5/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$5(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.net.URL)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$4(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.lang.String,long)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$hadoopConf$1(scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$9/Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$9(org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5,java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$currentJars()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$27/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27$$anonfun$apply$20/StagePage$$anonfun$27$$anonfun$apply$20(org.apache.spark.ui.jobs.StagePage$$anonfun$27)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27$$anonfun$apply$10/StagePage$$anonfun$27$$anonfun$apply$10(org.apache.spark.ui.jobs.StagePage$$anonfun$27)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27$$anonfun$apply$14/StagePage$$anonfun$27$$anonfun$apply$14(org.apache.spark.ui.jobs.StagePage$$anonfun$27)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$27$$anonfun$apply$4/StagePage$$anonfun$27$$anonfun$apply$4(org.apache.spark.ui.jobs.StagePage$$anonfun$27)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$3/getValue()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterSource/master()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/size()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingApps()|",
      "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$3/getValue()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterSource/master()|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$3/getValue()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master/postStop()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$postStop$1/Master$$anonfun$postStop$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/webUi()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterMetricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServer()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/stop()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$recoveryCompletionTask()|",
      "|java+method:///org/apache/spark/deploy/master/Master/applicationMetricsSystem()|",
      "|java+method:///org/apache/spark/deploy/master/Master/persistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/master/Master/leaderElectionAgent()|",
      "|java+method:///akka/actor/Cancellable/cancel()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/LeaderElectionAgent/stop()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/close()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$postStop$1/Master$$anonfun$postStop$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterMetricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServer()|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/stop()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$recoveryCompletionTask()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$webUi()|",
      "|java+method:///org/apache/spark/deploy/master/Master/leaderElectionAgent()|",
      "|java+method:///akka/actor/Cancellable/cancel()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$applicationMetricsSystem()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/LeaderElectionAgent/stop()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$persistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/close()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient/stop()|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$$anonfun$stop$1/AppClient$$anonfun$stop$1(org.apache.spark.deploy.client.AppClient)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/actor_$eq(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/actor()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/logInfo(scala.Function0)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/RpcUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$$anonfun$stop$1/AppClient$$anonfun$stop$1(org.apache.spark.deploy.client.AppClient)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/actor_$eq(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/actor()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/logInfo(scala.Function0)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/onExecutorAdded(org.apache.spark.scheduler.SparkListenerExecutorAdded)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/executorToLogUrls()|",
      "|java+method:///org/apache/spark/scheduler/cluster/ExecutorInfo/logUrlMap()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerExecutorAdded/executorInfo()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerExecutorAdded/executorId()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/executorToLogUrls()|",
      "|java+method:///org/apache/spark/scheduler/cluster/ExecutorInfo/logUrlMap()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerExecutorAdded/executorInfo()|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/executorIdToData()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$ExecutorUIData$/apply$default$2()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$ExecutorUIData$/apply$default$3()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerExecutorAdded/executorId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerExecutorAdded/time()|",
      "|java+constructor:///org/apache/spark/ui/jobs/UIData$ExecutorUIData/UIData$ExecutorUIData(long,scala.Option,scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/ClientActor/preStart()|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts(org.apache.spark.SparkConf,scala.Function1)|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/masterActor()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cores()|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/mainClass()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/memory()|",
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/master()|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverId()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/context()|",
      "|java+method:///org/apache/spark/deploy/master/Master$/toAkkaUrl(java.lang.String,java.lang.String)|",
      "|java+method:///scala/sys/SystemProperties/get(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/self()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts$default$2()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/masterActor_$eq(akka.actor.ActorSelection)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RequestKillDriver/DeployMessages$RequestKillDriver(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverOptions()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RequestSubmitDriver/DeployMessages$RequestSubmitDriver(org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cmd()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/jarUrl()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/deploy/DriverDescription/DriverDescription(java.lang.String,int,int,boolean,org.apache.spark.deploy.Command)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$2/ClientActor$$anonfun$2(org.apache.spark.deploy.ClientActor)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$3/ClientActor$$anonfun$3(org.apache.spark.deploy.ClientActor)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/supervise()|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$1/ClientActor$$anonfun$1(org.apache.spark.deploy.ClientActor)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$4/ClientActor$$anonfun$4(org.apache.spark.deploy.ClientActor)|",
      "|java+method:///akka/actor/ActorContext/actorSelection(java.lang.String)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts(org.apache.spark.SparkConf,scala.Function1)|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/context()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cores()|",
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts$default$2()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverOptions()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/mainClass()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/memory()|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$preStart$1/ClientActor$$anonfun$preStart$1(org.apache.spark.deploy.ClientActor,org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/org$apache$spark$deploy$ClientActor$$masterActors()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/driverId()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///scala/sys/SystemProperties/get(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/self()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/cmd()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/jarUrl()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/deploy/DriverDescription/DriverDescription(java.lang.String,int,int,boolean,org.apache.spark.deploy.Command)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$5/ClientActor$$anonfun$5(org.apache.spark.deploy.ClientActor)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$2/ClientActor$$anonfun$2(org.apache.spark.deploy.ClientActor)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$3/ClientActor$$anonfun$3(org.apache.spark.deploy.ClientActor)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/supervise()|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$4/ClientActor$$anonfun$4(org.apache.spark.deploy.ClientActor)|",
      "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$preStart$2/ClientActor$$anonfun$preStart$2(org.apache.spark.deploy.ClientActor,java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$69/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$69/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$69/apply(org.apache.spark.executor.ShuffleReadMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$26/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26$$anonfun$apply$9/StagePage$$anonfun$26$$anonfun$apply$9(org.apache.spark.ui.jobs.StagePage$$anonfun$26)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26$$anonfun$apply$19/StagePage$$anonfun$26$$anonfun$apply$19(org.apache.spark.ui.jobs.StagePage$$anonfun$26)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26$$anonfun$apply$13/StagePage$$anonfun$26$$anonfun$apply$13(org.apache.spark.ui.jobs.StagePage$$anonfun$26)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$26$$anonfun$apply$3/StagePage$$anonfun$26$$anonfun$apply$3(org.apache.spark.ui.jobs.StagePage$$anonfun$26)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/persist(org.apache.spark.storage.StorageLevel)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel_$eq(org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+constructor:///java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$persist$1/RDD$$anonfun$persist$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+method:///org/apache/spark/SparkContext/persistRDD(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel_$eq(org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/rdd/RDD/org$apache$spark$rdd$RDD$$sc()|",
      "|java+constructor:///java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$persist$1/RDD$$anonfun$persist$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+method:///org/apache/spark/SparkContext/persistRDD(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/hashCode()|",
    "called": "|java+method:///scala/runtime/Statics/mix(int,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/completed()|",
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/startTime()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/lastUpdated()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/endTime()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/sparkUser()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/ScalaRunTime$/_hashCode(scala.Product)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$master$Master$$anonfun$$$outer()|",
      "|java+method:///org/apache/spark/deploy/master/Master/state()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$state()|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$master$Master$$anonfun$$$outer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$25/JsonProtocol$$anonfun$25()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$18/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/SparkContext$$anonfun$18/apply(scala.Tuple2)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$18/apply(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker/postStop()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/stop()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/metricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/shuffleService()|",
      "|java+method:///org/apache/spark/deploy/worker/StandaloneWorkerShuffleService/stop()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/webUi()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$1/Worker$$anonfun$postStop$1(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$2/Worker$$anonfun$postStop$2(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/drivers()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$3/Worker$$anonfun$postStop$3(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registrationRetryTimer()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/stop()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/stop()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/metricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$webUi()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$1/Worker$$anonfun$postStop$1(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$2/Worker$$anonfun$postStop$2(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/drivers()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$postStop$3/Worker$$anonfun$postStop$3(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/shuffleService()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registrationRetryTimer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/apply(org.apache.spark.scheduler.AccumulableInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countByKey()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/reflect/ClassTag$/Long()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/collect()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countByKey$2/PairRDDFunctions$$anonfun$countByKey$2(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countByKey$1/PairRDDFunctions$$anonfun$countByKey$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countByKey$1/PairRDDFunctions$$anonfun$countByKey$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/read(java.lang.String,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/Buffer/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/read(java.lang.String,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/curator/framework/CuratorFramework/getChildren()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$1/ZooKeeperPersistenceEngine$$anonfun$1(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/WORKING_DIR()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$read$2/ZooKeeperPersistenceEngine$$anonfun$read$2(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine)|",
      "|java+method:///org/apache/curator/framework/api/GetChildrenBuilder/forPath(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/zk()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$read$1/ZooKeeperPersistenceEngine$$anonfun$read$1(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/generic/GenericTraversableTemplate/flatten(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/Buffer/filter(scala.Function1)|",
      "|java+method:///org/apache/curator/framework/CuratorFramework/getChildren()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$1/ZooKeeperPersistenceEngine$$anonfun$1(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/WORKING_DIR()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$read$2/ZooKeeperPersistenceEngine$$anonfun$read$2(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine)|",
      "|java+method:///org/apache/curator/framework/api/GetChildrenBuilder/forPath(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/zk()|",
      "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine$$anonfun$read$1/ZooKeeperPersistenceEngine$$anonfun$read$1(org.apache.spark.deploy.master.ZooKeeperPersistenceEngine,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/generic/GenericTraversableTemplate/flatten(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage/org$apache$spark$ui$jobs$StagePage$$getGettingResultTime(org.apache.spark.scheduler.TaskInfo)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage/taskRow(boolean,boolean,boolean,boolean,boolean,boolean,long,org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$7/HistoryPage$$anonfun$7(org.apache.spark.deploy.history.HistoryPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$4/apply$mcV$sp()|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addMasters(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/createClient()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addMasters(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$createClient()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate/toString()|",
    "called": "|java+method:///scala/runtime/ScalaRunTime$/_toString(scala.Product)|",
    "v1Body": [
      "|java+method:///scala/runtime/ScalaRunTime$/_toString(scala.Product)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate/groupId()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate/artifactId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$MavenCoordinate/version()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$56/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$16/JsonProtocol$$anonfun$16()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$14/JsonProtocol$$anonfun$14()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/stats()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$stats$2/DoubleRDDFunctions$$anonfun$stats$2(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$stats$1/DoubleRDDFunctions$$anonfun$stats$1(org.apache.spark.rdd.DoubleRDDFunctions)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$stats$1/DoubleRDDFunctions$$anonfun$stats$1(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerInfo$$anonfun$updateBlockInfo$6/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerInfo$$anonfun$updateBlockInfo$6/apply()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerId/hostPort()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerInfo/blockManagerId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerInfo$$anonfun$updateBlockInfo$6/apply()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerId/hostPort()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerInfo/blockManagerId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/start()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/writeInt(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/filePath()|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/writeUTF(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$2/SimrSchedulerBackend$$anonfun$start$2(org.apache.spark.scheduler.cluster.SimrSchedulerBackend,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$3/SimrSchedulerBackend$$anonfun$start$3(org.apache.spark.scheduler.cluster.SimrSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/actorSystem()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$2/SimrSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$1/SimrSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/close()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/tmpPath()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$1/SimrSchedulerBackend$$anonfun$start$1(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/writeInt(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/filePath()|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/writeUTF(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$2/SimrSchedulerBackend$$anonfun$start$2(org.apache.spark.scheduler.cluster.SimrSchedulerBackend,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$3/SimrSchedulerBackend$$anonfun$start$3(org.apache.spark.scheduler.cluster.SimrSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/rpcEnv()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/tmpPath()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rpc/RpcAddress/RpcAddress(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$2/SimrSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$1/SimrSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/uriOf(java.lang.String,org.apache.spark.rpc.RpcAddress,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FSDataOutputStream/close()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend$$anonfun$start$1/SimrSchedulerBackend$$anonfun$start$1(org.apache.spark.scheduler.cluster.SimrSchedulerBackend)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner/runCommandWithRetry(org.apache.spark.deploy.worker.ProcessBuilderLike,scala.Function1,boolean)|",
    "called": "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Sleeper/sleep(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ProcessBuilderLike/start()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/clock()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$runCommandWithRetry$2/DriverRunner$$anonfun$runCommandWithRetry$2(org.apache.spark.deploy.worker.DriverRunner,scala.runtime.IntRef,int)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalExitCode_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/logInfo(scala.Function0)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/sleeper()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/killed()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$runCommandWithRetry$1/DriverRunner$$anonfun$runCommandWithRetry$1(org.apache.spark.deploy.worker.DriverRunner,org.apache.spark.deploy.worker.ProcessBuilderLike)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Sleeper/sleep(int)|",
      "|java+method:///org/apache/spark/deploy/worker/ProcessBuilderLike/start()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/clock()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process()|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$runCommandWithRetry$2/DriverRunner$$anonfun$runCommandWithRetry$2(org.apache.spark.deploy.worker.DriverRunner,scala.runtime.IntRef,int)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$killed()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$finalExitCode_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/process_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/sleeper()|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$runCommandWithRetry$1/DriverRunner$$anonfun$runCommandWithRetry$1(org.apache.spark.deploy.worker.DriverRunner,org.apache.spark.deploy.worker.ProcessBuilderLike)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$17/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$17/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/name()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$17/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$6/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$6/apply(org.apache.spark.deploy.ExecutorDescription)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$6/apply(org.apache.spark.deploy.master.ApplicationInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$23/JsonProtocol$$anonfun$23()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StageTableBase/org$apache$spark$ui$jobs$StageTableBase$$renderStageRow(org.apache.spark.scheduler.StageInfo)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/stageRow(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/stageRow(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/rest/CreateSubmissionRequest$$anonfun$assertPropertyIsNumeric$1/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/toDouble()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4/apply(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4/apply(scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$8/AllJobsPage$$anonfun$8(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/JettyUtils$$anon$1/doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/extractFn()|",
      "|java+method:///org/apache/spark/SecurityManager/checkUIViewPermissions(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setHeader(java.lang.String,java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRemoteUser()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/contentType()|",
      "|java+method:///java/lang/IllegalArgumentException/getMessage()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/getWriter()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///java/io/PrintWriter/println(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setContentType(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendError(int,java.lang.String)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/responder()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/extractFn()|",
      "|java+method:///org/apache/spark/SecurityManager/checkUIViewPermissions(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setHeader(java.lang.String,java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRemoteUser()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/contentType()|",
      "|java+method:///java/lang/IllegalArgumentException/getMessage()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/getWriter()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///java/io/PrintWriter/println(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setContentType(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendError(int,java.lang.String)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/JettyUtils$ServletParams/responder()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+constructor:///org/apache/spark/ui/JettyUtils$$anon$1$$anonfun$doGet$1/JettyUtils$$anon$1$$anonfun$doGet$1(org.apache.spark.ui.JettyUtils$$anon$1,javax.servlet.http.HttpServletRequest,java.lang.Exception)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorRunTime()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/TaskInfo/launchTime()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$6/SparkContext$$anonfun$stop$6(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertUsable()|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue$default$2()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$8/FaultToleranceTest$$anonfun$8()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue(boolean,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///scala/concurrent/package$/future(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$8/FaultToleranceTest$$anonfun$8()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue(boolean,java.lang.String)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue$default$2()|",
      "|java+method:///scala/concurrent/package$/future(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/doKillExecutors(scala.collection.Seq)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$KillExecutors/CoarseGrainedClusterMessages$KillExecutors(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$askTimeout()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/yarnSchedulerActor()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askWithReply(java.lang.Object,akka.actor.ActorRef,scala.concurrent.duration.FiniteDuration)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/yarnSchedulerEndpoint()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$KillExecutors/CoarseGrainedClusterMessages$KillExecutors(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$9/StagePage$$anonfun$9(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcJ$sp/AbstractFunction0$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/statusUpdate(org.apache.mesos.SchedulerDriver,org.apache.mesos.Protos$TaskStatus)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/driver()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/reviveOffers()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosDriver()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$offsetBytes$2$$anonfun$apply$9/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/lang/StringBuffer/toString()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$min$1/RDD$$anonfun$min$1(org.apache.spark.rdd.RDD,scala.math.Ordering)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager/validateSettings()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$minNumExecutors()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/testing()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeout()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/tasksPerExecutor()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeout()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$sustainedSchedulerBacklogTimeout()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeoutS()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$minNumExecutors()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/testing()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeoutS()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$sustainedSchedulerBacklogTimeoutS()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/tasksPerExecutor()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2/apply()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countApproxDistinctByKey(int,int,org.apache.spark.Partitioner)|",
      "|java+method:///scala/math/package$/log(double)|",
      "|java+method:///scala/math/package$/ceil(double)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2$$anonfun$apply$23/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2$$anonfun$apply$23(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemory()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/sum(scala.math.Numeric)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/accountingLock()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/unrollMemoryMap()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/sum(scala.math.Numeric)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/accountingLock()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/unrollMemoryMap()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/pendingUnrollMemoryMap()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/countByValue(scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countByValue$1/RDD$$anonfun$countByValue$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countByKey()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countByValue$1/RDD$$anonfun$countByValue$1(org.apache.spark.rdd.RDD,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal(org.apache.spark.rdd.RDD,int,scala.collection.mutable.HashSet)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getCacheLocs(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/preferredLocations(org.apache.spark.Partition)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2(org.apache.spark.scheduler.DAGScheduler,int,scala.collection.mutable.HashSet,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value()|",
      "|java+method:///scala/collection/Seq/toList()|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2(org.apache.spark.scheduler.DAGScheduler,int,scala.collection.mutable.HashSet,java.lang.Object)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getCacheLocs(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+method:///scala/collection/immutable/List/nonEmpty()|",
      "|java+method:///org/apache/spark/rdd/RDD/preferredLocations(org.apache.spark.Partition)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value()|",
      "|java+method:///scala/collection/Seq/toList()|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/SizeEstimator$/visitSingleObject(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState)|",
    "called": "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$visitSingleObject$1/SizeEstimator$$anonfun$visitSingleObject$1(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/pointerFields()|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size_$eq(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size()|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/getClassInfo(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/visitArray(java.lang.Object,java.lang.Class,org.apache.spark.util.SizeEstimator$SearchState)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/shellSize()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$visitSingleObject$1/SizeEstimator$$anonfun$visitSingleObject$1(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size_$eq(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size()|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/getClassInfo(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/visitArray(java.lang.Object,java.lang.Class,org.apache.spark.util.SizeEstimator$SearchState)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/shellSize()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$ClassInfo/pointerFields()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/alignSize(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CheckpointRDD$/writeToFile(java.lang.String,org.apache.spark.broadcast.Broadcast,int,org.apache.spark.TaskContext,scala.collection.Iterator,scala.reflect.ClassTag)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/serializer/SerializationStream/close()|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean,int,short,long)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean,int)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serializeStream(java.io.OutputStream)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/TaskContext/partitionId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/TaskContext/attemptNumber()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/spark/SerializableWritable/value()|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getDefaultReplication()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$2/CheckpointRDD$$anonfun$writeToFile$2(org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/CheckpointRDD$$anonfun$writeToFile$1(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/serializer/SerializationStream/writeAll(scala.collection.Iterator,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/splitIdToFile(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean,int,short,long)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path,boolean,int)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$2/CheckpointRDD$$anonfun$writeToFile$2(scala.collection.Iterator,scala.reflect.ClassTag,org.apache.spark.serializer.SerializationStream)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$1/CheckpointRDD$$anonfun$writeToFile$1(org.apache.spark.serializer.SerializationStream)|",
      "|java+method:///org/apache/spark/TaskContext/partitionId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/splitIdToFile(int)|",
      "|java+method:///org/apache/spark/TaskContext/attemptNumber()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/apache/spark/SerializableWritable/value()|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getDefaultReplication()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serializeStream(java.io.OutputStream)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$3/CheckpointRDD$$anonfun$writeToFile$3(org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$writeToFile$4/CheckpointRDD$$anonfun$writeToFile$4(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/apply()|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/BlockRDD/assertValid()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/BlockRDD/toString()|",
      "|java+method:///org/apache/spark/rdd/BlockRDD/_isValid()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/BlockRDD/isValid()|",
      "|java+method:///org/apache/spark/rdd/BlockRDD/toString()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/collect()|",
    "called": "|java+method:///scala/Array$/concat(scala.collection.Seq,scala.reflect.ClassTag)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$17/RDD$$anonfun$17(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Array$/concat(scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$collect$1/RDD$$anonfun$collect$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/getRDDStorageInfo()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getRDDStorageInfo$1/SparkContext$$anonfun$getRDDStorageInfo$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/persistentRdds()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/StorageUtils$/updateRddInfo(scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap/values()|",
      "|java+method:///org/apache/spark/SparkContext/getExecutorStorageStatus()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$30/SparkContext$$anonfun$30(org.apache.spark.SparkContext)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getRDDStorageInfo$1/SparkContext$$anonfun$getRDDStorageInfo$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/persistentRdds()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$assertNotStopped()|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/StorageUtils$/updateRddInfo(scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap/values()|",
      "|java+method:///org/apache/spark/SparkContext/getExecutorStorageStatus()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$34/SparkContext$$anonfun$34(org.apache.spark.SparkContext)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$16/SparkContext$$anonfun$16(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/apply()|",
    "called": "|java+constructor:///scala/runtime/NonLocalReturnControl/NonLocalReturnControl(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/apply()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+constructor:///scala/runtime/NonLocalReturnControl/NonLocalReturnControl(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$2$$anonfun$apply$1/RDDPage$$anonfun$2$$anonfun$apply$1(org.apache.spark.ui.storage.RDDPage$$anonfun$2)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/apply()|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/apply$mcI$sp()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/WebUI/attachPage(org.apache.spark.ui.WebUIPage)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/JettyUtils$/createServletHandler(java.lang.String,org.apache.spark.ui.JettyUtils$ServletParams,org.apache.spark.SecurityManager,java.lang.String,scala.Function1)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/BufferLike/append(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$attachPage$1/WebUI$$anonfun$attachPage$1(org.apache.spark.ui.WebUI)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripSuffix(java.lang.String)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/WebUI/pageToHandlers()|",
      "|java+method:///org/apache/spark/ui/WebUI/attachHandler(org.spark-project.jetty.servlet.ServletContextHandler)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$2/WebUI$$anonfun$2(org.apache.spark.ui.WebUI,org.apache.spark.ui.WebUIPage)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$attachPage$2/WebUI$$anonfun$attachPage$2(org.apache.spark.ui.WebUI)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$3/WebUI$$anonfun$3(org.apache.spark.ui.WebUI,org.apache.spark.ui.WebUIPage)|",
      "|java+method:///org/apache/spark/ui/WebUIPage/prefix()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/htmlResponderToServlet(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/jsonResponderToServlet(scala.Function1)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/JettyUtils$/createServletHandler(java.lang.String,org.apache.spark.ui.JettyUtils$ServletParams,org.apache.spark.SecurityManager,java.lang.String,scala.Function1)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/BufferLike/append(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$attachPage$1/WebUI$$anonfun$attachPage$1(org.apache.spark.ui.WebUI)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/ui/WebUI/securityManager()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripSuffix(java.lang.String)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/WebUI/pageToHandlers()|",
      "|java+method:///org/apache/spark/ui/WebUI/attachHandler(org.spark-project.jetty.servlet.ServletContextHandler)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$2/WebUI$$anonfun$2(org.apache.spark.ui.WebUI,org.apache.spark.ui.WebUIPage)|",
      "|java+constructor:///org/apache/spark/ui/WebUI$$anonfun$3/WebUI$$anonfun$3(org.apache.spark.ui.WebUI,org.apache.spark.ui.WebUIPage)|",
      "|java+method:///org/apache/spark/ui/WebUIPage/prefix()|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/htmlResponderToServlet(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/JettyUtils$/jsonResponderToServlet(scala.Function1)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockStatus$/unapply(org.apache.spark.storage.BlockStatus)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7/apply$mcV$sp()|",
    "called": "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
    "v1Body": [
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/createClient()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/getLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ListBuffer/head()|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1/FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1(org.apache.spark.deploy.FaultToleranceTest$$anonfun$7)|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue$default$2()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay$default$1()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addMasters(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/masters()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$createClient()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$getLeader()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ListBuffer/head()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay$default$1()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$masters()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addMasters(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay(scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1/FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1(org.apache.spark.deploy.FaultToleranceTest$$anonfun$7)|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue$default$2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$26/JsonProtocol$$anonfun$26()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/killExecutors(scala.collection.Seq)|",
    "called": "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/dynamicAllocationTesting()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/killExecutors(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/master()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$killExecutors$2/SparkContext$$anonfun$killExecutors$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$killExecutors$1/SparkContext$$anonfun$killExecutors$1(org.apache.spark.SparkContext)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/killExecutors(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$killExecutors$2/SparkContext$$anonfun$killExecutors$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$killExecutors$1/SparkContext$$anonfun$killExecutors$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/supportDynamicAllocation()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$42/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$42$$anonfun$apply$8/JsonProtocol$$anonfun$42$$anonfun$apply$8(org.apache.spark.util.JsonProtocol$$anonfun$42)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$isReady$2/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/maxRegisteredWaitingTime()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$isReady$2/apply()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/maxRegisteredWaitingTimeMs()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$isReady$2/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/apply(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/ApplicationPage$$anonfun$5/apply(org.apache.spark.deploy.master.ExecutorDesc)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/RDDInfo/toString()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/tachyonSize()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/toString()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/externalBlockStoreSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/toString()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$/testContinuousSending(org.apache.spark.network.nio.ConnectionManager)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testContinuousSending$2/ConnectionManager$$anonfun$testContinuousSending$2()|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testContinuousSending$1/ConnectionManager$$anonfun$testContinuousSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$20/ConnectionManager$$anonfun$20()|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testContinuousSending$1/ConnectionManager$$anonfun$testContinuousSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testContinuousSending$2/ConnectionManager$$anonfun$testContinuousSending$2()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$21/ConnectionManager$$anonfun$21()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$12/JsonProtocol$$anonfun$12()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/updateBlockInfo(org.apache.spark.storage.BlockManagerId,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel,long,long,long)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$updateBlockInfo$1/BlockManagerMaster$$anonfun$updateBlockInfo$1(org.apache.spark.storage.BlockManagerMaster,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/BlockManagerMessages$UpdateBlockInfo(org.apache.spark.storage.BlockManagerId,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel,long,long,long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$updateBlockInfo$1/BlockManagerMaster$$anonfun$updateBlockInfo$1(org.apache.spark.storage.BlockManagerMaster,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/BlockManagerMessages$UpdateBlockInfo(org.apache.spark.storage.BlockManagerId,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel,long,long,long)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/logDebug(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
    "called": "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$7/BlockManager$$anonfun$7(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/DataReadMethod$/Disk()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/nio/ByteBuffer/position()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/contains(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/putIterator(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,boolean,boolean)|",
      "|java+method:///org/apache/spark/storage/PutResult/data()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataDeserialize(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/storage/BlockManager/tachyonStore()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/deserialized()|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///org/apache/spark/storage/DiskStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataDeserialize$default$3()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/nio/ByteBuffer/put(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/size()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/level()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$1/BlockManager$$anonfun$doGetLocal$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$2/BlockManager$$anonfun$doGetLocal$2(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$4/BlockManager$$anonfun$doGetLocal$4(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$5/BlockManager$$anonfun$doGetLocal$5(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$6/BlockManager$$anonfun$doGetLocal$6(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$7/BlockManager$$anonfun$doGetLocal$7(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$8/BlockManager$$anonfun$doGetLocal$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$9/BlockManager$$anonfun$doGetLocal$9(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/rewind()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockResult/BlockResult(scala.collection.Iterator,scala.Enumeration$Value,long)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///scala/util/Left/a()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getValues(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/waitForReady()|",
      "|java+method:///org/apache/spark/executor/DataReadMethod$/Memory()|",
      "|java+constructor:///org/apache/spark/storage/BlockException/BlockException(org.apache.spark.storage.BlockId,java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$3/BlockManager$$anonfun$doGetLocal$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/DataReadMethod$/Disk()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore/contains(org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/position()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$9/BlockManager$$anonfun$doGetLocal$9(org.apache.spark.storage.BlockManager,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/putIterator(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,boolean,boolean)|",
      "|java+method:///org/apache/spark/storage/PutResult/data()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataDeserialize(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/putBytes(org.apache.spark.storage.BlockId,long,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/deserialized()|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///org/apache/spark/storage/DiskStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataDeserialize$default$3()|",
      "|java+method:///org/apache/spark/storage/BlockManager/externalBlockStore()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$6/BlockManager$$anonfun$6(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/size()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/level()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/nio/ByteBuffer/rewind()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$1/BlockManager$$anonfun$doGetLocal$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$2/BlockManager$$anonfun$doGetLocal$2(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$4/BlockManager$$anonfun$doGetLocal$4(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$5/BlockManager$$anonfun$doGetLocal$5(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$6/BlockManager$$anonfun$doGetLocal$6(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$7/BlockManager$$anonfun$doGetLocal$7(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$8/BlockManager$$anonfun$doGetLocal$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockResult/BlockResult(scala.collection.Iterator,scala.Enumeration$Value,long)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///scala/util/Left/a()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getValues(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$10/BlockManager$$anonfun$doGetLocal$10(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/waitForReady()|",
      "|java+method:///org/apache/spark/executor/DataReadMethod$/Memory()|",
      "|java+constructor:///org/apache/spark/storage/BlockException/BlockException(org.apache.spark.storage.BlockId,java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$3/BlockManager$$anonfun$doGetLocal$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/killTask(long,java.lang.String,boolean)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/driver()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/killTask(org.apache.mesos.Protos$TaskID)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosDriver()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/killTask(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$2/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleReader/read()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/CoGroupPartition/index()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/NarrowCoGroupSplitDep/rdd()|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/getReader(org.apache.spark.shuffle.ShuffleHandle,int,int,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/rdd/NarrowCoGroupSplitDep/split()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/rdd/ShuffleCoGroupSplitDep/handle()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleReader/read()|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleHandle()|",
      "|java+method:///org/apache/spark/rdd/CoGroupPartition/narrowDeps()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/OneToOneDependency/rdd()|",
      "|java+method:///org/apache/spark/rdd/CoGroupPartition/index()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/getReader(org.apache.spark.shuffle.ShuffleHandle,int,int,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/rdd/NarrowCoGroupSplitDep/split()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5/apply(java.io.File)|",
    "called": "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/JavaConversions$/asJavaCollection(scala.collection.Iterable)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5$$anonfun$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5$$anonfun$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$worker$Worker$$anonfun$$$outer()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/APP_DATA_RETENTION_SECS()|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/util/Collection/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2/org$apache$spark$deploy$worker$Worker$$anonfun$$anonfun$$$outer()|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/util/Utils$/doesDirectoryContainAnyNewFiles(java.io.File,long)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConversions$/asJavaCollection(scala.collection.Iterable)|",
      "|java+method:///java/io/File/isDirectory()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5$$anonfun$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5$$anonfun$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$2$$anonfun$apply$mcV$sp$5)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$worker$Worker$$anonfun$$$outer()|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/util/Collection/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/executors()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$2/org$apache$spark$deploy$worker$Worker$$anonfun$$anonfun$$$outer()|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$APP_DATA_RETENTION_SECS()|",
      "|java+method:///org/apache/spark/util/Utils$/doesDirectoryContainAnyNewFiles(java.io.File,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/getLocalBytes(org.apache.spark.storage.BlockId)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockException/BlockException(org.apache.spark.storage.BlockId,java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockManager/getBytes(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockManager()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$getLocalBytes$1/BlockManager$$anonfun$getLocalBytes$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/buffer/ManagedBuffer/nioByteBuffer()|",
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockResolver/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockResolver()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$getLocalBytes$1/BlockManager$$anonfun$getLocalBytes$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/executor/Executor/Executor(java.lang.String,java.lang.String,org.apache.spark.SparkEnv,scala.collection.Seq,boolean)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/Utils$/setCustomHostname(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/getMaxResultSize(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///java/lang/Thread/setDefaultUncaughtExceptionHandler(java.lang.Thread$UncaughtExceptionHandler)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///org/apache/spark/util/Utils$/parseHostPort(java.lang.String)|",
      "|java+method:///akka/actor/Props$/apply(scala.Function0,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/executor/Executor/createClassLoader()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/startDriverHeartbeater()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$urlClassLoader()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/newDaemonCachedThreadPool(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/maxFrameSizeBytes(org.apache.spark.SparkConf)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+constructor:///org/apache/spark/executor/ExecutorSource/ExecutorSource(org.apache.spark.executor.Executor,java.lang.String)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///org/apache/spark/serializer/Serializer/setDefaultClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/executor/Executor/executorSource()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$2/Executor$$anonfun$2(org.apache.spark.executor.Executor)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$3/Executor$$anonfun$3(org.apache.spark.executor.Executor)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/storage/BlockManager/initialize(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/executor/Executor/addReplClassLoaderIfNeeded(java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/Executor/createClassLoader()|",
      "|java+method:///org/apache/spark/util/Utils$/setCustomHostname(java.lang.String)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonSingleThreadScheduledExecutor(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/util/Utils$/parseHostPort(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/HeartbeatReceiver$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/startDriverHeartbeater()|",
      "|java+constructor:///org/apache/spark/executor/ExecutorEndpoint/ExecutorEndpoint(org.apache.spark.rpc.RpcEnv,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/getMaxResultSize(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$urlClassLoader()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/executor/ExecutorEndpoint$/EXECUTOR_ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/executor/Executor/threadPool()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/maxFrameSizeBytes(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///org/apache/spark/serializer/Serializer/setDefaultClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/executor/Executor/executorSource()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///java/lang/Thread/setDefaultUncaughtExceptionHandler(java.lang.Thread$UncaughtExceptionHandler)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonCachedThreadPool(java.lang.String)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anonfun$2/Executor$$anonfun$2(org.apache.spark.executor.Executor)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/storage/BlockManager/initialize(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+method:///org/apache/spark/util/RpcUtils$/makeDriverRef(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+constructor:///org/apache/spark/executor/ExecutorSource/ExecutorSource(java.util.concurrent.ThreadPoolExecutor,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/executor/Executor/addReplClassLoaderIfNeeded(java.lang.ClassLoader)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig$/unapply(org.apache.spark.SparkConf$DeprecatedConfig)|",
    "called": "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/version()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/_newName()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/deprecationMessage()|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/oldName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/version()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/key()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/deprecationMessage()|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendMessage(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
    "called": "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$sendMessage$2/ConnectionManager$$anonfun$sendMessage$2(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$reportSendingMessageFailure(int,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/SynchronizedMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/network/nio/Message/senderAddress_$eq(java.net.InetSocketAddress)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/authEnabled()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$sendMessage$1/ConnectionManager$$anonfun$sendMessage$1(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message,org.apache.spark.network.nio.SendingConnection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/checkSendAuthFirst(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManagerId/toSocketAddress()|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/send(org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/id()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/connectionsById()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/wakeupSelector()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/network/nio/Message/id()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$13/ConnectionManager$$anonfun$13(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$sendMessage$2/ConnectionManager$$anonfun$sendMessage$2(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$reportSendingMessageFailure(int,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/SynchronizedMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$14/ConnectionManager$$anonfun$14(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/network/nio/Message/senderAddress_$eq(java.net.InetSocketAddress)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/authEnabled()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$sendMessage$1/ConnectionManager$$anonfun$sendMessage$1(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message,org.apache.spark.network.nio.SendingConnection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/checkSendAuthFirst(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManagerId/toSocketAddress()|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/send(org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/id()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/connectionsById()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/wakeupSelector()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/network/nio/Message/id()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/AkkaUtils$/org$apache$spark$util$AkkaUtils$$doCreateActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/collection/Seq/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///akka/actor/ActorSystem$/apply(java.lang.String,com.typesafe.config.Config)|",
      "|java+method:///org/apache/log4j/Logger/getLogger(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$2/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$2(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/logDebug(scala.Function0)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/akkaSSLOptions()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///akka/actor/Address/port()|",
      "|java+method:///com/typesafe/config/ConfigFactory/parseString(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///com/typesafe/config/Config/withFallback(com.typesafe.config.ConfigMergeable)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/maxFrameSizeBytes(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$2/AkkaUtils$$anonfun$2()|",
      "|java+method:///org/apache/spark/SSLOptions/createAkkaConfig()|",
      "|java+method:///com/typesafe/config/ConfigFactory/parseMap(java.util.Map)|",
      "|java+method:///akka/actor/ActorRefProvider/getDefaultAddress()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$1/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$1()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsJavaMap(scala.collection.Map)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///akka/actor/ExtendedActorSystem/provider()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAkkaConf()|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///akka/actor/ActorSystem$/apply(java.lang.String,com.typesafe.config.Config)|",
      "|java+method:///org/apache/log4j/Logger/getLogger(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$2/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$2(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/logDebug(scala.Function0)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/akkaSSLOptions()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///akka/actor/Address/port()|",
      "|java+method:///com/typesafe/config/ConfigFactory/parseString(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///com/typesafe/config/Config/withFallback(com.typesafe.config.ConfigMergeable)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/maxFrameSizeBytes(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$2/AkkaUtils$$anonfun$2()|",
      "|java+method:///org/apache/spark/SSLOptions/createAkkaConfig()|",
      "|java+method:///com/typesafe/config/ConfigFactory/parseMap(java.util.Map)|",
      "|java+method:///akka/actor/ActorRefProvider/getDefaultAddress()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+constructor:///org/apache/spark/util/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$1/AkkaUtils$$anonfun$org$apache$spark$util$AkkaUtils$$doCreateActorSystem$1()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsJavaMap(scala.collection.Map)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///akka/actor/ExtendedActorSystem/provider()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsSeconds(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getAkkaConf()|",
      "|java+method:///org/apache/spark/SecurityManager/getSecretKey()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$1/MasterPage$$anonfun$1(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerRemovedFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$46/JsonProtocol$$anonfun$46()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerBlockManagerRemoved/SparkListenerBlockManagerRemoved(long,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$6/JsonProtocol$$anonfun$6()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$48/JsonProtocol$$anonfun$48()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerBlockManagerRemoved/SparkListenerBlockManagerRemoved(long,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$6/JsonProtocol$$anonfun$6()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions/collectAsync()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///scala/package$/Range()|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$3/AsyncRDDActions$$anonfun$collectAsync$3(org.apache.spark.rdd.AsyncRDDActions,java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$2/AsyncRDDActions$$anonfun$collectAsync$2(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1/AsyncRDDActions$$anonfun$collectAsync$1(org.apache.spark.rdd.AsyncRDDActions,java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$collectAsync$1/AsyncRDDActions$$anonfun$collectAsync$1(org.apache.spark.rdd.AsyncRDDActions)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12(org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$12/AllJobsPage$$anonfun$12(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$2/Master$$anonfun$2(org.apache.spark.deploy.master.Master)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/blockStatusFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/storage/BlockStatus/BlockStatus(org.apache.spark.storage.StorageLevel,long,long,long)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/JsonAST$JValue/toSome()|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/storage/BlockStatus/BlockStatus(org.apache.spark.storage.StorageLevel,long,long,long)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$71/JsonProtocol$$anonfun$71(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$3/SparkContext$$anonfun$broadcast$3(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast)|",
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/newBroadcast(java.lang.Object,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///scala/reflect/package$/classTag(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$1/SparkContext$$anonfun$broadcast$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$2/SparkContext$$anonfun$broadcast$2(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast,org.apache.spark.util.CallSite)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/getCallSite()|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv/broadcastManager()|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Class/isAssignableFrom(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$3/SparkContext$$anonfun$broadcast$3(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast)|",
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/newBroadcast(java.lang.Object,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$assertNotStopped()|",
      "|java+method:///scala/reflect/package$/classTag(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$1/SparkContext$$anonfun$broadcast$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$broadcast$2/SparkContext$$anonfun$broadcast$2(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast,org.apache.spark.util.CallSite)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/getCallSite()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv/broadcastManager()|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$reduce$1/RDD$$anonfun$reduce$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$20/RDD$$anonfun$20(org.apache.spark.rdd.RDD,scala.Function2,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$19/RDD$$anonfun$19(org.apache.spark.rdd.RDD,scala.Function2)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$reduce$1/RDD$$anonfun$reduce$1(org.apache.spark.rdd.RDD,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$8/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$8/apply(org.apache.spark.scheduler.ActiveJob)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$8/apply(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD/CoGroupedRDD(scala.collection.Seq,org.apache.spark.Partitioner)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$1/PairRDDFunctions$$anonfun$cogroup$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/isArray()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$1/PairRDDFunctions$$anonfun$cogroup$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/getPoolForName(java.lang.String)|",
    "called": "|java+method:///scala/Option$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/Pool/schedulableNameToSchedulable()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/rootPool()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/Pool/schedulableNameToSchedulable()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/rootPool()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$assertNotStopped()|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1/apply$mcVI$sp(int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1(org.apache.spark.rdd.SubtractedRDD$$anonfun$getPartitions$1,int)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupPartition/CoGroupPartition(int,org.apache.spark.rdd.CoGroupSplitDep%5B%5D)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/rdd1()|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/rdd2()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1(org.apache.spark.rdd.SubtractedRDD$$anonfun$getPartitions$1,int)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupPartition/CoGroupPartition(int,scala.Option%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/rdd1()|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/IterableLike/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/rdd2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$getDefaultPropertiesFile$1/apply()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/collection/Map/get(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getDefaultPropertiesFile$1$$anonfun$apply$15/Utils$$anonfun$getDefaultPropertiesFile$1$$anonfun$apply$15(org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$1)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$getDefaultPropertiesFile$1/apply()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Map/get(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getDefaultPropertiesFile$1$$anonfun$apply$14/Utils$$anonfun$getDefaultPropertiesFile$1$$anonfun$apply$14(org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$1)|",
      "|java+method:///org/apache/spark/util/Utils$$anonfun$getDefaultPropertiesFile$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$nonLocalPaths$1/apply(java.lang.String)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$nonLocalPaths$1$$anonfun$9/Utils$$anonfun$nonLocalPaths$1$$anonfun$9(org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/formatWindowsPath(java.lang.String)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///org/apache/spark/util/Utils$/windowsDrive()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$nonLocalPaths$1$$anonfun$13/Utils$$anonfun$nonLocalPaths$1$$anonfun$13(org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///org/apache/spark/util/Utils$/windowsDrive()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/accumulable(java.lang.Object,java.lang.String,org.apache.spark.AccumulableParam)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/Accumulable/Accumulable(java.lang.Object,org.apache.spark.AccumulableParam,scala.Option)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+constructor:///org/apache/spark/Accumulable/Accumulable(java.lang.Object,org.apache.spark.AccumulableParam,scala.Option)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$accumulable$2/SparkContext$$anonfun$accumulable$2(org.apache.spark.SparkContext,org.apache.spark.Accumulable)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$53/StagePage$$anonfun$53(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/partitionBy(org.apache.spark.Partitioner)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/lang/Class/isArray()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/ShuffledRDD/ShuffledRDD(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$partitionBy$1/PairRDDFunctions$$anonfun$partitionBy$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions/takeAsync(int)|",
    "called": "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1/AsyncRDDActions$$anonfun$takeAsync$1(org.apache.spark.rdd.AsyncRDDActions,int,org.apache.spark.ComplexFutureAction)|",
      "|java+method:///org/apache/spark/ComplexFutureAction/run(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+constructor:///org/apache/spark/ComplexFutureAction/ComplexFutureAction()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$takeAsync$1/AsyncRDDActions$$anonfun$takeAsync$1(org.apache.spark.rdd.AsyncRDDActions,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$schedule()|",
    "called": "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/util/Random$/shuffle(scala.collection.TraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/state()|",
      "|java+method:///scala/collection/mutable/HashSet/toSeq()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingDrivers()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$7/Master$$anonfun$7(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingApps()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toList()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/master/Master/spreadOutApps()|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/ALIVE()|",
      "|java+method:///scala/collection/mutable/HashSet/withFilter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$5/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$5(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$1/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$1(org.apache.spark.deploy.master.Master,scala.collection.Seq,int,scala.runtime.IntRef)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$4/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$4(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$3/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$3(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2(org.apache.spark.deploy.master.Master)|"
    ],
    "v2Body": [
      "|java+method:///scala/util/Random$/shuffle(scala.collection.TraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$state()|",
      "|java+method:///scala/collection/mutable/HashSet$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+method:///org/apache/spark/deploy/master/Master/startExecutorsOnWorkers()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$1/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/ALIVE()|",
      "|java+method:///scala/collection/mutable/HashSet/withFilter(scala.Function1)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerAddedFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$45/JsonProtocol$$anonfun$45()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$5/JsonProtocol$$anonfun$5()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerBlockManagerAdded/SparkListenerBlockManagerAdded(long,org.apache.spark.storage.BlockManagerId,long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$47/JsonProtocol$$anonfun$47()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$5/JsonProtocol$$anonfun$5()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerBlockManagerAdded/SparkListenerBlockManagerAdded(long,org.apache.spark.storage.BlockManagerId,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$stop$4/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/SparkContext$$anonfun$stop$4/apply(org.apache.spark.scheduler.EventLoggingListener)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$stop$4/apply(org.apache.spark.ExecutorAllocationManager)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsFromJson$5/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsFromJson$5$$anonfun$apply$10/JsonProtocol$$anonfun$taskMetricsFromJson$5$$anonfun$apply$10(org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$5)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsFromJson$5$$anonfun$apply$12/JsonProtocol$$anonfun$taskMetricsFromJson$5$$anonfun$apply$12(org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$5)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/histogram(double%5B%5D,boolean)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$6/DoubleRDDFunctions$$anonfun$6(org.apache.spark.rdd.DoubleRDDFunctions,double%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/doubleArrayOps(double%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$histogram$1/DoubleRDDFunctions$$anonfun$histogram$1(org.apache.spark.rdd.DoubleRDDFunctions,double%5B%5D,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$5/DoubleRDDFunctions$$anonfun$5(org.apache.spark.rdd.DoubleRDDFunctions,double,double,int)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$histogram$2/DoubleRDDFunctions$$anonfun$histogram$2(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$histogram$2/DoubleRDDFunctions$$anonfun$histogram$2(org.apache.spark.rdd.DoubleRDDFunctions,double%5B%5D,boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/PrimitiveVector/resize(int)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/_array_$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/_array()|",
      "|java+method:///scala/collection/mutable/ArrayOps/copyToArray(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/_array_$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector/copyArrayWithLength(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/DAGScheduler$$anonfun$12(org.apache.spark.scheduler.DAGScheduler)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/updateJobIdStageIdMapsList$1(scala.collection.immutable.List,int)|",
    "called": "|java+method:///scala/collection/immutable/List/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$updateJobIdStageIdMapsList$1$1/DAGScheduler$$anonfun$updateJobIdStageIdMapsList$1$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getParentStages(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///org/apache/spark/scheduler/Stage/jobIds()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$7/DAGScheduler$$anonfun$7(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///scala/collection/immutable/List/filter(scala.Function1)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///scala/collection/immutable/List/nonEmpty()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///scala/collection/immutable/List/tail()|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElseUpdate(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$updateJobIdStageIdMapsList$1$1/DAGScheduler$$anonfun$updateJobIdStageIdMapsList$1$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getParentStages(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///org/apache/spark/scheduler/Stage/jobIds()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$8/DAGScheduler$$anonfun$8(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///scala/collection/immutable/List/filter(scala.Function1)|",
      "|java+method:///scala/collection/immutable/List/head()|",
      "|java+method:///scala/collection/immutable/List/nonEmpty()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkConf$DeprecatedConfig$/SparkConf$DeprecatedConfig$()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker/preStart()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/webUi()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/metricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/webUi_$eq(org.apache.spark.deploy.worker.ui.WorkerWebUI)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/shuffleService()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workDir()|",
      "|java+method:///org/apache/spark/deploy/worker/StandaloneWorkerShuffleService/startIfEnabled()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registerWithMaster()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/WorkerWebUI/WorkerWebUI(org.apache.spark.deploy.worker.Worker,java.io.File,int)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/bind()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$1/Worker$$anonfun$preStart$1(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$2/Worker$$anonfun$preStart$2(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$3/Worker$$anonfun$preStart$3(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workerSource()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$4/Worker$$anonfun$preStart$4(org.apache.spark.deploy.worker.Worker,org.apache.spark.deploy.worker.ui.WorkerWebUI)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/createWorkDir()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/registered()|"
    ],
    "v2Body": [
      "|java+method:///akka/actor/ActorSystem/eventStream()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registered()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/metricsSystem()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/shuffleService()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$webUi_$eq(org.apache.spark.deploy.worker.ui.WorkerWebUI)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workDir()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/createWorkDir()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+constructor:///org/apache/spark/deploy/worker/ui/WorkerWebUI/WorkerWebUI(org.apache.spark.deploy.worker.Worker,java.io.File,int)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/self()|",
      "|java+method:///org/apache/spark/deploy/ExternalShuffleService/startIfEnabled()|",
      "|java+method:///org/apache/spark/deploy/worker/ui/WorkerWebUI/bind()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$1/Worker$$anonfun$preStart$1(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$2/Worker$$anonfun$preStart$2(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$3/Worker$$anonfun$preStart$3(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$registerWithMaster()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/workerSource()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$preStart$4/Worker$$anonfun$preStart$4(org.apache.spark.deploy.worker.Worker,org.apache.spark.deploy.worker.ui.WorkerWebUI)|",
      "|java+method:///akka/event/EventStream/subscribe(akka.actor.ActorRef,java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$webUi()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/resize$mcI$sp(int)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/copyToArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/_array()|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/_array_$eq(int%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/copyArrayWithLength$mcI$sp(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/_array_$eq(int%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcI$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1/apply()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/util/Utils$/clone(java.lang.Object,org.apache.spark.serializer.SerializerInstance,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1$$anonfun$24/RDD$$anonfun$treeAggregate$1$$anonfun$24(org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1$$anonfun$25/RDD$$anonfun$treeAggregate$1$$anonfun$25(org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1,int)|",
      "|java+method:///scala/math/package$/pow(double,double)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///scala/math/package$/ceil(double)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(org.apache.spark.Partitioner,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/values()|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/math/package$/max(int,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1$$anonfun$23/RDD$$anonfun$treeAggregate$1$$anonfun$23(org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1,scala.Function2,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex$default$2()|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeAggregate$1$$anonfun$apply$39/RDD$$anonfun$treeAggregate$1$$anonfun$apply$39(org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/MasterPage$$anonfun$5(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$$anonfun$validateSettings$5/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$3/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$3(org.apache.spark.SparkConf$$anonfun$validateSettings$5,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4(org.apache.spark.SparkConf$$anonfun$validateSettings$5,java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$5/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$5(org.apache.spark.SparkConf$$anonfun$validateSettings$5,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4/SparkConf$$anonfun$validateSettings$5$$anonfun$apply$4(org.apache.spark.SparkConf$$anonfun$validateSettings$5,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/sparkUser_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appName_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/startTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appId_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/sparkUser_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appName_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appId_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appAttemptId_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/startTime_$eq(scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/env/EnvironmentPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/jvmInformation()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/classPathHeaders()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/sparkProperties()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/propertyHeader()|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$2/EnvironmentPage$$anonfun$2(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$3/EnvironmentPage$$anonfun$3(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$4/EnvironmentPage$$anonfun$4(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$1/EnvironmentPage$$anonfun$1(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/classpathEntries()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/systemProperties()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$render$1/EnvironmentPage$$anonfun$render$1(org.apache.spark.ui.env.EnvironmentPage,scala.xml.Elem)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/jvmInformation()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/classPathHeaders()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/sparkProperties()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentPage/propertyHeader()|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$2/EnvironmentPage$$anonfun$2(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$3/EnvironmentPage$$anonfun$3(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$4/EnvironmentPage$$anonfun$4(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$1/EnvironmentPage$$anonfun$1(org.apache.spark.ui.env.EnvironmentPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/classpathEntries()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/env/EnvironmentListener/systemProperties()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+constructor:///org/apache/spark/ui/env/EnvironmentPage$$anonfun$render$1/EnvironmentPage$$anonfun$render$1(org.apache.spark.ui.env.EnvironmentPage,scala.xml.Elem)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/checkSendAuthFirst(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/network/nio/SendingConnection/isSaslComplete()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$checkSendAuthFirst$1/ConnectionManager$$anonfun$checkSendAuthFirst$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/liftedTree1$1(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslClient/SparkSaslClient(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient_$eq(org.apache.spark.network.sasl.SparkSaslClient)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/nio/SendingConnection/isSaslComplete()|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslClient/SparkSaslClient(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$checkSendAuthFirst$1/ConnectionManager$$anonfun$checkSendAuthFirst$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/liftedTree1$1(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient_$eq(org.apache.spark.network.sasl.SparkSaslClient)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$3/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$3/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$3/apply()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$61/StagePage$$anonfun$61(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/TestUtils$$anonfun$7/TestUtils$$anonfun$7()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/getExecutorThreadDump(java.lang.String)|",
    "called": "|java+method:///scala/Tuple2/_2$mcI$sp()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/askWithReply(java.lang.Object,akka.actor.ActorRef,int,int,scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/getActorSystemHostPortForExecutor(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/retryWaitMs(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/SparkContext$/DRIVER_IDENTIFIER()|",
      "|java+method:///org/apache/spark/util/Utils$/getThreadDump()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/numRetries(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/makeExecutorRef(java.lang.String,org.apache.spark.SparkConf,java.lang.String,int,akka.actor.ActorSystem)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getExecutorThreadDump$1/SparkContext$$anonfun$getExecutorThreadDump$1(org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/SparkContext$/DRIVER_IDENTIFIER()|",
      "|java+method:///org/apache/spark/util/Utils$/getThreadDump()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/getRpcHostPortForExecutor(java.lang.String)|",
      "|java+method:///org/apache/spark/executor/ExecutorEndpoint$/EXECUTOR_ENDPOINT_NAME()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getExecutorThreadDump$1/SparkContext$$anonfun$getExecutorThreadDump$1(org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rpc/RpcAddress/RpcAddress(java.lang.String,int)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpointRef(java.lang.String,org.apache.spark.rpc.RpcAddress,java.lang.String)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/validateSubmitArguments()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/isTesting()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/printUsageAndExit(int,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+method:///scala/collection/immutable/Map/contains(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/printUsageAndExit$default$2()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/isTesting()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/isUserJar(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/printUsageAndExit(int,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+method:///scala/collection/immutable/Map/contains(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/printUsageAndExit$default$2()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/pyFiles()|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/apply()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/CacheManager/getOrCompute(org.apache.spark.rdd.RDD,org.apache.spark.Partition,org.apache.spark.TaskContext,org.apache.spark.storage.StorageLevel)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/remove(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/CacheManager/putInBlockManager$default$5()|",
      "|java+constructor:///org/apache/spark/InterruptibleIterator/InterruptibleIterator(org.apache.spark.TaskContext,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/incBytesRead(long)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anon$1/CacheManager$$anon$1(org.apache.spark.CacheManager,org.apache.spark.TaskContext,org.apache.spark.executor.InputMetrics,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/storage/BlockResult/data()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/CacheManager/acquireLockForPartition(org.apache.spark.storage.RDDBlockId)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/readMethod()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toSeq()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/CacheManager/loading()|",
      "|java+method:///org/apache/spark/CacheManager/logInfo(scala.Function0)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/getInputMetricsForReadMethod(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/rdd/RDD/computeOrReadCheckpoint(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/TaskContext/isRunningLocally()|",
      "|java+constructor:///org/apache/spark/storage/RDDBlockId/RDDBlockId(int,int)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$1/CacheManager$$anonfun$1(org.apache.spark.CacheManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/get(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/CacheManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/CacheManager/putInBlockManager(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,scala.collection.mutable.ArrayBuffer,scala.Option)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$getOrCompute$1/CacheManager$$anonfun$getOrCompute$1(org.apache.spark.CacheManager,org.apache.spark.storage.RDDBlockId)|",
      "|java+method:///org/apache/spark/storage/BlockResult/inputMetrics()|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$getOrCompute$2/CacheManager$$anonfun$getOrCompute$2(org.apache.spark.CacheManager,org.apache.spark.storage.RDDBlockId)|",
      "|java+method:///scala/collection/mutable/HashSet/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/Partition/index()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/CacheManager/putInBlockManager$default$5()|",
      "|java+constructor:///org/apache/spark/InterruptibleIterator/InterruptibleIterator(org.apache.spark.TaskContext,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/incBytesRead(long)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anon$1/CacheManager$$anon$1(org.apache.spark.CacheManager,org.apache.spark.TaskContext,org.apache.spark.executor.InputMetrics,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/storage/BlockResult/data()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toSeq()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/CacheManager/loading()|",
      "|java+method:///org/apache/spark/CacheManager/logInfo(scala.Function0)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/storage/BlockResult/bytes()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/getInputMetricsForReadMethod(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/rdd/RDD/computeOrReadCheckpoint(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/TaskContext/isRunningLocally()|",
      "|java+constructor:///org/apache/spark/storage/RDDBlockId/RDDBlockId(int,int)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$1/CacheManager$$anonfun$1(org.apache.spark.CacheManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/get(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/CacheManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/CacheManager/putInBlockManager(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,scala.collection.mutable.ArrayBuffer,scala.Option)|",
      "|java+method:///org/apache/spark/storage/BlockResult/readMethod()|",
      "|java+method:///org/apache/spark/CacheManager/acquireLockForPartition(org.apache.spark.storage.RDDBlockId)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$getOrCompute$1/CacheManager$$anonfun$getOrCompute$1(org.apache.spark.CacheManager,org.apache.spark.storage.RDDBlockId)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager$$anonfun$getOrCompute$2/CacheManager$$anonfun$getOrCompute$2(org.apache.spark.CacheManager,org.apache.spark.storage.RDDBlockId)|",
      "|java+method:///scala/collection/mutable/HashSet/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/Partition/index()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$2/MasterPage$$anonfun$2(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/getParentStages(org.apache.spark.rdd.RDD,int)|",
    "called": "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashSet/toList()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$1(org.apache.spark.rdd.RDD,int,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+method:///scala/collection/mutable/Stack/isEmpty()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashSet/toList()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$1(org.apache.spark.rdd.RDD,int,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/nonEmpty()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/PythonRunner$/formatPath(java.lang.String,boolean)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/util/Utils$/formatWindowsPath(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths(java.lang.String,boolean)|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/windowsDrive()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/isWindows()|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/ArrayOps/nonEmpty()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/util/Try/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/util/Try$/apply(scala.Function0)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/nonLocalPaths(java.lang.String,boolean)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$3/PythonRunner$$anonfun$3(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/nonEmpty()|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/PythonRunner$$anonfun$2/PythonRunner$$anonfun$2(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/isWindows()|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///java/lang/String/matches(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$38/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$38/apply(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$38/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/tell(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/service(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/handleError(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+constructor:///org/apache/spark/deploy/rest/ErrorServlet$$anonfun$20/ErrorServlet$$anonfun$20(org.apache.spark.deploy.rest.ErrorServlet)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+method:///org/apache/spark/deploy/rest/StandaloneRestServer$/SC_UNKNOWN_PROTOCOL_VERSION()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorResponse/highestProtocolVersion_$eq(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/serverVersion()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/handleError(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/rest/RestSubmissionServer$/SC_UNKNOWN_PROTOCOL_VERSION()|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorResponse/highestProtocolVersion_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/rest/ErrorServlet$$anonfun$7/ErrorServlet$$anonfun$7(org.apache.spark.deploy.rest.ErrorServlet)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/ErrorServlet/serverVersion()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$5/apply(scala.Tuple2)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/commitAndClose()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$fileBufferSize()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/fileSegment()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///scala/collection/Iterator/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.Serializer,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$5$$anonfun$apply$2/ExternalSorter$$anonfun$writePartitionedFile$5$$anonfun$apply$2(org.apache.spark.util.collection.ExternalSorter$$anonfun$writePartitionedFile$5,org.apache.spark.storage.BlockObjectWriter)|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$ser()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/storage/FileSegment/length()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/commitAndClose()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$fileBufferSize()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///scala/collection/Iterator/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter$$anonfun$writePartitionedFile$5$$anonfun$apply$2/ExternalSorter$$anonfun$writePartitionedFile$5$$anonfun$apply$2(org.apache.spark.util.collection.ExternalSorter$$anonfun$writePartitionedFile$5,org.apache.spark.storage.BlockObjectWriter)|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.SerializerInstance,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///scala/Tuple2/_1$mcI$sp()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/fileSegment()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/storage/FileSegment/length()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$18/apply(org.apache.spark.ui.jobs.UIData$JobUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$18$$anonfun$apply$3/AllJobsPage$$anonfun$18$$anonfun$apply$3(org.apache.spark.ui.jobs.AllJobsPage$$anonfun$18)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/completionTime()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/submissionTime()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$18$$anonfun$apply$1/AllJobsPage$$anonfun$18$$anonfun$apply$1(org.apache.spark.ui.jobs.AllJobsPage$$anonfun$18)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf,scala.Option)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/mapred/JobConf/setOutputKeyClass(java.lang.Class)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/getOutputCommitter()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopFile$1/PairRDDFunctions$$anonfun$saveAsHadoopFile$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setOutputCommitter(java.lang.Class)|",
      "|java+method:///org/apache/hadoop/mapred/FileOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/SparkHadoopWriter$/createPathFromString(java.lang.String,org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/hadoop/mapred/JobConf/setOutputValueClass(java.lang.Class)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$saveAsHadoopFile$4/PairRDDFunctions$$anonfun$saveAsHadoopFile$4(org.apache.spark.rdd.PairRDDFunctions,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf,scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$keyBy$1/RDD$$anonfun$keyBy$1(org.apache.spark.rdd.RDD,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/count()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$count$1/RDD$$anonfun$count$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag$/Long()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/org$apache$spark$rdd$RDD$$sc()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$count$1/RDD$$anonfun$count$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag$/Long()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/BlockRDD/getPartitions()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/BlockRDD/blockIds()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/BlockRDD/assertValid()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/BlockRDD$$anonfun$getPartitions$1/BlockRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.BlockRDD)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/BlockRDD/blockIds()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/BlockRDD/assertValid()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/BlockRDD$$anonfun$getPartitions$1/BlockRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.BlockRDD)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StageTableBase/makeDescription(org.apache.spark.scheduler.StageInfo)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/name()|",
      "|java+method:///scala/xml/Text/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/rddInfos()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$makeDescription$1/StageTableBase$$anonfun$makeDescription$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/details()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$4/StageTableBase$$anonfun$4(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$3/StageTableBase$$anonfun$3(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/xml/Text$/apply(java.lang.String)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$5/StageTableBase$$anonfun$5(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$4/StageTableBase$$anonfun$4(org.apache.spark.ui.jobs.StageTableBase,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/name()|",
      "|java+method:///scala/xml/Text/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/rddInfos()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/details()|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$3/StageTableBase$$anonfun$3(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/xml/Text$/apply(java.lang.String)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$makeDescription$1/StageTableBase$$anonfun$makeDescription$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$5/StageTableBase$$anonfun$5(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$$anonfun$validateSettings$2/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$2$$anonfun$apply$2/SparkConf$$anonfun$validateSettings$2$$anonfun$apply$2(org.apache.spark.SparkConf$$anonfun$validateSettings$2,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$2$$anonfun$apply$3/SparkConf$$anonfun$validateSettings$2$$anonfun$apply$3(org.apache.spark.SparkConf$$anonfun$validateSettings$2,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$3/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$3/apply()|",
      "|java+method:///org/apache/spark/package$/SPARK_VERSION()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$3/apply()|",
      "|java+method:///org/apache/spark/SparkContext$$anonfun$3/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///scala/runtime/VolatileByteRef/VolatileByteRef(byte)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$8/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$8(org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1,java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///java/lang/Class/getConstructors()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$36/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$36(org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/addListener(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1/zeroArgumentConstructor$1(java.lang.reflect.Constructor%5B%5D,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/find(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///scala/runtime/VolatileByteRef/VolatileByteRef(byte)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$15/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$15(org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///java/lang/Class/getConstructors()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$40/SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$40(org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/addListener(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1/zeroArgumentConstructor$1(java.lang.reflect.Constructor%5B%5D,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/find(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$/markPartiallyConstructed(org.apache.spark.SparkContext,boolean)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext$/assertNoOtherContextIsRunning(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed_$eq(scala.Option)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$/SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext$/assertNoOtherContextIsRunning(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed_$eq(scala.Option)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/ResultTask/runTask(org.apache.spark.TaskContext)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/ResultTask/metrics_$eq(scala.Option)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/ResultTask/metrics_$eq(scala.Option)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ResultTask/_executorDeserializeTime_$eq(long)|",
      "|java+method:///java/lang/System/currentTimeMillis()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1/apply(org.apache.spark.scheduler.ActiveJob)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///scala/collection/mutable/HashSet/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1$$anonfun$apply$13/DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1$$anonfun$apply$13(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1$$anonfun$apply$12/DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1$$anonfun$apply$12(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1,java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///scala/collection/mutable/HashSet/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stopExecutors()|",
    "called": "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$stopExecutors$1/CoarseGrainedSchedulerBackend$$anonfun$stopExecutors$1(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverActor()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/timeout()|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$$anonfun$stopExecutors$1/CoarseGrainedSchedulerBackend$$anonfun$stopExecutors$1(org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverEndpoint()|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/spill(org.apache.spark.util.collection.SizeTracker)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/revertPartialWritesAndClose()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/ExternalAppendOnlyMap$DiskMapIterator(org.apache.spark.util.collection.ExternalAppendOnlyMap,java.io.File,org.apache.spark.storage.BlockId,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.Serializer,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/destructiveSortedIterator(java.util.Comparator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$keyComparator()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$currentMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/createTempLocalBlock()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$spilledMaps()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/append(scala.collection.Seq)|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$serializerBatchSize()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/fileBufferSize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/curWriteMetrics()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/flush$1(scala.runtime.ObjectRef,scala.runtime.IntRef,scala.collection.mutable.ArrayBuffer)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+constructor:///org/apache/spark/executor/ShuffleWriteMetrics/ShuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/write(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/curWriteMetrics_$eq(org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///java/io/File/delete()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$DiskMapIterator/ExternalAppendOnlyMap$DiskMapIterator(org.apache.spark.util.collection.ExternalAppendOnlyMap,java.io.File,org.apache.spark.storage.BlockId,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/write(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/destructiveSortedIterator(java.util.Comparator)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$keyComparator()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$currentMap()|",
      "|java+constructor:///org/apache/spark/executor/ShuffleWriteMetrics/ShuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.SerializerInstance,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$ser()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/revertPartialWritesAndClose()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/createTempLocalBlock()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$spilledMaps()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/append(scala.collection.Seq)|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/org$apache$spark$util$collection$ExternalAppendOnlyMap$$serializerBatchSize()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/fileBufferSize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/curWriteMetrics()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/flush$1(scala.runtime.ObjectRef,scala.runtime.IntRef,scala.collection.mutable.ArrayBuffer)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/curWriteMetrics_$eq(org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///java/io/File/delete()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/getAllPools()|",
    "called": "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
    "v1Body": [
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/scheduler/Pool/schedulableQueue()|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/rootPool()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/rootPool()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$assertNotStopped()|",
      "|java+method:///org/apache/spark/scheduler/Pool/schedulableQueue()|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$read(long,scala.reflect.ClassTag)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///org/apache/spark/storage/BroadcastBlockId/BroadcastBlockId(long,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/io/CompressionCodec/compressedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/Utils$/constructURIForAuthentication(java.net.URI,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/securityManager()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///java/net/URL/openConnection()|",
      "|java+method:///org/apache/spark/storage/BroadcastBlockId$/apply$default$2()|",
      "|java+method:///java/net/URLConnection/setConnectTimeout(int)|",
      "|java+method:///java/net/URLConnection/setAllowUserInteraction(boolean)|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/readObject(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/bufferSize()|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$2/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$2()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/compress()|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$3/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$3()|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1(long)|",
      "|java+constructor:///java/net/URL/URL(java.lang.String)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/httpReadTimeout()|",
      "|java+method:///java/net/URLConnection/getInputStream()|",
      "|java+method:///org/apache/spark/storage/BroadcastBlockId/name()|",
      "|java+method:///java/net/URLConnection/setReadTimeout(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream,int)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/compressionCodec()|",
      "|java+method:///org/apache/spark/util/Utils$/setupSecureURLConnection(java.net.URLConnection,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$serverUri()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/logDebug(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$bufferSize()|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BroadcastBlockId/BroadcastBlockId(long,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/io/CompressionCodec/compressedInputStream(java.io.InputStream)|",
      "|java+method:///org/apache/spark/util/Utils$/constructURIForAuthentication(java.net.URI,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/setupSecureURLConnection(java.net.URLConnection,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/securityManager()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$compress()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///java/net/URL/openConnection()|",
      "|java+method:///org/apache/spark/storage/BroadcastBlockId$/apply$default$2()|",
      "|java+method:///java/net/URLConnection/setConnectTimeout(int)|",
      "|java+method:///java/net/URLConnection/setAllowUserInteraction(boolean)|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$5/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$5(scala.reflect.ClassTag,org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$3/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$3()|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+constructor:///java/net/URL/URL(java.lang.String)|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$4/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$4()|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$2/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$2(long)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/httpReadTimeout()|",
      "|java+method:///java/net/URLConnection/getInputStream()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$compressionCodec()|",
      "|java+method:///org/apache/spark/storage/BroadcastBlockId/name()|",
      "|java+method:///java/net/URLConnection/setReadTimeout(int)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserializeStream(java.io.InputStream)|",
      "|java+constructor:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1(org.apache.spark.serializer.DeserializationStream)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream,int)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$serverUri()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$delayedInit$body/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$6/FaultToleranceTest$$anonfun$6()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/containerSparkHome_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/test(java.lang.String,scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/numFailed_$eq(int)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$11/FaultToleranceTest$$anonfun$11()|",
      "|java+method:///scala/collection/mutable/ListBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/master/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$4/FaultToleranceTest$$anonfun$4()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/masters_$eq(scala.collection.mutable.ListBuffer)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$5/FaultToleranceTest$$anonfun$5()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/dockerMountDir_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7/FaultToleranceTest$$anonfun$7()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/conf()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/ZK_DIR_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/sparkHome()|",
      "|java+method:///java/lang/System/setProperty(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$1/FaultToleranceTest$$anonfun$1()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/numPassed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/zk_$eq(org.apache.curator.framework.CuratorFramework)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/sparkHome_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$2/FaultToleranceTest$$anonfun$2()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/conf_$eq(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/containerSparkHome()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/workers_$eq(scala.collection.mutable.ListBuffer)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$3/FaultToleranceTest$$anonfun$3()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$5/FaultToleranceTest$$anonfun$5()|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$6/FaultToleranceTest$$anonfun$6()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$test(java.lang.String,scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/ZK_DIR_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$11/FaultToleranceTest$$anonfun$11()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$sparkHome()|",
      "|java+method:///scala/collection/mutable/ListBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$numPassed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$workers_$eq(scala.collection.mutable.ListBuffer)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$3/FaultToleranceTest$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$4/FaultToleranceTest$$anonfun$4()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$conf()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$containerSparkHome_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$7/FaultToleranceTest$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$numFailed_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient$default$2()|",
      "|java+method:///java/lang/System/setProperty(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$conf_$eq(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$1/FaultToleranceTest$$anonfun$1()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$containerSparkHome()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/zk_$eq(org.apache.curator.framework.CuratorFramework)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$2/FaultToleranceTest$$anonfun$2()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$dockerMountDir_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$sparkHome_$eq(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$masters_$eq(scala.collection.mutable.ListBuffer)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
    "called": "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/DiskStore$$anonfun$putBytes$2(org.apache.spark.storage.DiskStore,java.nio.ByteBuffer,long,java.io.File,long)|",
      "|java+method:///org/apache/spark/storage/DiskStore/logDebug(scala.Function0)|",
      "|java+method:///java/nio/ByteBuffer/duplicate()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/package$/Right()|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/DiskStore$$anonfun$putBytes$1(org.apache.spark.storage.DiskStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///java/nio/channels/FileChannel/close()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/PutResult$/apply$default$3()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/io/FileOutputStream/getChannel()|",
      "|java+method:///java/nio/channels/FileChannel/write(java.nio.ByteBuffer)|",
      "|java+constructor:///org/apache/spark/storage/PutResult/PutResult(long,scala.util.Either,scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/DiskStore$$anonfun$putBytes$1(org.apache.spark.storage.DiskStore,java.nio.ByteBuffer,java.nio.channels.FileChannel)|",
      "|java+method:///org/apache/spark/storage/DiskStore/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/DiskStore$$anonfun$putBytes$2(org.apache.spark.storage.DiskStore,java.nio.channels.FileChannel)|",
      "|java+method:///java/nio/ByteBuffer/duplicate()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/PutResult$/apply$default$3()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/io/FileOutputStream/getChannel()|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/package$/Right()|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$3/DiskStore$$anonfun$putBytes$3(org.apache.spark.storage.DiskStore,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$4/DiskStore$$anonfun$putBytes$4(org.apache.spark.storage.DiskStore,java.nio.ByteBuffer,long,java.io.File,long)|",
      "|java+constructor:///org/apache/spark/storage/PutResult/PutResult(long,scala.util.Either,scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/taskEndReasonFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.String,java.lang.String,java.lang.StackTraceElement%5B%5D,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/ExecutorLostFailure/ExecutorLostFailure(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonFromJson$2/JsonProtocol$$anonfun$taskEndReasonFromJson$2()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+constructor:///org/apache/spark/FetchFailed/FetchFailed(org.apache.spark.storage.BlockManagerId,int,int,int,java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$59/JsonProtocol$$anonfun$59()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$58/JsonProtocol$$anonfun$58()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$57/JsonProtocol$$anonfun$57()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$56/JsonProtocol$$anonfun$56()|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonFromJson$1/JsonProtocol$$anonfun$taskEndReasonFromJson$1()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/stackTraceFromJson(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.String,java.lang.String,java.lang.StackTraceElement%5B%5D,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/ExecutorLostFailure/ExecutorLostFailure(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/blockManagerIdFromJson(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonFromJson$2/JsonProtocol$$anonfun$taskEndReasonFromJson$2()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+constructor:///org/apache/spark/FetchFailed/FetchFailed(org.apache.spark.storage.BlockManagerId,int,int,int,java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$61/JsonProtocol$$anonfun$61()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$64/JsonProtocol$$anonfun$64()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$63/JsonProtocol$$anonfun$63()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$62/JsonProtocol$$anonfun$62()|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonFromJson$1/JsonProtocol$$anonfun$taskEndReasonFromJson$1()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/stackTraceFromJson(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$29/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/diskBytesSpilled()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$29$$anonfun$apply$6/StagePage$$anonfun$29$$anonfun$apply$6(org.apache.spark.ui.jobs.StagePage$$anonfun$29)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$29$$anonfun$apply$16/StagePage$$anonfun$29$$anonfun$apply$16(org.apache.spark.ui.jobs.StagePage$$anonfun$29)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/treeReduce(scala.Function2,int)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$21/RDD$$anonfun$21(org.apache.spark.rdd.RDD,scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$22/RDD$$anonfun$22(org.apache.spark.rdd.RDD,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$23/RDD$$anonfun$23(org.apache.spark.rdd.RDD,scala.Function2)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Option$/empty()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1/RDD$$anonfun$treeReduce$1(org.apache.spark.rdd.RDD,int)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$2/RDD$$anonfun$treeReduce$2(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD/treeAggregate(java.lang.Object,scala.Function2,scala.Function2,int,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1/RDD$$anonfun$treeReduce$1(org.apache.spark.rdd.RDD,scala.Function2,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$4/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$4/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/scheduler/Stage/parents()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$4/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/parents()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$visit$4$1/apply(org.apache.spark.Dependency)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/isAvailable()|",
      "|java+method:///org/apache/spark/NarrowDependency/rdd()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getShuffleMapStage(org.apache.spark.ShuffleDependency,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/isAvailable()|",
      "|java+method:///org/apache/spark/NarrowDependency/rdd()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/rdd()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getShuffleMapStage(org.apache.spark.ShuffleDependency,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$9/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$9/apply()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/ByteBuffer/put(java.nio.ByteBuffer)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$doGetLocal$9/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorRef()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$6/FsHistoryProvider$$anonfun$6(org.apache.spark.deploy.history.FsHistoryProvider)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/first()|",
    "called": "|java+method:///scala/Array$/unapplySeq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Array$/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/SeqLike/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/take(int)|",
      "|java+constructor:///java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)|",
      "|java+method:///scala/collection/SeqLike/lengthCompare(int)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$first$1/RDD$$anonfun$first$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/removeBroadcast(long,boolean,boolean)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeBroadcast$1/BlockManagerMaster$$anonfun$removeBroadcast$1(org.apache.spark.storage.BlockManagerMaster,long,boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveBroadcast/BlockManagerMessages$RemoveBroadcast(long,boolean)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/sameThread()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeBroadcast$1/BlockManagerMaster$$anonfun$removeBroadcast$1(org.apache.spark.storage.BlockManagerMaster,long,boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveBroadcast/BlockManagerMessages$RemoveBroadcast(long,boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$23/JobProgressListener$$anonfun$23(org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.scheduler.SparkListenerJobEnd)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/status_$eq(org.apache.spark.JobExecutionStatus)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedJobs()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/completionTime_$eq(scala.Option)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeJobs()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/jobResult()|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$2/JobProgressListener$$anonfun$onJobEnd$2(org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.scheduler.SparkListenerJobEnd,org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedJobs()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/time()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$1/JobProgressListener$$anonfun$onJobEnd$1(org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$3/JobProgressListener$$anonfun$onJobEnd$3(org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Option/filter(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/jobId()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/trimJobsIfNecessary(scala.collection.mutable.ListBuffer)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$23/JobProgressListener$$anonfun$23(org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.scheduler.SparkListenerJobEnd)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/status_$eq(org.apache.spark.JobExecutionStatus)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedJobs()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numFailedJobs_$eq(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/completionTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeJobs()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numFailedJobs()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$2/JobProgressListener$$anonfun$onJobEnd$2(org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.scheduler.SparkListenerJobEnd,org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedJobs()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/time()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$1/JobProgressListener$$anonfun$onJobEnd$1(org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener$$anonfun$onJobEnd$3/JobProgressListener$$anonfun$onJobEnd$3(org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numCompletedJobs()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///scala/Option/filter(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/jobId()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numCompletedJobs_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerJobEnd/jobResult()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/trimJobsIfNecessary(scala.collection.mutable.ListBuffer)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$90/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$90/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$90/apply(org.apache.spark.executor.ShuffleWriteMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/rest/StatusRequestServlet/doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/rest/StatusRequestServlet/parseSubmissionId(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/StatusRequestServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/rest/StatusRequestServlet$$anonfun$9/StatusRequestServlet$$anonfun$9(org.apache.spark.deploy.rest.StatusRequestServlet,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/rest/StatusRequestServlet$$anonfun$8/StatusRequestServlet$$anonfun$8(org.apache.spark.deploy.rest.StatusRequestServlet)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/rest/StatusRequestServlet$$anonfun$5/StatusRequestServlet$$anonfun$5(org.apache.spark.deploy.rest.StatusRequestServlet)|",
      "|java+method:///org/apache/spark/deploy/rest/StatusRequestServlet/parseSubmissionId(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/rest/StatusRequestServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+constructor:///org/apache/spark/deploy/rest/StatusRequestServlet$$anonfun$6/StatusRequestServlet$$anonfun$6(org.apache.spark.deploy.rest.StatusRequestServlet,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/meanApprox(long,double)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/partial/MeanEvaluator/MeanEvaluator(int,double)|",
      "|java+method:///org/apache/spark/SparkContext/runApproximateJob(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$1/DoubleRDDFunctions$$anonfun$1(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$meanApprox$1/DoubleRDDFunctions$$anonfun$meanApprox$1(org.apache.spark.rdd.DoubleRDDFunctions,long,double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/local/LocalBackend/start()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///akka/actor/Props$/apply(scala.Function0,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/local/LocalBackend/localActor_$eq(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend$$anonfun$start$1/LocalBackend$$anonfun$start$1(org.apache.spark.scheduler.local.LocalBackend)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/local/LocalEndpoint/LocalEndpoint(org.apache.spark.rpc.RpcEnv,org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.scheduler.local.LocalBackend,int)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/scheduler/local/LocalBackend/totalCores()|",
      "|java+method:///org/apache/spark/scheduler/local/LocalBackend/localEndpoint_$eq(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$24/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24$$anonfun$apply$17/StagePage$$anonfun$24$$anonfun$apply$17(org.apache.spark.ui.jobs.StagePage$$anonfun$24)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24$$anonfun$apply$7/StagePage$$anonfun$24$$anonfun$apply$7(org.apache.spark.ui.jobs.StagePage$$anonfun$24)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24$$anonfun$apply$1/StagePage$$anonfun$24$$anonfun$apply$1(org.apache.spark.ui.jobs.StagePage$$anonfun$24)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$24$$anonfun$apply$11/StagePage$$anonfun$24$$anonfun$apply$11(org.apache.spark.ui.jobs.StagePage$$anonfun$24)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/saveAsTextFile(java.lang.String)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/implicitly(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$35/RDD$$anonfun$35(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$saveAsTextFile$1/RDD$$anonfun$saveAsTextFile$1(org.apache.spark.rdd.RDD,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/addFile(java.lang.String,boolean)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/HttpFileServer/addFile(java.io.File)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///java/io/File/getCanonicalFile()|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///java/io/FileNotFoundException/FileNotFoundException(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$addFile$1/SparkContext$$anonfun$addFile$1(org.apache.spark.SparkContext,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/postEnvironmentUpdate()|",
      "|java+method:///org/apache/spark/SparkContext/addedFiles()|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///java/net/URI/toString()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/isDirectory(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///java/io/File/toURI()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/SparkEnv/httpFileServer()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/HttpFileServer/addFile(java.io.File)|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+method:///java/net/URI/toString()|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/isDir()|",
      "|java+method:///java/io/File/getCanonicalFile()|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///java/io/FileNotFoundException/FileNotFoundException(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$addFile$1/SparkContext$$anonfun$addFile$1(org.apache.spark.SparkContext,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/postEnvironmentUpdate()|",
      "|java+method:///org/apache/spark/SparkContext/addedFiles()|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getFileStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///java/io/File/toURI()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/SparkEnv/httpFileServer()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/SparkFiles$/getRootDirectory()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager/getFile(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/nonNegativeHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$tachyonDirs()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/createFile(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/subDirs()|",
      "|java+method:///scala/Predef$/any2stringadd(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/StringAdd$/$plus$extension(java.lang.Object,java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/exist(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$subDirsPerTachyonDir()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/nonNegativeHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/tachyonDirs()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFS/getFile(tachyon.TachyonURI)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/subDirs()|",
      "|java+method:///tachyon/client/TachyonFS/createFile(tachyon.TachyonURI)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///tachyon/client/TachyonFS/mkdir(tachyon.TachyonURI)|",
      "|java+constructor:///tachyon/TachyonURI/TachyonURI(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/client()|",
      "|java+method:///tachyon/client/TachyonFS/exist(tachyon.TachyonURI)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$subDirsPerTachyonDir()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$17/SparkContext$$anonfun$17(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3/apply(org.apache.spark.rdd.RDDOperationScope)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/apply(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$5/apply(org.apache.spark.deploy.master.ApplicationInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/UnionRDD$$anonfun$1/apply(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster(akka.actor.Address)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/masterAkkaUrls()|",
      "|java+method:///akka/actor/Address/hostPort()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster$1/AppClient$ClientActor$$anonfun$org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster$1(org.apache.spark.deploy.client.AppClient$ClientActor)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///akka/actor/Address/hostPort()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$masterAkkaUrls()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster$1/AppClient$ClientActor$$anonfun$org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster$1(org.apache.spark.deploy.client.AppClient$ClientActor)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$50/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/registerWithExternalShuffleServer()|",
    "called": "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$1/BlockManager$$anonfun$registerWithExternalShuffleServer$1(org.apache.spark.storage.BlockManager,org.apache.spark.network.shuffle.protocol.ExecutorShuffleInfo,int,int,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/localDirs()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/ExecutorShuffleInfo/ExecutorShuffleInfo(java.lang.String%5B%5D,int,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirsPerLocalDir()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$2/BlockManager$$anonfun$registerWithExternalShuffleServer$2(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$6/BlockManager$$anonfun$6(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$1/BlockManager$$anonfun$registerWithExternalShuffleServer$1(org.apache.spark.storage.BlockManager,org.apache.spark.network.shuffle.protocol.ExecutorShuffleInfo,int,int,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/localDirs()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$5/BlockManager$$anonfun$5(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/ExecutorShuffleInfo/ExecutorShuffleInfo(java.lang.String%5B%5D,int,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirsPerLocalDir()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$2/BlockManager$$anonfun$registerWithExternalShuffleServer$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$$anon$1/run()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/executor/Executor$$anon$1$$anonfun$run$9/Executor$$anon$1$$anonfun$run$9(org.apache.spark.executor.Executor$$anon$1)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anon$1$$anonfun$run$7/Executor$$anon$1$$anonfun$run$7(org.apache.spark.executor.Executor$$anon$1,scala.collection.mutable.ArrayBuffer,long)|",
      "|java+method:///scala/math/package$/random()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$gcTime()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askWithReply(java.lang.Object,akka.actor.ActorRef,int,int,scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reregister()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/executor/Executor$$anon$1$$anonfun$run$8/Executor$$anon$1$$anonfun$run$8(org.apache.spark.executor.Executor$$anon$1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/blockManagerId()|",
      "|java+method:///scala/collection/JavaConversions$/collectionAsScalaIterable(java.util.Collection)|",
      "|java+method:///org/apache/spark/HeartbeatResponse/reregisterBlockManager()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/values()|",
      "|java+constructor:///org/apache/spark/Heartbeat/Heartbeat(java.lang.String,scala.Tuple2%5B%5D,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$isStopped()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$runningTasks()|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/executor/Executor$$anon$1$$anonfun$run$1/Executor$$anon$1$$anonfun$run$1(org.apache.spark.executor.Executor$$anon$1)|",
      "|java+method:///org/apache/spark/util/Utils$/logUncaughtExceptions(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$5/PartitionerAwareUnionRDD$$anonfun$5(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12/apply(scala.Tuple2)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/setIfMissing(java.lang.String,java.lang.String)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12$$anonfun$apply$13/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12$$anonfun$apply$13(org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12,java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/sys/SystemProperties/getOrElseUpdate(java.lang.Object,scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/doFetchFile(java.lang.String,java.io.File,java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/getHadoopFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile$default$5()|",
      "|java+method:///org/apache/spark/util/Utils$/setupSecureURLConnection(java.net.URLConnection,org.apache.spark.SecurityManager)|",
      "|java+method:///java/net/URI/isAbsolute()|",
      "|java+method:///java/net/URLConnection/connect()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///java/net/URL/openConnection()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/net/URLConnection/setConnectTimeout(int)|",
      "|java+method:///java/net/URLConnection/setAllowUserInteraction(boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile(java.lang.String,java.io.File,java.io.File,boolean,boolean)|",
      "|java+constructor:///java/io/File/File(java.net.URI)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+constructor:///java/net/URL/URL(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$3/Utils$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$doFetchFile$2/Utils$$anonfun$doFetchFile$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$doFetchFile$1/Utils$$anonfun$doFetchFile$1()|",
      "|java+method:///java/net/URLConnection/getInputStream()|",
      "|java+method:///java/net/URLConnection/setReadTimeout(int)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.net.URI)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/util/Utils$/constructURIForAuthentication(java.net.URI,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/downloadFile(java.lang.String,java.io.InputStream,java.io.File,boolean)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchHcfsFile(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.FileSystem,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration,boolean,scala.Option)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/getHadoopFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile$default$5()|",
      "|java+method:///org/apache/spark/util/Utils$/setupSecureURLConnection(java.net.URLConnection,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsSeconds(java.lang.String,java.lang.String)|",
      "|java+method:///java/net/URI/isAbsolute()|",
      "|java+method:///java/net/URLConnection/connect()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///java/net/URL/openConnection()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/net/URLConnection/setConnectTimeout(int)|",
      "|java+method:///java/net/URLConnection/setAllowUserInteraction(boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile(java.lang.String,java.io.File,java.io.File,boolean,boolean)|",
      "|java+constructor:///java/io/File/File(java.net.URI)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+constructor:///java/net/URL/URL(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$doFetchFile$2/Utils$$anonfun$doFetchFile$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$doFetchFile$1/Utils$$anonfun$doFetchFile$1()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$4/Utils$$anonfun$4()|",
      "|java+method:///java/net/URLConnection/getInputStream()|",
      "|java+method:///java/net/URLConnection/setReadTimeout(int)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.net.URI)|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/util/Utils$/constructURIForAuthentication(java.net.URI,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/downloadFile(java.lang.String,java.io.InputStream,java.io.File,boolean)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/fetchHcfsFile(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.FileSystem,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration,boolean,scala.Option)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/Collections/singletonList(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///java/util/Collections/emptyList()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$createResource(java.lang.String,double)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/Collections/singletonList(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,org.apache.mesos.Protos$TaskInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///java/util/Collections/emptyList()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$createResource(java.lang.String,double)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$$anonfun$resolveDependencyPaths$1/apply(java.lang.Object)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/drop(int)|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$$anonfun$resolveDependencyPaths$1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/lang/String/lastIndexOf(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/ivy/core/module/id/ModuleRevisionId/getOrganisation()|",
      "|java+method:///org/apache/ivy/core/module/id/ModuleRevisionId/getRevision()|",
      "|java+method:///org/apache/ivy/core/module/descriptor/Artifact/getModuleRevisionId()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/ivy/core/module/id/ModuleRevisionId/getName()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$$anonfun$resolveDependencyPaths$1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/api/python/PythonRDD$MonitorThread/run()|",
    "called": "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
    "v1Body": [
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///org/apache/spark/TaskContext/isInterrupted()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/TaskContext/isCompleted()|",
      "|java+method:///scala/collection/mutable/Map/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv/destroyPythonWorker(java.lang.String,scala.collection.immutable.Map,java.net.Socket)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$MonitorThread$$anonfun$run$3/PythonRDD$MonitorThread$$anonfun$run$3(org.apache.spark.api.python.PythonRDD$MonitorThread)|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$MonitorThread$$anonfun$run$2/PythonRDD$MonitorThread$$anonfun$run$2(org.apache.spark.api.python.PythonRDD$MonitorThread)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD$MonitorThread/org$apache$spark$api$python$PythonRDD$MonitorThread$$$outer()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///org/apache/spark/TaskContext/isInterrupted()|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/TaskContext/isCompleted()|",
      "|java+method:///scala/collection/mutable/Map/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv/destroyPythonWorker(java.lang.String,scala.collection.immutable.Map,java.net.Socket)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$MonitorThread$$anonfun$run$4/PythonRDD$MonitorThread$$anonfun$run$4(org.apache.spark.api.python.PythonRDD$MonitorThread)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD$MonitorThread/org$apache$spark$api$python$PythonRDD$MonitorThread$$$outer()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$MonitorThread$$anonfun$run$5/PythonRDD$MonitorThread$$anonfun$run$5(org.apache.spark.api.python.PythonRDD$MonitorThread)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$getThreadDump$2/apply(java.lang.management.ThreadInfo)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/ArrayOps/mkString(java.lang.String)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadState()|",
      "|java+method:///java/lang/management/ThreadInfo/getStackTrace()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadName()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$2$$anonfun$12/Utils$$anonfun$getThreadDump$2$$anonfun$12(org.apache.spark.util.Utils$$anonfun$getThreadDump$2)|",
      "|java+constructor:///org/apache/spark/util/ThreadStackTrace/ThreadStackTrace(long,java.lang.String,java.lang.Thread$State,java.lang.String)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadId()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/ArrayOps/mkString(java.lang.String)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadState()|",
      "|java+method:///java/lang/management/ThreadInfo/getStackTrace()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadName()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getThreadDump$2$$anonfun$16/Utils$$anonfun$getThreadDump$2$$anonfun$16(org.apache.spark.util.Utils$$anonfun$getThreadDump$2)|",
      "|java+constructor:///org/apache/spark/util/ThreadStackTrace/ThreadStackTrace(long,java.lang.String,java.lang.Thread$State,java.lang.String)|",
      "|java+method:///java/lang/management/ThreadInfo/getThreadId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$82/StagePage$$anonfun$82(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9/apply$mcZ$sp()|",
    "called": "|java+method:///scala/collection/mutable/ListBuffer/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/masters()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$stateValid$1(scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/ListBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$4/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$4(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$3/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$3(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$2/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$2(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$masters()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$stateValid$1(scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/ListBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$4/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$4(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$3/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$3(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$2/FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$2(org.apache.spark.deploy.FaultToleranceTest$$anonfun$9)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/serializer/SerializationDebugger$/improveException(java.lang.Object,java.io.NotSerializableException)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///java/io/NotSerializableException/getMessage()|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/org$apache$spark$serializer$SerializationDebugger$$reflect()|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/find(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/serializer/SerializationDebugger$$anonfun$improveException$1/SerializationDebugger$$anonfun$improveException$1()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///java/io/NotSerializableException/NotSerializableException(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/enableDebugging()|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/org$apache$spark$serializer$SerializationDebugger$$reflect()|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/find(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/serializer/SerializationDebugger$$anonfun$improveException$1/SerializationDebugger$$anonfun$improveException$1()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/serializer/SerializationDebugger$$anonfun$improveException$2/SerializationDebugger$$anonfun$improveException$2()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///java/io/NotSerializableException/NotSerializableException(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///java/io/NotSerializableException/getMessage()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/serializer/SerializationDebugger$/enableDebugging()|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/subtract(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/subtract(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$18/RDD$$anonfun$18(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/subtract$default$3(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$1/RDD$$anonfun$subtract$1(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$16/AllJobsPage$$anonfun$16(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedJobs()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$17/AllJobsPage$$anonfun$17(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$18/AllJobsPage$$anonfun$18(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeJobs()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ListBuffer/reverse()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedJobs()|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$19/AllJobsPage$$anonfun$19(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/org$apache$spark$ui$jobs$AllJobsPage$$listener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/jobsTable(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$render$1/AllJobsPage$$anonfun$render$1(org.apache.spark.ui.jobs.AllJobsPage,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$20/AllJobsPage$$anonfun$20(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/collection/generic/TraversableForwarder/toSeq()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/startTime()|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/makeTimeline(scala.collection.Seq,scala.collection.mutable.HashMap,long)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$18/AllJobsPage$$anonfun$18(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numCompletedJobs()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeJobs()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/startTime()|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$21/AllJobsPage$$anonfun$21(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numFailedJobs()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/sc()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/jobProgresslistener()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedJobs()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedJobs()|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$19/AllJobsPage$$anonfun$19(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/jobsTable(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$render$1/AllJobsPage$$anonfun$render$1(org.apache.spark.ui.jobs.AllJobsPage,scala.runtime.ObjectRef)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/executorIdToData()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$20/AllJobsPage$$anonfun$20(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/generic/TraversableForwarder/toSeq()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$22/AllJobsPage$$anonfun$22(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/executorListener()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ListBuffer/reverse()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/scheduler/WorkerOffer/WorkerOffer(java.lang.String,java.lang.String,int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/JdbcRDD/getPartitions()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/JdbcRDD$$anonfun$getPartitions$1/JdbcRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.JdbcRDD,long)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/math/BigInt/$plus(scala.math.BigInt)|",
      "|java+method:///scala/math/BigInt$/apply(int)|",
      "|java+method:///scala/math/BigInt/$minus(scala.math.BigInt)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/package$/BigInt()|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/JdbcRDD$$anonfun$getPartitions$1/JdbcRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.JdbcRDD,scala.math.BigInt)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/math/BigInt$/long2bigInt(long)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$4/MasterPage$$anonfun$4(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$87/StagePage$$anonfun$87(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/takeOrdered(int,scala.math.Ordering)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///scala/Array$/empty(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sorted(scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$takeOrdered$1/RDD$$anonfun$takeOrdered$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$34/RDD$$anonfun$34(org.apache.spark.rdd.RDD,int,scala.math.Ordering)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$takeOrdered$1/RDD$$anonfun$takeOrdered$1(org.apache.spark.rdd.RDD,int,scala.math.Ordering)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/randomSplit(double%5B%5D,long)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Iterator/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/scanLeft(java.lang.Object,scala.Function2,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/ArrayOps/sliding(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToDouble(java.lang.Object)|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$1/RDD$$anonfun$1(org.apache.spark.rdd.RDD,double)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$2/RDD$$anonfun$2(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/doubleArrayOps(double%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$randomSplit$1/RDD$$anonfun$randomSplit$1(org.apache.spark.rdd.RDD,long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/reflect/ClassTag$/Double()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sum(scala.math.Numeric)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$randomSplit$1/RDD$$anonfun$randomSplit$1(org.apache.spark.rdd.RDD,double%5B%5D,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/copyStream(java.io.InputStream,java.io.OutputStream,boolean,boolean)|",
    "called": "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///java/io/OutputStream/close()|",
      "|java+method:///java/nio/channels/FileChannel/position()|",
      "|java+method:///java/io/InputStream/read(byte%5B%5D)|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+method:///java/io/OutputStream/write(byte%5B%5D,int,int)|",
      "|java+method:///java/nio/channels/FileChannel/size()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyStream$1/Utils$$anonfun$copyStream$1(long,long,long)|",
      "|java+method:///java/io/FileOutputStream/getChannel()|",
      "|java+method:///java/nio/channels/FileChannel/transferTo(long,long,java.nio.channels.WritableByteChannel)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///java/io/FileInputStream/getChannel()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyStream$2/Utils$$anonfun$copyStream$2(java.io.InputStream,java.io.OutputStream,boolean)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$copyStream$1/Utils$$anonfun$copyStream$1(java.io.InputStream,java.io.OutputStream,boolean,scala.runtime.LongRef)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$4/SparkContext$$anonfun$4(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$$anonfun$4/apply(org.apache.spark.SparkConf$DeprecatedConfig)|",
    "called": "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/oldName()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/key()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$26/SparkContext$$anonfun$26(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/tachyonSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/externalBlockStoreSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerQueueEmpty$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerQueueEmpty$1/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerQueueEmpty$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$2$$anon$1/run()|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$2/org$apache$spark$ui$UIWorkloadGenerator$$anonfun$$anonfun$$$outer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$/org$apache$spark$ui$UIWorkloadGenerator$$setProperties$1(java.lang.String,scala.Enumeration$Value,org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Function0/apply$mcJ$sp()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$2/org$apache$spark$ui$UIWorkloadGenerator$$anonfun$$anonfun$$$outer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$/org$apache$spark$ui$UIWorkloadGenerator$$setProperties$1(java.lang.String,scala.Enumeration$Value,org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Function0/apply$mcJ$sp()|",
      "|java+method:///java/util/concurrent/Semaphore/release()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1/apply()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1/apply()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1/apply()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1$$anonfun$apply$49/PairRDDFunctions$$anonfun$subtractByKey$1$$anonfun$apply$49(org.apache.spark.rdd.PairRDDFunctions$$anonfun$subtractByKey$1)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/subtractByKey(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$3/PartitionerAwareUnionRDD$$anonfun$3(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/runTask(org.apache.spark.TaskContext)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/log()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/getWriter(org.apache.spark.shuffle.ShuffleHandle,int,org.apache.spark.TaskContext)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/runTask(org.apache.spark.TaskContext)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleHandle()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/metrics_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/partitionId()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleWriter/write(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleWriter/stop(boolean)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/_executorDeserializeTime_$eq(long)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/log()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/getWriter(org.apache.spark.shuffle.ShuffleHandle,int,org.apache.spark.TaskContext)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/runTask(org.apache.spark.TaskContext)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleHandle()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/metrics_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/partitionId()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleWriter/write(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleWriter/stop(boolean)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1(org.apache.spark.ui.jobs.UIData$JobUIData)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$15/AllJobsPage$$anonfun$15(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/submissionTime()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numSkippedStages()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numTasks()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$10/AllJobsPage$$anonfun$10(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$13/AllJobsPage$$anonfun$13(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobId()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numFailedStages()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/basePath()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$1/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$1(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$9/AllJobsPage$$anonfun$9(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$5/AllJobsPage$$anonfun$5(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$8/AllJobsPage$$anonfun$8(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$3/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$3(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$7/AllJobsPage$$anonfun$7(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$4/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$4(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$6/AllJobsPage$$anonfun$6(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$2/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$2(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numSkippedTasks()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/size()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/makeProgressBar(int,int,int,int,int)|",
      "|java+method:///scala/Option/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobGroup()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numActiveTasks()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numCompletedTasks()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numFailedTasks()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$11/AllJobsPage$$anonfun$11(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$12/AllJobsPage$$anonfun$12(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$1/AllJobsPage$$anonfun$1(org.apache.spark.ui.jobs.AllJobsPage,org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/completedStageIndices()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$14/AllJobsPage$$anonfun$14(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$15/AllJobsPage$$anonfun$15(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$17/AllJobsPage$$anonfun$17(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/submissionTime()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numSkippedStages()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/org$apache$spark$ui$jobs$AllJobsPage$$getLastStageNameAndDescription(org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobId()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numFailedStages()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$16/AllJobsPage$$anonfun$16(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/basePath()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$1/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$1(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$3/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$3(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$4/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$4(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$2/AllJobsPage$$anonfun$org$apache$spark$ui$jobs$AllJobsPage$$makeRow$1$2(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numSkippedTasks()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/size()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/makeProgressBar(int,int,int,int,int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobGroup()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numActiveTasks()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numCompletedTasks()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numTasks()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/numFailedTasks()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$2/AllJobsPage$$anonfun$2(org.apache.spark.ui.jobs.AllJobsPage,org.apache.spark.ui.jobs.UIData$JobUIData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/completedStageIndices()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$14/AllJobsPage$$anonfun$14(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$9/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$9/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$9/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$14/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$14/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$14/apply(org.apache.spark.scheduler.ActiveJob)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo$/unapply(org.apache.spark.deploy.history.ApplicationHistoryInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/completed()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/startTime()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/lastUpdated()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/endTime()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/sparkUser()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/Tuple7/Tuple7(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/attempts()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$17/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$17/apply(org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$17/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$1/ClientActor$$anonfun$1(org.apache.spark.deploy.ClientActor)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/rddInfoFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/tachyonSize_$eq(long)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions_$eq(int)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize_$eq(long)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo/RDDInfo(int,java.lang.String,int,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize_$eq(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/JsonAST$JValue/toSome()|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelFromJson(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo/RDDInfo(int,java.lang.String,int,org.apache.spark.storage.StorageLevel,scala.collection.Seq,scala.Option)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$69/JsonProtocol$$anonfun$69(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/externalBlockStoreSize_$eq(long)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions_$eq(int)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$65/JsonProtocol$$anonfun$65()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$68/JsonProtocol$$anonfun$68()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$67/JsonProtocol$$anonfun$67()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$66/JsonProtocol$$anonfun$66()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize_$eq(long)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize_$eq(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD/CoGroupedRDD(scala.collection.Seq,org.apache.spark.Partitioner)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$3/PairRDDFunctions$$anonfun$cogroup$3(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/isArray()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$3/PairRDDFunctions$$anonfun$cogroup$3(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$2/RDD$$anonfun$distinct$2(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkDocker$/startNode(scala.sys.process.ProcessBuilder)|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/sys/process/ProcessLogger$/apply(scala.Function1)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/package$/promise()|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkDocker$$anonfun$startNode$1/SparkDocker$$anonfun$startNode$1(scala.concurrent.Promise,java.io.FileWriter)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+constructor:///java/io/FileWriter/FileWriter(java.io.File)|",
      "|java+method:///scala/sys/process/ProcessBuilder/run(scala.sys.process.ProcessLogger)|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/Docker$/getLastProcessId()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///java/io/File/deleteOnExit()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/createTempDir$default$1()|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir$default$2()|",
      "|java+method:///scala/sys/process/ProcessLogger$/apply(scala.Function1)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/package$/promise()|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkDocker$$anonfun$startNode$1/SparkDocker$$anonfun$startNode$1(scala.concurrent.Promise,java.io.FileWriter)|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir(java.lang.String,java.lang.String)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+constructor:///java/io/FileWriter/FileWriter(java.io.File)|",
      "|java+method:///scala/sys/process/ProcessBuilder/run(scala.sys.process.ProcessLogger)|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/Docker$/getLastProcessId()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String,java.io.File)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$13/apply(org.apache.spark.scheduler.Stage)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/id()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Nothing()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$11/UIWorkloadGenerator$$anonfun$11()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$main$1/UIWorkloadGenerator$$anonfun$main$1(scala.Enumeration$Value,org.apache.spark.SparkContext,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$10/UIWorkloadGenerator$$anonfun$10(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/setMaster(java.lang.String)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/reflect/ClassTag$/Unit()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$12/UIWorkloadGenerator$$anonfun$12(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/scheduler/SchedulingMode$/withName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/makeRDD(scala.collection.Seq,int,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext/SparkContext(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$8/UIWorkloadGenerator$$anonfun$8(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$6/UIWorkloadGenerator$$anonfun$6(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$5/UIWorkloadGenerator$$anonfun$5(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$3/UIWorkloadGenerator$$anonfun$3(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$1/UIWorkloadGenerator$$anonfun$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/SparkConf/setAppName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$13/UIWorkloadGenerator$$anonfun$13()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$14/UIWorkloadGenerator$$anonfun$14()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/cache()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$/NUM_PARTITIONS()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/scheduler/SchedulingMode$/FAIR()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$9/UIWorkloadGenerator$$anonfun$9()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$7/UIWorkloadGenerator$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$4/UIWorkloadGenerator$$anonfun$4()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$2/UIWorkloadGenerator$$anonfun$2()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Nothing()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/concurrent/Semaphore/acquire()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$11/UIWorkloadGenerator$$anonfun$11()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(scala.Function2)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$10/UIWorkloadGenerator$$anonfun$10(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/setMaster(java.lang.String)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+constructor:///java/util/concurrent/Semaphore/Semaphore(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/reflect/ClassTag$/Unit()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$12/UIWorkloadGenerator$$anonfun$12(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$main$1/UIWorkloadGenerator$$anonfun$main$1(scala.Enumeration$Value,org.apache.spark.SparkContext,scala.collection.Seq,java.util.concurrent.Semaphore)|",
      "|java+method:///org/apache/spark/scheduler/SchedulingMode$/withName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/makeRDD(scala.collection.Seq,int,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext/SparkContext(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$8/UIWorkloadGenerator$$anonfun$8(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$6/UIWorkloadGenerator$$anonfun$6(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$5/UIWorkloadGenerator$$anonfun$5(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$3/UIWorkloadGenerator$$anonfun$3(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$1/UIWorkloadGenerator$$anonfun$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/SparkConf/setAppName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$13/UIWorkloadGenerator$$anonfun$13()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$14/UIWorkloadGenerator$$anonfun$14()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/cache()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/ui/UIWorkloadGenerator$/NUM_PARTITIONS()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/scheduler/SchedulingMode$/FAIR()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$9/UIWorkloadGenerator$$anonfun$9()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$7/UIWorkloadGenerator$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$4/UIWorkloadGenerator$$anonfun$4()|",
      "|java+constructor:///org/apache/spark/ui/UIWorkloadGenerator$$anonfun$2/UIWorkloadGenerator$$anonfun$2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$22/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$22$$anonfun$apply$15/StagePage$$anonfun$22$$anonfun$apply$15(org.apache.spark.ui.jobs.StagePage$$anonfun$22)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$22$$anonfun$apply$5/StagePage$$anonfun$22$$anonfun$apply$5(org.apache.spark.ui.jobs.StagePage$$anonfun$22)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage/org$apache$spark$ui$jobs$StagePage$$getGettingResultTime(org.apache.spark.scheduler.TaskInfo)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap/ExternalAppendOnlyMap(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.serializer.Serializer,org.apache.spark.storage.BlockManager)|",
    "called": "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$HashComparator/ExternalAppendOnlyMap$HashComparator()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/sparkConf()|",
      "|java+method:///scala/collection/TraversableLike$class/$init$(scala.collection.TraversableLike)|",
      "|java+method:///org/apache/spark/util/collection/Spillable$class/$init$(org.apache.spark.util.collection.Spillable)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/collection/TraversableOnce$class/$init$(scala.collection.TraversableOnce)|",
      "|java+method:///scala/collection/Traversable$class/$init$(scala.collection.Traversable)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/GenTraversableOnce$class/$init$(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/GenTraversable$class/$init$(scala.collection.GenTraversable)|",
      "|java+method:///scala/collection/IterableLike$class/$init$(scala.collection.IterableLike)|",
      "|java+method:///scala/collection/Iterable$class/$init$(scala.collection.Iterable)|",
      "|java+method:///scala/collection/Parallelizable$class/$init$(scala.collection.Parallelizable)|",
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/SizeTrackingAppendOnlyMap()|",
      "|java+method:///scala/collection/generic/GenericTraversableTemplate$class/$init$(scala.collection.generic.GenericTraversableTemplate)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/GenIterable$class/$init$(scala.collection.GenIterable)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap$HashComparator/ExternalAppendOnlyMap$HashComparator()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/sparkConf()|",
      "|java+method:///scala/collection/TraversableLike$class/$init$(scala.collection.TraversableLike)|",
      "|java+method:///org/apache/spark/util/collection/Spillable$class/$init$(org.apache.spark.util.collection.Spillable)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsKb(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/collection/TraversableOnce$class/$init$(scala.collection.TraversableOnce)|",
      "|java+method:///scala/collection/Traversable$class/$init$(scala.collection.Traversable)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/GenTraversableOnce$class/$init$(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/GenTraversable$class/$init$(scala.collection.GenTraversable)|",
      "|java+method:///scala/collection/IterableLike$class/$init$(scala.collection.IterableLike)|",
      "|java+method:///scala/collection/Iterable$class/$init$(scala.collection.Iterable)|",
      "|java+method:///scala/collection/Parallelizable$class/$init$(scala.collection.Parallelizable)|",
      "|java+constructor:///org/apache/spark/util/collection/SizeTrackingAppendOnlyMap/SizeTrackingAppendOnlyMap()|",
      "|java+method:///scala/collection/generic/GenericTraversableTemplate$class/$init$(scala.collection.generic.GenericTraversableTemplate)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/GenIterable$class/$init$(scala.collection.GenIterable)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/resize$mcJ$sp(int)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///scala/collection/mutable/ArrayOps/copyToArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|",
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/_array_$eq(long%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/_array()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/copyArrayWithLength$mcJ$sp(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/_array_$eq(long%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcJ$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/error(java.lang.String)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/size()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/logError(scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashMap/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/activeTaskSets()|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$error$1/TaskSchedulerImpl$$anonfun$error$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$error$3/TaskSchedulerImpl$$anonfun$error$3(org.apache.spark.scheduler.TaskSchedulerImpl,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$error$2/TaskSchedulerImpl$$anonfun$error$2(org.apache.spark.scheduler.TaskSchedulerImpl,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/size()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/activeTaskSets()|",
      "|java+method:///scala/collection/mutable/HashMap/nonEmpty()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$error$1/TaskSchedulerImpl$$anonfun$error$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$error$2/TaskSchedulerImpl$$anonfun$error$2(org.apache.spark.scheduler.TaskSchedulerImpl,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$16/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$16/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/name()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$16/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/firstDebugString$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/spark/rdd/RDD/debugChildren$1(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$firstDebugString$1$1/RDD$$anonfun$firstDebugString$1$1(org.apache.spark.rdd.RDD,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/debugSelf$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/spark/rdd/RDD/debugChildren$1(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$firstDebugString$1$1/RDD$$anonfun$firstDebugString$1$1(org.apache.spark.rdd.RDD,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/RDD/debugSelf$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$3/MasterPage$$anonfun$3(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$13/SparkContext$$anonfun$13(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$37/StagePage$$anonfun$37(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$/testParallelDecreasingSending(org.apache.spark.network.nio.ConnectionManager)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/reduceLeft(scala.Function2)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$2/ConnectionManager$$anonfun$testParallelDecreasingSending$2(org.apache.spark.network.nio.ConnectionManager,int,java.nio.ByteBuffer%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$17/ConnectionManager$$anonfun$17(int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$1/ConnectionManager$$anonfun$testParallelDecreasingSending$1()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$1/ConnectionManager$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$3/ConnectionManager$$anonfun$testParallelDecreasingSending$3()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$19/ConnectionManager$$anonfun$19()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/reduceLeft(scala.Function2)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$18/ConnectionManager$$anonfun$18(int)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$2/ConnectionManager$$anonfun$testParallelDecreasingSending$2(org.apache.spark.network.nio.ConnectionManager,int,java.nio.ByteBuffer%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$20/ConnectionManager$$anonfun$20()|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$1/ConnectionManager$$anonfun$testParallelDecreasingSending$1()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$1/ConnectionManager$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelDecreasingSending$3/ConnectionManager$$anonfun$testParallelDecreasingSending$3()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks(org.apache.spark.scheduler.Stage,int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/outputCommitCoordinator()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo_$eq(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///org/apache/spark/scheduler/Stage/pendingTasks()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/properties()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/runtime/RichException/getStackTraceString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/stageStart(int)|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$13/DAGScheduler$$anonfun$13(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///scala/Predef$/exceptionWrapper(java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$14/DAGScheduler$$anonfun$14(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.runtime.ObjectRef,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/closureSerializer()|",
      "|java+method:///scala/reflect/ClassTag$/AnyRef()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/sc()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo$/fromStage(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/taskScheduler()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/Stage/newAttemptId()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$2/DAGScheduler$$anonfun$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerStageSubmitted/SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numPartitions()|",
      "|java+method:///org/apache/spark/scheduler/Stage/resultOfJob()|",
      "|java+method:///org/apache/spark/scheduler/Stage/isShuffleMap()|",
      "|java+method:///java/nio/ByteBuffer/array()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/submitTasks(org.apache.spark.scheduler.TaskSet)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/Range/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$3/DAGScheduler$$anonfun$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///scala/collection/mutable/HashSet/clear()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSet/TaskSet(org.apache.spark.scheduler.Task%5B%5D,int,int,int,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/Stage/numPartitions()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/NotSerializableException/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/Stage/shuffleDep()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$16/DAGScheduler$$anonfun$16(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef,org.apache.spark.scheduler.ActiveJob,org.apache.spark.scheduler.ResultStage)|",
      "|java+method:///scala/Predef$/exceptionWrapper(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/Stage/newAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/outputCommitCoordinator()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///org/apache/spark/scheduler/Stage/pendingTasks()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/shuffleDep()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/rdd()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/runtime/RichException/getStackTraceString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/stageStart(int)|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/closureSerializer()|",
      "|java+method:///scala/reflect/ClassTag$/AnyRef()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/isAvailable()|",
      "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/sc()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo$/fromStage(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/taskScheduler()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$2/DAGScheduler$$anonfun$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ShuffleMapStage)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$14/DAGScheduler$$anonfun$14(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$1/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerStageSubmitted/SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numPartitions()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/array()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/submitTasks(org.apache.spark.scheduler.TaskSet)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/numPartitions()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/resultOfJob()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/numAvailableOutputs()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$4(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/Range/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$3/DAGScheduler$$anonfun$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///scala/collection/mutable/HashSet/clear()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSet/TaskSet(org.apache.spark.scheduler.Task%5B%5D,int,int,int,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$15/DAGScheduler$$anonfun$15(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef,org.apache.spark.scheduler.ShuffleMapStage)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/rdd()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo_$eq(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/io/NotSerializableException/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/numPartitions()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/BitSet/setUntil(int)|",
    "called": "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/BitSet/words()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/BitSet/words()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/apply()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/apply()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$/testParallelSending(org.apache.spark.network.nio.ConnectionManager)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelSending$2/ConnectionManager$$anonfun$testParallelSending$2()|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$16/ConnectionManager$$anonfun$16()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelSending$1/ConnectionManager$$anonfun$testParallelSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelSending$2/ConnectionManager$$anonfun$testParallelSending$2()|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testParallelSending$1/ConnectionManager$$anonfun$testParallelSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$17/ConnectionManager$$anonfun$17()|",
      "|java+method:///java/lang/System/currentTimeMillis()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler/DAGScheduler(org.apache.spark.SparkContext,org.apache.spark.scheduler.TaskScheduler,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.MapOutputTrackerMaster,org.apache.spark.storage.BlockManagerMaster,org.apache.spark.SparkEnv,org.apache.spark.util.Clock)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///java/util/concurrent/Executors/newScheduledThreadPool(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/setDAGScheduler(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/DAGSchedulerEventProcessLoop(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/start()|",
      "|java+method:///org/apache/spark/util/Utils$/namedThreadFactory(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/SparkEnv/outputCommitCoordinator()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonSingleThreadScheduledExecutor(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/setDAGScheduler(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/DAGSchedulerEventProcessLoop(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/start()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/SparkEnv/outputCommitCoordinator()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25/apply(java.lang.String)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/drivers()|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$master$Master$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$2/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$2(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$3/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$3(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/find(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$drivers()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$master$Master$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/HashSet/find(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$4/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$4(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$5/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25$$anonfun$apply$5(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,boolean,scala.Function2,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/dagScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/localProperties()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$2/SparkContext$$anonfun$runJob$2(org.apache.spark.SparkContext,org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$1/SparkContext$$anonfun$runJob$1(org.apache.spark.SparkContext,org.apache.spark.util.CallSite)|",
      "|java+method:///org/apache/spark/SparkContext/progressBar()|",
      "|java+method:///org/apache/spark/rdd/RDD/doCheckpoint()|",
      "|java+method:///org/apache/spark/SparkContext/stopped()|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,org.apache.spark.util.CallSite,boolean,scala.Function2,java.util.Properties,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///java/lang/InheritableThreadLocal/get()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/getCallSite()|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$3/SparkContext$$anonfun$runJob$3(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/dagScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/localProperties()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$2/SparkContext$$anonfun$runJob$2(org.apache.spark.SparkContext,org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$1/SparkContext$$anonfun$runJob$1(org.apache.spark.SparkContext,org.apache.spark.util.CallSite)|",
      "|java+method:///org/apache/spark/SparkContext/progressBar()|",
      "|java+method:///org/apache/spark/rdd/RDD/doCheckpoint()|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///java/lang/InheritableThreadLocal/get()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/getCallSite()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,org.apache.spark.util.CallSite,boolean,scala.Function2,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$runJob$3/SparkContext$$anonfun$runJob$3(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///java/util/concurrent/atomic/AtomicBoolean/get()|",
      "|java+method:///org/apache/spark/SparkContext/stopped()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleTaskCompletion(org.apache.spark.scheduler.CompletionEvent)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$1/DAGScheduler$$anonfun$handleTaskCompletion$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ResultTask)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/attempt()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/outputCommitCoordinator()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$15/DAGScheduler$$anonfun$handleTaskCompletion$15(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManagerId/executorId()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/util/concurrent/ScheduledExecutorService/schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/pendingTasks()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$minus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/FetchFailed/message()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$10/DAGScheduler$$anonfun$handleTaskCompletion$10(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$/RESUBMIT_TIMEOUT()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$11/DAGScheduler$$anonfun$handleTaskCompletion$11(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerTaskEnd/SparkListenerTaskEnd(int,int,java.lang.String,org.apache.spark.TaskEndReason,org.apache.spark.scheduler.TaskInfo,org.apache.spark.executor.TaskMetrics)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$13/DAGScheduler$$anonfun$handleTaskCompletion$13(org.apache.spark.scheduler.DAGScheduler,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finished()|",
      "|java+method:///org/apache/spark/FetchFailed/bmAddress()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleExecutorLost(java.lang.String,boolean,scala.Option)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/clearCacheLocs()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$16/DAGScheduler$$anonfun$handleTaskCompletion$16(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Task)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///org/apache/spark/scheduler/Stage/removeOutputLoc(int,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedEpoch()|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/result()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/Task/stageId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/ResultTask/outputId()|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numFinished_$eq(int)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskMetrics()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///scala/Int$/int2long(int)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/reason()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+method:///org/apache/spark/FetchFailed/shuffleId()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$3/DAGScheduler$$anonfun$handleTaskCompletion$3(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/updateAccumulators(org.apache.spark.scheduler.CompletionEvent)|",
      "|java+method:///org/apache/spark/scheduler/MapStatus/location()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/task()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$2/DAGScheduler$$anonfun$handleTaskCompletion$2(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/registerMapOutputs(int,org.apache.spark.scheduler.MapStatus%5B%5D,boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$4/DAGScheduler$$anonfun$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/collection/mutable/HashSet/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/messageScheduler()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/disallowStageRetryForTest()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/collection/mutable/HashSet/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/FetchFailed/mapId()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$18/DAGScheduler$$anonfun$handleTaskCompletion$18(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/Task/partitionId()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$15/DAGScheduler$$anonfun$15(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$6/DAGScheduler$$anonfun$handleTaskCompletion$6(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numPartitions()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$8/DAGScheduler$$anonfun$handleTaskCompletion$8(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$5/DAGScheduler$$anonfun$handleTaskCompletion$5(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$7/DAGScheduler$$anonfun$handleTaskCompletion$7(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$17/DAGScheduler$$anonfun$handleTaskCompletion$17(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,org.apache.spark.scheduler.Stage)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$9/DAGScheduler$$anonfun$handleTaskCompletion$9(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anon$2/DAGScheduler$$anon$2(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$4/DAGScheduler$$anonfun$handleTaskCompletion$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/resultOfJob()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/partitionId()|",
      "|java+method:///org/apache/spark/scheduler/Stage/addOutputLoc(int,org.apache.spark.scheduler.MapStatus)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/cleanupStateForJobAndIndependentStages(org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/unregisterMapOutput(int,int,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/epoch()|",
      "|java+method:///scala/collection/mutable/ArrayOps/exists(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/markStageAsFinished$default$2()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/DAGScheduler$$anonfun$handleTaskCompletion$14(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskInfo()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|",
      "|java+method:///org/apache/spark/scheduler/Stage/outputLocs()|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/taskCompleted(int,long,long,org.apache.spark.TaskEndReason)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numFinished()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///org/apache/spark/scheduler/Stage/shuffleDep()|",
      "|java+method:///scala/collection/mutable/ResizableArray/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$12/DAGScheduler$$anonfun$handleTaskCompletion$12(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$1/DAGScheduler$$anonfun$handleTaskCompletion$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ResultTask)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numFinished_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManagerId/executorId()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///java/util/concurrent/ScheduledExecutorService/schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/outputLocs()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/pendingTasks()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$12/DAGScheduler$$anonfun$handleTaskCompletion$12(org.apache.spark.scheduler.DAGScheduler,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$minus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/FetchFailed/message()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$/RESUBMIT_TIMEOUT()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$11/DAGScheduler$$anonfun$handleTaskCompletion$11(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerTaskEnd/SparkListenerTaskEnd(int,int,java.lang.String,org.apache.spark.TaskEndReason,org.apache.spark.scheduler.TaskInfo,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/shuffleDep()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finished()|",
      "|java+method:///org/apache/spark/FetchFailed/bmAddress()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$10/DAGScheduler$$anonfun$handleTaskCompletion$10(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleExecutorLost(java.lang.String,boolean,scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/pendingTasks()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/clearCacheLocs()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedEpoch()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/result()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$15/DAGScheduler$$anonfun$handleTaskCompletion$15(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Task)|",
      "|java+method:///org/apache/spark/scheduler/Task/stageId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/ResultTask/outputId()|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/attempt()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/removeOutputLoc(int,org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskMetrics()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/Int$/int2long(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/reason()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+method:///org/apache/spark/FetchFailed/shuffleId()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$3/DAGScheduler$$anonfun$handleTaskCompletion$3(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/updateAccumulators(org.apache.spark.scheduler.CompletionEvent)|",
      "|java+method:///org/apache/spark/scheduler/MapStatus/location()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/task()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$2/DAGScheduler$$anonfun$handleTaskCompletion$2(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/registerMapOutputs(int,org.apache.spark.scheduler.MapStatus%5B%5D,boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$4/DAGScheduler$$anonfun$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/collection/mutable/HashSet/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/messageScheduler()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/disallowStageRetryForTest()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/collection/mutable/HashSet/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/FetchFailed/mapId()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/outputCommitCoordinator()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$9/DAGScheduler$$anonfun$handleTaskCompletion$9(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ShuffleMapStage)|",
      "|java+method:///org/apache/spark/scheduler/Task/partitionId()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$6/DAGScheduler$$anonfun$handleTaskCompletion$6(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numPartitions()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$8/DAGScheduler$$anonfun$handleTaskCompletion$8(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$7/DAGScheduler$$anonfun$handleTaskCompletion$7(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anon$2/DAGScheduler$$anon$2(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$4/DAGScheduler$$anonfun$handleTaskCompletion$4(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$5/DAGScheduler$$anonfun$handleTaskCompletion$5(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$17/DAGScheduler$$anonfun$17(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/partitionId()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/cleanupStateForJobAndIndependentStages(org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/MapOutputTrackerMaster/unregisterMapOutput(int,int,org.apache.spark.storage.BlockManagerId)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$17/DAGScheduler$$anonfun$handleTaskCompletion$17(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,org.apache.spark.scheduler.ShuffleMapStage)|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/resultOfJob()|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/addOutputLoc(int,org.apache.spark.scheduler.MapStatus)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapTask/epoch()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/markStageAsFinished$default$2()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$16/DAGScheduler$$anonfun$handleTaskCompletion$16(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,org.apache.spark.scheduler.ShuffleMapStage)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$14/DAGScheduler$$anonfun$handleTaskCompletion$14(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskInfo()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/taskCompleted(int,long,long,org.apache.spark.TaskEndReason)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$13/DAGScheduler$$anonfun$handleTaskCompletion$13(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/numFinished()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///scala/collection/mutable/ResizableArray/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$11/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$11/apply()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/numPassed()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/numFailed()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$11/apply()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$numPassed()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$numFailed()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$filterWith$1/RDD$$anonfun$filterWith$1(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$3/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$3/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$3/apply()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countApproxDistinctByKey(double,org.apache.spark.Partitioner)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/postApplicationStart()|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerApplicationStart/SparkListenerApplicationStart(java.lang.String,scala.Option,long,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///org/apache/spark/SparkContext/applicationId()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///org/apache/spark/SparkContext/startTime()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerApplicationStart/SparkListenerApplicationStart(java.lang.String,scala.Option,long,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/applicationAttemptId()|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///org/apache/spark/SparkContext/applicationId()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///org/apache/spark/SparkContext/startTime()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/api/java/JavaUtils$SerializableMapWrapper/get(java.lang.Object)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/collection/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/api/java/JavaUtils$SerializableMapWrapper$$anonfun$get$1/JavaUtils$SerializableMapWrapper$$anonfun$get$1(org.apache.spark.api.java.JavaUtils$SerializableMapWrapper)|",
      "|java+method:///scala/collection/Map/getOrElse(java.lang.Object,scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
    "called": "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Tuple4/_1()|",
      "|java+method:///scala/Tuple4/_2()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster$$anonfun$start$2/LocalSparkCluster$$anonfun$start$2(org.apache.spark.deploy.LocalSparkCluster,org.apache.spark.SparkConf,java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/masterActorSystems()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/org$apache$spark$deploy$LocalSparkCluster$$localHostname()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster$$anonfun$start$1/LocalSparkCluster$$anonfun$start$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master$/startSystemAndActor(java.lang.String,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/clone()|",
      "|java+method:///org/apache/spark/SparkConf/setIfMissing(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostNameForURI()|",
      "|java+method:///scala/Tuple4/_1()|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster$$anonfun$start$2/LocalSparkCluster$$anonfun$start$2(org.apache.spark.deploy.LocalSparkCluster,org.apache.spark.SparkConf,java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/masterActorSystems()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/org$apache$spark$deploy$LocalSparkCluster$$localHostname()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster$$anonfun$start$1/LocalSparkCluster$$anonfun$start$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master$/startSystemAndActor(java.lang.String,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/clone()|",
      "|java+method:///org/apache/spark/SparkConf/setIfMissing(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/Tuple4/_2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/masterWebUIPort_$eq(int)|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///scala/Tuple4/_3()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6/apply(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/mapToJson(scala.collection.Map)|",
    "called": "|java+method:///scala/collection/Map$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/Map$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$39/JsonProtocol$$anonfun$39()|",
      "|java+constructor:///org/json4s/JsonAST$JObject/JsonAST$JObject(scala.collection.immutable.List)|",
      "|java+method:///scala/collection/Map/toList()|",
      "|java+method:///scala/collection/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Map$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$41/JsonProtocol$$anonfun$41()|",
      "|java+constructor:///org/json4s/JsonAST$JObject/JsonAST$JObject(scala.collection.immutable.List)|",
      "|java+method:///scala/collection/Map/toList()|",
      "|java+method:///scala/collection/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$20/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
    "v1Body": [
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$20/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$20/apply(java.nio.ByteBuffer)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/take(int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$33/RDD$$anonfun$33(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/size()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///java/lang/Math/max(int,int)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$take$1/RDD$$anonfun$take$1(org.apache.spark.rdd.RDD,int,scala.collection.mutable.ArrayBuffer)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$take$1/RDD$$anonfun$take$1(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/removeBroadcast(long,boolean)|",
    "called": "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/keys()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$4/BlockManager$$anonfun$4(org.apache.spark.storage.BlockManager,long)|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBroadcast$2/BlockManager$$anonfun$removeBroadcast$2(org.apache.spark.storage.BlockManager,boolean)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBroadcast$1/BlockManager$$anonfun$removeBroadcast$1(org.apache.spark.storage.BlockManager,long)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/Iterable/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/keys()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$4/BlockManager$$anonfun$4(org.apache.spark.storage.BlockManager,long)|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBroadcast$2/BlockManager$$anonfun$removeBroadcast$2(org.apache.spark.storage.BlockManager,boolean)|",
      "|java+method:///scala/collection/Iterable/collect(scala.PartialFunction,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBroadcast$1/BlockManager$$anonfun$removeBroadcast$1(org.apache.spark.storage.BlockManager,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$72/StagePage$$anonfun$72(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/apply()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/apply()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$10/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$10(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$11/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$11(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$9/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13$$anonfun$apply$9(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$stateValid$1(scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.IntRef,scala.runtime.ObjectRef)|",
    "called": "|java+method:///scala/collection/mutable/ListBuffer/size()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ListBuffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/masters()|",
      "|java+method:///scala/collection/mutable/BufferLike/$minus$minus(scala.collection.GenTraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/workers()|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$stateValid$1$1/FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$stateValid$1$1()|",
      "|java+method:///scala/collection/generic/TraversableForwarder/isEmpty()|",
      "|java+method:///scala/collection/mutable/ListBuffer/size()|",
      "|java+method:///scala/collection/mutable/ListBuffer$/canBuildFrom()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ListBuffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/BufferLike/$minus$minus(scala.collection.GenTraversableOnce)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$masters()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$workers()|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$stateValid$1$1/FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$stateValid$1$1()|",
      "|java+method:///scala/collection/generic/TraversableForwarder/isEmpty()|",
      "|java+method:///scala/collection/mutable/ListBuffer/size()|",
      "|java+method:///scala/collection/mutable/ListBuffer$/canBuildFrom()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/dropOldBlocks(long,scala.Function1)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/level()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/getEntrySet()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///org/apache/spark/storage/DiskStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+method:///org/apache/spark/util/TimeStampedValue/timestamp()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///org/apache/spark/storage/BlockManager/tachyonStore()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropOldBlocks$1/BlockManager$$anonfun$dropOldBlocks$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/util/TimeStampedValue/value()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/storage/BlockManager/externalBlockStore()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/level()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/getEntrySet()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///org/apache/spark/storage/DiskStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+method:///org/apache/spark/util/TimeStampedValue/timestamp()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropOldBlocks$1/BlockManager$$anonfun$dropOldBlocks$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useOffHeap()|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useMemory()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/util/TimeStampedValue/value()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/HistoryPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/getApplicationList()|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/getProviderConfig()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$5/HistoryPage$$anonfun$5(org.apache.spark.deploy.history.HistoryPage,boolean)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/org$apache$spark$deploy$history$HistoryPage$$makePageLink(int,boolean)|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/appHeader()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/plusOrMinus()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Iterable/filter(scala.Function1)|",
      "|java+constructor:///scala/xml/EntityRef/EntityRef(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$2/HistoryPage$$anonfun$2(org.apache.spark.deploy.history.HistoryPage,int)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/pageSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/rangeIndices(scala.collection.Seq,scala.Function1,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$4/HistoryPage$$anonfun$4(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$1/HistoryPage$$anonfun$1(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$6/HistoryPage$$anonfun$6(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$3/HistoryPage$$anonfun$3(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$7/HistoryPage$$anonfun$7(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$render$1/HistoryPage$$anonfun$render$1(org.apache.spark.deploy.history.HistoryPage,scala.xml.Elem)|",
      "|java+method:///scala/collection/immutable/Iterable$/canBuildFrom()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/Iterable/slice(int,int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/getApplicationList()|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/getProviderConfig()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$5/HistoryPage$$anonfun$5(org.apache.spark.deploy.history.HistoryPage,boolean)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/org$apache$spark$deploy$history$HistoryPage$$makePageLink(int,boolean)|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/appHeader()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/plusOrMinus()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///scala/collection/Iterable/exists(scala.Function1)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Iterable/filter(scala.Function1)|",
      "|java+constructor:///scala/xml/EntityRef/EntityRef(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$2/HistoryPage$$anonfun$2(org.apache.spark.deploy.history.HistoryPage,int)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/pageSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/rangeIndices(scala.collection.Seq,scala.Function1,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$4/HistoryPage$$anonfun$4(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$8/HistoryPage$$anonfun$8(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$1/HistoryPage$$anonfun$1(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryPage/appWithAttemptHeader()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$9/HistoryPage$$anonfun$9(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$6/HistoryPage$$anonfun$6(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$3/HistoryPage$$anonfun$3(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$7/HistoryPage$$anonfun$7(org.apache.spark.deploy.history.HistoryPage)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$render$1/HistoryPage$$anonfun$render$1(org.apache.spark.deploy.history.HistoryPage,scala.xml.Elem)|",
      "|java+method:///scala/collection/immutable/Iterable$/canBuildFrom()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/Iterable/slice(int,int)|",
      "|java+method:///java/lang/Math/min(int,int)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/FailedStageTable/toNodeSeq()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numCompletedStages()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeStages()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/pendingStages()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/isFairScheduler()|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/sc()|",
      "|java+method:///scala/collection/mutable/ListBuffer/reverse()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedStages()|",
      "|java+constructor:///org/apache/spark/ui/jobs/FailedStageTable/FailedStageTable(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedStages()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/listener()|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/basePath()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$6/AllStagesPage$$anonfun$6(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$1/AllStagesPage$$anonfun$1(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$5/AllStagesPage$$anonfun$5(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$4/AllStagesPage$$anonfun$4(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$8/AllStagesPage$$anonfun$8(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$7/AllStagesPage$$anonfun$7(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$2/AllStagesPage$$anonfun$2(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$3/AllStagesPage$$anonfun$3(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/isFairScheduler()|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$render$1/AllStagesPage$$anonfun$render$1(org.apache.spark.ui.jobs.AllStagesPage,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolTable/PoolTable(scala.collection.Seq,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+method:///scala/collection/generic/TraversableForwarder/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+method:///org/apache/spark/SparkContext/startTime()|",
      "|java+method:///org/apache/spark/ui/jobs/PoolTable/toNodeSeq()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numFailedStages()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/FailedStageTable/toNodeSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/failedStages()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numCompletedStages()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeStages()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/pendingStages()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/isFairScheduler()|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/sc()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/AllStagesPage/listener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/completedStages()|",
      "|java+constructor:///org/apache/spark/ui/jobs/FailedStageTable/FailedStageTable(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean)|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/basePath()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$6/AllStagesPage$$anonfun$6(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$1/AllStagesPage$$anonfun$1(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$5/AllStagesPage$$anonfun$5(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$4/AllStagesPage$$anonfun$4(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$3/AllStagesPage$$anonfun$3(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$2/AllStagesPage$$anonfun$2(org.apache.spark.ui.jobs.AllStagesPage)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/progressListener()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/isFairScheduler()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllStagesPage$$anonfun$render$1/AllStagesPage$$anonfun$render$1(org.apache.spark.ui.jobs.AllStagesPage,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolTable/PoolTable(scala.collection.Seq,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///scala/collection/generic/TraversableForwarder/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/PoolTable/toNodeSeq()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/numFailedStages()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ListBuffer/reverse()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$addIfAbsent$1(org.apache.spark.deploy.history.FsApplicationHistoryInfo,scala.collection.mutable.LinkedHashMap)|",
    "called": "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/IN_PROGRESS()|",
      "|java+method:///scala/collection/mutable/LinkedHashMap/$plus$eq(scala.Tuple2)|",
      "|java+method:///scala/collection/mutable/LinkedHashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/id()|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/logPath()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/LinkedHashMap/contains(java.lang.Object)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/LinkedHashMap/$plus$eq(scala.Tuple2)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/id()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/LinkedHashMap/contains(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/apply(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$1/apply()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$73/StagePage$$anonfun$73(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$/startSystemAndActor(java.lang.String,int,int,org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/restPort()|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/webUIPort()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/deploy/master/Master$/actorName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///org/apache/spark/deploy/master/Master$/systemName()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/restPort()|",
      "|java+method:///org/apache/spark/util/RpcUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/webUIPort()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/deploy/master/Master$/actorName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///org/apache/spark/deploy/master/Master$/systemName()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/countApprox(long,double)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/partial/CountEvaluator/CountEvaluator(int,double)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///org/apache/spark/SparkContext/runApproximateJob(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$31/RDD$$anonfun$31(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApprox$1/RDD$$anonfun$countApprox$1(org.apache.spark.rdd.RDD,long,double)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$19/SparkContext$$anonfun$19(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$23/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$23$$anonfun$apply$16/StagePage$$anonfun$23$$anonfun$apply$16(org.apache.spark.ui.jobs.StagePage$$anonfun$23)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$23$$anonfun$apply$6/StagePage$$anonfun$23$$anonfun$apply$6(org.apache.spark.ui.jobs.StagePage$$anonfun$23)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/org$apache$spark$ui$jobs$StagePage$$getSchedulerDelay(org.apache.spark.scheduler.TaskInfo,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/join(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$join$1/PairRDDFunctions$$anonfun$join$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/flatMapValues(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$join$1/PairRDDFunctions$$anonfun$join$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12/apply(scala.Tuple2)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$12/apply(scala.Tuple2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/apply()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$5/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$5(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$4/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$4(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/apply()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/apply()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$9/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$9(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$8/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$8(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$11/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$11(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$10/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12$$anonfun$apply$10(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/foldByKey(java.lang.Object,org.apache.spark.Partitioner,scala.Function2)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$foldByKey$1/PairRDDFunctions$$anonfun$foldByKey$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function2,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$6()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+constructor:///scala/runtime/VolatileByteRef/VolatileByteRef(byte)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$2/PairRDDFunctions$$anonfun$2(org.apache.spark.rdd.PairRDDFunctions,byte%5B%5D,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$5()|",
      "|java+method:///java/nio/ByteBuffer/limit()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$foldByKey$1/PairRDDFunctions$$anonfun$foldByKey$1(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object,org.apache.spark.Partitioner,scala.Function2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$21/SparkContext$$anonfun$21(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/SizeEstimator$/visitArray(java.lang.Object,java.lang.Class,org.apache.spark.util.SizeEstimator$SearchState)|",
    "called": "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size_$eq(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/objectSize()|",
      "|java+method:///java/lang/Class/getComponentType()|",
      "|java+constructor:///scala/runtime/DoubleRef/DoubleRef(double)|",
      "|java+method:///java/lang/reflect/Array/getLength(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size()|",
      "|java+constructor:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/OpenHashSet$mcI$sp(int,scala.reflect.ClassTag)|",
      "|java+method:///java/lang/Class/isPrimitive()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/INT_SIZE()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$primitiveSize(java.lang.Class)|",
      "|java+constructor:///java/util/Random/Random(long)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/ARRAY_SAMPLE_SIZE()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$pointerSize()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/ARRAY_SIZE_FOR_SAMPLING()|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$visitArray$2/SizeEstimator$$anonfun$visitArray$2(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState,int,scala.runtime.DoubleRef,java.util.Random,org.apache.spark.util.collection.OpenHashSet)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/alignSize(long)|",
      "|java+constructor:///org/apache/spark/util/SizeEstimator$$anonfun$visitArray$1/SizeEstimator$$anonfun$visitArray$1(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size_$eq(long)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///java/lang/Class/getComponentType()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/ARRAY_SIZE_FOR_SAMPLING()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/size()|",
      "|java+constructor:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/OpenHashSet$mcI$sp(int,scala.reflect.ClassTag)|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///java/lang/Class/isPrimitive()|",
      "|java+method:///scala/runtime/ScalaRunTime$/array_length(java.lang.Object)|",
      "|java+method:///scala/runtime/ScalaRunTime$/array_apply(java.lang.Object,int)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/INT_SIZE()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$primitiveSize(java.lang.Class)|",
      "|java+constructor:///java/util/Random/Random(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$SearchState/enqueue(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/objectSize()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/ARRAY_SAMPLE_SIZE()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/org$apache$spark$util$SizeEstimator$$pointerSize()|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/alignSize(long)|",
      "|java+method:///org/apache/spark/util/SizeEstimator$/sampleArray(java.lang.Object,org.apache.spark.util.SizeEstimator$SearchState,java.util.Random,org.apache.spark.util.collection.OpenHashSet,int)|",
      "|java+method:///scala/math/package$/min(long,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$16/apply()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$16/apply()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$16$$anonfun$apply$3/SparkContext$$anonfun$16$$anonfun$apply$3(org.apache.spark.SparkContext$$anonfun$16)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$$anonfun$16/apply()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/shuffle/sort/SortShuffleManager/getWriter(org.apache.spark.shuffle.ShuffleHandle,int,org.apache.spark.TaskContext)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/shuffle/sort/SortShuffleWriter/SortShuffleWriter(org.apache.spark.shuffle.IndexShuffleBlockManager,org.apache.spark.shuffle.BaseShuffleHandle,int,org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleManager/shuffleBlockManager()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/putIfAbsent(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/BaseShuffleHandle/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleManager/shuffleMapNumber()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/shuffle/BaseShuffleHandle/numMaps()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleManager/shuffleBlockResolver()|",
      "|java+constructor:///org/apache/spark/shuffle/sort/SortShuffleWriter/SortShuffleWriter(org.apache.spark.shuffle.IndexShuffleBlockResolver,org.apache.spark.shuffle.BaseShuffleHandle,int,org.apache.spark.TaskContext)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/putIfAbsent(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/BaseShuffleHandle/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleManager/shuffleMapNumber()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/shuffle/BaseShuffleHandle/numMaps()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$foreachWith$1/RDD$$anonfun$foreachWith$1(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2/AbstractFunction2()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/MasterPage$$anonfun$7(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/api/python/PythonRDD$$anon$2/run()|",
    "called": "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
    "v1Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///java/io/DataOutputStream/close()|",
      "|java+method:///org/apache/spark/api/python/PythonRDD$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/net/Socket/getOutputStream()|",
      "|java+method:///java/net/ServerSocket/accept()|",
      "|java+constructor:///java/io/DataOutputStream/DataOutputStream(java.io.OutputStream)|",
      "|java+constructor:///java/io/BufferedOutputStream/BufferedOutputStream(java.io.OutputStream)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD$/writeIteratorToStream(scala.collection.Iterator,java.io.DataOutputStream)|",
      "|java+method:///java/net/ServerSocket/close()|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$$anon$2$$anonfun$run$4/PythonRDD$$anon$2$$anonfun$run$4(org.apache.spark.api.python.PythonRDD$$anon$2)|"
    ],
    "v2Body": [
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///org/apache/spark/api/python/PythonRDD$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/net/Socket/getOutputStream()|",
      "|java+method:///java/net/ServerSocket/close()|",
      "|java+method:///java/net/ServerSocket/accept()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$$anon$2$$anonfun$run$1/PythonRDD$$anon$2$$anonfun$run$1(org.apache.spark.api.python.PythonRDD$$anon$2,java.io.DataOutputStream)|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$$anon$2$$anonfun$run$2/PythonRDD$$anon$2$$anonfun$run$2(org.apache.spark.api.python.PythonRDD$$anon$2,java.io.DataOutputStream)|",
      "|java+constructor:///java/io/DataOutputStream/DataOutputStream(java.io.OutputStream)|",
      "|java+constructor:///java/io/BufferedOutputStream/BufferedOutputStream(java.io.OutputStream)|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/api/python/PythonRDD$$anon$2$$anonfun$run$6/PythonRDD$$anon$2$$anonfun$run$6(org.apache.spark.api.python.PythonRDD$$anon$2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionCoalescer/PartitionCoalescer(int,org.apache.spark.rdd.RDD,double)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/collection/mutable/Set$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/util/Random/Random(int)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/collection/mutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/collection/mutable/Set$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/util/Random/Random(int)|",
      "|java+method:///scala/collection/mutable/Map$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/registerShuffleDependencies(org.apache.spark.ShuffleDependency,int)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/creationSite()|",
      "|java+method:///scala/collection/mutable/Stack/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getAncestorShuffleDependencies(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///org/apache/spark/ShuffleDependency/rdd()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newOrUsedStage(org.apache.spark.rdd.RDD,int,org.apache.spark.ShuffleDependency,int,org.apache.spark.util.CallSite)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/Stack/pop()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getAncestorShuffleDependencies(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/collection/mutable/Stack/nonEmpty()|",
      "|java+method:///org/apache/spark/ShuffleDependency/rdd()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newOrUsedShuffleStage(org.apache.spark.ShuffleDependency,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/Stack/pop()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile(java.lang.String,java.io.File,java.io.File,boolean,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput(scala.collection.Seq,java.io.File,scala.collection.Map,boolean)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile$default$5()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/io/RandomAccessFile/getChannel()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+method:///java/lang/String/hashCode()|",
      "|java+method:///org/apache/hadoop/fs/FileUtil/chmod(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput$default$3()|",
      "|java+method:///java/nio/channels/FileChannel/lock()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///java/io/RandomAccessFile/RandomAccessFile(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput$default$4()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchFile$1/Utils$$anonfun$fetchFile$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchFile$2/Utils$$anonfun$fetchFile$2(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/Utils$/doFetchFile(java.lang.String,java.io.File,java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/nio/channels/FileLock/release()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile(java.lang.String,java.io.File,java.io.File,boolean,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput(scala.collection.Seq,java.io.File,scala.collection.Map,boolean)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///org/apache/spark/util/Utils$/copyFile$default$5()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/io/RandomAccessFile/getChannel()|",
      "|java+method:///org/apache/spark/util/Utils$/isWindows()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+method:///java/lang/String/hashCode()|",
      "|java+method:///org/apache/hadoop/fs/FileUtil/chmod(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput$default$3()|",
      "|java+method:///java/nio/channels/FileChannel/lock()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///java/io/RandomAccessFile/RandomAccessFile(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput$default$4()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchFile$1/Utils$$anonfun$fetchFile$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$fetchFile$2/Utils$$anonfun$fetchFile$2(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/Utils$/doFetchFile(java.lang.String,java.io.File,java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///java/nio/channels/FileLock/release()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$getCallSite$1/apply(java.lang.String)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/CallSite$/LONG_FORM()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/getLocalProperty(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getCallSite$1$$anonfun$31/SparkContext$$anonfun$getCallSite$1$$anonfun$31(org.apache.spark.SparkContext$$anonfun$getCallSite$1)|",
      "|java+constructor:///org/apache/spark/util/CallSite/CallSite(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/getLocalProperty(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getCallSite$1$$anonfun$35/SparkContext$$anonfun$getCallSite$1$$anonfun$35(org.apache.spark.SparkContext$$anonfun$getCallSite$1)|",
      "|java+method:///org/apache/spark/util/CallSite$/LONG_FORM()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/CallSite/CallSite(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$2/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$2/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsTarget()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$2/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$2/apply(org.apache.spark.deploy.master.ApplicationInfo)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/appIdToUI()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/appSource()|",
      "|java+method:///org/apache/spark/deploy/master/Master/applicationMetricsSystem()|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$2$$anonfun$apply$16/Master$$anonfun$removeApplication$2$$anonfun$apply$16(org.apache.spark.deploy.master.Master$$anonfun$removeApplication$2)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/removeSource(org.apache.spark.metrics.source.Source)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$appIdToUI()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/removeSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$removeApplication$2$$anonfun$apply$19/Master$$anonfun$removeApplication$2$$anonfun$apply$19(org.apache.spark.deploy.master.Master$$anonfun$removeApplication$2)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/appSource()|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$applicationMetricsSystem()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmit$/org$apache$spark$deploy$SparkSubmit$$addJarToClasspath(java.lang.String,org.apache.spark.util.MutableURLClassLoader)|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printWarning(java.lang.String)|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/addURL(java.net.URL)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI(java.lang.String,boolean)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI$default$2()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printWarning(java.lang.String)|",
      "|java+method:///org/apache/spark/util/MutableURLClassLoader/addURL(java.net.URL)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI(java.lang.String)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener/JobProgressListener(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener$/DEFAULT_RETAINED_JOBS()|",
      "|java+method:///scala/collection/mutable/ListBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/scheduler/SparkListener$class/$init$(org.apache.spark.scheduler.SparkListener)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/HashMap$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener$/DEFAULT_RETAINED_STAGES()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/SparkUI$/DEFAULT_RETAINED_JOBS()|",
      "|java+method:///scala/collection/mutable/HashMap$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ListBuffer$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/scheduler/SparkListener$class/$init$(org.apache.spark.scheduler.SparkListener)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/ui/SparkUI$/DEFAULT_RETAINED_STAGES()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$8/apply$mcZ$sp()|",
    "called": "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$8$$anonfun$apply$mcZ$sp$1/FaultToleranceTest$$anonfun$8$$anonfun$apply$mcZ$sp$1(org.apache.spark.deploy.FaultToleranceTest$$anonfun$8)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD/collect()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/parallelize(scala.collection.Seq,int,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+method:///org/apache/spark/SparkContext/parallelize$default$2()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/sc()|",
      "|java+method:///java/lang/Exception/printStackTrace()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$8$$anonfun$apply$mcZ$sp$1/FaultToleranceTest$$anonfun$8$$anonfun$apply$mcZ$sp$1(org.apache.spark.deploy.FaultToleranceTest$$anonfun$8)|",
      "|java+method:///org/apache/spark/rdd/RDD/collect()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/parallelize(scala.collection.Seq,int,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue(boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$sc()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///java/lang/Exception/printStackTrace()|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertTrue$default$2()|",
      "|java+method:///org/apache/spark/SparkContext/parallelize$default$2()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$18/JsonProtocol$$anonfun$18()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$14/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/lookup(java.lang.Object)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/collect()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$lookup$2/PairRDDFunctions$$anonfun$lookup$2(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+method:///scala/Predef$/wrapIntArray(int%5B%5D)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/Partitioner/getPartition(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/filter(scala.Function1)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Some/x()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$lookup$1/PairRDDFunctions$$anonfun$lookup$1(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$11/PairRDDFunctions$$anonfun$11(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$lookup$1/PairRDDFunctions$$anonfun$lookup$1(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/scheduler/WorkerOffer/WorkerOffer(java.lang.String,java.lang.String,int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/removeShuffle(int,boolean)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeShuffle$1/BlockManagerMaster$$anonfun$removeShuffle$1(org.apache.spark.storage.BlockManagerMaster,int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveShuffle/BlockManagerMessages$RemoveShuffle(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeShuffle$1/BlockManagerMaster$$anonfun$removeShuffle$1(org.apache.spark.storage.BlockManagerMaster,int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/sameThread()|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveShuffle/BlockManagerMessages$RemoveShuffle(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$11/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$11/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$11/apply(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart$/unapply(org.apache.spark.scheduler.SparkListenerApplicationStart)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|",
      "|java+constructor:///scala/Tuple5/Tuple5(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$79/StagePage$$anonfun$79(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,boolean,scala.Function2,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$32/SparkContext$$anonfun$32(org.apache.spark.SparkContext,scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,boolean,scala.Function2,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$36/SparkContext$$anonfun$36(org.apache.spark.SparkContext,scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$35/JsonProtocol$$anonfun$35()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$filter$1/RDD$$anonfun$filter$1(org.apache.spark.rdd.RDD,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/Tuple2/_2$mcI$sp()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/ShuffleCoGroupSplitDep/ShuffleCoGroupSplitDep(org.apache.spark.shuffle.ShuffleHandle)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleHandle()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/dependencies()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/NarrowCoGroupSplitDep/NarrowCoGroupSplitDep(org.apache.spark.rdd.RDD,int,org.apache.spark.Partition)|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1/org$apache$spark$rdd$CoGroupedRDD$$anonfun$$$outer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/dependencies()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/NarrowCoGroupSplitDep/NarrowCoGroupSplitDep(org.apache.spark.rdd.RDD,int,org.apache.spark.Partition)|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1/org$apache$spark$rdd$CoGroupedRDD$$anonfun$$$outer()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleBeginEvent(org.apache.spark.scheduler.Task,org.apache.spark.scheduler.TaskInfo)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/Task/stageId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerTaskStart/SparkListenerTaskStart(int,int,org.apache.spark.scheduler.TaskInfo)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$10/DAGScheduler$$anonfun$10(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$1/DAGScheduler$$anonfun$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/Task/stageId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerTaskStart/SparkListenerTaskStart(int,int,org.apache.spark.scheduler.TaskInfo)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$1/DAGScheduler$$anonfun$1(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/DAGScheduler$$anonfun$11(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/Accumulators$$anonfun$add$2/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/Accumulable/$plus$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Map/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///scala/Tuple2/_1$mcJ$sp()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/Accumulators$/logWarning(scala.Function0)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulable/$plus$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Map/contains(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalAccessError/IllegalAccessError(java.lang.String)|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///scala/Tuple2/_1$mcJ$sp()|",
      "|java+constructor:///org/apache/spark/Accumulators$$anonfun$add$2$$anonfun$apply$1/Accumulators$$anonfun$add$2$$anonfun$apply$1(org.apache.spark.Accumulators$$anonfun$add$2,long)|",
      "|java+method:///scala/ref/ReferenceWrapper/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/loadEnvironmentArguments()|",
    "called": "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$11/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$11(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///java/util/jar/Attributes/getValue(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/action()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$20/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$20(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath()|",
      "|java+method:///org/apache/spark/util/Utils$/stripDirectory(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$10/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$10(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$12/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$12(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores()|",
      "|java+constructor:///java/util/jar/JarFile/JarFile(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/action_$eq(scala.Enumeration$Value)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$13/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$13(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$14/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$14(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$15/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$15(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars_$eq(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$16/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$16(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors_$eq(java.lang.String)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$5/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$5(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$9/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$9(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$4/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$4(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$8/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$8(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$3/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$3(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$7/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$7(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$17/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$17(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$2/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$2(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$6/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$6(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$1/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$1(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$18/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$18(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores_$eq(java.lang.String)|",
      "|java+method:///java/util/jar/Manifest/getMainAttributes()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode()|",
      "|java+method:///java/util/jar/JarFile/getManifest()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$19/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$19(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master_$eq(java.lang.String)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/ivyRepoPath_$eq(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/sparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$11/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$11(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///java/net/URI/URI(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master()|",
      "|java+method:///java/util/jar/Attributes/getValue(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass_$eq(java.lang.String)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/action()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$20/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$20(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath()|",
      "|java+method:///org/apache/spark/util/Utils$/stripDirectory(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$10/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$10(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$12/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$12(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores()|",
      "|java+constructor:///java/util/jar/JarFile/JarFile(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/action_$eq(scala.Enumeration$Value)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$13/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$13(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mainClass()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$14/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$14(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$15/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$15(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraLibraryPath_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/jars_$eq(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$16/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$16(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/numExecutors_$eq(java.lang.String)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isPython()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$5/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$5(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$9/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$9(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$4/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$4(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$8/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$8(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$3/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$3(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$7/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$7(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$17/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$17(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$2/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$2(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$6/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$6(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$1/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$1(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$18/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$18(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+method:///java/net/URI/getPath()|",
      "|java+method:///java/net/URI/getScheme()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/totalExecutorCores_$eq(java.lang.String)|",
      "|java+method:///java/util/jar/Manifest/getMainAttributes()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/isR()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/deployMode()|",
      "|java+method:///java/util/jar/JarFile/getManifest()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/name()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$19/SparkSubmitArguments$$anonfun$loadEnvironmentArguments$19(org.apache.spark.deploy.SparkSubmitArguments)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/master_$eq(java.lang.String)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverCores()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorCores_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/ivyRepoPath_$eq(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/sparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/primaryResource()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/executorMemory()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraJavaOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverMemory_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/driverExtraClassPath()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$foreachPartition$1/RDD$$anonfun$foreachPartition$1(org.apache.spark.rdd.RDD,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/apply()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$7/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$7(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$6/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$6(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$5/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$5(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$4/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11$$anonfun$apply$4(org.apache.spark.deploy.worker.Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/apply()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/apply()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions/foreachAsync(scala.Function1)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/package$/Range()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachAsync$2/AsyncRDDActions$$anonfun$foreachAsync$2(org.apache.spark.rdd.AsyncRDDActions,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachAsync$1/AsyncRDDActions$$anonfun$foreachAsync$1(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachAsync$3/AsyncRDDActions$$anonfun$foreachAsync$3(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachAsync$1/AsyncRDDActions$$anonfun$foreachAsync$1(org.apache.spark.rdd.AsyncRDDActions,scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/requestExecutors(int)|",
    "called": "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/dynamicAllocationTesting()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/requestExecutors(int)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/master()|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestExecutors$1/SparkContext$$anonfun$requestExecutors$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestExecutors$2/SparkContext$$anonfun$requestExecutors$2(org.apache.spark.SparkContext)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/requestExecutors(int)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/supportDynamicAllocation()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestExecutors$1/SparkContext$$anonfun$requestExecutors$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestExecutors$2/SparkContext$$anonfun$requestExecutors$2(org.apache.spark.SparkContext)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$32/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$32/apply(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$32/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1/org$apache$spark$deploy$worker$Worker$$anonfun$$$outer()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/connectionAttemptCount()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2/apply()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$connectionAttemptCount()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1/org$apache$spark$deploy$worker$Worker$$anonfun$$$outer()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SubtractedRDD/compute(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
    "called": "|java+method:///scala/collection/TraversableOnce$/flattenTraversableOnce(scala.collection.TraversableOnce,scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///scala/collection/TraversableOnce$/flattenTraversableOnce(scala.collection.TraversableOnce,scala.Function1)|",
      "|java+method:///scala/collection/mutable/Map/iterator()|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$3/SubtractedRDD$$anonfun$compute$3(org.apache.spark.rdd.SubtractedRDD)|",
      "|java+method:///org/apache/spark/rdd/CoGroupPartition/deps()|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$1/SubtractedRDD$$anonfun$compute$1(org.apache.spark.rdd.SubtractedRDD,java.util.HashMap)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$2/SubtractedRDD$$anonfun$compute$2(org.apache.spark.rdd.SubtractedRDD,java.util.HashMap)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/integrate$1(org.apache.spark.rdd.CoGroupSplitDep,scala.Function1,org.apache.spark.TaskContext,org.apache.spark.rdd.CoGroupPartition)|",
      "|java+constructor:///java/util/HashMap/HashMap()|",
      "|java+method:///scala/collection/TraversableOnce$FlattenOps/flatten()|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///scala/collection/TraversableOnce$/flattenTraversableOnce(scala.collection.TraversableOnce,scala.Function1)|",
      "|java+method:///scala/collection/mutable/Map/iterator()|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$3/SubtractedRDD$$anonfun$compute$3(org.apache.spark.rdd.SubtractedRDD)|",
      "|java+constructor:///java/util/HashMap/HashMap()|",
      "|java+method:///scala/collection/Iterator/map(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/integrate$1(int,scala.Function1,org.apache.spark.TaskContext,org.apache.spark.rdd.CoGroupPartition)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$1/SubtractedRDD$$anonfun$compute$1(org.apache.spark.rdd.SubtractedRDD,java.util.HashMap)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$compute$2/SubtractedRDD$$anonfun$compute$2(org.apache.spark.rdd.SubtractedRDD,java.util.HashMap)|",
      "|java+method:///scala/collection/TraversableOnce$FlattenOps/flatten()|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CartesianRDD/getPartitions()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/CartesianRDD$$anonfun$getPartitions$1/CartesianRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CartesianRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd1()|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd2()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/CartesianRDD$$anonfun$getPartitions$1/CartesianRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CartesianRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd1()|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd2()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/kryo()|",
      "|java+method:///com/esotericsoftware/kryo/io/Output/clear()|",
      "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/output()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///com/esotericsoftware/kryo/KryoException/getMessage()|",
      "|java+method:///com/esotericsoftware/kryo/Kryo/writeClassAndObject(com.esotericsoftware.kryo.io.Output,java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///com/esotericsoftware/kryo/io/Output/toBytes()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/borrowKryo()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///com/esotericsoftware/kryo/io/Output/clear()|",
      "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/output()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///com/esotericsoftware/kryo/Kryo/writeClassAndObject(com.esotericsoftware.kryo.io.Output,java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///com/esotericsoftware/kryo/io/Output/toBytes()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/wrap(byte%5B%5D)|",
      "|java+method:///org/apache/spark/serializer/KryoSerializerInstance/releaseKryo(com.esotericsoftware.kryo.Kryo)|",
      "|java+method:///com/esotericsoftware/kryo/KryoException/getMessage()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore/putIterator(org.apache.spark.storage.BlockId,scala.collection.Iterator,org.apache.spark.storage.StorageLevel,boolean)|",
    "called": "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/DiskStore/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/DiskStore$$anonfun$putIterator$2(org.apache.spark.storage.DiskStore,java.io.File,long,long)|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerializeStream$default$4()|",
      "|java+method:///scala/package$/Right()|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dataSerializeStream(org.apache.spark.storage.BlockId,java.io.OutputStream,scala.collection.Iterator,org.apache.spark.serializer.Serializer)|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/PutResult$/apply$default$3()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/DiskStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/DiskStore$$anonfun$putIterator$1(org.apache.spark.storage.DiskStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///org/apache/spark/storage/BlockStore/blockManager()|",
      "|java+constructor:///org/apache/spark/storage/PutResult/PutResult(long,scala.util.Either,scala.collection.Seq)|",
      "|java+method:///java/io/FileOutputStream/close()|",
      "|java+method:///java/io/File/delete()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskStore/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$2/DiskStore$$anonfun$putIterator$2(org.apache.spark.storage.DiskStore,java.io.FileOutputStream)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$4/DiskStore$$anonfun$putIterator$4(org.apache.spark.storage.DiskStore,java.io.File,long,long)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/DiskStore$$anonfun$putIterator$1(org.apache.spark.storage.DiskStore,org.apache.spark.storage.BlockId,scala.collection.Iterator,java.io.FileOutputStream)|",
      "|java+method:///scala/package$/Right()|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///java/io/File/length()|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/storage/PutResult$/apply$default$3()|",
      "|java+constructor:///org/apache/spark/storage/PutResult/PutResult(long,scala.util.Either,scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/storage/DiskStore/getBytes(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/util/Utils$/tryWithSafeFinally(scala.Function0,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/getFile(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+constructor:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$3/DiskStore$$anonfun$putIterator$3(org.apache.spark.storage.DiskStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/io/File/delete()|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/TaskResultGetter$$anon$2$$anonfun$run$1/apply$mcV$sp()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/abort(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/logDebug(scala.Function0)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///java/lang/ThreadLocal/get()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/canFetchMoreResults(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/metrics()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleSuccessfulTask(org.apache.spark.scheduler.TaskSetManager,long,org.apache.spark.scheduler.DirectTaskResult)|",
      "|java+method:///org/apache/spark/scheduler/IndirectTaskResult/blockId()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter$$anon$2/org$apache$spark$scheduler$TaskResultGetter$$anon$$$outer()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/removeBlock(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleFailedTask(org.apache.spark.scheduler.TaskSetManager,long,scala.Enumeration$Value,org.apache.spark.TaskEndReason)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getRemoteBytes(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$1/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$1(org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1)|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/serializer()|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$apply$mcV$sp$1/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/setResultSize(long)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleTaskGettingResult(org.apache.spark.scheduler.TaskSetManager,long)|",
      "|java+constructor:///scala/runtime/NonLocalReturnControl$mcV$sp/NonLocalReturnControl$mcV$sp(java.lang.Object,scala.runtime.BoxedUnit)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/IndirectTaskResult/size()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/abort(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/value()|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/logDebug(scala.Function0)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///java/lang/ThreadLocal/get()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/canFetchMoreResults(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DirectTaskResult/metrics()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleSuccessfulTask(org.apache.spark.scheduler.TaskSetManager,long,org.apache.spark.scheduler.DirectTaskResult)|",
      "|java+method:///org/apache/spark/scheduler/IndirectTaskResult/blockId()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter$$anon$2/org$apache$spark$scheduler$TaskResultGetter$$anon$$$outer()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/removeBlock(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleFailedTask(org.apache.spark.scheduler.TaskSetManager,long,scala.Enumeration$Value,org.apache.spark.TaskEndReason)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getRemoteBytes(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$1/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$1(org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1)|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/serializer()|",
      "|java+method:///org/apache/spark/scheduler/TaskResultGetter/logError(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$apply$mcV$sp$1/TaskResultGetter$$anon$2$$anonfun$run$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/setResultSize(long)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/handleTaskGettingResult(org.apache.spark.scheduler.TaskSetManager,long)|",
      "|java+constructor:///scala/runtime/NonLocalReturnControl$mcV$sp/NonLocalReturnControl$mcV$sp(java.lang.Object,scala.runtime.BoxedUnit)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/IndirectTaskResult/size()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskBlockManager/getAllFiles()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/flatten(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$DummyImplicit$/dummyImplicit()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirs()|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$3/DiskBlockManager$$anonfun$getAllFiles$3(org.apache.spark.storage.DiskBlockManager)|",
      "|java+method:///scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$2/DiskBlockManager$$anonfun$getAllFiles$2(org.apache.spark.storage.DiskBlockManager)|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$1/DiskBlockManager$$anonfun$getAllFiles$1(org.apache.spark.storage.DiskBlockManager)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$DummyImplicit$/dummyImplicit()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirs()|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$3/DiskBlockManager$$anonfun$getAllFiles$3(org.apache.spark.storage.DiskBlockManager)|",
      "|java+method:///scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$2/DiskBlockManager$$anonfun$getAllFiles$2(org.apache.spark.storage.DiskBlockManager)|",
      "|java+constructor:///org/apache/spark/storage/DiskBlockManager$$anonfun$getAllFiles$1/DiskBlockManager$$anonfun$getAllFiles$1(org.apache.spark.storage.DiskBlockManager)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/binaryRecords(java.lang.String,int,org.apache.hadoop.conf.Configuration)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$27/SparkContext$$anonfun$27(org.apache.spark.SparkContext,int)|",
      "|java+method:///org/apache/hadoop/conf/Configuration/setInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/input/FixedLengthBinaryInputFormat$/RECORD_LENGTH_PROPERTY()|",
      "|java+method:///org/apache/spark/SparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$binaryRecords$1/SparkContext$$anonfun$binaryRecords$1(org.apache.spark.SparkContext,java.lang.String,int,org.apache.hadoop.conf.Configuration)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/getExecutorMemoryStatus()|",
    "called": "|java+method:///scala/collection/immutable/Map$/canBuildFrom()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getExecutorMemoryStatus$1/SparkContext$$anonfun$getExecutorMemoryStatus$1(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///scala/collection/immutable/Map$/canBuildFrom()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/getMemoryStatus()|",
      "|java+method:///org/apache/spark/SparkContext/env()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$getExecutorMemoryStatus$1/SparkContext$$anonfun$getExecutorMemoryStatus$1(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/Map/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$assertNotStopped()|",
      "|java+method:///scala/collection/immutable/Map$/canBuildFrom()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/getMemoryStatus()|",
      "|java+method:///org/apache/spark/SparkContext/env()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore/ensureFreeSpace(org.apache.spark.storage.BlockId,long)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/storage/ResultWithDroppedBlocks/ResultWithDroppedBlocks(boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$entries()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/freeMemory()|",
      "|java+method:///org/apache/spark/storage/MemoryEntry/size()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$1/MemoryStore$$anonfun$ensureFreeSpace$1(org.apache.spark.storage.MemoryStore,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemory()|",
      "|java+method:///java/util/LinkedHashMap/entrySet()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$5/MemoryStore$$anonfun$ensureFreeSpace$5(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$2/MemoryStore$$anonfun$ensureFreeSpace$2(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getRddId(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$4/MemoryStore$$anonfun$ensureFreeSpace$4(org.apache.spark.storage.MemoryStore,scala.collection.mutable.ArrayBuffer)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$3/MemoryStore$$anonfun$ensureFreeSpace$3(org.apache.spark.storage.MemoryStore,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logInfo(scala.Function0)|",
      "|java+method:///java/util/Set/iterator()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/ResultWithDroppedBlocks/ResultWithDroppedBlocks(boolean,scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$entries()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$1/MemoryStore$$anonfun$1(org.apache.spark.storage.MemoryStore)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/freeMemory()|",
      "|java+method:///org/apache/spark/storage/MemoryEntry/size()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$1/MemoryStore$$anonfun$ensureFreeSpace$1(org.apache.spark.storage.MemoryStore,long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/currentUnrollMemory()|",
      "|java+method:///java/util/LinkedHashMap/entrySet()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$5/MemoryStore$$anonfun$ensureFreeSpace$5(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$2/MemoryStore$$anonfun$ensureFreeSpace$2(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getRddId(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$4/MemoryStore$$anonfun$ensureFreeSpace$4(org.apache.spark.storage.MemoryStore,scala.collection.mutable.ArrayBuffer)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$ensureFreeSpace$3/MemoryStore$$anonfun$ensureFreeSpace$3(org.apache.spark.storage.MemoryStore,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/pendingUnrollMemoryMap()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logInfo(scala.Function0)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+method:///java/lang/Thread/getId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/stageInfoFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extractOpt(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/failureReason_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$50/JsonProtocol$$anonfun$50()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$48/JsonProtocol$$anonfun$48()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$53/JsonProtocol$$anonfun$53()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$52/JsonProtocol$$anonfun$52()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$51/JsonProtocol$$anonfun$51()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$49/JsonProtocol$$anonfun$49()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoFromJson$1/JsonProtocol$$anonfun$stageInfoFromJson$1(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime_$eq(scala.Option)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$7/JsonProtocol$$anonfun$7()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo/StageInfo(int,int,java.lang.String,int,scala.collection.Seq,java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extractOpt(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/failureReason_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$54/JsonProtocol$$anonfun$54()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$58/JsonProtocol$$anonfun$58()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$53/JsonProtocol$$anonfun$53()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$57/JsonProtocol$$anonfun$57()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$52/JsonProtocol$$anonfun$52()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$56/JsonProtocol$$anonfun$56()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$51/JsonProtocol$$anonfun$51()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$55/JsonProtocol$$anonfun$55()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoFromJson$1/JsonProtocol$$anonfun$stageInfoFromJson$1(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo/StageInfo(int,int,java.lang.String,int,scala.collection.Seq,scala.collection.Seq,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime_$eq(scala.Option)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$7/JsonProtocol$$anonfun$7()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$11/StagePage$$anonfun$11(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1$mcJJ$sp/AbstractFunction1$mcJJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$serverUri()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/apply()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$$anonfun$org$apache$spark$broadcast$HttpBroadcast$$read$1/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$49/JsonProtocol$$anonfun$49()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$6/StagePage$$anonfun$6(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1$mcJJ$sp/AbstractFunction1$mcJJ$sp()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1$mcJJ$sp/AbstractFunction1$mcJJ$sp()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcJ$sp/AbstractFunction0$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext/SparkContext(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/dagScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/dynamicAllocationTesting()|",
      "|java+method:///org/apache/spark/util/MetadataCleanerType$/SPARK_CONTEXT()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/executorAllocationManager()|",
      "|java+method:///akka/actor/Props$/apply(scala.Function0,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/SparkContext/postApplicationStart()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///org/apache/spark/SparkConf/clone()|",
      "|java+method:///org/apache/spark/SparkConf/setIfMissing(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ExecutorAllocationClient$class/$init$(org.apache.spark.ExecutorAllocationClient)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///org/apache/spark/SparkContext/postEnvironmentUpdate()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/start()|",
      "|java+method:///org/apache/spark/SparkContext/allowMultipleContexts()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener/EventLoggingListener(java.lang.String,java.net.URI,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/jobProgressListener()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$9/SparkContext$$anonfun$9(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/tachyonFolderName()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerSource/BlockManagerSource(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/SparkContext/jars()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$8/SparkContext$$anonfun$8(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/io/CompressionCodec$/getCodecName(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/start()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler/DAGScheduler(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/TraversableLike/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/Utils$/getCallSite$default$1()|",
      "|java+constructor:///org/apache/spark/util/MetadataCleaner/MetadataCleaner(scala.Enumeration$Value,scala.Function1,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+constructor:///org/apache/spark/util/TimeStampedWeakValueHashMap/TimeStampedWeakValueHashMap(boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$7/SparkContext$$anonfun$7(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext$/setActiveContext(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/dagScheduler_$eq(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/SparkContext/eventLogDir()|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/postStartHook()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/validateSettings()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(int)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$6/SparkContext$$anonfun$6(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/ui/SparkUI$/createLiveUI(org.apache.spark.SparkContext,org.apache.spark.SparkConf,org.apache.spark.scheduler.SparkListenerBus,org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.SecurityManager,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/log()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap$/apply(scala.collection.Seq)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/getCurrentUserName()|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$5/SparkContext$$anonfun$5(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener/JobProgressListener(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/DEFAULT_LOG_DIR()|",
      "|java+method:///org/apache/spark/SparkContext/createSparkEnv(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$4/SparkContext$$anonfun$4(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/Seq/flatten(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/applicationId()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///scala/Some/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/master()|",
      "|java+method:///org/apache/spark/SparkContext/dynamicAllocationEnabled()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/addListener(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$3/SparkContext$$anonfun$3(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/mutable/HashMap/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/initDriverMetrics()|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+method:///org/apache/spark/SparkContext/applicationId()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$18/SparkContext$$anonfun$18(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$2/SparkContext$$anonfun$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$15/SparkContext$$anonfun$15(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$16/SparkContext$$anonfun$16(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$17/SparkContext$$anonfun$17(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/setupAndStartListenerBus()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anon$1/SparkContext$$anon$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$20/SparkContext$$anonfun$20(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkStatusTracker/SparkStatusTracker(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$14/SparkContext$$anonfun$14(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$25/SparkContext$$anonfun$25(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$19/SparkContext$$anonfun$19(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$10/SparkContext$$anonfun$10(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$21/SparkContext$$anonfun$21(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$22/SparkContext$$anonfun$22(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/ContextCleaner/ContextCleaner(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$11/SparkContext$$anonfun$11(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$12/SparkContext$$anonfun$12(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$23/SparkContext$$anonfun$23(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$13/SparkContext$$anonfun$13(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$24/SparkContext$$anonfun$24(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/isEventLogEnabled()|",
      "|java+method:///scala/collection/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$createTaskScheduler(org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$1/SparkContext$$anonfun$1(org.apache.spark.SparkContext)|",
      "|java+method:///java/lang/System/setProperty(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGSchedulerSource/DAGSchedulerSource(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext$/DRIVER_IDENTIFIER()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/LiveListenerBus/LiveListenerBus()|",
      "|java+method:///org/apache/spark/SparkEnv$/set(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkConf/getExecutorEnv()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap$/$lessinit$greater$default$1()|",
      "|java+method:///org/apache/spark/util/Utils$/getCallSite(scala.Function1)|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/storage/BlockManager/initialize(java.lang.String)|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/metricsSystem()|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/isInfoEnabled()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripSuffix(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext$/markPartiallyConstructed(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar/ConsoleProgressBar(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager/ExecutorAllocationManager(org.apache.spark.ExecutorAllocationClient,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/SparkContext/files()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI$default$2()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/dagScheduler()|",
      "|java+method:///org/apache/spark/util/MetadataCleanerType$/SPARK_CONTEXT()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/SparkContext/postApplicationStart()|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///org/apache/spark/SparkConf/clone()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/_hadoopConfiguration()|",
      "|java+method:///org/apache/spark/SparkContext/_files_$eq(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/setIfMissing(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ExecutorAllocationClient$class/$init$(org.apache.spark.ExecutorAllocationClient)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$_conf()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/_schedulerBackend_$eq(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/HeartbeatReceiver$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///org/apache/spark/SparkContext/postEnvironmentUpdate()|",
      "|java+method:///scala/util/control/NonFatal$/unapply(java.lang.Throwable)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener/start()|",
      "|java+method:///org/apache/spark/SparkContext/allowMultipleContexts()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$_env()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/getServletHandlers()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/jobProgressListener()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$9/SparkContext$$anonfun$9(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_cleaner()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerSource/BlockManagerSource(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/SparkContext/_taskScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/_jobProgressListener_$eq(org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+method:///org/apache/spark/SparkContext/_applicationId_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/jars()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$8/SparkContext$$anonfun$8(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/io/CompressionCodec$/getCodecName(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/_eventLogDir_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/externalBlockStoreFolderName()|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/start()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler/DAGScheduler(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/TraversableLike/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/Utils$/getCallSite$default$1()|",
      "|java+constructor:///org/apache/spark/util/MetadataCleaner/MetadataCleaner(scala.Enumeration$Value,scala.Function1,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/isLocal()|",
      "|java+method:///org/apache/spark/SparkContext/_shutdownHookRef_$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$7/SparkContext$$anonfun$7(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext$/setActiveContext(org.apache.spark.SparkContext,boolean)|",
      "|java+constructor:///org/apache/spark/util/TimeStampedWeakValueHashMap/TimeStampedWeakValueHashMap(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/applicationAttemptId()|",
      "|java+method:///org/apache/spark/SparkContext/_progressBar_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/_executorAllocationManager()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicBoolean/AtomicBoolean(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/postStartHook()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/validateSettings()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(int)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$6/SparkContext$$anonfun$6(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/log()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/HashMap$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/_executorMemory_$eq(int)|",
      "|java+method:///org/apache/spark/util/Utils$/getCurrentUserName()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$5/SparkContext$$anonfun$5(org.apache.spark.SparkContext)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/_ui_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobProgressListener/JobProgressListener(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/_eventLogger_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/_jobProgressListener()|",
      "|java+method:///org/apache/spark/util/Utils$/resolveURI(java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/DEFAULT_LOG_DIR()|",
      "|java+method:///org/apache/spark/SparkContext/createSparkEnv(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$4/SparkContext$$anonfun$4(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/registerSource(org.apache.spark.metrics.source.Source)|",
      "|java+method:///scala/collection/Seq/flatten(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///org/apache/spark/SparkContext/_statusTracker_$eq(org.apache.spark.SparkStatusTracker)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/applicationId()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/_eventLogCodec_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///scala/Some/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/master()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/SparkContext/_heartbeatReceiver_$eq(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/addListener(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$3/SparkContext$$anonfun$3(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/mutable/HashMap/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/SparkContext/_applicationAttemptId_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkEnv/securityManager()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$18/SparkContext$$anonfun$18(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/send(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/setupAndStartListenerBus()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$20/SparkContext$$anonfun$20(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkStatusTracker/SparkStatusTracker(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$14/SparkContext$$anonfun$14(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$25/SparkContext$$anonfun$25(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$2/SparkContext$$anonfun$2(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/ui/SparkUI$/createLiveUI(org.apache.spark.SparkContext,org.apache.spark.SparkConf,org.apache.spark.scheduler.SparkListenerBus,org.apache.spark.ui.jobs.JobProgressListener,org.apache.spark.SecurityManager,java.lang.String,long)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$19/SparkContext$$anonfun$19(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$10/SparkContext$$anonfun$10(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$21/SparkContext$$anonfun$21(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_hadoopConfiguration_$eq(org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anon$2/SparkContext$$anon$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$26/SparkContext$$anonfun$26(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$15/SparkContext$$anonfun$15(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$22/SparkContext$$anonfun$22(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/ContextCleaner/ContextCleaner(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$11/SparkContext$$anonfun$11(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$16/SparkContext$$anonfun$16(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$27/SparkContext$$anonfun$27(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$12/SparkContext$$anonfun$12(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$23/SparkContext$$anonfun$23(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$17/SparkContext$$anonfun$17(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$28/SparkContext$$anonfun$28(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_dagScheduler_$eq(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$13/SparkContext$$anonfun$13(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$24/SparkContext$$anonfun$24(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_eventLogDir()|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///org/apache/spark/SparkContext/isEventLogEnabled()|",
      "|java+method:///scala/collection/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$createTaskScheduler(org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkContext$/DRIVER_IDENTIFIER()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$1/SparkContext$$anonfun$1(org.apache.spark.SparkContext)|",
      "|java+method:///java/lang/System/setProperty(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGSchedulerSource/DAGSchedulerSource(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/LiveListenerBus/LiveListenerBus()|",
      "|java+method:///org/apache/spark/util/Utils$/addShutdownHook(int,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/set(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkConf/getExecutorEnv()|",
      "|java+method:///org/apache/spark/SparkContext/startTime()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap$/$lessinit$greater$default$1()|",
      "|java+method:///org/apache/spark/util/Utils$/getCallSite(scala.Function1)|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/EventLoggingListener/EventLoggingListener(java.lang.String,scala.Option,java.net.URI,org.apache.spark.SparkConf,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/storage/BlockManager/initialize(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/_jars_$eq(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/metricsSystem()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/SparkContext/_ui()|",
      "|java+method:///org/apache/spark/SparkContext/_cleaner_$eq(scala.Option)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$_env_$eq(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$_conf_$eq(org.apache.spark.SparkConf)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/_taskScheduler_$eq(org.apache.spark.scheduler.TaskScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/_applicationId()|",
      "|java+method:///org/slf4j/Logger/isInfoEnabled()|",
      "|java+constructor:///org/apache/spark/HeartbeatReceiver/HeartbeatReceiver(org.apache.spark.SparkContext)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripSuffix(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/_heartbeatReceiver()|",
      "|java+method:///org/apache/spark/SparkContext$/markPartiallyConstructed(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///java/util/UUID/toString()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar/ConsoleProgressBar(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_metadataCleaner_$eq(org.apache.spark.util.MetadataCleaner)|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler()|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager/ExecutorAllocationManager(org.apache.spark.ExecutorAllocationClient,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/Utils$/SPARK_CONTEXT_SHUTDOWN_PRIORITY()|",
      "|java+method:///org/apache/spark/SparkContext/_applicationAttemptId()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/SparkContext/_executorAllocationManager_$eq(scala.Option)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/SparkContext/files()|",
      "|java+method:///org/apache/spark/SparkContext/supportDynamicAllocation()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$/assertNoOtherContextIsRunning(org.apache.spark.SparkContext,boolean)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1/SparkContext$$anonfun$assertNoOtherContextIsRunning$1(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed()|",
      "|java+method:///org/apache/spark/SparkContext$/SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1/SparkContext$$anonfun$assertNoOtherContextIsRunning$1(org.apache.spark.SparkContext,boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/OpenHashSet/getPos(java.lang.Object)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/hasher()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$_mask()|",
      "|java+method:///scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/ScalaRunTime$/array_apply(java.lang.Object,int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/_data()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|",
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/hasher()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$_mask()|",
      "|java+method:///scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/ScalaRunTime$/array_apply(java.lang.Object,int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/_data()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$6/apply(scala.collection.Seq)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToInfo()|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage/org$apache$spark$ui$jobs$AllJobsPage$$listener()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/max(scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq/nonEmpty()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/saveAsSequenceFile(java.lang.String,scala.Option)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/saveAsHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf,scala.Option)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions$default$4(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/org$apache$spark$rdd$SequenceFileRDDFunctions$$valueWritableClass()|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1(org.apache.spark.rdd.SequenceFileRDDFunctions)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$4/SequenceFileRDDFunctions$$anonfun$4(org.apache.spark.rdd.SequenceFileRDDFunctions)|",
      "|java+constructor:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$3/SequenceFileRDDFunctions$$anonfun$3(org.apache.spark.rdd.SequenceFileRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/org$apache$spark$rdd$SequenceFileRDDFunctions$$keyWritableClass()|",
      "|java+constructor:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$2/SequenceFileRDDFunctions$$anonfun$2(org.apache.spark.rdd.SequenceFileRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/valueClass()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1(org.apache.spark.rdd.SequenceFileRDDFunctions,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$29/JsonProtocol$$anonfun$29()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/AsynchronousListenerBus$$anon$1/run()|",
    "called": "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/util/AsynchronousListenerBus$$anon$1$$anonfun$run$1/AsynchronousListenerBus$$anon$1$$anonfun$run$1(org.apache.spark.util.AsynchronousListenerBus$$anon$1,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///org/apache/spark/util/Utils$/logUncaughtExceptions(scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/AsynchronousListenerBus$$anon$1$$anonfun$run$1/AsynchronousListenerBus$$anon$1$$anonfun$run$1(org.apache.spark.util.AsynchronousListenerBus$$anon$1,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///org/apache/spark/util/Utils$/tryOrStopSparkContext(org.apache.spark.SparkContext,scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///org/apache/spark/util/AsynchronousListenerBus/org$apache$spark$util$AsynchronousListenerBus$$sparkContext()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/removeRdd(int,boolean)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeRdd$1/BlockManagerMaster$$anonfun$removeRdd$1(org.apache.spark.storage.BlockManagerMaster,int)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveRdd/BlockManagerMessages$RemoveRdd(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$removeRdd$1/BlockManagerMaster$$anonfun$removeRdd$1(org.apache.spark.storage.BlockManagerMaster,int)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/sameThread()|",
      "|java+method:///scala/concurrent/Future/onFailure(scala.PartialFunction,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$RemoveRdd/BlockManagerMessages$RemoveRdd(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$13/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$13/apply(org.apache.spark.ui.exec.ExecutorSummaryInfo)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/exec/ExecutorsPage$$anonfun$13/apply(org.apache.spark.status.api.v1.ExecutorSummary)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$visit$3$1/apply(org.apache.spark.Dependency)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/isAvailable()|",
      "|java+method:///org/apache/spark/NarrowDependency/rdd()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getShuffleMapStage(org.apache.spark.ShuffleDependency,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/Stage/jobId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ShuffleMapStage/isAvailable()|",
      "|java+method:///org/apache/spark/NarrowDependency/rdd()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getShuffleMapStage(org.apache.spark.ShuffleDependency,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$8/MasterPage$$anonfun$8(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/executeAndGetOutput(scala.collection.Seq,java.io.File,scala.collection.Map,boolean)|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$6/Utils$$anonfun$6(java.lang.StringBuffer)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$executeAndGetOutput$1/Utils$$anonfun$executeAndGetOutput$1(scala.collection.Seq,java.lang.StringBuffer,int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/processStreamByLine(java.lang.String,java.io.InputStream,scala.Function1)|",
      "|java+method:///java/lang/StringBuffer/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/lang/Thread/join()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/executeCommand(scala.collection.Seq,java.io.File,scala.collection.Map,boolean)|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///org/apache/spark/util/Utils$/logError(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///java/lang/StringBuffer/StringBuffer()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$executeAndGetOutput$1/Utils$$anonfun$executeAndGetOutput$1(scala.collection.Seq,java.lang.StringBuffer,int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$10/Utils$$anonfun$10(java.lang.StringBuffer)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/processStreamByLine(java.lang.String,java.io.InputStream,scala.Function1)|",
      "|java+method:///java/lang/StringBuffer/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/lang/Thread/join()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/executeCommand(scala.collection.Seq,java.io.File,scala.collection.Map,boolean)|",
      "|java+method:///java/lang/Process/waitFor()|",
      "|java+method:///org/apache/spark/util/Utils$/logError(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///java/lang/StringBuffer/StringBuffer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleJobGroupCancelled(java.lang.String)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$9/DAGScheduler$$anonfun$9(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobGroupCancelled$1/DAGScheduler$$anonfun$handleJobGroupCancelled$1(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$8/DAGScheduler$$anonfun$8(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/HashSet$/canBuildFrom()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobGroupCancelled$1/DAGScheduler$$anonfun$handleJobGroupCancelled$1(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$9/DAGScheduler$$anonfun$9(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/HashSet$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$10/DAGScheduler$$anonfun$10(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/getBlockData(org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///scala/Option/isDefined()|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockManager/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockNotFoundException/BlockNotFoundException(java.lang.String)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockManager()|",
      "|java+constructor:///org/apache/spark/network/buffer/NioManagedBuffer/NioManagedBuffer(java.nio.ByteBuffer)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/storage/BlockNotFoundException/BlockNotFoundException(java.lang.String)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockResolver()|",
      "|java+constructor:///org/apache/spark/network/buffer/NioManagedBuffer/NioManagedBuffer(java.nio.ByteBuffer)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockResolver/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2(org.apache.spark.deploy.master.Master)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/hashCode()|",
    "called": "|java+method:///scala/runtime/Statics/mix(int,int)|",
    "v1Body": [
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appId()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/time()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/SparkListenerApplicationStart/appName()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/keyBy(scala.Function1)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$keyBy$1/RDD$$anonfun$keyBy$1(org.apache.spark.rdd.RDD,scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$keyBy$1/RDD$$anonfun$keyBy$1(org.apache.spark.rdd.RDD,scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/zipWithUniqueId()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$zipWithUniqueId$1/RDD$$anonfun$zipWithUniqueId$1(org.apache.spark.rdd.RDD,long)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex$default$2()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$zipWithUniqueId$1/RDD$$anonfun$zipWithUniqueId$1(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/UnionRDD$$anonfun$getDependencies$1/apply(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/RangeDependency/RangeDependency(org.apache.spark.rdd.RDD,int,int,int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/RangeDependency/RangeDependency(org.apache.spark.rdd.RDD,int,int,int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/addExecutor(org.apache.spark.deploy.master.WorkerInfo,int,scala.Option)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+constructor:///org/apache/spark/deploy/master/ExecutorDesc/ExecutorDesc(int,org.apache.spark.deploy.master.ApplicationInfo,org.apache.spark.deploy.master.WorkerInfo,int,int)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/newExecutorId(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerSlave()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/id()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+constructor:///org/apache/spark/deploy/master/ExecutorDesc/ExecutorDesc(int,org.apache.spark.deploy.master.ApplicationInfo,org.apache.spark.deploy.master.WorkerInfo,int,int)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/newExecutorId(scala.Option)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerExecutorMB()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/id()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/cleanupStateForJobAndIndependentStages(org.apache.spark.scheduler.ActiveJob)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/scheduler/Stage/resultOfJob_$eq(scala.Option)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/filterKeys(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/collection/Map/foreach(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$1/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$1(org.apache.spark.scheduler.DAGScheduler,scala.Option)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$2/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/SetLike/isEmpty()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/resultOfJob_$eq(scala.Option)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/filterKeys(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/collection/Map/foreach(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$1/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$1(org.apache.spark.scheduler.DAGScheduler,scala.Option)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$2/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/SetLike/isEmpty()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/fold(java.lang.Object,scala.Function2)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$25/RDD$$anonfun$25(org.apache.spark.rdd.RDD,scala.Function2,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$24/RDD$$anonfun$24(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///org/apache/spark/util/Utils$/clone(java.lang.Object,org.apache.spark.serializer.SerializerInstance,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$fold$1/RDD$$anonfun$fold$1(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/getPreferredLocations(org.apache.spark.Partition)|",
    "called": "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/Map/maxBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$5/PartitionerAwareUnionRDD$$anonfun$5(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$4/PartitionerAwareUnionRDD$$anonfun$4(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDDPartition/parents()|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$2/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$2(org.apache.spark.rdd.PartitionerAwareUnionRDD,org.apache.spark.Partition,scala.Option)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$1/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$1(org.apache.spark.rdd.PartitionerAwareUnionRDD,org.apache.spark.Partition)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/rdds()|",
      "|java+method:///scala/collection/Seq/groupBy(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$6/PartitionerAwareUnionRDD$$anonfun$6(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/Iterable/toSeq()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$5/PartitionerAwareUnionRDD$$anonfun$5(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/Seq/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDDPartition/parents()|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$2/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$2(org.apache.spark.rdd.PartitionerAwareUnionRDD,org.apache.spark.Partition,scala.Option)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$1/PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$1(org.apache.spark.rdd.PartitionerAwareUnionRDD,org.apache.spark.Partition)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD/rdds()|",
      "|java+method:///scala/collection/Seq/groupBy(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$7/PartitionerAwareUnionRDD$$anonfun$7(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/collection/immutable/Map/maxBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$6/PartitionerAwareUnionRDD$$anonfun$6(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/Iterable/toSeq()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/ClientActor$$anonfun$4/ClientActor$$anonfun$4(org.apache.spark.deploy.ClientActor)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$18/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$18$$anonfun$apply$11/StagePage$$anonfun$18$$anonfun$apply$11(org.apache.spark.ui.jobs.StagePage$$anonfun$18)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$18$$anonfun$apply$1/StagePage$$anonfun$18$$anonfun$apply$1(org.apache.spark.ui.jobs.StagePage$$anonfun$18)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorDeserializeTime()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1/apply(org.apache.spark.scheduler.Stage)|",
    "called": "|java+method:///scala/Option/withFilter(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$7/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$7(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/org$apache$spark$scheduler$DAGScheduler$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$11/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$11(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+method:///scala/Option$WithFilter/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/find(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$6/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$6(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$10/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$10(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$6/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$6(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3/org$apache$spark$scheduler$DAGScheduler$$anonfun$$$outer()|",
      "|java+method:///scala/Option$WithFilter/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/waitingStages()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/find(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/failedStages()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$5/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$5(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$10/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$10(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$7/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$7(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8(org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/apply()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/apply()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/apply()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMessages$RegisterBlockManager$/apply(java.lang.Object,java.lang.Object,java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$RegisterBlockManager$/apply(org.apache.spark.storage.BlockManagerId,long,akka.actor.ActorRef)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$RegisterBlockManager$/apply(org.apache.spark.storage.BlockManagerId,long,org.apache.spark.rpc.RpcEndpointRef)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$cleanup(long)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/files()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashSet/internalMap()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/deleteBroadcastFile(java.io.File)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/entrySet()|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|"
    ],
    "v2Body": [
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/org$apache$spark$broadcast$HttpBroadcast$$files()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashSet/internalMap()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/util/Map$Entry/getValue()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/broadcast/HttpBroadcast$/deleteBroadcastFile(java.io.File)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/entrySet()|",
      "|java+method:///scala/Tuple2/_2$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/apply(org.apache.spark.scheduler.WorkerOffer)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$35/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$35/apply(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$35/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions/foreachPartitionAsync(scala.Function1)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+method:///scala/package$/Range()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachPartitionAsync$1/AsyncRDDActions$$anonfun$foreachPartitionAsync$1(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachPartitionAsync$2/AsyncRDDActions$$anonfun$foreachPartitionAsync$2(org.apache.spark.rdd.AsyncRDDActions)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$foreachPartitionAsync$1/AsyncRDDActions$$anonfun$foreachPartitionAsync$1(org.apache.spark.rdd.AsyncRDDActions,scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/TestUtils$/createCompiledClass(java.lang.String,java.io.File,java.lang.String,java.lang.String,scala.collection.Seq)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/TestUtils$JavaSourceFromString/TestUtils$JavaSourceFromString(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///javax/tools/ToolProvider/getSystemJavaCompiler()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///javax/tools/JavaCompiler/getTask(java.io.Writer,javax.tools.JavaFileManager,javax.tools.DiagnosticListener,java.lang.Iterable,java.lang.Iterable,java.lang.Iterable)|",
      "|java+method:///scala/collection/Seq/nonEmpty()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///javax/tools/JavaCompiler$CompilationTask/call()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$5/TestUtils$$anonfun$5()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$7/TestUtils$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$6/TestUtils$$anonfun$6()|",
      "|java+method:///org/spark-project/guava/io/Files/move(java.io.File,java.io.File)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/io/File/exists()|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$1/TestUtils$$anonfun$createCompiledClass$1(java.io.File)|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$createCompiledClass$2/TestUtils$$anonfun$createCompiledClass$2(java.io.File)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/TestUtils$JavaSourceFromString/TestUtils$JavaSourceFromString(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$7/TestUtils$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/TestUtils$$anonfun$6/TestUtils$$anonfun$6()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/TestUtils$/createCompiledClass(java.lang.String,java.io.File,org.apache.spark.TestUtils$JavaSourceFromString,scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/debugChildren$1(org.apache.spark.rdd.RDD,java.lang.String)|",
    "called": "|java+method:///scala/collection/Seq$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$41/RDD$$anonfun$41(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/org$apache$spark$rdd$RDD$$debugString$1(org.apache.spark.rdd.RDD,java.lang.String,boolean,boolean)|",
      "|java+method:///scala/collection/Seq/last()|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/Dependency/rdd()|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///scala/collection/Seq/take(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/collection/Seq$/empty()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/RDD/org$apache$spark$rdd$RDD$$debugString$1(org.apache.spark.rdd.RDD,java.lang.String,boolean,boolean)|",
      "|java+method:///scala/collection/Seq/last()|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/Dependency/rdd()|",
      "|java+method:///scala/collection/Seq/head()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$37/RDD$$anonfun$37(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///scala/collection/Seq/length()|",
      "|java+method:///scala/collection/Seq/take(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/collection/Seq$/empty()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/ProcessBuilderLike$$anon$3/command()|",
    "called": "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/ProcessBuilderLike$$anon$3/command()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///java/lang/ProcessBuilder/command()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///java/lang/ProcessBuilder/command()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/storage/StoragePage/org$apache$spark$ui$storage$StoragePage$$rddRow(org.apache.spark.storage.RDDInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/description()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/tachyonSize()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/storage/StorageTab/basePath()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/externalBlockStoreSize()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/description()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/storage/StorageTab/basePath()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner$$anon$1/run()|",
    "called": "|java+method:///scala/Option/isDefined()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverId()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang$default$2(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$5()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/supervise()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$createWorkingDirectory()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalException_$eq(scala.Option)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalState_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anon$1$$anonfun$1/DriverRunner$$anon$1$$anonfun$1(org.apache.spark.deploy.worker.DriverRunner$$anon$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar(java.io.File)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/sparkHome()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$launchDriver(java.lang.ProcessBuilder,java.io.File,boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalExitCode()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalException()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/killed()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/worker()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$killed()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$launchDriver(java.lang.ProcessBuilder,java.io.File,boolean)|",
      "|java+method:///akka/actor/ScalaActorRef/$bang$default$2(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$5()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/supervise()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder$default$6()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$finalExitCode()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverId()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$createWorkingDirectory()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalException_$eq(scala.Option)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildProcessBuilder(org.apache.spark.deploy.Command,int,java.lang.String,scala.Function1,scala.collection.Seq,scala.collection.Map)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalState_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anon$1$$anonfun$1/DriverRunner$$anon$1$$anonfun$1(org.apache.spark.deploy.worker.DriverRunner$$anon$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar(java.io.File)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/sparkHome()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/finalException()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/worker()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$1/apply()|",
    "called": "|java+method:///scala/collection/mutable/HashSet/size()|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$1/apply()|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsPending()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsTarget()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$1/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/countApproxDistinct(double)|",
    "called": "|java+method:///scala/math/package$/log(double)|",
    "v1Body": [
      "|java+method:///scala/math/package$/ceil(double)|",
      "|java+method:///org/apache/spark/rdd/RDD/countApproxDistinct(int,int)|",
      "|java+method:///scala/math/package$/log(double)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countApproxDistinct$2/RDD$$anonfun$countApproxDistinct$2(org.apache.spark.rdd.RDD,double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$62/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$62/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$62/apply(org.apache.spark.executor.OutputMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$updateAccumulators$1/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/Accumulators$/stringifyPartialValue(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/accumulables()|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/Accumulable/name()|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Tuple2/_1$mcJ$sp()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/accumulables()|",
      "|java+method:///scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulators$/stringifyValue(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulable/zero()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskInfo()|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///org/apache/spark/Accumulable/value()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/Accumulators$/stringifyPartialValue(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/ref/ReferenceWrapper/get()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/Accumulable/name()|",
      "|java+method:///scala/Tuple2/_1$mcJ$sp()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/accumulables()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/accumulables()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/equals(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulators$/stringifyValue(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulable/zero()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ListBuffer/$plus$eq(java.lang.Object)|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/CompletionEvent/taskInfo()|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///org/apache/spark/Accumulable/value()|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/getBlockStatus(org.apache.spark.storage.BlockId,boolean)|",
    "called": "|java+method:///scala/concurrent/Future$/sequence(scala.collection.TraversableOnce,scala.collection.generic.CanBuildFrom,scala.concurrent.ExecutionContext)|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/Iterable/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$getBlockStatus$1/BlockManagerMaster$$anonfun$getBlockStatus$1(org.apache.spark.storage.BlockManagerMaster)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$GetBlockStatus/BlockManagerMessages$GetBlockStatus(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/Iterable$/canBuildFrom()|",
      "|java+method:///scala/collection/immutable/Map/unzip(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+method:///scala/concurrent/Future$/sequence(scala.collection.TraversableOnce,scala.collection.generic.CanBuildFrom,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster$$anonfun$getBlockStatus$1/BlockManagerMaster$$anonfun$getBlockStatus$1(org.apache.spark.storage.BlockManagerMaster)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$GetBlockStatus/BlockManagerMessages$GetBlockStatus(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///scala/Predef$/implicitly(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/collection/immutable/Map/unzip(scala.Function1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/Iterable/zip(scala.collection.GenIterable,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/Iterable$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/sameThread()|",
      "|java+method:///scala/concurrent/Future$/sequence(scala.collection.TraversableOnce,scala.collection.generic.CanBuildFrom,scala.concurrent.ExecutionContext)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/asyncReregister()|",
    "called": "|java+method:///scala/concurrent/Future$/apply(scala.Function0,scala.concurrent.ExecutionContext)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterLock()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterTask_$eq(scala.concurrent.Future)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$asyncReregister$1/BlockManager$$anonfun$asyncReregister$1(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/concurrent/Future$/apply(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///scala/concurrent/ExecutionContext$Implicits$/global()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterTask()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterLock()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterTask_$eq(scala.concurrent.Future)|",
      "|java+method:///org/apache/spark/storage/BlockManager/futureExecutionContext()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$asyncReregister$1/BlockManager$$anonfun$asyncReregister$1(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/concurrent/Future$/apply(scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$asyncReregisterTask()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/getCallSite(scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/BooleanRef/BooleanRef(boolean)|",
    "v1Body": [
      "|java+method:///java/lang/System/getProperty(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/take(int)|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getCallSite$1/Utils$$anonfun$getCallSite$1(scala.Function1,scala.runtime.ObjectRef,scala.runtime.ObjectRef,scala.runtime.IntRef,scala.runtime.BooleanRef,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/CallSite/CallSite(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Thread/getStackTrace()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/canBuildFrom()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///scala/runtime/BooleanRef/BooleanRef(boolean)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/System/getProperty(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$colon$plus(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/take(int)|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getCallSite$1/Utils$$anonfun$getCallSite$1(scala.Function1,scala.runtime.ObjectRef,scala.runtime.ObjectRef,scala.runtime.IntRef,scala.runtime.BooleanRef,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/CallSite/CallSite(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Thread/getStackTrace()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///scala/runtime/IntRef/IntRef(int)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer$/canBuildFrom()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///scala/runtime/BooleanRef/BooleanRef(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,akka.actor.ActorSystem)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/$init$(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
    "called": "|java+method:///scala/Option$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/settings()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$getOption$1/SparkConf$$anonfun$getOption$1(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/settings()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$mapValues$1/PairRDDFunctions$$anonfun$mapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/MapPartitionsRDD/MapPartitionsRDD(org.apache.spark.rdd.RDD,scala.Function3,boolean,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$mapValues$1/PairRDDFunctions$$anonfun$mapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/openLegacyEventLog(org.apache.hadoop.fs.Path)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$1/FsHistoryProvider$$anonfun$openLegacyEventLog$1(org.apache.spark.deploy.history.FsHistoryProvider,scala.runtime.ObjectRef,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$2/FsHistoryProvider$$anonfun$openLegacyEventLog$2(org.apache.spark.deploy.history.FsHistoryProvider,java.io.BufferedInputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$3/FsHistoryProvider$$anonfun$openLegacyEventLog$3(org.apache.spark.deploy.history.FsHistoryProvider,java.io.BufferedInputStream)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$8/FsHistoryProvider$$anonfun$8(org.apache.spark.deploy.history.FsHistoryProvider)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$1/FsHistoryProvider$$anonfun$openLegacyEventLog$1(org.apache.spark.deploy.history.FsHistoryProvider,scala.runtime.ObjectRef,scala.runtime.ObjectRef)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$2/FsHistoryProvider$$anonfun$openLegacyEventLog$2(org.apache.spark.deploy.history.FsHistoryProvider,java.io.BufferedInputStream)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///java/io/BufferedInputStream/BufferedInputStream(java.io.InputStream)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$openLegacyEventLog$3/FsHistoryProvider$$anonfun$openLegacyEventLog$3(org.apache.spark.deploy.history.FsHistoryProvider,java.io.BufferedInputStream)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$17/FsHistoryProvider$$anonfun$17(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/intersection(org.apache.spark.rdd.RDD,int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$11/RDD$$anonfun$11(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$12/RDD$$anonfun$12(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$13/RDD$$anonfun$13(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions$default$4(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keys()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/filter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$3/RDD$$anonfun$intersection$3(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/apply()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/apply$mcV$sp()|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/taskMetricsToJson(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/memoryBytesSpilled()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$1/JsonProtocol$$anonfun$taskMetricsToJson$1()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$2/JsonProtocol$$anonfun$taskMetricsToJson$2()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/hostname()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$7/JsonProtocol$$anonfun$taskMetricsToJson$7()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/resultSize()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/jvmGCTime()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$26/JsonProtocol$$anonfun$26()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$21/JsonProtocol$$anonfun$21()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$19/JsonProtocol$$anonfun$19()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$25/JsonProtocol$$anonfun$25()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$20/JsonProtocol$$anonfun$20()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$18/JsonProtocol$$anonfun$18()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$24/JsonProtocol$$anonfun$24()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$17/JsonProtocol$$anonfun$17()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$22/JsonProtocol$$anonfun$22()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$3/JsonProtocol$$anonfun$taskMetricsToJson$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$23/JsonProtocol$$anonfun$23()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$4/JsonProtocol$$anonfun$taskMetricsToJson$4()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorDeserializeTime()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$5/JsonProtocol$$anonfun$taskMetricsToJson$5()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$6/JsonProtocol$$anonfun$taskMetricsToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$8/JsonProtocol$$anonfun$taskMetricsToJson$8()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/resultSerializationTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorRunTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/diskBytesSpilled()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/memoryBytesSpilled()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$1/JsonProtocol$$anonfun$taskMetricsToJson$1()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$2/JsonProtocol$$anonfun$taskMetricsToJson$2()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/hostname()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$7/JsonProtocol$$anonfun$taskMetricsToJson$7()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/resultSize()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/jvmGCTime()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$26/JsonProtocol$$anonfun$26()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$21/JsonProtocol$$anonfun$21()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$19/JsonProtocol$$anonfun$19()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$25/JsonProtocol$$anonfun$25()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$20/JsonProtocol$$anonfun$20()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$18/JsonProtocol$$anonfun$18()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$24/JsonProtocol$$anonfun$24()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$27/JsonProtocol$$anonfun$27()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$22/JsonProtocol$$anonfun$22()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$3/JsonProtocol$$anonfun$taskMetricsToJson$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$23/JsonProtocol$$anonfun$23()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$4/JsonProtocol$$anonfun$taskMetricsToJson$4()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorDeserializeTime()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$5/JsonProtocol$$anonfun$taskMetricsToJson$5()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$6/JsonProtocol$$anonfun$taskMetricsToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskMetricsToJson$8/JsonProtocol$$anonfun$taskMetricsToJson$8()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/resultSerializationTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/updatedBlocks()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorRunTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/diskBytesSpilled()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$68/StagePage$$anonfun$68(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage/org$apache$spark$ui$jobs$StagePage$$getSchedulerDelay(org.apache.spark.scheduler.TaskInfo,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskInfo()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///org/apache/spark/scheduler/TaskInfo/status()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/ClientActor$$anonfun$receiveWithLogging$1/applyOrElse(java.lang.Object,scala.Function1)|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/ClientArguments/master()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/message()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/success()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/message()|",
      "|java+method:///akka/remote/AssociationErrorEvent/cause()|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/driverId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/success()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/pollAndReportStatus(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///akka/remote/AssociationErrorEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/driverId()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/org$apache$spark$deploy$ClientActor$$masterActors()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/success()|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///akka/actor/ActorContext/actorSelection(akka.actor.ActorPath)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/message()|",
      "|java+method:///akka/remote/AssociationErrorEvent/cause()|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/driverId()|",
      "|java+method:///org/apache/spark/util/Utils$/responseFromBackup(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/success()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/org$apache$spark$deploy$ClientActor$$lostMasters()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/message()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/context()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/pollAndReportStatus(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///akka/remote/AssociationErrorEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/driverId()|",
      "|java+method:///org/apache/spark/deploy/ClientActor/sender()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/org$apache$spark$deploy$ClientActor$$activeMasterActor_$eq(akka.actor.ActorSelection)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/worker/ExecutorRunner$$anon$1/ExecutorRunner$$anon$1(org.apache.spark.deploy.worker.ExecutorRunner)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/fullId()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.String)|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/ExecutorRunner/org$apache$spark$deploy$worker$ExecutorRunner$$fullId()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.String)|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$12/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$12/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleTaskCompletion$12/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/jobEndFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$4/JsonProtocol$$anonfun$4()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/jobResultFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$44/JsonProtocol$$anonfun$44()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$4/JsonProtocol$$anonfun$4()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/jobResultFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$46/JsonProtocol$$anonfun$46()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/RedirectThread/run()|",
    "called": "|java+method:///scala/util/control/Exception$Catch/apply(scala.Function0)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/util/RedirectThread$$anonfun$run$2/RedirectThread$$anonfun$run$2(org.apache.spark.util.RedirectThread)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/util/control/Exception$Catch/apply(scala.Function0)|",
      "|java+method:///scala/util/control/Exception$/ignoring(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/RedirectThread$$anonfun$run$1/RedirectThread$$anonfun$run$1(org.apache.spark.util.RedirectThread)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/util/control/Exception$Catch/apply(scala.Function0)|",
      "|java+method:///scala/util/control/Exception$/ignoring(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1/apply$mcVI$sp(int)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/cancelTasks(int,boolean)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$2(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$18/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$18(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$4(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/taskScheduler()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$3(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/TaskScheduler/cancelTasks(int,boolean)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished(org.apache.spark.scheduler.Stage,scala.Option)|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$2/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$2(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$20/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$20(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$4/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$4(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runningStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/taskScheduler()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$3/DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$3(org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1,int)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/storage/StoragePage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/storage/StoragePage$$anonfun$1/StoragePage$$anonfun$1(org.apache.spark.ui.storage.StoragePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/ui/storage/StoragePage/rddHeader()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/storage/StorageListener/rddInfoList()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/storage/StoragePage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+constructor:///org/apache/spark/ui/storage/StoragePage$$anonfun$render$1/StoragePage$$anonfun$render$1(org.apache.spark.ui.storage.StoragePage,scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/storage/StoragePage$$anonfun$1/StoragePage$$anonfun$1(org.apache.spark.ui.storage.StoragePage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+method:///org/apache/spark/ui/storage/StoragePage/rddHeader()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/storage/StoragePage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+constructor:///org/apache/spark/ui/storage/StoragePage$$anonfun$render$1/StoragePage$$anonfun$render$1(org.apache.spark.ui.storage.StoragePage,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///org/apache/spark/ui/storage/StorageListener/rddInfoList()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/SparkListenerApplicationStart$/SparkListenerApplicationStart$()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction5/AbstractFunction5()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMaster/getMatchingBlockIds(scala.Function1,boolean)|",
    "called": "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/askDriverWithReply(java.lang.Object)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$GetMatchingBlockIds/BlockManagerMessages$GetMatchingBlockIds(scala.Function1,boolean)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/timeout()|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$GetMatchingBlockIds/BlockManagerMessages$GetMatchingBlockIds(scala.Function1,boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$onExecutorIdle(java.lang.String)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/clock()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorsPendingToRemove()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logDebug(scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$2/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$2(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeout()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/removeTimes()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/clock()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorsPendingToRemove()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIdleTimeoutS()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$2/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$2(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/removeTimes()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///java/util/concurrent/ConcurrentHashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/settings()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///java/util/concurrent/ConcurrentHashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/SparkConf$/logDeprecationWarning(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/settings()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/portMaxRetries(org.apache.spark.SparkConf)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$portMaxRetries$1/Utils$$anonfun$portMaxRetries$1()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$portMaxRetries$2/Utils$$anonfun$portMaxRetries$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$13/Utils$$anonfun$13()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$portMaxRetries$1/Utils$$anonfun$portMaxRetries$1()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$portMaxRetries$2/Utils$$anonfun$portMaxRetries$2()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$17/Utils$$anonfun$17()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/StorageStatus/updateStorageInfo(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockStatus)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/storage/RDDBlockId/rddId()|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_rddStorageInfo()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_nonRddStorageInfo_$eq(scala.Tuple3)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$1/StorageStatus$$anonfun$1(org.apache.spark.storage.StorageStatus)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$3/StorageStatus$$anonfun$3(org.apache.spark.storage.StorageStatus)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$2/StorageStatus$$anonfun$2(org.apache.spark.storage.StorageStatus)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/getBlock(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_nonRddStorageInfo()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/storage/RDDBlockId/rddId()|",
      "|java+method:///scala/math/package$/max(long,long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_rddStorageInfo()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_nonRddStorageInfo_$eq(scala.Tuple3)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$1/StorageStatus$$anonfun$1(org.apache.spark.storage.StorageStatus)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$3/StorageStatus$$anonfun$3(org.apache.spark.storage.StorageStatus)|",
      "|java+constructor:///org/apache/spark/storage/StorageStatus$$anonfun$2/StorageStatus$$anonfun$2(org.apache.spark.storage.StorageStatus)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/getBlock(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageStatus/_nonRddStorageInfo()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1$$anonfun$16/RDD$$anonfun$treeReduce$1$$anonfun$16(org.apache.spark.rdd.RDD$$anonfun$treeReduce$1,scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1$$anonfun$17/RDD$$anonfun$treeReduce$1$$anonfun$17(org.apache.spark.rdd.RDD$$anonfun$treeReduce$1,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1$$anonfun$18/RDD$$anonfun$treeReduce$1$$anonfun$18(org.apache.spark.rdd.RDD$$anonfun$treeReduce$1,scala.Function2)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1$$anonfun$apply$37/RDD$$anonfun$treeReduce$1$$anonfun$apply$37(org.apache.spark.rdd.RDD$$anonfun$treeReduce$1)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$treeReduce$1$$anonfun$apply$38/RDD$$anonfun$treeReduce$1$$anonfun$apply$38(org.apache.spark.rdd.RDD$$anonfun$treeReduce$1)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Option$/empty()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD/treeAggregate(java.lang.Object,scala.Function2,scala.Function2,int,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockStatus/hashCode()|",
    "called": "|java+method:///scala/runtime/Statics/mix(int,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/Executor$TaskRunner/run()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$maxResultSize()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/startGCTime_$eq(long)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$4/Executor$TaskRunner$$anonfun$4(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$5/Executor$TaskRunner$$anonfun$5(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$6/Executor$TaskRunner$$anonfun$6(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/releaseMemoryForThisThread()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/shuffle/FetchFailedException/toTaskEndReason()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/IndirectTaskResult/IndirectTaskResult(org.apache.spark.storage.BlockId,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$1/Executor$TaskRunner$$anonfun$run$1(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleMemoryManager()|",
      "|java+constructor:///org/apache/spark/TaskKilledException/TaskKilledException()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$5/Executor$TaskRunner$$anonfun$run$5(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptedTask_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$4/Executor$TaskRunner$$anonfun$run$4(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/Executor$TaskRunner$$anonfun$run$2(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$7/Executor$TaskRunner$$anonfun$7(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread$default$1()|",
      "|java+method:///org/apache/spark/scheduler/Task/killed()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/reservedSizeBytes()|",
      "|java+method:///org/apache/spark/TaskState$/FAILED()|",
      "|java+method:///org/apache/spark/TaskState$/KILLED()|",
      "|java+constructor:///org/apache/spark/storage/TaskResultBlockId/TaskResultBlockId(long)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/Accumulators$/clear()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$6/Executor$TaskRunner$$anonfun$run$6(org.apache.spark.executor.Executor$TaskRunner,long)|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/org$apache$spark$executor$Executor$TaskRunner$$$outer()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.Throwable,scala.Option)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult/DirectTaskResult(java.nio.ByteBuffer,scala.collection.mutable.Map,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_AND_DISK_SER()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$EMPTY_BYTE_BUFFER()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptedTask()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/Task/metrics()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$3/Executor$TaskRunner$$anonfun$run$3(org.apache.spark.executor.Executor$TaskRunner,long,scala.runtime.LongRef,long,long,long)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/MapOutputTracker/updateEpoch(long)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$gcTime()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/killed()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptNumber()|",
      "|java+method:///org/apache/spark/executor/CommitDeniedException/toTaskEndReason()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$4()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel,boolean,scala.Option)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$5()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/util/Utils$/isFatalError(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/util/SparkUncaughtExceptionHandler$/uncaughtException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/executor/ExecutorBackend/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$akkaFrameSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$runningTasks()|",
      "|java+method:///org/apache/spark/scheduler/Task/run(long,int)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task_$eq(org.apache.spark.scheduler.Task)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/Task$/deserializeWithDependencies(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$updateDependencies(scala.collection.mutable.HashMap,scala.collection.mutable.HashMap)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///org/apache/spark/Accumulators$/values()|"
    ],
    "v2Body": [
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$maxResultSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$4/Executor$TaskRunner$$anonfun$4(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$5/Executor$TaskRunner$$anonfun$5(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$6/Executor$TaskRunner$$anonfun$6(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$computeTotalGcTime()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/releaseMemoryForThisThread()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/shuffle/FetchFailedException/toTaskEndReason()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/IndirectTaskResult/IndirectTaskResult(org.apache.spark.storage.BlockId,int)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread$default$1()|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleMemoryManager()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$6/Executor$TaskRunner$$anonfun$run$6(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/TaskKilledException/TaskKilledException()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$5/Executor$TaskRunner$$anonfun$run$5(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$3/Executor$TaskRunner$$anonfun$run$3(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/Executor$TaskRunner$$anonfun$run$2(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/scheduler/Task/killed()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/reservedSizeBytes()|",
      "|java+method:///org/apache/spark/TaskState$/FAILED()|",
      "|java+method:///org/apache/spark/TaskState$/KILLED()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/TaskMemoryManager/TaskMemoryManager(org.apache.spark.unsafe.memory.ExecutorMemoryManager)|",
      "|java+constructor:///org/apache/spark/storage/TaskResultBlockId/TaskResultBlockId(long)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/Accumulators$/clear()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/org$apache$spark$executor$Executor$TaskRunner$$$outer()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.Throwable,scala.Option)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult/DirectTaskResult(java.nio.ByteBuffer,scala.collection.mutable.Map,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_AND_DISK_SER()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$EMPTY_BYTE_BUFFER()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/Task/metrics()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$4/Executor$TaskRunner$$anonfun$run$4(org.apache.spark.executor.Executor$TaskRunner,long,scala.runtime.LongRef,long,long,long)|",
      "|java+method:///org/apache/spark/scheduler/Task/setTaskMemoryManager(org.apache.spark.unsafe.memory.TaskMemoryManager)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/MapOutputTracker/updateEpoch(long)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/killed()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptNumber()|",
      "|java+method:///org/apache/spark/executor/CommitDeniedException/toTaskEndReason()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$4()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel,boolean,scala.Option)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$5()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$7/Executor$TaskRunner$$anonfun$7(org.apache.spark.executor.Executor$TaskRunner,scala.runtime.LongRef)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/util/Utils$/isFatalError(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/util/SparkUncaughtExceptionHandler$/uncaughtException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/executor/ExecutorBackend/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$akkaFrameSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$runningTasks()|",
      "|java+method:///org/apache/spark/scheduler/Task/run(long,int)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task_$eq(org.apache.spark.scheduler.Task)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/Task$/deserializeWithDependencies(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$updateDependencies(scala.collection.mutable.HashMap,scala.collection.mutable.HashMap)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/SparkEnv/executorMemoryManager()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///org/apache/spark/Accumulators$/values()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$3/Executor$TaskRunner$$anonfun$3(org.apache.spark.executor.Executor$TaskRunner,java.lang.String)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/startGCTime_$eq(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/removeRdd(int)|",
    "called": "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/keys()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$12/BlockManager$$anonfun$12(org.apache.spark.storage.BlockManager,int)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$11/BlockManager$$anonfun$11(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeRdd$1/BlockManager$$anonfun$removeRdd$1(org.apache.spark.storage.BlockManager,int)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeRdd$2/BlockManager$$anonfun$removeRdd$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/collection/TraversableLike/filter(scala.Function1)|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+method:///scala/collection/Iterable/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/keys()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$11/BlockManager$$anonfun$11(org.apache.spark.storage.BlockManager,int)|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$10/BlockManager$$anonfun$10(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeRdd$1/BlockManager$$anonfun$removeRdd$1(org.apache.spark.storage.BlockManager,int)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeRdd$2/BlockManager$$anonfun$removeRdd$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/collection/TraversableLike/filter(scala.Function1)|",
      "|java+method:///scala/collection/Iterable/size()|",
      "|java+method:///scala/collection/Iterable/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/Accumulators$/register(org.apache.spark.Accumulable,boolean)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/Accumulable/id()|",
      "|java+method:///scala/collection/mutable/MapLike/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///org/apache/spark/Accumulators$/localAccums()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/lang/ThreadLocal/get()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/ref/WeakReference/WeakReference(java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulable/id()|",
      "|java+method:///scala/collection/mutable/MapLike/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/Accumulators$/originals()|",
      "|java+method:///org/apache/spark/Accumulators$/localAccums()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/lang/ThreadLocal/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/rest/KillRequestServlet/doPost(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/deploy/rest/KillRequestServlet$$anonfun$7/KillRequestServlet$$anonfun$7(org.apache.spark.deploy.rest.KillRequestServlet,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+constructor:///org/apache/spark/deploy/rest/KillRequestServlet$$anonfun$6/KillRequestServlet$$anonfun$6(org.apache.spark.deploy.rest.KillRequestServlet)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/rest/KillRequestServlet/parseSubmissionId(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/rest/KillRequestServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|"
    ],
    "v2Body": [
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/rest/KillRequestServlet/parseSubmissionId(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/rest/KillRequestServlet$$anonfun$3/KillRequestServlet$$anonfun$3(org.apache.spark.deploy.rest.KillRequestServlet)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/rest/KillRequestServlet/sendResponse(org.apache.spark.deploy.rest.SubmitRestProtocolResponse,javax.servlet.http.HttpServletResponse)|",
      "|java+constructor:///org/apache/spark/deploy/rest/KillRequestServlet$$anonfun$4/KillRequestServlet$$anonfun$4(org.apache.spark.deploy.rest.KillRequestServlet,javax.servlet.http.HttpServletResponse)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/apply(scala.Tuple2)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8/apply(scala.Tuple2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage/errorMessageCell(scala.Option)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/commons/lang3/StringEscapeUtils/escapeHtml4(java.lang.String)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$94/StagePage$$anonfun$94(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///java/lang/String/indexOf(int)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$108/StagePage$$anonfun$108(org.apache.spark.ui.jobs.StagePage)|",
      "|java+method:///org/apache/commons/lang3/StringEscapeUtils/escapeHtml4(java.lang.String)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///java/lang/String/indexOf(int)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$81/StagePage$$anonfun$81(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/DAGScheduler$$anonfun$11(org.apache.spark.scheduler.DAGScheduler)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/collectAsMap()|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/sizeHint(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/collect()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$collectAsMap$1/PairRDDFunctions$$anonfun$collectAsMap$1(org.apache.spark.rdd.PairRDDFunctions,scala.collection.mutable.HashMap)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$collectAsMap$1/PairRDDFunctions$$anonfun$collectAsMap$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/storage/RDDPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$render$1/RDDPage$$anonfun$render$1(org.apache.spark.ui.storage.RDDPage)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$7/RDDPage$$anonfun$7(org.apache.spark.ui.storage.RDDPage,scala.collection.Map)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/storage/StorageListener/storageStatusList()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/blockHeader()|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/listener()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$render$2/RDDPage$$anonfun$render$2(org.apache.spark.ui.storage.RDDPage,scala.xml.NodeBuffer)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/RDDPage$$anonfun$2(org.apache.spark.ui.storage.RDDPage,java.lang.Object)|",
      "|java+method:///scala/collection/Seq/find(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$5/RDDPage$$anonfun$5(org.apache.spark.ui.storage.RDDPage,int)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$3/RDDPage$$anonfun$3(org.apache.spark.ui.storage.RDDPage,int)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$1/RDDPage$$anonfun$1(org.apache.spark.ui.storage.RDDPage,int)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$8/RDDPage$$anonfun$8(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$6/RDDPage$$anonfun$6(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$4/RDDPage$$anonfun$4(org.apache.spark.ui.storage.RDDPage)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/description()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/storage/StorageUtils$/getRddBlockLocations(int,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/collection/SeqLike/sortWith(scala.Function2)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/storage/StorageListener/rddInfoList()|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/workerHeader()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/memoryUsed()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$6()|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/numPartitions()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/blockHeader()|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$render$1/RDDPage$$anonfun$render$1(org.apache.spark.ui.storage.RDDPage)|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/diskUsed()|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/listener()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$3/RDDPage$$anonfun$3(org.apache.spark.ui.storage.RDDPage,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$render$2/RDDPage$$anonfun$render$2(org.apache.spark.ui.storage.RDDPage,scala.xml.NodeBuffer)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable$default$7()|",
      "|java+method:///org/apache/spark/status/api/v1/AllRDDResource$/getRDDStorageInfo(int,org.apache.spark.ui.storage.StorageListener,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$1/RDDPage$$anonfun$1(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$6/RDDPage$$anonfun$6(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$4/RDDPage$$anonfun$4(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$2/RDDPage$$anonfun$2(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$7/RDDPage$$anonfun$7(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///org/apache/spark/ui/storage/RDDPage$$anonfun$5/RDDPage$$anonfun$5(org.apache.spark.ui.storage.RDDPage)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/storageLevel()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/partitions()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/name()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/dataDistribution()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/storage/RDDPage/workerHeader()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/listingTable(scala.collection.Seq,scala.Function1,scala.collection.Iterable,boolean,scala.Option,scala.collection.Seq,boolean)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/status/api/v1/RDDStorageInfo/numCachedPartitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///java/lang/Class/getSimpleName()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/org$apache$spark$rdd$SequenceFileRDDFunctions$$keyWritableClass()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/apply()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/org$apache$spark$rdd$SequenceFileRDDFunctions$$valueWritableClass()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/apply$mcV$sp()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/PoolPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$1/PoolPage$$anonfun$1(org.apache.spark.ui.jobs.PoolPage)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolTable/PoolTable(scala.collection.Seq,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$2/PoolPage$$anonfun$2(org.apache.spark.ui.jobs.PoolPage,java.lang.String)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/listener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/poolToActiveStages()|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/basePath()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$render$2/PoolPage$$anonfun$render$2(org.apache.spark.ui.jobs.PoolPage,scala.xml.NodeSeq)|",
      "|java+method:///org/apache/spark/ui/jobs/PoolPage/sc()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/PoolPage/listener()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/isFairScheduler()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/PoolTable/toNodeSeq()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$render$1/PoolPage$$anonfun$render$1(org.apache.spark.ui.jobs.PoolPage)|"
    ],
    "v2Body": [
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$1/PoolPage$$anonfun$1(org.apache.spark.ui.jobs.PoolPage)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolTable/PoolTable(scala.collection.Seq,org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$2/PoolPage$$anonfun$2(org.apache.spark.ui.jobs.PoolPage,java.lang.String)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/Option$/option2Iterable(scala.Option)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/poolToActiveStages()|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///scala/collection/Seq/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/basePath()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$render$2/PoolPage$$anonfun$render$2(org.apache.spark.ui.jobs.PoolPage,scala.xml.NodeSeq)|",
      "|java+method:///org/apache/spark/ui/jobs/PoolPage/sc()|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/toSeq()|",
      "|java+method:///org/apache/spark/ui/jobs/PoolPage/listener()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/progressListener()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/isFairScheduler()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/Seq/size()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/PoolTable/toNodeSeq()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/PoolPage$$anonfun$render$1/PoolPage$$anonfun$render$1(org.apache.spark.ui.jobs.PoolPage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore/tryToPut(org.apache.spark.storage.BlockId,java.lang.Object,long,boolean)|",
    "called": "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory_$eq(long)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/accountingLock()|",
      "|java+method:///java/nio/ByteBuffer/duplicate()|",
      "|java+method:///java/util/LinkedHashMap/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/package$/Right()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory()|",
      "|java+method:///scala/util/Right$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/ResultWithDroppedBlocks/droppedBlocks()|",
      "|java+method:///org/apache/spark/storage/BlockStore/blockManager()|",
      "|java+method:///org/apache/spark/storage/BlockManager/dropFromMemory(org.apache.spark.storage.BlockId,scala.util.Either)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$plus$eq(scala.collection.TraversableOnce)|",
      "|java+method:///scala/util/Left$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/ResultWithDroppedBlocks/ResultWithDroppedBlocks(boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/ensureFreeSpace(org.apache.spark.storage.BlockId,long)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$tryToPut$2/MemoryStore$$anonfun$tryToPut$2(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$entries()|",
      "|java+constructor:///org/apache/spark/storage/MemoryEntry/MemoryEntry(java.lang.Object,long,boolean)|",
      "|java+method:///scala/package$/Left()|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$tryToPut$1/MemoryStore$$anonfun$tryToPut$1(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,long,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/storage/ResultWithDroppedBlocks/success()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logInfo(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore/tryToPut(org.apache.spark.storage.BlockId,scala.Function0,long,boolean)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$tryToPut$1/MemoryStore$$anonfun$tryToPut$1(org.apache.spark.storage.MemoryStore,java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorExitCode$/explainExitCode(int)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/TACHYON_STORE_FAILED_TO_INITIALIZE()|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/DISK_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/UNCAUGHT_EXCEPTION()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/UNCAUGHT_EXCEPTION_TWICE()|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/TACHYON_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/OOM()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/DISK_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/UNCAUGHT_EXCEPTION_TWICE()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/EXTERNAL_BLOCK_STORE_FAILED_TO_CREATE_DIR()|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/UNCAUGHT_EXCEPTION()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/executor/ExecutorExitCode$/EXTERNAL_BLOCK_STORE_FAILED_TO_INITIALIZE()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/SparkExitCode$/OOM()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/taskEndReasonToJson(org.apache.spark.TaskEndReason)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/ExceptionFailure/fullStackTrace()|",
      "|java+method:///org/apache/spark/util/Utils$/emptyJson()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/FetchFailed/message()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonToJson$1/JsonProtocol$$anonfun$taskEndReasonToJson$1()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/FetchFailed/bmAddress()|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/ExceptionFailure/stackTrace()|",
      "|java+method:///org/apache/spark/ExceptionFailure/description()|",
      "|java+method:///org/apache/spark/ExecutorLostFailure/execId()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$37/JsonProtocol$$anonfun$37()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$32/JsonProtocol$$anonfun$32()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$36/JsonProtocol$$anonfun$36()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$31/JsonProtocol$$anonfun$31()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$29/JsonProtocol$$anonfun$29()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$35/JsonProtocol$$anonfun$35()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$30/JsonProtocol$$anonfun$30()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$28/JsonProtocol$$anonfun$28()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$34/JsonProtocol$$anonfun$34()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$33/JsonProtocol$$anonfun$33()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$38/JsonProtocol$$anonfun$38()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$27/JsonProtocol$$anonfun$27()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/FetchFailed/shuffleId()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/stackTraceToJson(java.lang.StackTraceElement%5B%5D)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/FetchFailed/mapId()|",
      "|java+method:///org/apache/spark/ExceptionFailure/className()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ExceptionFailure/metrics()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/FetchFailed/reduceId()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/ExceptionFailure/fullStackTrace()|",
      "|java+method:///org/apache/spark/util/Utils$/emptyJson()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/FetchFailed/message()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$taskEndReasonToJson$1/JsonProtocol$$anonfun$taskEndReasonToJson$1()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/FetchFailed/bmAddress()|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/ExceptionFailure/stackTrace()|",
      "|java+method:///org/apache/spark/ExceptionFailure/description()|",
      "|java+method:///org/apache/spark/ExecutorLostFailure/execId()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$37/JsonProtocol$$anonfun$37()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$32/JsonProtocol$$anonfun$32()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$36/JsonProtocol$$anonfun$36()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$31/JsonProtocol$$anonfun$31()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$29/JsonProtocol$$anonfun$29()|",
      "|java+method:///org/apache/spark/util/Utils$/getFormattedClassName(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$35/JsonProtocol$$anonfun$35()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$30/JsonProtocol$$anonfun$30()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$34/JsonProtocol$$anonfun$34()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$38/JsonProtocol$$anonfun$38()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$33/JsonProtocol$$anonfun$33()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$39/JsonProtocol$$anonfun$39()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$28/JsonProtocol$$anonfun$28()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/FetchFailed/shuffleId()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/stackTraceToJson(java.lang.StackTraceElement%5B%5D)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/FetchFailed/mapId()|",
      "|java+method:///org/apache/spark/ExceptionFailure/className()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ExceptionFailure/metrics()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/FetchFailed/reduceId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/glom()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$glom$1/RDD$$anonfun$glom$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+constructor:///org/apache/spark/rdd/MapPartitionsRDD/MapPartitionsRDD(org.apache.spark.rdd.RDD,scala.Function3,boolean,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/MapPartitionsRDD$/$lessinit$greater$default$3()|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$glom$1/RDD$$anonfun$glom$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$mapValues$1/PairRDDFunctions$$anonfun$mapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$84/StagePage$$anonfun$84(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$5/SparkContext$$anonfun$5(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/org$apache$spark$util$collection$ExternalSorter$SpillReader$$readNextItem()|",
    "called": "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInPartition_$eq(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInBatch_$eq(int)|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/readObject(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/finished()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInPartition()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/org$apache$spark$util$collection$ExternalSorter$SpillReader$$$outer()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/skipToNextPartition()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/lastPartitionId_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/nextBatchStream()|",
      "|java+method:///scala/reflect/ClassTag$/Nothing()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serializerBatchSize()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInBatch()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/finished_$eq(boolean)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/partitionId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream_$eq(org.apache.spark.serializer.DeserializationStream)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInPartition_$eq(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/finished()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInPartition()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/org$apache$spark$util$collection$ExternalSorter$SpillReader$$$outer()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/readKey(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/skipToNextPartition()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/lastPartitionId_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/nextBatchStream()|",
      "|java+method:///scala/reflect/ClassTag$/Nothing()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInBatch_$eq(int)|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/readValue(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serializerBatchSize()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/deserializeStream()|",
      "|java+method:///org/apache/spark/serializer/DeserializationStream/close()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$numPartitions()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/indexInBatch()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/finished_$eq(boolean)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$SpillReader/partitionId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$7/StagePage$$anonfun$7(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcJ$sp/AbstractFunction0$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$59/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$59/apply(org.apache.spark.executor.ShuffleReadMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$59/apply(org.apache.spark.executor.InputMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1/apply(org.apache.spark.storage.RDDInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions_$eq(int)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/tachyonSize_$eq(long)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$5/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$5(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1)|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel_$eq(org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/TraversableLike/headOption()|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$4/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$4(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$6/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$6(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$8/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$8(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$7/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$7(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$9/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$9(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize_$eq(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize_$eq(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions_$eq(int)|",
      "|java+method:///scala/collection/TraversableOnce/sum(scala.math.Numeric)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$5/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$5(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1)|",
      "|java+method:///scala/collection/Seq/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel_$eq(org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/collection/TraversableLike/headOption()|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$4/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$4(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$6/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$6(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$8/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$8(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$7/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$7(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+constructor:///org/apache/spark/storage/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$9/StorageUtils$$anonfun$updateRddInfo$1$$anonfun$9(org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1,int)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize_$eq(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize_$eq(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/externalBlockStoreSize_$eq(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/org$apache$spark$deploy$master$ui$MasterPage$$driverRow(org.apache.spark.deploy.master.DriverInfo)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$1/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$1(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$2/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$2(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/deploy/Command/arguments()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/cores()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/desc()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/id()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/worker()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/submitDate()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$1/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$1(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$2/MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$2(org.apache.spark.deploy.master.ui.MasterPage)|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/killEnabled()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/Command/arguments()|",
      "|java+method:///java/lang/String/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/RUNNING()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/mem()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/id()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/worker()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/submitDate()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/command()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/SUBMITTED()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/RELAUNCHING()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/cores()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$15/StagePage$$anonfun$15(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$27/JsonProtocol$$anonfun$27()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/RangeDependency/getParents(int)|",
    "called": "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapIntArray(int%5B%5D)|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapIntArray(int%5B%5D)|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/RangeDependency/getParents(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$3/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$3/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsTarget()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$3/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveMavenCoordinates(java.lang.String,scala.Option,scala.Option,boolean)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/getModuleDescriptor()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitUtils$$anonfun$9/SparkSubmitUtils$$anonfun$9()|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/setDefaultResolver(java.lang.String)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/createRepoResolvers(scala.Option)|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setTransitive(boolean)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/addMatcher(org.apache.ivy.plugins.matcher.PatternMatcher)|",
      "|java+method:///java/lang/System/setOut(java.io.PrintStream)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/extractMavenCoordinates(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/printStream()|",
      "|java+method:///org/apache/ivy/core/retrieve/RetrieveOptions/setLog(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getAllProblemMessages()|",
      "|java+method:///java/util/List/toArray()|",
      "|java+method:///org/apache/ivy/Ivy/retrieve(org.apache.ivy.core.module.id.ModuleRevisionId,java.lang.String,org.apache.ivy.core.retrieve.RetrieveOptions)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/addDependenciesToIvy(org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor,scala.collection.Seq,java.lang.String)|",
      "|java+method:///org/apache/ivy/core/retrieve/RetrieveOptions/setConfs(java.lang.String%5B%5D)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/ivy/plugins/matcher/GlobPatternMatcher/GlobPatternMatcher()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/setDefaultCache(java.io.File)|",
      "|java+method:///org/apache/ivy/core/module/descriptor/ModuleDescriptor/getModuleRevisionId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/getDefaultIvyUserDir()|",
      "|java+method:///org/apache/ivy/Ivy/resolve(org.apache.ivy.core.module.descriptor.ModuleDescriptor,org.apache.ivy.core.resolve.ResolveOptions)|",
      "|java+method:///org/apache/ivy/plugins/resolver/ChainResolver/getName()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/addExclusionRules(org.apache.ivy.core.settings.IvySettings,java.lang.String,org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/ivy/Ivy/newInstance(org.apache.ivy.core.settings.IvySettings)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getModuleDescriptor()|",
      "|java+constructor:///org/apache/ivy/core/resolve/ResolveOptions/ResolveOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/addResolver(org.apache.ivy.plugins.resolver.DependencyResolver)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getArtifacts()|",
      "|java+constructor:///org/apache/ivy/core/retrieve/RetrieveOptions/RetrieveOptions()|",
      "|java+constructor:///org/apache/ivy/core/settings/IvySettings/IvySettings()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setLog(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/getDefaultCache()|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setDownload(boolean)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/hasError()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveDependencyPaths(java.lang.Object%5B%5D,java.io.File)|",
      "|java+method:///org/apache/ivy/core/module/descriptor/DefaultModuleDescriptor/setDefaultConf(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/getModuleDescriptor()|",
      "|java+constructor:///org/apache/spark/deploy/SparkSubmitUtils$$anonfun$9/SparkSubmitUtils$$anonfun$9()|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/setDefaultIvyUserDir(java.io.File)|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setTransitive(boolean)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/addMatcher(org.apache.ivy.plugins.matcher.PatternMatcher)|",
      "|java+method:///java/lang/System/setOut(java.io.PrintStream)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/extractMavenCoordinates(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/printStream()|",
      "|java+method:///org/apache/ivy/core/retrieve/RetrieveOptions/setLog(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getAllProblemMessages()|",
      "|java+method:///java/util/List/toArray()|",
      "|java+method:///org/apache/ivy/Ivy/retrieve(org.apache.ivy.core.module.id.ModuleRevisionId,java.lang.String,org.apache.ivy.core.retrieve.RetrieveOptions)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/createRepoResolvers(scala.Option,org.apache.ivy.core.settings.IvySettings)|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/addDependenciesToIvy(org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor,scala.collection.Seq,java.lang.String)|",
      "|java+method:///org/apache/ivy/core/retrieve/RetrieveOptions/setConfs(java.lang.String%5B%5D)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/ivy/plugins/matcher/GlobPatternMatcher/GlobPatternMatcher()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/setDefaultCache(java.io.File)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/setDefaultResolver(java.lang.String)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/module/descriptor/ModuleDescriptor/getModuleRevisionId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/getDefaultIvyUserDir()|",
      "|java+method:///org/apache/ivy/Ivy/resolve(org.apache.ivy.core.module.descriptor.ModuleDescriptor,org.apache.ivy.core.resolve.ResolveOptions)|",
      "|java+method:///org/apache/ivy/plugins/resolver/ChainResolver/getName()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/addExclusionRules(org.apache.ivy.core.settings.IvySettings,java.lang.String,org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/ivy/Ivy/newInstance(org.apache.ivy.core.settings.IvySettings)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getModuleDescriptor()|",
      "|java+constructor:///org/apache/ivy/core/resolve/ResolveOptions/ResolveOptions()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/RuntimeException/RuntimeException(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/addResolver(org.apache.ivy.plugins.resolver.DependencyResolver)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/getArtifacts()|",
      "|java+constructor:///org/apache/ivy/core/retrieve/RetrieveOptions/RetrieveOptions()|",
      "|java+constructor:///org/apache/ivy/core/settings/IvySettings/IvySettings()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setLog(java.lang.String)|",
      "|java+method:///org/apache/ivy/core/settings/IvySettings/getDefaultCache()|",
      "|java+method:///org/apache/ivy/core/resolve/ResolveOptions/setDownload(boolean)|",
      "|java+method:///org/apache/ivy/core/report/ResolveReport/hasError()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitUtils$/resolveDependencyPaths(java.lang.Object%5B%5D,java.io.File)|",
      "|java+method:///org/apache/ivy/core/module/descriptor/DefaultModuleDescriptor/setDefaultConf(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$21/JsonProtocol$$anonfun$21()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/HttpServer/uri()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ServerStateException/ServerStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/SSLOptions/enabled()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/HttpServer/server()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/localIpAddress()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/HttpServer/port()|",
      "|java+method:///org/apache/spark/SecurityManager/fileServerSSLOptions()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ServerStateException/ServerStateException(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostNameForURI()|",
      "|java+method:///org/apache/spark/SSLOptions/enabled()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/HttpServer/server()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/HttpServer/port()|",
      "|java+method:///org/apache/spark/SecurityManager/fileServerSSLOptions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/apply()|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1/org$apache$spark$deploy$worker$Worker$$anonfun$$$outer()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/sender()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$24/JsonProtocol$$anonfun$24()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/StageInfo$/fromStage(org.apache.spark.scheduler.Stage,scala.Option)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo$/fromRdd(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/getNarrowAncestors()|",
      "|java+method:///org/apache/spark/scheduler/Stage/details()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo$$anonfun$fromStage$1/StageInfo$$anonfun$fromStage$1(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/Stage/attemptId()|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo/StageInfo(int,int,java.lang.String,int,scala.collection.Seq,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo$$anonfun$1/StageInfo$$anonfun$1()|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/apache/spark/storage/RDDInfo$/fromRdd(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/getNarrowAncestors()|",
      "|java+method:///org/apache/spark/scheduler/Stage/details()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo$$anonfun$fromStage$1/StageInfo$$anonfun$fromStage$1(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/Stage/attemptId()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo/StageInfo(int,int,java.lang.String,int,scala.collection.Seq,scala.collection.Seq,java.lang.String)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/List/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo$$anonfun$1/StageInfo$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/scheduler/StageInfo$$anonfun$fromStage$2/StageInfo$$anonfun$fromStage$2()|",
      "|java+method:///org/apache/spark/scheduler/Stage/name()|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/Stage/parents()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/HistoryServer$$anon$1/doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///java/lang/Exception/getCause()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$2/HistoryServer$$anon$1$$anonfun$2(org.apache.spark.deploy.history.HistoryServer$$anon$1)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$2/HistoryServer$$anon$1$$anonfun$doGet$2(org.apache.spark.deploy.history.HistoryServer$$anon$1,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$1/HistoryServer$$anon$1$$anonfun$doGet$1(org.apache.spark.deploy.history.HistoryServer$$anon$1,scala.xml.Elem)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/encodeRedirectURL(java.lang.String)|",
      "|java+method:///org/spark-project/guava/cache/LoadingCache/get(java.lang.Object)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendError(int,java.lang.String)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendRedirect(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/org$apache$spark$deploy$history$HistoryServer$$appCache()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRequestURI()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendError(int,java.lang.String)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$2/HistoryServer$$anon$1$$anonfun$2(org.apache.spark.deploy.history.HistoryServer$$anon$1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/org$apache$spark$deploy$history$HistoryServer$$loadAppUi(java.lang.String,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$1/HistoryServer$$anon$1$$anonfun$doGet$1(org.apache.spark.deploy.history.HistoryServer$$anon$1,scala.xml.Elem)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/encodeRedirectURL(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$2/HistoryServer$$anon$1$$anonfun$doGet$2(org.apache.spark.deploy.history.HistoryServer$$anon$1,javax.servlet.http.HttpServletResponse)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getPathInfo()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/basicSparkPage(scala.Function0,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/sendRedirect(java.lang.String)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRequestURI()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///javax/servlet/http/HttpServletResponse/setStatus(int)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf/validateSettings()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$1/SparkConf$$anonfun$validateSettings$1(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5/SparkConf$$anonfun$validateSettings$5(org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf$/org$apache$spark$SparkConf$$deprecatedConfigs()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$3/SparkConf$$anonfun$validateSettings$3(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$2/SparkConf$$anonfun$validateSettings$2(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/collection/Iterable/foreach(scala.Function1)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$4/SparkConf$$anonfun$validateSettings$4(org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/immutable/Map/values()|",
      "|java+method:///scala/sys/SystemProperties/get(java.lang.String)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6/SparkConf$$anonfun$validateSettings$6(org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$7/SparkConf$$anonfun$validateSettings$7(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$1/SparkConf$$anonfun$validateSettings$1(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$4/SparkConf$$anonfun$validateSettings$4(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$5/SparkConf$$anonfun$validateSettings$5(org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$3/SparkConf$$anonfun$validateSettings$3(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$2/SparkConf$$anonfun$validateSettings$2(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/sys/SystemProperties/get(java.lang.String)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6/SparkConf$$anonfun$validateSettings$6(org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicLong/AtomicLong(long)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+constructor:///java/util/Timer/Timer(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler$class/$init$(org.apache.spark.scheduler.TaskScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/conf()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/liftedTree1$1()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter/TaskResultGetter(org.apache.spark.SparkEnv,org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicLong/AtomicLong(long)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///java/util/Timer/Timer(boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskScheduler$class/$init$(org.apache.spark.scheduler.TaskScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/conf()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/scheduler/TaskResultGetter/TaskResultGetter(org.apache.spark.SparkEnv,org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/liftedTree1$1()|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsMs(java.lang.String,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/apply()|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/org$apache$spark$storage$TachyonBlockManager$$MAX_DIR_CREATION_ATTEMPTS()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2/org$apache$spark$storage$TachyonBlockManager$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/apply()|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore$/MAX_DIR_CREATION_ATTEMPTS()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor$/CoarseGrainedClusterMessages$RegisterExecutor$()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction4/AbstractFunction4()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction5/AbstractFunction5()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitJob(org.apache.spark.rdd.RDD,scala.Function2,scala.collection.Seq,org.apache.spark.util.CallSite,boolean,scala.Function2,java.util.Properties)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/JobSubmitted/JobSubmitted(int,org.apache.spark.rdd.RDD,scala.Function2,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/scheduler/JobWaiter/JobWaiter(org.apache.spark.scheduler.DAGScheduler,int,int,scala.Function2)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$submitJob$2/DAGScheduler$$anonfun$submitJob$2(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/nextJobId()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/getAndIncrement()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq/find(scala.Function1)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$submitJob$1/DAGScheduler$$anonfun$submitJob$1(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///scala/collection/Seq/size()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/JobSubmitted/JobSubmitted(int,org.apache.spark.rdd.RDD,scala.Function2,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/scheduler/JobWaiter/JobWaiter(org.apache.spark.scheduler.DAGScheduler,int,int,scala.Function2)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$submitJob$2/DAGScheduler$$anonfun$submitJob$2(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///org/apache/commons/lang3/SerializationUtils/clone(java.io.Serializable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/nextJobId()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/getAndIncrement()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq/find(scala.Function1)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$submitJob$1/DAGScheduler$$anonfun$submitJob$1(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///scala/collection/Seq/size()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$60/StagePage$$anonfun$60(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverRunner/org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar(java.io.File)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/conf()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar$1/DriverRunner$$anonfun$org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar$1(org.apache.spark.deploy.worker.DriverRunner,org.apache.hadoop.fs.Path,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/logInfo(scala.Function0)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/jarUrl()|",
      "|java+method:///org/apache/hadoop/fs/FileUtil/copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.io.File,boolean,org.apache.hadoop.conf.Configuration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/securityManager()|",
      "|java+constructor:///java/io/File/File(java.io.File,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverRunner$$anonfun$org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar$1/DriverRunner$$anonfun$org$apache$spark$deploy$worker$DriverRunner$$downloadUserJar$1(org.apache.spark.deploy.worker.DriverRunner,org.apache.hadoop.fs.Path,java.io.File)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/logInfo(scala.Function0)|",
      "|java+method:///java/io/File/exists()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/util/Utils$/fetchFile(java.lang.String,java.io.File,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,org.apache.hadoop.conf.Configuration,long,boolean)|",
      "|java+method:///org/apache/spark/deploy/DriverDescription/jarUrl()|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/DriverRunner/driverDesc()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/fullOuterJoin(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$fullOuterJoin$1/PairRDDFunctions$$anonfun$fullOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/flatMapValues(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$fullOuterJoin$1/PairRDDFunctions$$anonfun$fullOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/apply$mcJ$sp()|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/submitJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,scala.Function2,scala.Function0)|",
      "|java+method:///scala/package$/Range()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$5/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$5(org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1)|",
      "|java+method:///scala/collection/immutable/Range$/apply(int,int)|",
      "|java+method:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1/apply()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicLong/AtomicLong()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$2/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$2(org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1,java.util.concurrent.atomic.AtomicLong)|",
      "|java+constructor:///org/apache/spark/rdd/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$1/AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$1(org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1,java.util.concurrent.atomic.AtomicLong)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$1/apply()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$doCleanupBroadcast$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$13/JsonProtocol$$anonfun$13()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$89/StagePage$$anonfun$89(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/Connection/printRemainingBuffer(java.nio.ByteBuffer)|",
    "called": "|java+method:///scala/Predef$/print(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/nio/ByteBuffer/position()|",
      "|java+method:///scala/Predef$/byteArrayOps(byte%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/print(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/network/nio/Connection$$anonfun$printRemainingBuffer$1/Connection$$anonfun$printRemainingBuffer$1(org.apache.spark.network.nio.Connection)|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/nio/ByteBuffer/position(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/print(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/position()|",
      "|java+method:///scala/Predef$/byteArrayOps(byte%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/network/nio/Connection$$anonfun$printRemainingBuffer$1/Connection$$anonfun$printRemainingBuffer$1(org.apache.spark.network.nio.Connection)|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/nio/ByteBuffer/remaining()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/nio/ByteBuffer/position(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$6/MasterPage$$anonfun$6(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/ConsoleProgressBar/org$apache$spark$ui$ConsoleProgressBar$$refresh()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/FIRST_DELAY()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/statusTracker()|",
      "|java+method:///scala/collection/mutable/ArrayOps/take(int)|",
      "|java+method:///org/apache/spark/SparkStatusTracker/getActiveStageIds()|",
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/show(long,scala.collection.Seq)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/lastFinishTime()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$5/ConsoleProgressBar$$anonfun$5(org.apache.spark.ui.ConsoleProgressBar,long)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$2/ConsoleProgressBar$$anonfun$2(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$3/ConsoleProgressBar$$anonfun$3(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatten(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$4/ConsoleProgressBar$$anonfun$4(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$6/ConsoleProgressBar$$anonfun$6(org.apache.spark.ui.ConsoleProgressBar)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/FIRST_DELAY()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$5/ConsoleProgressBar$$anonfun$5(org.apache.spark.ui.ConsoleProgressBar,long)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/statusTracker()|",
      "|java+method:///scala/collection/mutable/ArrayOps/take(int)|",
      "|java+method:///org/apache/spark/SparkStatusTracker/getActiveStageIds()|",
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/show(long,scala.collection.Seq)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$3/ConsoleProgressBar$$anonfun$3(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatten(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$4/ConsoleProgressBar$$anonfun$4(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$6/ConsoleProgressBar$$anonfun$6(org.apache.spark.ui.ConsoleProgressBar)|",
      "|java+method:///org/apache/spark/ui/ConsoleProgressBar/lastFinishTime()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$2/ConsoleProgressBar$$anonfun$2(org.apache.spark.ui.ConsoleProgressBar,org.apache.spark.SparkStatusTracker)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/run()|",
    "called": "|java+method:///scala/Tuple2/_2$mcI$sp()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/keys()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/select()|",
      "|java+method:///java/nio/channels/SelectionKey/isConnectable()|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerWrite(java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$8/ConnectionManager$$anonfun$8(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///java/lang/Thread/isInterrupted()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$6/ConnectionManager$$anonfun$run$6(org.apache.spark.network.nio.ConnectionManager,int,org.apache.spark.network.nio.Connection,int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$14/ConnectionManager$$anonfun$run$14(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/isTraceEnabled()|",
      "|java+method:///java/nio/channels/SelectionKey/isValid()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerConnect(java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$13/ConnectionManager$$anonfun$run$13(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/registerRequests()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/mutable/SynchronizedQueue/dequeue()|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/connect()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/addListeners(org.apache.spark.network.nio.Connection)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$12/ConnectionManager$$anonfun$run$12(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/selectorThread()|",
      "|java+method:///java/nio/channels/SelectionKey/isWritable()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$selector()|",
      "|java+method:///java/nio/channels/SelectionKey/isAcceptable()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$10/ConnectionManager$$anonfun$run$10(org.apache.spark.network.nio.ConnectionManager,int)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$11/ConnectionManager$$anonfun$run$11(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/addConnection(org.apache.spark.network.nio.Connection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/connectionsByKey()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/keyInterestChangeRequests()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logTrace(scala.Function0)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerRead(java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerForceCloseByException(java.nio.channels.SelectionKey,java.lang.Exception)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$15/ConnectionManager$$anonfun$run$15(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/nio/channels/SelectionKey/interestOps(int)|",
      "|java+method:///scala/collection/mutable/SynchronizedQueue/isEmpty()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/acceptConnection(java.nio.channels.SelectionKey)|",
      "|java+method:///java/nio/channels/SelectionKey/isReadable()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///java/nio/channels/SelectionKey/interestOps()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$11/ConnectionManager$$anonfun$11(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///java/nio/channels/CancelledKeyException/CancelledKeyException()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$10/ConnectionManager$$anonfun$10(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$9/ConnectionManager$$anonfun$9(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$9/ConnectionManager$$anonfun$run$9(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$8/ConnectionManager$$anonfun$run$8(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$7/ConnectionManager$$anonfun$run$7(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/selectedKeys()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$12/ConnectionManager$$anonfun$12(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/keys()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/select()|",
      "|java+method:///java/nio/channels/SelectionKey/isConnectable()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerWrite(java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$8/ConnectionManager$$anonfun$8(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/util/Iterator/remove()|",
      "|java+method:///java/lang/Thread/isInterrupted()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$6/ConnectionManager$$anonfun$run$6(org.apache.spark.network.nio.ConnectionManager,int,org.apache.spark.network.nio.Connection,int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$14/ConnectionManager$$anonfun$run$14(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/isTraceEnabled()|",
      "|java+method:///java/nio/channels/SelectionKey/isValid()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerConnect(java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$13/ConnectionManager$$anonfun$run$13(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/registerRequests()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+method:///scala/collection/mutable/SynchronizedQueue/dequeue()|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/connect()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/addListeners(org.apache.spark.network.nio.Connection)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$12/ConnectionManager$$anonfun$run$12(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/selectorThread()|",
      "|java+method:///java/nio/channels/SelectionKey/isWritable()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$selector()|",
      "|java+method:///java/nio/channels/SelectionKey/isAcceptable()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$10/ConnectionManager$$anonfun$run$10(org.apache.spark.network.nio.ConnectionManager,int)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/isActive()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$11/ConnectionManager$$anonfun$run$11(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/addConnection(org.apache.spark.network.nio.Connection)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/connectionsByKey()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/keyInterestChangeRequests()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logTrace(scala.Function0)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerRead(java.nio.channels.SelectionKey)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/triggerForceCloseByException(java.nio.channels.SelectionKey,java.lang.Exception)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$15/ConnectionManager$$anonfun$run$15(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/nio/channels/SelectionKey/interestOps(int)|",
      "|java+method:///scala/collection/mutable/SynchronizedQueue/isEmpty()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/acceptConnection(java.nio.channels.SelectionKey)|",
      "|java+method:///java/nio/channels/SelectionKey/isReadable()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///java/nio/channels/SelectionKey/interestOps()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$11/ConnectionManager$$anonfun$11(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///java/nio/channels/CancelledKeyException/CancelledKeyException()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$10/ConnectionManager$$anonfun$10(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$9/ConnectionManager$$anonfun$9(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$9/ConnectionManager$$anonfun$run$9(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$8/ConnectionManager$$anonfun$run$8(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$run$7/ConnectionManager$$anonfun$run$7(org.apache.spark.network.nio.ConnectionManager,java.nio.channels.SelectionKey)|",
      "|java+method:///java/nio/channels/spi/AbstractSelector/selectedKeys()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/setupAndStartListenerBus()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/start()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$35/SparkContext$$anonfun$35(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$34/SparkContext$$anonfun$34(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1/SparkContext$$anonfun$setupAndStartListenerBus$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/stop()|",
      "|java+method:///org/apache/spark/SparkContext/_listenerBusStarted_$eq(boolean)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/start(org.apache.spark.SparkContext)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$38/SparkContext$$anonfun$38(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$39/SparkContext$$anonfun$39(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$setupAndStartListenerBus$1/SparkContext$$anonfun$setupAndStartListenerBus$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$16/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$16/apply(org.apache.spark.ui.jobs.UIData$JobUIData)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$16/apply(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/TachyonBlockManager/rootDirs()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider/FsHistoryProvider(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/mutable/LinkedHashMap/LinkedHashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/LinkedHashMap/LinkedHashMap()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/initialize()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/SPARK_VERSION_KEY()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/util/Utils$/getHadoopFileSystem(java.lang.String,org.apache.hadoop.conf.Configuration)|",
      "|java+constructor:///org/apache/spark/deploy/history/ApplicationHistoryProvider/ApplicationHistoryProvider()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/COMPRESSION_CODEC_KEY()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anon$1/FsHistoryProvider$$anon$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$2/FsHistoryProvider$$anonfun$2(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$1/FsHistoryProvider$$anonfun$1(org.apache.spark.deploy.history.FsHistoryProvider)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/util/SystemClock/SystemClock()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider/FsHistoryProvider(org.apache.spark.SparkConf,org.apache.spark.util.Clock)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$51/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$51/apply(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$51/apply(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$11/AllJobsPage$$anonfun$11(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/leftOuterJoin(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$leftOuterJoin$1/PairRDDFunctions$$anonfun$leftOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/flatMapValues(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$leftOuterJoin$1/PairRDDFunctions$$anonfun$leftOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$5/CoarseMesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/apply()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/apply()|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putIterator$1/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/coalesce(int,boolean,scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/CoalescedRDD$/$lessinit$greater$default$3()|",
      "|java+constructor:///org/apache/spark/HashPartitioner/HashPartitioner(int)|",
      "|java+constructor:///org/apache/spark/rdd/CoalescedRDD/CoalescedRDD(org.apache.spark.rdd.RDD,int,double,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$7/RDD$$anonfun$7(org.apache.spark.rdd.RDD,int)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/values()|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+constructor:///org/apache/spark/rdd/ShuffledRDD/ShuffledRDD(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitionsWithIndex(scala.Function2,boolean,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$coalesce$1/RDD$$anonfun$coalesce$1(org.apache.spark.rdd.RDD,int,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/ZooKeeperPersistenceEngine(org.apache.spark.SparkConf,akka.serialization.Serialization)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/SparkCuratorUtil$/mkdir(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/WORKING_DIR()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/zk()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/deploy/master/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine$class/$init$(org.apache.spark.deploy.master.PersistenceEngine)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/PersistenceEngine/PersistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient$default$2()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/mkdir(org.apache.curator.framework.CuratorFramework,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/SparkCuratorUtil$/newClient(org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/WORKING_DIR()|",
      "|java+method:///org/apache/spark/deploy/master/ZooKeeperPersistenceEngine/zk()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf/setAll(scala.collection.Traversable)|",
    "called": "|java+method:///scala/collection/JavaConverters$/mapAsJavaMapConverter(scala.collection.Map)|",
    "v1Body": [
      "|java+method:///scala/collection/convert/Decorators$AsJava/asJava()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/putAll(java.util.Map)|",
      "|java+method:///scala/collection/JavaConverters$/mapAsJavaMapConverter(scala.collection.Map)|",
      "|java+method:///org/apache/spark/SparkConf/settings()|",
      "|java+method:///scala/collection/Traversable/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$setAll$1/SparkConf$$anonfun$setAll$1(org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/Traversable/foreach(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$replay(org.apache.hadoop.fs.FileStatus,org.apache.spark.scheduler.ReplayListenerBus)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appId()|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/getPath()|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/replay(java.io.InputStream,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$getModificationTime(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/openLegacyEventLog(org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/FsApplicationHistoryInfo(java.lang.String,java.lang.String,java.lang.String,long,long,long,java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/scheduler/ApplicationEventListener/ApplicationEventListener()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/isApplicationCompleted(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logInfo(scala.Function0)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/isLegacyLogDirectory(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/endTime()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appName()|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/addListener(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/startTime()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/openEventLog(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$3/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$3(org.apache.spark.deploy.history.FsHistoryProvider,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$4/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$4(org.apache.spark.deploy.history.FsHistoryProvider,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$5/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$5(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$2/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$2(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$6/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$6(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$1/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/Path/getName()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appId()|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/getPath()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$getModificationTime(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/isApplicationCompleted(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logInfo(scala.Function0)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/isLegacyLogDirectory(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/replay(java.io.InputStream,java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/openLegacyEventLog(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/endTime()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appName()|",
      "|java+method:///java/io/InputStream/close()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsApplicationAttemptInfo/FsApplicationAttemptInfo(java.lang.String,java.lang.String,java.lang.String,scala.Option,long,long,long,java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/scheduler/ApplicationEventListener/ApplicationEventListener()|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/addListener(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/appAttemptId()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/startTime()|",
      "|java+method:///org/apache/spark/scheduler/EventLoggingListener$/openEventLog(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$5/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$5(org.apache.spark.deploy.history.FsHistoryProvider,org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$3/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$3(org.apache.spark.deploy.history.FsHistoryProvider,org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$4/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$4(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$2/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$2(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$6/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$6(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$1/FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$replay$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/dropFromMemory(org.apache.spark.storage.BlockId,scala.util.Either)|",
    "called": "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+method:///scala/util/Right/b()|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///org/apache/spark/storage/BlockInfo/level()|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/DiskStore/putArray(org.apache.spark.storage.BlockId,java.lang.Object%5B%5D,org.apache.spark.storage.StorageLevel,boolean)|",
      "|java+method:///scala/util/Left/a()|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/tellMaster()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$5/BlockManager$$anonfun$dropFromMemory$5(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/DiskStore/contains(org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$1/BlockManager$$anonfun$dropFromMemory$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$2/BlockManager$$anonfun$dropFromMemory$2(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$3/BlockManager$$anonfun$dropFromMemory$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$4/BlockManager$$anonfun$dropFromMemory$4(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/useDisk()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/contains(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/getSize(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/DiskStore/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/waitForReady()|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$dropFromMemory$1/BlockManager$$anonfun$dropFromMemory$1(org.apache.spark.storage.BlockManager,scala.util.Either)|",
      "|java+method:///org/apache/spark/storage/BlockManager/dropFromMemory(org.apache.spark.storage.BlockId,scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/sequenceFile(java.lang.String,int,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.Function0,scala.Function0)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/Function0/apply()|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$sequenceFile$1/SparkContext$$anonfun$sequenceFile$1(org.apache.spark.SparkContext,org.apache.spark.WritableConverter,org.apache.spark.WritableConverter)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/WritableConverter/writableClass()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$sequenceFile$3/SparkContext$$anonfun$sequenceFile$3(org.apache.spark.SparkContext,java.lang.String,int,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.Function0,scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/stageInfoToJson(org.apache.spark.scheduler.StageInfo)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$1/JsonProtocol$$anonfun$stageInfoToJson$1()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/name()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$4/JsonProtocol$$anonfun$stageInfoToJson$4()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/rddInfos()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/details()|",
      "|java+method:///scala/collection/TraversableOnce/toList()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/numTasks()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/accumulables()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$2/JsonProtocol$$anonfun$stageInfoToJson$2()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$3/JsonProtocol$$anonfun$stageInfoToJson$3()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/failureReason()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$15/JsonProtocol$$anonfun$15()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$10/JsonProtocol$$anonfun$10()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$14/JsonProtocol$$anonfun$14()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$13/JsonProtocol$$anonfun$13()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$12/JsonProtocol$$anonfun$12()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$5/JsonProtocol$$anonfun$stageInfoToJson$5()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$16/JsonProtocol$$anonfun$16()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$11/JsonProtocol$$anonfun$11()|",
      "|java+constructor:///org/json4s/JsonAST$JArray/JsonAST$JArray(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$6/JsonProtocol$$anonfun$stageInfoToJson$6()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$1/JsonProtocol$$anonfun$stageInfoToJson$1()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/name()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$4/JsonProtocol$$anonfun$stageInfoToJson$4()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/rddInfos()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/Iterable/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/details()|",
      "|java+method:///scala/collection/TraversableOnce/toList()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/numTasks()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/accumulables()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$2/JsonProtocol$$anonfun$stageInfoToJson$2()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/parentIds()|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$3/JsonProtocol$$anonfun$stageInfoToJson$3()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/failureReason()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$15/JsonProtocol$$anonfun$15()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$10/JsonProtocol$$anonfun$10()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$14/JsonProtocol$$anonfun$14()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$13/JsonProtocol$$anonfun$13()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$17/JsonProtocol$$anonfun$17()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$12/JsonProtocol$$anonfun$12()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$5/JsonProtocol$$anonfun$stageInfoToJson$5()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$16/JsonProtocol$$anonfun$16()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$11/JsonProtocol$$anonfun$11()|",
      "|java+constructor:///org/json4s/JsonAST$JArray/JsonAST$JArray(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$stageInfoToJson$6/JsonProtocol$$anonfun$stageInfoToJson$6()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/org$apache$spark$deploy$master$ui$MasterPage$$appRow(org.apache.spark.deploy.master.ApplicationInfo)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDate(java.util.Date)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/duration()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerSlave()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/coresGranted()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///java/lang/String/toString()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/RUNNING()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDuration(long)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/killEnabled()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDate(java.util.Date)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/megabytesToString(long)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/duration()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/WAITING()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/appUiUrl()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerExecutorMB()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/RDDInfo$/fromRdd(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo$$anonfun$1/RDDInfo$$anonfun$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/name()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/getStorageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo/RDDInfo(int,java.lang.String,int,org.apache.spark.storage.StorageLevel)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo$$anonfun$1/RDDInfo$$anonfun$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/name()|",
      "|java+method:///org/apache/spark/rdd/RDD/scope()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/getStorageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo$$anonfun$2/RDDInfo$$anonfun$2()|",
      "|java+constructor:///org/apache/spark/storage/RDDInfo/RDDInfo(int,java.lang.String,int,org.apache.spark.storage.StorageLevel,scala.collection.Seq,scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$12/MasterPage$$anonfun$12(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$51/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$/rddInfoFromJson(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/rightOuterJoin(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$rightOuterJoin$1/PairRDDFunctions$$anonfun$rightOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/flatMapValues(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$rightOuterJoin$1/PairRDDFunctions$$anonfun$rightOuterJoin$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$15/JsonProtocol$$anonfun$15()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/textFile(java.lang.String,int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$textFile$1/SparkContext$$anonfun$textFile$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,int)|",
      "|java+method:///org/apache/spark/rdd/RDD/setName(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$textFile$1/SparkContext$$anonfun$textFile$1(org.apache.spark.SparkContext,java.lang.String,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$5/getValue()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$5/getValue()|",
      "|java+method:///org/apache/spark/executor/Executor/threadPool()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/executor/ExecutorSource/executor()|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getMaximumPoolSize()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$5/getValue()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getMaximumPoolSize()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/runLocallyWithinThread(org.apache.spark.scheduler.ActiveJob)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/TaskContextImpl$/$lessinit$greater$default$6()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/TaskContextHelper$/unset()|",
      "|java+constructor:///org/apache/spark/TaskContextImpl/TaskContextImpl(int,int,long,int,boolean,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///org/apache/spark/TaskContextHelper$/setTaskContext(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///org/apache/spark/TaskContextImpl/markTaskCompleted()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/partitions()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$runLocallyWithinThread$1/DAGScheduler$$anonfun$runLocallyWithinThread$1(org.apache.spark.scheduler.DAGScheduler,long)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/id()|",
      "|java+method:///org/apache/spark/TaskContextImpl$/$lessinit$greater$default$7()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/rdd()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/TaskContextImpl/markTaskCompleted()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/TaskMemoryManager/TaskMemoryManager(org.apache.spark.unsafe.memory.ExecutorMemoryManager)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/TaskContext$/setTaskContext(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/sc()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+constructor:///org/apache/spark/TaskContextImpl/TaskContextImpl(int,int,long,int,org.apache.spark.unsafe.memory.TaskMemoryManager,boolean,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+method:///org/apache/spark/TaskContext$/unset()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/partitions()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/executorMemoryManager()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/HadoopRDD/getJobConf()|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/putCachedMetadata(java.lang.String,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/SerializableWritable/value()|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/getCachedMetadata(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/jobConfCacheKey()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$6/HadoopRDD$$anonfun$getJobConf$6(org.apache.spark.rdd.HadoopRDD,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$4/HadoopRDD$$anonfun$getJobConf$4(org.apache.spark.rdd.HadoopRDD)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$5/HadoopRDD$$anonfun$getJobConf$5(org.apache.spark.rdd.HadoopRDD)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/containsCachedMetadata(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/shouldCloneJobConf()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$2/HadoopRDD$$anonfun$getJobConf$2(org.apache.spark.rdd.HadoopRDD,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$1/HadoopRDD$$anonfun$getJobConf$1(org.apache.spark.rdd.HadoopRDD)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/CONFIGURATION_INSTANTIATION_LOCK()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$3/HadoopRDD$$anonfun$getJobConf$3(org.apache.spark.rdd.HadoopRDD)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/org$apache$spark$rdd$HadoopRDD$$putCachedMetadata(java.lang.String,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/SerializableWritable/value()|",
      "|java+method:///org/apache/spark/broadcast/Broadcast/value()|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/getCachedMetadata(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/jobConfCacheKey()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$6/HadoopRDD$$anonfun$getJobConf$6(org.apache.spark.rdd.HadoopRDD,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$4/HadoopRDD$$anonfun$getJobConf$4(org.apache.spark.rdd.HadoopRDD)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$5/HadoopRDD$$anonfun$getJobConf$5(org.apache.spark.rdd.HadoopRDD)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/containsCachedMetadata(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/shouldCloneJobConf()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$2/HadoopRDD$$anonfun$getJobConf$2(org.apache.spark.rdd.HadoopRDD,org.apache.hadoop.mapred.JobConf)|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$1/HadoopRDD$$anonfun$getJobConf$1(org.apache.spark.rdd.HadoopRDD)|",
      "|java+constructor:///org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD$/CONFIGURATION_INSTANTIATION_LOCK()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$3/HadoopRDD$$anonfun$getJobConf$3(org.apache.spark.rdd.HadoopRDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$1/SparkContext$$anonfun$stop$1(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$47/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildCommandSeq(org.apache.spark.deploy.Command,int,java.lang.String)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/worker/CommandUtils$/buildJavaOpts(org.apache.spark.deploy.Command,int,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/Command/arguments()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/worker/CommandUtils$$anonfun$1/CommandUtils$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/deploy/worker/CommandUtils$$anonfun$2/CommandUtils$$anonfun$2()|",
      "|java+method:///org/apache/spark/deploy/Command/mainClass()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/Buffer/toSeq()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/Command/arguments()|",
      "|java+method:///org/apache/spark/launcher/WorkerCommandBuilder/buildCommand()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/deploy/Command/mainClass()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/launcher/WorkerCommandBuilder/WorkerCommandBuilder(java.lang.String,int,org.apache.spark.deploy.Command)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/worker/Worker/Worker(java.lang.String,int,int,int,int,java.lang.String%5B%5D,java.lang.String,java.lang.String,java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
    "called": "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/testing()|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$5/Worker$$anonfun$5(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/util/ActorLogReceive$class/$init$(org.apache.spark.util.ActorLogReceive)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/seconds()|",
      "|java+method:///scala/math/package$/round(double)|",
      "|java+method:///scala/util/Random/nextDouble()|",
      "|java+constructor:///org/apache/spark/deploy/worker/WorkerSource/WorkerSource(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/generateWorkerId()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///akka/actor/Actor$class/$init$(akka.actor.Actor)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/REGISTRATION_RETRY_FUZZ_MULTIPLIER()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/FUZZ_MULTIPLIER_INTERVAL_LOWER_BOUND()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///java/util/UUID/getMostSignificantBits()|",
      "|java+constructor:///scala/util/Random/Random(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/sys/SystemProperties/apply(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/INITIAL_REGISTRATION_RETRIES()|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$4/Worker$$anonfun$4(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///org/apache/spark/deploy/worker/StandaloneWorkerShuffleService/StandaloneWorkerShuffleService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/context()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/testing()|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$5/Worker$$anonfun$5(org.apache.spark.deploy.worker.Worker)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/util/ActorLogReceive$class/$init$(org.apache.spark.util.ActorLogReceive)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/seconds()|",
      "|java+method:///scala/math/package$/round(double)|",
      "|java+method:///scala/util/Random/nextDouble()|",
      "|java+constructor:///org/apache/spark/deploy/worker/WorkerSource/WorkerSource(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/generateWorkerId()|",
      "|java+constructor:///org/apache/spark/deploy/ExternalShuffleService/ExternalShuffleService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///akka/actor/Actor$class/$init$(akka.actor.Actor)|",
      "|java+method:///java/util/UUID/randomUUID()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/REGISTRATION_RETRY_FUZZ_MULTIPLIER()|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/FUZZ_MULTIPLIER_INTERVAL_LOWER_BOUND()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///java/util/UUID/getMostSignificantBits()|",
      "|java+constructor:///scala/util/Random/Random(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/sys/SystemProperties/apply(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/deploy/worker/Worker$$anonfun$4/Worker$$anonfun$4(org.apache.spark.deploy.worker.Worker)|",
      "|java+method:///org/apache/spark/deploy/worker/Worker/org$apache$spark$deploy$worker$Worker$$INITIAL_REGISTRATION_RETRIES()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor$/unapply(org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutor)|",
    "called": "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///scala/Tuple4/Tuple4(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorRef()|",
      "|java+constructor:///scala/Tuple5/Tuple5(java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/aggregateByKey(java.lang.Object,org.apache.spark.Partitioner,scala.Function2,scala.Function2,scala.reflect.ClassTag)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/runtime/VolatileByteRef/VolatileByteRef(byte)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/get(byte%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$1/PairRDDFunctions$$anonfun$1(org.apache.spark.rdd.PairRDDFunctions,scala.reflect.ClassTag,byte%5B%5D,scala.runtime.ObjectRef,scala.runtime.VolatileByteRef)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$5()|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$6()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$aggregateByKey$1/PairRDDFunctions$$anonfun$aggregateByKey$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function2,scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$aggregateByKey$1/PairRDDFunctions$$anonfun$aggregateByKey$1(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object,org.apache.spark.Partitioner,scala.Function2,scala.Function2,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CheckpointRDD/getPartitions()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sorted(scala.math.Ordering)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$3/CheckpointRDD$$anonfun$3(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$2/CheckpointRDD$$anonfun$2(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$1/CheckpointRDD$$anonfun$1(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$getPartitions$1/CheckpointRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/fs()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/checkpointPath()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/splitIdToFile(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/ArrayOps/sorted(scala.math.Ordering)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$3/CheckpointRDD$$anonfun$3(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$2/CheckpointRDD$$anonfun$2(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$1/CheckpointRDD$$anonfun$1(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD$$anonfun$getPartitions$1/CheckpointRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.CheckpointRDD)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/fs()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/checkpointPath()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/listStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/splitIdToFile(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$17/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$17/apply(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToByte(byte)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anonfun$17/apply(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/OrderedRDDFunctions/sortByKey$default$2()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagesTab/isFairScheduler()|",
    "called": "|java+method:///scala/Option/exists(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/listener()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/Option/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$isFairScheduler$1/StagesTab$$anonfun$isFairScheduler$1(org.apache.spark.ui.jobs.StagesTab)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/schedulingMode()|",
      "|java+method:///scala/Option/exists(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$isFairScheduler$1/StagesTab$$anonfun$isFairScheduler$1(org.apache.spark.ui.jobs.StagesTab)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/progressListener()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$28/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/memoryBytesSpilled()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$28$$anonfun$apply$15/StagePage$$anonfun$28$$anonfun$apply$15(org.apache.spark.ui.jobs.StagePage$$anonfun$28)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$28$$anonfun$apply$5/StagePage$$anonfun$28$$anonfun$apply$5(org.apache.spark.ui.jobs.StagePage$$anonfun$28)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerBacklogged$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerBacklogged$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeout()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$schedulerBacklogTimeoutS()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerBacklogged$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/getAncestorShuffleDependencies(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/Stack/isEmpty()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$2(org.apache.spark.rdd.RDD,scala.collection.mutable.Stack,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$2(org.apache.spark.rdd.RDD,scala.collection.mutable.Stack,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/nonEmpty()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/rddInfoToJson(org.apache.spark.storage.RDDInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5/JsonProtocol$$anonfun$rddInfoToJson$5()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/tachyonSize()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6/JsonProtocol$$anonfun$rddInfoToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$7/JsonProtocol$$anonfun$rddInfoToJson$7()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$1/JsonProtocol$$anonfun$rddInfoToJson$1()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelToJson(org.apache.spark.storage.StorageLevel)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$2/JsonProtocol$$anonfun$rddInfoToJson$2()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3/JsonProtocol$$anonfun$rddInfoToJson$3()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4/JsonProtocol$$anonfun$rddInfoToJson$4()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/RDDInfo/numCachedPartitions()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(scala.Tuple2)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5/JsonProtocol$$anonfun$rddInfoToJson$5()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6/JsonProtocol$$anonfun$rddInfoToJson$6()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$7/JsonProtocol$$anonfun$rddInfoToJson$7()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$8/JsonProtocol$$anonfun$rddInfoToJson$8()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/scope()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/diskSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/memSize()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/externalBlockStoreSize()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$40/JsonProtocol$$anonfun$40()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$1/JsonProtocol$$anonfun$rddInfoToJson$1()|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelToJson(org.apache.spark.storage.StorageLevel)|",
      "|java+constructor:///org/json4s/JsonAST$JArray/JsonAST$JArray(scala.collection.immutable.List)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$2/JsonProtocol$$anonfun$rddInfoToJson$2()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/storageLevel()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3/JsonProtocol$$anonfun$rddInfoToJson$3()|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4/JsonProtocol$$anonfun$rddInfoToJson$4()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$9/JsonProtocol$$anonfun$rddInfoToJson$9()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/parentIds()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/numPartitions()|",
      "|java+method:///scala/collection/TraversableOnce/toList()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$5()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$6()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$7/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$7(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$6/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$6(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$5/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$5(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$22/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$22(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$21/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$21(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$19/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$19(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$20/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$20(org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1/apply()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$53/JsonProtocol$$anonfun$53()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/hadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/assertNotStopped()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$28/SparkContext$$anonfun$28(org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SerializableWritable/SerializableWritable(org.apache.hadoop.io.Writable)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+constructor:///org/apache/spark/rdd/HadoopRDD/HadoopRDD(org.apache.spark.SparkContext,org.apache.spark.broadcast.Broadcast,scala.Option,java.lang.Class,java.lang.Class,java.lang.Class,int)|",
      "|java+method:///org/apache/spark/rdd/HadoopRDD/setName(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$hadoopFile$1/SparkContext$$anonfun$hadoopFile$1(org.apache.spark.SparkContext,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/requestTotalExecutors(int)|",
    "called": "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/dynamicAllocationTesting()|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestTotalExecutors$2/SparkContext$$anonfun$requestTotalExecutors$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestTotalExecutors$1/SparkContext$$anonfun$requestTotalExecutors$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/requestTotalExecutors(int)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/master()|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestTotalExecutors$2/SparkContext$$anonfun$requestTotalExecutors$2(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$requestTotalExecutors$1/SparkContext$$anonfun$requestTotalExecutors$1(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/schedulerBackend()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/requestTotalExecutors(int)|",
      "|java+method:///org/apache/spark/SparkContext/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/supportDynamicAllocation()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1/apply$mcV$sp()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askTimeout(org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$2/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$2(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1,org.apache.spark.SparkConf)|",
      "|java+method:///akka/actor/ActorSystem/shutdown()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$3/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$3(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1,org.apache.spark.SparkEnv)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///akka/actor/ActorSystem/actorSelection(java.lang.String)|",
      "|java+method:///scala/collection/Seq/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$1/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$1(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/createExecutorEnv(org.apache.spark.SparkConf,java.lang.String,java.lang.String,int,int,boolean)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost$default$2()|",
      "|java+method:///akka/actor/ActorSystem/awaitTermination()|",
      "|java+method:///akka/pattern/Patterns$/ask(akka.actor.ActorSelection,java.lang.Object,akka.util.Timeout)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/shutdown()|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv$/create(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$5/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$5(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1,org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/stopExecutorDelegationTokenRenewer()|",
      "|java+method:///scala/collection/Seq/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend/CoarseGrainedExecutorBackend(org.apache.spark.rpc.RpcEnv,java.lang.String,java.lang.String,java.lang.String,int,scala.collection.Seq,org.apache.spark.SparkEnv)|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$3/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$3(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$4/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$4(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1,org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/executor/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$2/CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$2(org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/startExecutorDelegationTokenRenewer(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpointRefByURI(java.lang.String)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/SparkEnv$/createExecutorEnv(org.apache.spark.SparkConf,java.lang.String,java.lang.String,int,int,boolean)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/awaitTermination()|",
      "|java+method:///org/apache/spark/executor/CoarseGrainedExecutorBackend$/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost$default$2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$5/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$5/apply(org.apache.hadoop.fs.FileStatus)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$5/apply(org.apache.hadoop.fs.FileStatus%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/stop()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/dagScheduler()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext/dagScheduler_$eq(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/progressBar()|",
      "|java+method:///org/apache/spark/SparkContext/metadataCleaner()|",
      "|java+method:///akka/actor/ActorSystem/stop(akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/SparkContext/eventLogger()|",
      "|java+method:///org/apache/spark/SparkEnv$/set(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/SparkContext/stopped_$eq(boolean)|",
      "|java+method:///org/apache/spark/SparkContext/postApplicationEnd()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stop()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+method:///org/apache/spark/SparkContext/executorAllocationManager()|",
      "|java+method:///org/apache/spark/util/MetadataCleaner/cancel()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/SparkContext/heartbeatReceiver()|",
      "|java+method:///org/apache/spark/SparkContext/taskScheduler_$eq(org.apache.spark.scheduler.TaskScheduler)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$1/SparkContext$$anonfun$stop$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$2/SparkContext$$anonfun$stop$2(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkEnv/stop()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$3/SparkContext$$anonfun$stop$3(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$4/SparkContext$$anonfun$stop$4(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$5/SparkContext$$anonfun$stop$5(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$6/SparkContext$$anonfun$stop$6(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$7/SparkContext$$anonfun$stop$7(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///org/apache/spark/SparkContext/stopped()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+method:///org/apache/spark/SparkContext$/clearActiveContext()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$_env()|",
      "|java+method:///org/apache/spark/SparkContext/_cleaner()|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/stop()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/stop(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+method:///org/apache/spark/SparkContext/metadataCleaner()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/SparkContext/_listenerBusStarted_$eq(boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stop()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/report()|",
      "|java+method:///org/apache/spark/util/MetadataCleaner/cancel()|",
      "|java+method:///org/apache/spark/SparkContext/_executorAllocationManager()|",
      "|java+method:///org/apache/spark/SparkContext/_shutdownHookRef()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$1/SparkContext$$anonfun$stop$1(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$2/SparkContext$$anonfun$stop$2(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkEnv/stop()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$3/SparkContext$$anonfun$stop$3(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$4/SparkContext$$anonfun$stop$4(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$5/SparkContext$$anonfun$stop$5(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$6/SparkContext$$anonfun$stop$6(org.apache.spark.SparkContext)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$stop$7/SparkContext$$anonfun$stop$7(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/SparkContext/_dagScheduler_$eq(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/listenerBus()|",
      "|java+method:///java/util/concurrent/atomic/AtomicBoolean/compareAndSet(boolean,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/stopped()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkEnv$/set(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkContext/_progressBar()|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/SparkContext/_dagScheduler()|",
      "|java+method:///org/apache/spark/SparkContext/_ui()|",
      "|java+method:///org/apache/spark/SparkContext/_eventLogger()|",
      "|java+method:///org/apache/spark/SparkContext/postApplicationEnd()|",
      "|java+method:///org/apache/spark/SparkContext/_taskScheduler_$eq(org.apache.spark.scheduler.TaskScheduler)|",
      "|java+method:///org/apache/spark/SparkContext/_listenerBusStarted()|",
      "|java+method:///org/apache/spark/SparkContext/_heartbeatReceiver()|",
      "|java+method:///org/apache/spark/SparkContext/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext$/clearActiveContext()|",
      "|java+method:///org/apache/spark/util/Utils$/removeShutdownHook(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/groupBy(scala.Function1,org.apache.spark.Partitioner,scala.reflect.ClassTag,scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$groupBy$1/RDD$$anonfun$groupBy$1(org.apache.spark.rdd.RDD,scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/groupByKey(org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$groupBy$3/RDD$$anonfun$groupBy$3(org.apache.spark.rdd.RDD,scala.Function1,org.apache.spark.Partitioner,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$2/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/MapOutputTracker/trackerActor()|",
      "|java+method:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$2/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$2/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker/trackerEndpoint()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$10/AllJobsPage$$anonfun$10(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$25/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25$$anonfun$apply$18/StagePage$$anonfun$25$$anonfun$apply$18(org.apache.spark.ui.jobs.StagePage$$anonfun$25)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25$$anonfun$apply$8/StagePage$$anonfun$25$$anonfun$apply$8(org.apache.spark.ui.jobs.StagePage$$anonfun$25)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25$$anonfun$apply$12/StagePage$$anonfun$25$$anonfun$apply$12(org.apache.spark.ui.jobs.StagePage$$anonfun$25)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$25$$anonfun$apply$2/StagePage$$anonfun$25$$anonfun$apply$2(org.apache.spark.ui.jobs.StagePage$$anonfun$25)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/zip(org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/zipPartitions(org.apache.spark.rdd.RDD,boolean,scala.Function2,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$zip$1/RDD$$anonfun$zip$1(org.apache.spark.rdd.RDD)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$zip$1/RDD$$anonfun$zip$1(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$23/StagePage$$anonfun$23(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/storage/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2/TachyonBlockManager$$anonfun$createTachyonDirs$2$$anonfun$apply$2(org.apache.spark.storage.TachyonBlockManager$$anonfun$createTachyonDirs$2,java.lang.String)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$22/StagePage$$anonfun$22(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/resize$mcD$sp(int)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/_array_$eq(double%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/_array()|",
      "|java+method:///scala/collection/mutable/ArrayOps/copyToArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///scala/reflect/ClassTag/newArray(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/copyArrayWithLength$mcD$sp(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/_array_$eq(double%5B%5D)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements_$eq(int)|",
      "|java+method:///org/apache/spark/util/collection/PrimitiveVector$mcD$sp/org$apache$spark$util$collection$PrimitiveVector$$_numElements()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/persistRDD(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/persistentRdds()|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$persistRDD$1/SparkContext$$anonfun$persistRDD$1(org.apache.spark.SparkContext,org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/persistentRdds()|",
      "|java+method:///org/apache/spark/SparkContext/_executorAllocationManager()|",
      "|java+method:///org/apache/spark/util/TimeStampedWeakValueHashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countApproxDistinctByKey(int,int,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$4/PairRDDFunctions$$anonfun$countApproxDistinctByKey$4(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,org.apache.spark.serializer.Serializer)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$5()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$7/PairRDDFunctions$$anonfun$7(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2(org.apache.spark.rdd.PairRDDFunctions,int)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1(org.apache.spark.rdd.PairRDDFunctions,int)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$5/PairRDDFunctions$$anonfun$5(org.apache.spark.rdd.PairRDDFunctions,int,int)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/combineByKey$default$6()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$6/PairRDDFunctions$$anonfun$6(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$3/PairRDDFunctions$$anonfun$countApproxDistinctByKey$3(org.apache.spark.rdd.PairRDDFunctions,int,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1/PairRDDFunctions$$anonfun$countApproxDistinctByKey$1(org.apache.spark.rdd.PairRDDFunctions,int,int,org.apache.spark.Partitioner)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$foreach$1/RDD$$anonfun$foreach$1(org.apache.spark.rdd.RDD,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/apply$mcV$sp()|",
    "called": "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$11/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$11(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$2/getValue()|",
    "called": "|java+method:///scala/collection/mutable/HashSet/size()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$2/getValue()|",
      "|java+method:///org/apache/spark/deploy/master/MasterSource/master()|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterSource$$anon$2/getValue()|",
      "|java+method:///org/apache/spark/deploy/master/MasterSource/master()|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+constructor:///org/apache/spark/deploy/master/MasterSource$$anon$2$$anonfun$getValue$1/MasterSource$$anon$2$$anonfun$getValue$1(org.apache.spark.deploy.master.MasterSource$$anon$2)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$preStart$1/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$preStart$1/apply()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterUrl()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$masterUrl()|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$preStart$1/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1/apply(org.apache.spark.deploy.history.FsApplicationHistoryInfo)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/ReplayListenerBus/ReplayListenerBus()|",
      "|java+method:///org/apache/spark/SparkConf/clone()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/UI_PATH_PREFIX()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getFileStatus(org.apache.hadoop.fs.Path)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/sparkUser()|",
      "|java+constructor:///org/apache/spark/scheduler/ApplicationEventListener/ApplicationEventListener()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ReplayListenerBus/addListener(java.lang.Object)|",
      "|java+method:///org/apache/spark/SecurityManager/setAdminAcls(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/setViewAcls(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/name()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/viewAcls()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|",
      "|java+method:///org/apache/spark/ui/SparkUI/getSecurityManager()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SecurityManager/setAcls(boolean)|",
      "|java+method:///org/apache/spark/ui/SparkUI$/createHistoryUI(org.apache.spark.SparkConf,org.apache.spark.scheduler.SparkListenerBus,org.apache.spark.SecurityManager,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/logPath()|",
      "|java+method:///org/apache/spark/ui/SparkUI/setAppName(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$replay(org.apache.hadoop.fs.FileStatus,org.apache.spark.scheduler.ReplayListenerBus)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+method:///org/apache/spark/scheduler/ApplicationEventListener/adminAcls()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/List/find(scala.Function1)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/history/FsApplicationHistoryInfo/attempts()|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$3(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkEnv$/create(org.apache.spark.SparkConf,java.lang.String,java.lang.String,int,boolean,boolean,org.apache.spark.scheduler.LiveListenerBus,int,scala.Option)|",
    "called": "|java+method:///scala/Tuple2/_2$mcI$sp()|",
    "v1Body": [
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster/BlockManagerMaster(akka.actor.ActorRef,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/registerOrLookup$1(java.lang.String,scala.Function0,org.apache.spark.SparkConf,boolean,akka.actor.ActorSystem)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$2/SparkEnv$$anonfun$create$2(org.apache.spark.serializer.Serializer)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/HttpFileServer/serverUri()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$1/SparkEnv$$anonfun$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/broadcast/BroadcastManager/BroadcastManager(boolean,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/spark/SparkEnv$/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$4/SparkEnv$$anonfun$create$4()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorActor_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$1/SparkEnv$$anonfun$create$1()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/HttpFileServer/initialize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+constructor:///org/apache/spark/network/nio/NioBlockTransferService/NioBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$2/SparkEnv$$anonfun$2(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker/trackerActor_$eq(akka.actor.ActorRef)|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerMaster/MapOutputTrackerMaster(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerWorker/MapOutputTrackerWorker(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClass$1(java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+constructor:///org/apache/spark/HttpFileServer/HttpFileServer(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager/CacheManager(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$4/SparkEnv$$anonfun$4(org.apache.spark.scheduler.OutputCommitCoordinator)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClassFromConf$1(java.lang.String,java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$3/SparkEnv$$anonfun$3(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$3/SparkEnv$$anonfun$create$3(org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker)|",
      "|java+constructor:///org/apache/spark/SparkEnv/SparkEnv(java.lang.String,akka.actor.ActorSystem,org.apache.spark.serializer.Serializer,org.apache.spark.serializer.Serializer,org.apache.spark.CacheManager,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.broadcast.BroadcastManager,org.apache.spark.network.BlockTransferService,org.apache.spark.storage.BlockManager,org.apache.spark.SecurityManager,org.apache.spark.HttpFileServer,java.lang.String,org.apache.spark.metrics.MetricsSystem,org.apache.spark.shuffle.ShuffleMemoryManager,org.apache.spark.scheduler.OutputCommitCoordinator,org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager/BlockManager(java.lang.String,akka.actor.ActorSystem,org.apache.spark.storage.BlockManagerMaster,org.apache.spark.serializer.Serializer,org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.network.BlockTransferService,org.apache.spark.SecurityManager,int)|",
      "|java+constructor:///org/apache/spark/shuffle/ShuffleMemoryManager/ShuffleMemoryManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService/NettyBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///org/apache/spark/rpc/RpcAddress/port()|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/ExecutorMemoryManager/ExecutorMemoryManager(org.apache.spark.unsafe.memory.MemoryAllocator)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService/NettyBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///org/apache/spark/SparkEnv$/registerOrLookupEndpoint$1(java.lang.String,scala.Function0,org.apache.spark.SparkConf,boolean,org.apache.spark.rpc.RpcEnv)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$2/SparkEnv$$anonfun$2(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/ENDPOINT_NAME()|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$2/SparkEnv$$anonfun$create$2(org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster$/DRIVER_ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/HttpFileServer/serverUri()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$1/SparkEnv$$anonfun$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/broadcast/BroadcastManager/BroadcastManager(boolean,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorRef_$eq(scala.Option)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/spark/SparkEnv$/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$1/SparkEnv$$anonfun$create$1()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/org$apache$spark$SparkEnv$$driverTmpDirToDelete_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/HttpFileServer/initialize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+constructor:///org/apache/spark/network/nio/NioBlockTransferService/NioBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$3/SparkEnv$$anonfun$create$3(org.apache.spark.SparkConf,org.apache.spark.rpc.RpcEnv,org.apache.spark.MapOutputTracker)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerMaster/MapOutputTrackerMaster(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv$/create(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerWorker/MapOutputTrackerWorker(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClass$1(java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///org/apache/spark/MapOutputTracker/trackerEndpoint_$eq(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+constructor:///org/apache/spark/HttpFileServer/HttpFileServer(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager/BlockManager(java.lang.String,org.apache.spark.rpc.RpcEnv,org.apache.spark.storage.BlockManagerMaster,org.apache.spark.serializer.Serializer,org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.network.BlockTransferService,org.apache.spark.SecurityManager,int)|",
      "|java+constructor:///org/apache/spark/CacheManager/CacheManager(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClassFromConf$1(java.lang.String,java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rpc/akka/AkkaRpcEnv/actorSystem()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$3/SparkEnv$$anonfun$3(org.apache.spark.SparkConf,boolean)|",
      "|java+constructor:///org/apache/spark/shuffle/ShuffleMemoryManager/ShuffleMemoryManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkEnv/SparkEnv(java.lang.String,org.apache.spark.rpc.RpcEnv,org.apache.spark.serializer.Serializer,org.apache.spark.serializer.Serializer,org.apache.spark.CacheManager,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.broadcast.BroadcastManager,org.apache.spark.network.BlockTransferService,org.apache.spark.storage.BlockManager,org.apache.spark.SecurityManager,org.apache.spark.HttpFileServer,java.lang.String,org.apache.spark.metrics.MetricsSystem,org.apache.spark.shuffle.ShuffleMemoryManager,org.apache.spark.unsafe.memory.ExecutorMemoryManager,org.apache.spark.scheduler.OutputCommitCoordinator,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/address()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster/BlockManagerMaster(org.apache.spark.rpc.RpcEndpointRef,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$4/SparkEnv$$anonfun$4(org.apache.spark.rpc.RpcEnv,org.apache.spark.scheduler.OutputCommitCoordinator)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stop()|",
    "called": "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverActor()|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///akka/pattern/AskableActorRef$/ask$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stopExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/timeout()|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///scala/concurrent/Await$/ready(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/driverEndpoint()|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stopExecutors()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1/apply$mcV$sp()|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/REGISTRATION_RETRIES()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/registered()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDead(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$2/AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/registrationRetryTimer()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1/org$apache$spark$deploy$client$AppClient$ClientActor$$anonfun$$$outer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/tryRegisterAllMasters()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDead(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$REGISTRATION_RETRIES()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$registered()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$2/AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$registerWithMaster$1$$anonfun$apply$mcV$sp$1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/registrationRetryTimer()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$registerWithMaster$1/org$apache$spark$deploy$client$AppClient$ClientActor$$anonfun$$$outer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$2/getValue()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getActiveCount()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/executor/ExecutorSource/executor()|",
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$2/getValue()|",
      "|java+method:///org/apache/spark/executor/Executor/threadPool()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$2/getValue()|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getActiveCount()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$collectPartitions$1/RDD$$anonfun$collectPartitions$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4/FsHistoryProvider$$anonfun$getAppUI$1$$anonfun$apply$4(org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,akka.actor.ActorSystem)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/Master/Master(java.lang.String,int,int,org.apache.spark.SecurityManager,org.apache.spark.SparkConf)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$1/Master$$anonfun$1(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/STANDBY()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///org/apache/spark/deploy/rest/StandaloneRestServer/StandaloneRestServer(java.lang.String,int,akka.actor.ActorRef,java.lang.String,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/util/ActorLogReceive$class/$init$(org.apache.spark.util.ActorLogReceive)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/master/MasterSource/MasterSource(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServerEnabled()|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterUrl()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///akka/actor/Actor$class/$init$(akka.actor.Actor)|",
      "|java+method:///org/apache/spark/deploy/master/Master/defaultCores()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterWebUI/MasterWebUI(org.apache.spark.deploy.master.Master,int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServer()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/STANDBY()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/rest/StandaloneRestServer/StandaloneRestServer(java.lang.String,int,org.apache.spark.SparkConf,akka.actor.ActorRef,java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil$/get()|",
      "|java+method:///org/apache/spark/util/ActorLogReceive$class/$init$(org.apache.spark.util.ActorLogReceive)|",
      "|java+method:///org/apache/spark/deploy/SparkHadoopUtil/newConfiguration(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$2/Master$$anonfun$2(org.apache.spark.deploy.master.Master)|",
      "|java+constructor:///org/apache/spark/deploy/master/MasterSource/MasterSource(org.apache.spark.deploy.master.Master)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$masterUrl()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServerEnabled()|",
      "|java+method:///org/apache/spark/SparkConf/getLong(java.lang.String,long)|",
      "|java+method:///akka/actor/Actor$class/$init$(akka.actor.Actor)|",
      "|java+method:///org/apache/spark/deploy/master/Master/defaultCores()|",
      "|java+constructor:///org/apache/spark/deploy/master/ui/MasterWebUI/MasterWebUI(org.apache.spark.deploy.master.Master,int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/restServer()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/JsonProtocol$/writeApplicationInfo(org.apache.spark.deploy.master.ApplicationInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///java/util/Date/toString()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/duration()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/startTime()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$3/JsonProtocol$$anonfun$writeApplicationInfo$3()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$8/JsonProtocol$$anonfun$writeApplicationInfo$8()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$1/JsonProtocol$$anonfun$writeApplicationInfo$1()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$6/JsonProtocol$$anonfun$writeApplicationInfo$6()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$4/JsonProtocol$$anonfun$writeApplicationInfo$4()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$9/JsonProtocol$$anonfun$writeApplicationInfo$9()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$2/JsonProtocol$$anonfun$writeApplicationInfo$2()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$7/JsonProtocol$$anonfun$writeApplicationInfo$7()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$5/JsonProtocol$$anonfun$writeApplicationInfo$5()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerSlave()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/submitDate()|",
      "|java+method:///org/json4s/JsonDSL$/pair2jvalue(scala.Tuple2,scala.Function1)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/json4s/JsonDSL$JsonAssoc/$tilde(scala.Tuple2,scala.Function1)|",
      "|java+method:///java/util/Date/toString()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/duration()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+method:///org/json4s/JsonDSL$JsonListAssoc/$tilde(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/memoryPerExecutorMB()|",
      "|java+method:///org/json4s/JsonDSL$/pair2Assoc(scala.Tuple2,scala.Function1)|",
      "|java+method:///org/json4s/JsonDSL$/jobject2assoc(org.json4s.JsonAST$JObject)|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/name()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/user()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/desc()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/startTime()|",
      "|java+method:///org/apache/spark/deploy/ApplicationDescription/maxCores()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$3/JsonProtocol$$anonfun$writeApplicationInfo$3()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$8/JsonProtocol$$anonfun$writeApplicationInfo$8()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$1/JsonProtocol$$anonfun$writeApplicationInfo$1()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$6/JsonProtocol$$anonfun$writeApplicationInfo$6()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$4/JsonProtocol$$anonfun$writeApplicationInfo$4()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$9/JsonProtocol$$anonfun$writeApplicationInfo$9()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$2/JsonProtocol$$anonfun$writeApplicationInfo$2()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$7/JsonProtocol$$anonfun$writeApplicationInfo$7()|",
      "|java+constructor:///org/apache/spark/deploy/JsonProtocol$$anonfun$writeApplicationInfo$5/JsonProtocol$$anonfun$writeApplicationInfo$5()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/doRequestTotalExecutors(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/yarnSchedulerActor()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askWithReply(java.lang.Object,akka.actor.ActorRef,scala.concurrent.duration.FiniteDuration)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RequestExecutors/CoarseGrainedClusterMessages$RequestExecutors(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$askTimeout()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/YarnSchedulerBackend/yarnSchedulerEndpoint()|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RequestExecutors/CoarseGrainedClusterMessages$RequestExecutors(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorSource/org$apache$spark$executor$ExecutorSource$$fileStats(java.lang.String)|",
    "called": "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
    "v1Body": [
      "|java+method:///scala/collection/TraversableLike/headOption()|",
      "|java+method:///scala/collection/mutable/Buffer/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/executor/ExecutorSource$$anonfun$org$apache$spark$executor$ExecutorSource$$fileStats$1/ExecutorSource$$anonfun$org$apache$spark$executor$ExecutorSource$$fileStats$1(org.apache.spark.executor.ExecutorSource,java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getAllStatistics()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/Buffer/find(scala.Function1)|",
      "|java+constructor:///org/apache/spark/executor/ExecutorSource$$anonfun$org$apache$spark$executor$ExecutorSource$$fileStats$1/ExecutorSource$$anonfun$org$apache$spark$executor$ExecutorSource$$fileStats$1(org.apache.spark.executor.ExecutorSource,java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getAllStatistics()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkConf$/SparkConf$()|",
    "called": "|java+method:///scala/collection/Seq$/canBuildFrom()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/SparkConf$DeprecatedConfig/SparkConf$DeprecatedConfig(java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$4/SparkConf$$anonfun$4()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig$/apply$default$4()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/Map()|",
      "|java+constructor:///org/apache/spark/SparkConf$DeprecatedConfig/SparkConf$DeprecatedConfig(java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/SparkConf$AlternateConfig/SparkConf$AlternateConfig(java.lang.String,java.lang.String,scala.Function1)|",
      "|java+method:///scala/collection/Iterable$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/collection/Iterable/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/SparkConf$AlternateConfig$/apply$default$3()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$7/SparkConf$$anonfun$7()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$4/SparkConf$$anonfun$4()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$6/SparkConf$$anonfun$6()|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$5/SparkConf$$anonfun$5()|",
      "|java+method:///org/apache/spark/SparkConf$/org$apache$spark$SparkConf$$configsWithAlternatives()|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/immutable/Map/keys()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/apply(org.apache.spark.deploy.master.DriverInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$7/apply(org.apache.spark.deploy.master.ApplicationInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$6/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$6/apply(scala.Tuple2)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$6/apply(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$onExecutorAdded(java.lang.String)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsPending_$eq(int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$5/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$5(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$3/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$3(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$1/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$1(org.apache.spark.ExecutorAllocationManager)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$2/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$2(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsPending()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$3/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$3(org.apache.spark.ExecutorAllocationManager,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$1/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$1(org.apache.spark.ExecutorAllocationManager)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$2/ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$2(org.apache.spark.ExecutorAllocationManager)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StageTableBase/stageRow(org.apache.spark.scheduler.StageInfo)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDate(java.util.Date)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/numActiveTasks()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/schedulingPool()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/numTasks()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$1/StageTableBase$$anonfun$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$stageRow$2/StageTableBase$$anonfun$stageRow$2(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$stageRow$1/StageTableBase$$anonfun$stageRow$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/completedIndices()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$2/StageTableBase$$anonfun$2(org.apache.spark.ui.jobs.StageTableBase,long)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/size()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteBytes()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/makeProgressBar(int,int,int,int,int)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/makeDescription(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputBytes()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///java/util/Date/Date(long)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$7/StageTableBase$$anonfun$7(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/numFailedTasks()|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$6/StageTableBase$$anonfun$6(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadTotalBytes()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/formatDate(java.util.Date)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/numActiveTasks()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/schedulingPool()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/stageIdToData()|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/missingStageRow(int)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/numTasks()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/attemptId()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$1/StageTableBase$$anonfun$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$stageRow$2/StageTableBase$$anonfun$stageRow$2(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$stageRow$1/StageTableBase$$anonfun$stageRow$1(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/completedIndices()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$2/StageTableBase$$anonfun$2(org.apache.spark.ui.jobs.StageTableBase,long)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet/size()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/inputBytes()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleWriteBytes()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/makeProgressBar(int,int,int,int,int)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/makeDescription(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/outputBytes()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/submissionTime()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/stageId()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///java/util/Date/Date(long)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$7/StageTableBase$$anonfun$7(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/numFailedTasks()|",
      "|java+constructor:///scala/Tuple2$mcII$sp/Tuple2$mcII$sp(int,int)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$6/StageTableBase$$anonfun$6(org.apache.spark.ui.jobs.StageTableBase)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$StageUIData/shuffleReadTotalBytes()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$13/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1/RDD$$anonfun$doCheckpoint$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcV$sp/AbstractFunction0$mcV$sp()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/initialize()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$/DEFAULT_LOG_DIR()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getFileStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/logCheckingThread()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/checkForLogs()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/isDir()|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/pool()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/getFileStatus(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$initialize$2/FsHistoryProvider$$anonfun$initialize$2(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$initialize$1/FsHistoryProvider$$anonfun$initialize$1(org.apache.spark.deploy.history.FsHistoryProvider)|",
      "|java+method:///java/util/concurrent/ScheduledExecutorService/scheduleAtFixedRate(java.lang.Runnable,long,long,java.util.concurrent.TimeUnit)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/getRunner(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider$/DEFAULT_LOG_DIR()|",
      "|java+method:///org/apache/hadoop/fs/FileStatus/isDir()|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/UPDATE_INTERVAL_S()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$logDir()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/CLEAN_INTERVAL_S()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$fs()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/exec/ExecutorThreadDumpPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$render$1/ExecutorThreadDumpPage$$anonfun$render$1(org.apache.spark.ui.exec.ExecutorThreadDumpPage,scala.xml.Node)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$1/ExecutorThreadDumpPage$$anonfun$1(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/getExecutorThreadDump(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$3/ExecutorThreadDumpPage$$anonfun$3(org.apache.spark.ui.exec.ExecutorThreadDumpPage,long)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$2/ExecutorThreadDumpPage$$anonfun$2(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorThreadDumpPage/sc()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$5/ExecutorThreadDumpPage$$anonfun$5(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$render$1/ExecutorThreadDumpPage$$anonfun$render$1(org.apache.spark.ui.exec.ExecutorThreadDumpPage,scala.xml.Node)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$1/ExecutorThreadDumpPage$$anonfun$1(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///org/apache/spark/SparkContext/getExecutorThreadDump(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$3/ExecutorThreadDumpPage$$anonfun$3(org.apache.spark.ui.exec.ExecutorThreadDumpPage,long)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$2/ExecutorThreadDumpPage$$anonfun$2(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorThreadDumpPage/sc()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/ui/exec/ExecutorThreadDumpPage$$anonfun$5/ExecutorThreadDumpPage$$anonfun$5(org.apache.spark.ui.exec.ExecutorThreadDumpPage)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/distinct(int,scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$1/RDD$$anonfun$distinct$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$2/RDD$$anonfun$distinct$2(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$3/RDD$$anonfun$distinct$3(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKey(scala.Function2,int)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$1/RDD$$anonfun$distinct$1(org.apache.spark.rdd.RDD,int,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/executorHeartbeatReceived(java.lang.String,scala.Tuple4%5B%5D,org.apache.spark.storage.BlockManagerId)|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate/SparkListenerExecutorMetricsUpdate(java.lang.String,scala.collection.Seq)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+constructor:///akka/util/Timeout/Timeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///akka/pattern/AskableActorRef$/$qmark$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverActor()|",
      "|java+method:///akka/util/Timeout/duration()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$BlockManagerHeartbeat/BlockManagerMessages$BlockManagerHeartbeat(org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate/SparkListenerExecutorMetricsUpdate(java.lang.String,scala.collection.Seq)|",
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/driverEndpoint()|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.concurrent.duration.FiniteDuration,scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMessages$BlockManagerHeartbeat/BlockManagerMessages$BlockManagerHeartbeat(org.apache.spark.storage.BlockManagerId)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/apply(scala.Tuple2)|",
    "called": "|java+method:///scala/Tuple2/_2$mcI$sp()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/ShuffleCoGroupSplitDep/ShuffleCoGroupSplitDep(org.apache.spark.shuffle.ShuffleHandle)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/rdd/NarrowCoGroupSplitDep/NarrowCoGroupSplitDep(org.apache.spark.rdd.RDD,int,org.apache.spark.Partition)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/dependencies()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1/org$apache$spark$rdd$SubtractedRDD$$anonfun$$$outer()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleHandle()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1/org$apache$spark$rdd$SubtractedRDD$$anonfun$$$outer()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///org/apache/spark/rdd/NarrowCoGroupSplitDep/NarrowCoGroupSplitDep(org.apache.spark.rdd.RDD,int,org.apache.spark.Partition)|",
      "|java+method:///org/apache/spark/rdd/SubtractedRDD/dependencies()|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///scala/collection/Seq/apply(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$86/StagePage$$anonfun$86(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/histogram(int)|",
    "called": "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Tuple2/_2$mcD$sp()|",
      "|java+method:///scala/collection/Seq/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/double2Double(double)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///scala/runtime/RichDouble$/isInfinity$extension(double)|",
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///scala/Predef$/wrapDoubleArray(double%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/customRange$1(double,double,int)|",
      "|java+constructor:///java/lang/UnsupportedOperationException/UnsupportedOperationException(java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/Predef$/doubleWrapper(double)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$4/DoubleRDDFunctions$$anonfun$4(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$3/DoubleRDDFunctions$$anonfun$3(org.apache.spark.rdd.DoubleRDDFunctions)|",
      "|java+method:///org/apache/spark/rdd/DoubleRDDFunctions/histogram(double%5B%5D,boolean)|",
      "|java+method:///java/lang/Double/isNaN()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Tuple2/_1$mcD$sp()|",
      "|java+method:///scala/reflect/ClassTag$/Double()|",
      "|java+method:///scala/collection/immutable/List$/apply(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///scala/Tuple2$mcDD$sp/Tuple2$mcDD$sp(double,double)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$histogram$1/DoubleRDDFunctions$$anonfun$histogram$1(org.apache.spark.rdd.DoubleRDDFunctions,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$59/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$/accumulableInfoFromJson(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/tryRegisterAllMasters()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/client/AppClient/masterAkkaUrls()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$tryRegisterAllMasters$1/AppClient$ClientActor$$anonfun$tryRegisterAllMasters$1(org.apache.spark.deploy.client.AppClient$ClientActor)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$masterAkkaUrls()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$tryRegisterAllMasters$1/AppClient$ClientActor$$anonfun$tryRegisterAllMasters$1(org.apache.spark.deploy.client.AppClient$ClientActor)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StageTableBase$$anonfun$4/apply(org.apache.spark.storage.RDDInfo)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/prependBaseUri$default$2()|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/storage/RDDInfo/id()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,java.lang.String,scala.xml.MetaData)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/RDDInfo/name()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$94/StagePage$$anonfun$94(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/handleJobSubmitted(int,org.apache.spark.rdd.RDD,scala.Function2,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$2/DAGScheduler$$anonfun$handleJobSubmitted$2(org.apache.spark.scheduler.DAGScheduler,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runLocally(org.apache.spark.scheduler.ActiveJob)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobStart/SparkListenerJobStart(int,long,scala.collection.Seq,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/localExecutionEnabled()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$1/DAGScheduler$$anonfun$handleJobSubmitted$1(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$11/DAGScheduler$$anonfun$11(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/clearCacheLocs()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/ActiveJob/ActiveJob(int,org.apache.spark.scheduler.Stage,scala.Function2,int%5B%5D,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/Stage/resultOfJob_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$4/DAGScheduler$$anonfun$handleJobSubmitted$4(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$3/DAGScheduler$$anonfun$handleJobSubmitted$3(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$5/DAGScheduler$$anonfun$handleJobSubmitted$5(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/parents()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newStage(org.apache.spark.rdd.RDD,int,scala.Option,int,org.apache.spark.util.CallSite)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$2/DAGScheduler$$anonfun$handleJobSubmitted$2(org.apache.spark.scheduler.DAGScheduler,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newResultStage(org.apache.spark.rdd.RDD,int,int,org.apache.spark.util.CallSite)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/runLocally(org.apache.spark.scheduler.ActiveJob)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/localExecutionEnabled()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$1/DAGScheduler$$anonfun$handleJobSubmitted$1(org.apache.spark.scheduler.DAGScheduler,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$12/DAGScheduler$$anonfun$12(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/parents()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToActiveJob()|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/List/isEmpty()|",
      "|java+method:///scala/reflect/ClassTag$/Int()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/clearCacheLocs()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/submitWaitingStages()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$submitStage(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/collection/Seq$/empty()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/Predef$/intArrayOps(int%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$4/DAGScheduler$$anonfun$handleJobSubmitted$4(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$3/DAGScheduler$$anonfun$handleJobSubmitted$3(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$handleJobSubmitted$5/DAGScheduler$$anonfun$handleJobSubmitted$5(org.apache.spark.scheduler.DAGScheduler,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/scheduler/ActiveJob/ActiveJob(int,org.apache.spark.scheduler.ResultStage,scala.Function2,int%5B%5D,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobStart/SparkListenerJobStart(int,long,scala.collection.Seq,java.util.Properties)|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/resultOfJob_$eq(scala.Option)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$21/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$21$$anonfun$apply$14/StagePage$$anonfun$21$$anonfun$apply$14(org.apache.spark.ui.jobs.StagePage$$anonfun$21)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$21$$anonfun$apply$4/StagePage$$anonfun$21$$anonfun$apply$4(org.apache.spark.ui.jobs.StagePage$$anonfun$21)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/outputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/resultSerializationTime()|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/getSystemProperties()|",
    "called": "|java+method:///scala/collection/mutable/Set$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///java/util/Properties/stringPropertyNames()|",
      "|java+method:///scala/collection/mutable/Set/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Set/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$8/Utils$$anonfun$8()|",
      "|java+method:///java/lang/System/getProperties()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/Set$/canBuildFrom()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaSet(java.util.Set)|"
    ],
    "v2Body": [
      "|java+method:///java/util/Properties/stringPropertyNames()|",
      "|java+method:///scala/collection/mutable/Set/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Set/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$12/Utils$$anonfun$12()|",
      "|java+method:///java/lang/System/getProperties()|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///scala/collection/mutable/Set$/canBuildFrom()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaSet(java.util.Set)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/SparkSubmitArguments/SparkSubmitArguments(scala.collection.Seq,scala.collection.immutable.Map)|",
    "called": "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/parseOpts(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/validateArguments()|",
      "|java+method:///scala/collection/Seq/toList()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mergeDefaultSparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/loadEnvironmentArguments()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/parse(java.util.List)|",
      "|java+constructor:///org/apache/spark/launcher/SparkSubmitArgumentsParser/SparkSubmitArgumentsParser()|",
      "|java+method:///scala/collection/Seq/toList()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmit$/printErrorAndExit(java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/ignoreNonSparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/validateArguments()|",
      "|java+method:///java/lang/IllegalArgumentException/getMessage()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/mergeDefaultSparkProperties()|",
      "|java+method:///org/apache/spark/deploy/SparkSubmitArguments/loadEnvironmentArguments()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$5/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$5/apply(scala.collection.Seq)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$5/apply(char)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToChar(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$88/StagePage$$anonfun$88(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/DoubleRDDFunctions$$anonfun$stats$1/DoubleRDDFunctions$$anonfun$stats$1(org.apache.spark.rdd.DoubleRDDFunctions)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/getOrCreateLocalRootDirs(org.apache.spark.SparkConf)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getOrCreateLocalRootDirs$2/Utils$$anonfun$getOrCreateLocalRootDirs$2()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$getOrCreateLocalRootDirs$1/Utils$$anonfun$getOrCreateLocalRootDirs$1(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/util/Utils$/getYarnLocalDirs(org.apache.spark.SparkConf)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/util/Utils$/isRunningInYarnContainer(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/flatMap(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkConf/getenv(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/localRootDirs_$eq(java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/util/Utils$/localRootDirs()|",
      "|java+method:///org/apache/spark/util/Utils$/getOrCreateLocalRootDirsImpl(org.apache.spark.SparkConf)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/Aggregator/combineCombinersByKey(scala.collection.Iterator,org.apache.spark.TaskContext)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$/$lessinit$greater$default$5()|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$3/Aggregator$$anonfun$3(org.apache.spark.Aggregator)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/iterator()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///scala/Product2/_1()|",
      "|java+method:///scala/Product2/_2()|",
      "|java+constructor:///org/apache/spark/util/collection/AppendOnlyMap/AppendOnlyMap(int)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap$/$lessinit$greater$default$1()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/insert(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/Aggregator/isSpillEnabled()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap/ExternalAppendOnlyMap(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.serializer.Serializer,org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/iterator()|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/changeValue(java.lang.Object,scala.Function2)|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$2/Aggregator$$anonfun$2(org.apache.spark.Aggregator,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/Aggregator/mergeCombiners()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$/$lessinit$greater$default$4()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$combineCombinersByKey$1/Aggregator$$anonfun$combineCombinersByKey$1(org.apache.spark.Aggregator,org.apache.spark.util.collection.ExternalAppendOnlyMap)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$/$lessinit$greater$default$5()|",
      "|java+method:///scala/collection/Iterator/next()|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$3/Aggregator$$anonfun$3(org.apache.spark.Aggregator)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/iterator()|",
      "|java+method:///scala/collection/Iterator/hasNext()|",
      "|java+method:///scala/Product2/_1()|",
      "|java+constructor:///org/apache/spark/util/collection/AppendOnlyMap/AppendOnlyMap(int)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap$/$lessinit$greater$default$1()|",
      "|java+method:///org/apache/spark/Aggregator/isSpillEnabled()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalAppendOnlyMap/ExternalAppendOnlyMap(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.serializer.Serializer,org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/iterator()|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/changeValue(java.lang.Object,scala.Function2)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/insertAll(scala.collection.Iterator)|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$2/Aggregator$$anonfun$2(org.apache.spark.Aggregator,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/Aggregator/mergeCombiners()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap$/$lessinit$greater$default$4()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/Aggregator$$anonfun$combineCombinersByKey$1/Aggregator$$anonfun$combineCombinersByKey$1(org.apache.spark.Aggregator,org.apache.spark.util.collection.ExternalAppendOnlyMap)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockStatus/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/tachyonSize()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockStatus/diskSize()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/externalBlockStoreSize()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/spark/storage/BlockStatus/storageLevel()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/storage/BlockStatus/memSize()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryPage$$anonfun$6/HistoryPage$$anonfun$6(org.apache.spark.deploy.history.HistoryPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/MapOutputTracker/getServerStatuses(int,int)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/MapOutputTracker/liftedTree1$1()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$4/MapOutputTracker$$anonfun$getServerStatuses$4(org.apache.spark.MapOutputTracker,int)|",
      "|java+method:///org/apache/spark/MapOutputTracker/fetching()|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$1/MapOutputTracker$$anonfun$getServerStatuses$1(org.apache.spark.MapOutputTracker,int)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/MapOutputTracker/mapStatuses()|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$3/MapOutputTracker$$anonfun$getServerStatuses$3(org.apache.spark.MapOutputTracker)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/MapOutputTracker/askTracker(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$2/MapOutputTracker$$anonfun$getServerStatuses$2(org.apache.spark.MapOutputTracker)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/shuffle/MetadataFetchFailedException/MetadataFetchFailedException(int,int,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/org$apache$spark$MapOutputTracker$$convertMapStatuses(int,int,org.apache.spark.scheduler.MapStatus%5B%5D)|",
      "|java+constructor:///org/apache/spark/GetMapOutputStatuses/GetMapOutputStatuses(int)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/deserializeMapStatuses(byte%5B%5D)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/MapOutputTracker/liftedTree1$1()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$4/MapOutputTracker$$anonfun$getServerStatuses$4(org.apache.spark.MapOutputTracker,int)|",
      "|java+method:///org/apache/spark/MapOutputTracker/askTracker(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/MapOutputTracker/fetching()|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$1/MapOutputTracker$$anonfun$getServerStatuses$1(org.apache.spark.MapOutputTracker,int)|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$2/MapOutputTracker$$anonfun$getServerStatuses$2(org.apache.spark.MapOutputTracker)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker/logError(scala.Function0)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///org/apache/spark/MapOutputTracker/mapStatuses()|",
      "|java+constructor:///org/apache/spark/MapOutputTracker$$anonfun$getServerStatuses$3/MapOutputTracker$$anonfun$getServerStatuses$3(org.apache.spark.MapOutputTracker)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/shuffle/MetadataFetchFailedException/MetadataFetchFailedException(int,int,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker/logInfo(scala.Function0)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/org$apache$spark$MapOutputTracker$$convertMapStatuses(int,int,org.apache.spark.scheduler.MapStatus%5B%5D)|",
      "|java+constructor:///org/apache/spark/GetMapOutputStatuses/GetMapOutputStatuses(int)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/deserializeMapStatuses(byte%5B%5D)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$13/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$13/apply(int)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$13/apply(org.apache.spark.scheduler.Stage)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$92/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$92/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$92/apply(org.apache.spark.executor.TaskMetrics)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/completed()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/startTime()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/lastUpdated()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/endTime()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/sparkUser()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/id()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/attempts()|",
      "|java+method:///org/apache/spark/deploy/history/ApplicationHistoryInfo/name()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$16/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/stop(boolean)|",
    "called": "|java+method:///scala/Option$/apply(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/stopping()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/stop()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/mapStatus()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/dep()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/stopping_$eq(boolean)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/removeDataByMap(int,int)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter_$eq(org.apache.spark.util.collection.ExternalSorter)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockResolver/removeDataByMap(int,int)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/shuffle/sort/SortShuffleWriter$$anonfun$stop$1/SortShuffleWriter$$anonfun$stop$1(org.apache.spark.shuffle.sort.SortShuffleWriter,long)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/mapStatus()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/dep()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/stopping()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/stop()|",
      "|java+method:///java/lang/System/nanoTime()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/stopping_$eq(boolean)|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter_$eq(org.apache.spark.util.collection.ExternalSorter)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/jobStartFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/propertiesFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$3/JsonProtocol$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$43/JsonProtocol$$anonfun$43(scala.collection.immutable.List)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$42/JsonProtocol$$anonfun$42()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobStart/SparkListenerJobStart(int,long,scala.collection.Seq,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$41/JsonProtocol$$anonfun$41()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$40/JsonProtocol$$anonfun$40()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/propertiesFromJson(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$3/JsonProtocol$$anonfun$3()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$45/JsonProtocol$$anonfun$45(scala.collection.immutable.List)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$43/JsonProtocol$$anonfun$43()|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$42/JsonProtocol$$anonfun$42()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobStart/SparkListenerJobStart(int,long,scala.collection.Seq,java.util.Properties)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$44/JsonProtocol$$anonfun$44()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD$$anonfun$sample$1/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$sample$1/apply()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToDouble(double)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PartitionwiseSampledRDD/PartitionwiseSampledRDD(org.apache.spark.rdd.RDD,org.apache.spark.util.random.RandomSampler,boolean,long,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$$anonfun$sample$1/apply()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$sample$1$$anonfun$apply$10/RDD$$anonfun$sample$1$$anonfun$apply$10(org.apache.spark.rdd.RDD$$anonfun$sample$1)|",
      "|java+constructor:///org/apache/spark/util/random/BernoulliSampler/BernoulliSampler(double,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/util/random/PoissonSampler/PoissonSampler(double,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$20/AllJobsPage$$anonfun$20(org.apache.spark.ui.jobs.AllJobsPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1/applyOrElse(java.lang.Object,scala.Function1)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Some/x()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/DeployMessages$KillDriverResponse(java.lang.String,boolean,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/DeployMessages$DriverStatusResponse(boolean,scala.Option,scala.Option,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/state()|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/lastHeartbeat_$eq(long)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/id()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$recoveryCompletionTask_$eq(akka.actor.Cancellable)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Set/find(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/driver()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterWebUiUrl()|",
      "|java+constructor:///org/apache/spark/deploy/master/WorkerInfo/WorkerInfo(java.lang.String,java.lang.String,int,int,int,akka.actor.ActorRef,int,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/driverIds()|",
      "|java+method:///org/apache/spark/deploy/master/Master/beginRecovery(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/DeployMessages$MasterStateResponse(java.lang.String,int,scala.Option,org.apache.spark.deploy.master.WorkerInfo%5B%5D,org.apache.spark.deploy.master.ApplicationInfo%5B%5D,org.apache.spark.deploy.master.ApplicationInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D,scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/MasterMessages$BoundPortsResponse(int,int,scala.Option)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/webUi()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/worker()|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/removeExecutor(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/readPersistedData()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+method:///scala/collection/immutable/List/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/drivers()|",
      "|java+method:///org/apache/spark/deploy/master/Master/idToApp()|",
      "|java+method:///org/apache/spark/deploy/master/Master/completeRecovery()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/webUiPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/master/Master/masterUrl()|",
      "|java+method:///org/apache/spark/deploy/master/Master/addressToWorker()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestKillDriver/driverId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/publicAddress()|",
      "|java+method:///scala/collection/Iterable/exists(scala.Function1)|",
      "|java+method:///akka/actor/Scheduler/scheduleOnce(scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterApplication/appDescription()|",
      "|java+method:///org/apache/spark/deploy/master/Master/timeOutDeadWorkers()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/master/Master/createApplication(org.apache.spark.deploy.ApplicationDescription,akka.actor.ActorRef)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/context()|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$27/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$27(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/DeployMessages$SubmitDriverResponse(boolean,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+method:///org/apache/spark/deploy/master/Master/addressToApp()|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ReconnectWorker/DeployMessages$ReconnectWorker(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisterWorkerFailed/DeployMessages$RegisterWorkerFailed(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/state()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/master/Master/idToWorker()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$3/Master$$anonfun$receiveWithLogging$1$$anonfun$3(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/execId()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/application()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$5/Master$$anonfun$receiveWithLogging$1$$anonfun$5(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,int)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/WAITING()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/ALIVE()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/STANDBY()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$6/Master$$anonfun$receiveWithLogging$1$$anonfun$6(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/sender()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$28/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$28(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/removeExecutor(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$29/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$29(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/driverId()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/RUNNING()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$4/Master$$anonfun$receiveWithLogging$1$$anonfun$4(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///akka/actor/ActorPath/address()|",
      "|java+method:///scala/collection/mutable/HashSet$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addWorker(org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+method:///scala/collection/mutable/HashSet/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String,int,int,int)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String,int)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/resetRetryCount()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/exitStatus()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/incrementRetryCount()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/id()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/RECOVERING()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/DeployMessages$RegisteredWorker(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/registerWorker(org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/cores()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/DeployMessages$ExecutorUpdated(int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/executors()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+method:///org/apache/spark/deploy/master/Master/createDriver(org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///scala/collection/mutable/HashSet/find(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChangeAcknowledged/appId()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$26/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$26(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/MAX_NUM_RETRY()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/DeployMessages$RegisteredApplication(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/removeApplication(org.apache.spark.deploy.master.ApplicationInfo,scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestDriverStatus/driverId()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/worker()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/registerApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$schedule()|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/memory()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerState$/ALIVE()|",
      "|java+method:///org/apache/spark/deploy/master/Master/waitingDrivers()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/exception()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/port()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$Heartbeat/workerId()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/Master/completedApps()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/Master/completedDrivers()|",
      "|java+method:///org/apache/spark/deploy/master/Master/canCompleteRecovery()|",
      "|java+method:///org/apache/spark/deploy/master/Master/WORKER_TIMEOUT()|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/message()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/actor()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addDriver(org.apache.spark.deploy.master.DriverInfo)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/Master/removeDriver(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/Master/persistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestSubmitDriver/driverDescription()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$restServerBoundPort()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/id()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/exception()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/host()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Some/x()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$KillDriverResponse/DeployMessages$KillDriverResponse(java.lang.String,boolean,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$completedDrivers()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStatusResponse/DeployMessages$DriverStatusResponse(boolean,scala.Option,scala.Option,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$WORKER_TIMEOUT()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/state()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$drivers()|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/lastHeartbeat_$eq(long)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/id()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$recoveryCompletionTask_$eq(akka.actor.Cancellable)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$plus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Set/find(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/driver()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$24(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$25(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$addressToWorker()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$MasterStateResponse/DeployMessages$MasterStateResponse(java.lang.String,int,scala.Option,org.apache.spark.deploy.master.WorkerInfo%5B%5D,org.apache.spark.deploy.master.ApplicationInfo%5B%5D,org.apache.spark.deploy.master.ApplicationInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D,org.apache.spark.deploy.master.DriverInfo%5B%5D,scala.Enumeration$Value)|",
      "|java+constructor:///org/apache/spark/deploy/master/WorkerInfo/WorkerInfo(java.lang.String,java.lang.String,int,int,int,akka.actor.ActorRef,int,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/driverIds()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$masterUrl()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/MasterMessages$BoundPortsResponse/MasterMessages$BoundPortsResponse(int,int,scala.Option)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterWebUI/boundPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$8(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/DeployMessages$DriverStateChanged(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/worker()|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$createApplication(org.apache.spark.deploy.ApplicationDescription,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/removeExecutor(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+method:///org/apache/spark/deploy/master/Master/self()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/readPersistedData()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$9(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$state()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$16(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/Master/idToApp()|",
      "|java+method:///akka/actor/ActorRef/path()|",
      "|java+method:///scala/collection/immutable/List/filter(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/webUiPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logInfo(scala.Function0)|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$13(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$masterWebUiUrl()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestKillDriver/driverId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/publicAddress()|",
      "|java+method:///scala/collection/Iterable/exists(scala.Function1)|",
      "|java+method:///akka/actor/Scheduler/scheduleOnce(scala.concurrent.duration.FiniteDuration,akka.actor.ActorRef,java.lang.Object,scala.concurrent.ExecutionContext,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterApplication/appDescription()|",
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$UnregisterApplication/appId()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/immutable/List/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/context()|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$14(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$SubmitDriverResponse/DeployMessages$SubmitDriverResponse(boolean,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/apps()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$29/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$29(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$6/Master$$anonfun$receiveWithLogging$1$$anonfun$6(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,int)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$12(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.ApplicationDescription)|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$7/Master$$anonfun$receiveWithLogging$1$$anonfun$7(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ReconnectWorker/DeployMessages$ReconnectWorker(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///akka/actor/ActorContext/dispatcher()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$registerWorker(org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisterWorkerFailed/DeployMessages$RegisterWorkerFailed(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$completeRecovery()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/execId()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/application()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$createDriver(org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/WAITING()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/ALIVE()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/STANDBY()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$15(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/sender()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$28/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$28(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$18(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$30/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$30(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$31/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$31(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/removeExecutor(org.apache.spark.deploy.master.ExecutorDesc)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$11(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$10(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashSet/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/HashMap/values()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/driverId()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/RUNNING()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$4/Master$$anonfun$receiveWithLogging$1$$anonfun$4(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///akka/actor/ActorPath/address()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$timeOutDeadWorkers()|",
      "|java+method:///scala/collection/mutable/HashSet$/canBuildFrom()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addWorker(org.apache.spark.deploy.master.WorkerInfo)|",
      "|java+method:///scala/collection/mutable/HashSet/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String,int,int,int)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$17(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String,int)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$registerApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+method:///org/apache/spark/deploy/master/Master/workers()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$addressToApp()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/resetRetryCount()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$5/Master$$anonfun$receiveWithLogging$1$$anonfun$5(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/exitStatus()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/incrementRetryCount()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/id()|",
      "|java+method:///org/apache/spark/deploy/master/RecoveryState$/RECOVERING()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisteredWorker/DeployMessages$RegisteredWorker(java.lang.String,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/cores()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$completedApps()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/DeployMessages$ExecutorUpdated(int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FINISHED()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/executors()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$23(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$22(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addApplication(org.apache.spark.deploy.master.ApplicationInfo)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$21(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$19(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$canCompleteRecovery()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$27/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$27(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/find(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$idToWorker()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChangeAcknowledged/appId()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$26/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$26(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationState$/MAX_NUM_RETRY()|",
      "|java+method:///org/apache/spark/util/Utils$/BACKUP_STANDALONE_MASTER_PREFIX()|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/id()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/DeployMessages$RegisteredApplication(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/master/Master/removeApplication(org.apache.spark.deploy.master.ApplicationInfo,scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestDriverStatus/driverId()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/worker()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/isFinished()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$removeDriver(java.lang.String,scala.Enumeration$Value,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$persistenceEngine()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$schedule()|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/millis()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/memory()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerState$/ALIVE()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/exception()|",
      "|java+method:///org/apache/spark/deploy/master/Master/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/port()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$Heartbeat/workerId()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$DriverStateChanged/state()|",
      "|java+method:///org/apache/spark/deploy/master/ExecutorDesc/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/message()|",
      "|java+method:///org/apache/spark/deploy/master/WorkerInfo/actor()|",
      "|java+method:///org/apache/spark/deploy/master/PersistenceEngine/addDriver(org.apache.spark.deploy.master.DriverInfo)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/executors()|",
      "|java+method:///scala/collection/mutable/HashSet/add(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/ApplicationInfo/state_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/ERROR()|",
      "|java+constructor:///org/apache/spark/deploy/master/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/Master$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.master.Master$$anonfun$receiveWithLogging$1,org.apache.spark.deploy.DriverDescription)|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$beginRecovery(scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RequestSubmitDriver/driverDescription()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$restServerBoundPort()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$waitingDrivers()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/FAILED()|",
      "|java+method:///org/apache/spark/deploy/master/DriverState$/KILLED()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$WorkerSchedulerStateResponse/id()|",
      "|java+method:///org/apache/spark/deploy/master/Master/org$apache$spark$deploy$master$Master$$webUi()|",
      "|java+method:///org/apache/spark/deploy/master/DriverInfo/exception()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisterWorker/host()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/canCommit(int,long,long)|",
    "called": "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/logError(scala.Function0)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/timeout()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/maxAttempts()|",
      "|java+constructor:///org/apache/spark/scheduler/AskPermissionToCommitOutput/AskPermissionToCommitOutput(int,long,long)|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/askWithReply(java.lang.Object,akka.actor.ActorRef,int,int,scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorActor()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/retryInterval()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/OutputCommitCoordinator$$anonfun$canCommit$1/OutputCommitCoordinator$$anonfun$canCommit$1(org.apache.spark.scheduler.OutputCommitCoordinator)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/logError(scala.Function0)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rpc/RpcEndpointRef/askWithRetry(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorRef()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/AskPermissionToCommitOutput/AskPermissionToCommitOutput(int,long,long)|",
      "|java+method:///scala/reflect/ClassTag$/Boolean()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/OutputCommitCoordinator$$anonfun$canCommit$1/OutputCommitCoordinator$$anonfun$canCommit$1(org.apache.spark.scheduler.OutputCommitCoordinator)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/SubtractedRDD/getPartitions()|",
    "called": "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/Partitioner/numPartitions()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1/SubtractedRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.SubtractedRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/Partitioner/numPartitions()|",
      "|java+method:///scala/collection/immutable/Range/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/SubtractedRDD$$anonfun$getPartitions$1/SubtractedRDD$$anonfun$getPartitions$1(org.apache.spark.rdd.SubtractedRDD,org.apache.spark.Partition%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$7/apply(org.apache.spark.SparkStageInfo)|",
    "called": "|java+method:///scala/collection/immutable/StringOps/size()|",
    "v1Body": [
      "|java+method:///scala/collection/immutable/StringOps/size()|",
      "|java+method:///org/apache/spark/SparkStageInfo/numCompletedTasks()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$7$$anonfun$8/ConsoleProgressBar$$anonfun$7$$anonfun$8(org.apache.spark.ui.ConsoleProgressBar$$anonfun$7,int)|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkStageInfo/numActiveTasks()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkStageInfo/stageId()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkStageInfo/numTasks()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/spark/SparkStageInfo/numCompletedTasks()|",
      "|java+constructor:///org/apache/spark/ui/ConsoleProgressBar$$anonfun$7$$anonfun$8/ConsoleProgressBar$$anonfun$7$$anonfun$8(org.apache.spark.ui.ConsoleProgressBar$$anonfun$7,int)|",
      "|java+method:///scala/collection/TraversableOnce/mkString(java.lang.String)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkStageInfo/numActiveTasks()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkStageInfo/numTasks()|",
      "|java+method:///org/apache/spark/SparkStageInfo/stageId()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/JobPage/render(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$1/JobPage$$anonfun$render$1(org.apache.spark.ui.jobs.JobPage)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/status()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/jobIdToData()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$4/JobPage$$anonfun$render$4(org.apache.spark.ui.jobs.JobPage,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/ui/jobs/FailedStageTable/toNodeSeq()|",
      "|java+method:///scala/collection/mutable/Buffer/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$5/JobPage$$anonfun$5(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/FailedStageTable/FailedStageTable(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$4/JobPage$$anonfun$4(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$1/JobPage$$anonfun$1(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$3/JobPage$$anonfun$3(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$2/JobPage$$anonfun$2(org.apache.spark.ui.jobs.JobPage)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/listener()|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/killEnabled()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/basePath()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/JobPage/org$apache$spark$ui$jobs$JobPage$$listener()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobGroup()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/isFairScheduler()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$2/JobPage$$anonfun$render$2(org.apache.spark.ui.jobs.JobPage,scala.xml.Elem)|",
      "|java+method:///scala/collection/mutable/Buffer$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$3/JobPage$$anonfun$render$3(org.apache.spark.ui.jobs.JobPage,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer)|",
      "|java+method:///scala/collection/mutable/Buffer/size()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$1/JobPage$$anonfun$render$1(org.apache.spark.ui.jobs.JobPage)|",
      "|java+method:///scala/math/Ordering$/Option(scala.math.Ordering)|",
      "|java+method:///scala/xml/Elem/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/operationGraphListener()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/ui/jobs/StageTableBase/toNodeSeq()|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/status()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/jobIdToData()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$4/JobPage$$anonfun$render$4(org.apache.spark.ui.jobs.JobPage,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/ui/jobs/FailedStageTable/toNodeSeq()|",
      "|java+method:///scala/collection/mutable/Buffer/sortBy(scala.Function1,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/jobProgresslistener()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$5/JobPage$$anonfun$5(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/FailedStageTable/FailedStageTable(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$7/JobPage$$anonfun$7(org.apache.spark.ui.jobs.JobPage)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$6/JobPage$$anonfun$6(org.apache.spark.ui.jobs.JobPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$8/JobPage$$anonfun$8(org.apache.spark.ui.jobs.JobPage)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/killEnabled()|",
      "|java+constructor:///org/apache/spark/ui/jobs/StageTableBase/StageTableBase(scala.collection.Seq,java.lang.String,org.apache.spark.ui.jobs.JobProgressListener,boolean,boolean)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/stageIds()|",
      "|java+method:///scala/collection/mutable/Buffer/$plus$plus(scala.collection.GenTraversableOnce)|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/basePath()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/showDagVizForJob(int,scala.collection.Seq)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/xml/NodeSeq$/canBuildFrom()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage(java.lang.String,scala.Function0,org.apache.spark.ui.SparkUITab,scala.Option,scala.Option,boolean)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$4/JobPage$$anonfun$4(org.apache.spark.ui.jobs.JobPage,org.apache.spark.ui.jobs.JobProgressListener)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$JobUIData/jobGroup()|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$4()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/isFairScheduler()|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$5()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/startTime()|",
      "|java+method:///org/apache/spark/ui/UIUtils$/headerSparkPage$default$6()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$2/JobPage$$anonfun$render$2(org.apache.spark.ui.jobs.JobPage,scala.xml.Elem)|",
      "|java+method:///scala/collection/mutable/Buffer$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/exec/ExecutorsListener/executorIdToData()|",
      "|java+method:///scala/xml/NodeSeq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer/nonEmpty()|",
      "|java+constructor:///org/apache/spark/ui/jobs/JobPage$$anonfun$render$3/JobPage$$anonfun$render$3(org.apache.spark.ui.jobs.JobPage,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer,scala.collection.mutable.Buffer)|",
      "|java+method:///scala/collection/mutable/Buffer/size()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/executorListener()|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/scope/RDDOperationGraphListener/getOperationGraphForJob(int)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/SeqLike/reverse()|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/immutable/StringOps/nonEmpty()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/ui/jobs/JobPage/makeTimeline(scala.collection.Seq,scala.collection.mutable.HashMap,long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/flatMapValues(scala.Function1)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+constructor:///org/apache/spark/rdd/MapPartitionsRDD/MapPartitionsRDD(org.apache.spark.rdd.RDD,scala.Function3,boolean,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$flatMapValues$1/PairRDDFunctions$$anonfun$flatMapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$flatMapValues$1/PairRDDFunctions$$anonfun$flatMapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/accumulator(java.lang.Object,java.lang.String,org.apache.spark.AccumulatorParam)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/Accumulator/Accumulator(java.lang.Object,org.apache.spark.AccumulatorParam,scala.Option)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/Accumulator/Accumulator(java.lang.Object,org.apache.spark.AccumulatorParam,scala.Option)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$accumulator$2/SparkContext$$anonfun$accumulator$2(org.apache.spark.SparkContext,org.apache.spark.Accumulator)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/storageLevelFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/apply(boolean,boolean,boolean,boolean,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Boolean()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|"
    ],
    "v2Body": [
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/JsonAST$JValue/toSome()|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/apply(boolean,boolean,boolean,boolean,int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Boolean()|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$70/JsonProtocol$$anonfun$70(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/reflect/ManifestFactory$/Int()|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/ExternalSorter$$anonfun$spillToPartitionFiles$1/apply()|",
    "called": "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$$anonfun$spillToPartitionFiles$1/apply()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$ser()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$fileBufferSize()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/open()|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.Serializer,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$curWriteMetrics()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/createTempShuffleBlock()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$serInstance()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$blockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter$$anonfun$spillToPartitionFiles$1/apply()|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/storage/BlockObjectWriter/open()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/getDiskWriter(org.apache.spark.storage.BlockId,java.io.File,org.apache.spark.serializer.SerializerInstance,int,org.apache.spark.executor.ShuffleWriteMetrics)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$diskBlockManager()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$fileBufferSize()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/org$apache$spark$util$collection$ExternalSorter$$curWriteMetrics()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/createTempShuffleBlock()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$3/apply$mcV$sp()|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addMasters(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/createClient()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addMasters(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay(scala.concurrent.duration.Duration)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$createClient()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/shuffleDebugString$1(org.apache.spark.rdd.RDD,java.lang.String,boolean)|",
    "called": "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/spark/rdd/RDD/debugChildren$1(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///java/lang/String/replaceAll(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$shuffleDebugString$1$1/RDD$$anonfun$shuffleDebugString$1$1(org.apache.spark.rdd.RDD,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/debugSelf$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///org/apache/spark/rdd/RDD/debugChildren$1(org.apache.spark.rdd.RDD,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///java/lang/String/replaceAll(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$shuffleDebugString$1$1/RDD$$anonfun$shuffleDebugString$1$1(org.apache.spark.rdd.RDD,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/debugSelf$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/immutable/StringOps/$times(int)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$3/getValue()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$3/getValue()|",
      "|java+method:///org/apache/spark/executor/Executor/threadPool()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getCompletedTaskCount()|",
      "|java+method:///org/apache/spark/executor/ExecutorSource/executor()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$3/getValue()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getCompletedTaskCount()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/hasRootAsShutdownDeleteDir(tachyon.client.TachyonFile)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$hasRootAsShutdownDeleteDir$2/Utils$$anonfun$hasRootAsShutdownDeleteDir$2(tachyon.client.TachyonFile)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$2/Utils$$anonfun$2(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFile/getPath()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/collection/mutable/HashSet/exists(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/shutdownDeleteTachyonPaths()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/Utils$/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$hasRootAsShutdownDeleteDir$2/Utils$$anonfun$hasRootAsShutdownDeleteDir$2(tachyon.client.TachyonFile)|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$3/Utils$$anonfun$3(java.lang.String)|",
      "|java+method:///tachyon/client/TachyonFile/getPath()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/collection/mutable/HashSet/exists(scala.Function1)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/shutdownDeleteTachyonPaths()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/saveAsObjectFile(java.lang.String)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/saveAsSequenceFile$default$2()|",
      "|java+method:///org/apache/spark/rdd/SequenceFileRDDFunctions/saveAsSequenceFile(java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,org.apache.spark.WritableFactory,org.apache.spark.WritableFactory)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$37/RDD$$anonfun$37(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$38/RDD$$anonfun$38(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/WritableFactory$/writableWritableFactory(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$saveAsObjectFile$1/RDD$$anonfun$saveAsObjectFile$1(org.apache.spark.rdd.RDD,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/getListing()|",
    "called": "|java+method:///scala/collection/mutable/LinkedHashMap/values()|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/LinkedHashMap/values()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/applications()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/LinkedHashMap/values()|",
      "|java+method:///org/apache/spark/deploy/history/FsHistoryProvider/org$apache$spark$deploy$history$FsHistoryProvider$$applications()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/util/Utils$/Utils$()|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Runtime/getRuntime()|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+method:///java/lang/Runtime/addShutdownHook(java.lang.Thread)|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///org/spark-project/guava/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anon$4/Utils$$anon$4()|"
    ],
    "v2Body": [
      "|java+method:///scala/sys/package$/env()|",
      "|java+method:///org/apache/spark/util/SparkShutdownHookManager/install()|",
      "|java+constructor:///java/util/concurrent/ConcurrentHashMap/ConcurrentHashMap()|",
      "|java+constructor:///java/util/Random/Random()|",
      "|java+method:///scala/collection/immutable/Map/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/addShutdownHook(int,scala.Function0)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/shutdownHooks()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/spark/util/Utils$/TEMP_DIR_SHUTDOWN_PRIORITY()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/util/Utils$$anonfun$1/Utils$$anonfun$1()|",
      "|java+constructor:///org/apache/spark/util/SparkShutdownHookManager/SparkShutdownHookManager()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2/apply(org.apache.spark.CleanupTask)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1/org$apache$spark$ContextCleaner$$anonfun$$$outer()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupRDD(int,boolean)|",
      "|java+method:///org/apache/spark/CleanBroadcast/broadcastId()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupBroadcast(long,boolean)|",
      "|java+method:///org/apache/spark/CleanRDD/rddId()|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$blockOnCleanupTasks()|",
      "|java+method:///org/apache/spark/ContextCleaner/logDebug(scala.Function0)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$blockOnShuffleCleanupTasks()|",
      "|java+method:///org/apache/spark/CleanShuffle/shuffleId()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupShuffle(int,boolean)|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$referenceBuffer()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2$$anonfun$apply$1/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2$$anonfun$apply$1(org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2,org.apache.spark.CleanupTask)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupRDD(int,boolean)|",
      "|java+method:///org/apache/spark/CleanBroadcast/broadcastId()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupBroadcast(long,boolean)|",
      "|java+method:///org/apache/spark/CleanRDD/rddId()|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$blockOnCleanupTasks()|",
      "|java+method:///org/apache/spark/ContextCleaner/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanCheckpoint(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$blockOnShuffleCleanupTasks()|",
      "|java+method:///org/apache/spark/CleanShuffle/shuffleId()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupShuffle(int,boolean)|",
      "|java+method:///org/apache/spark/CleanCheckpoint/rddId()|",
      "|java+method:///org/apache/spark/CleanAccum/accId()|",
      "|java+method:///org/apache/spark/ContextCleaner/org$apache$spark$ContextCleaner$$referenceBuffer()|",
      "|java+method:///org/apache/spark/ContextCleaner/doCleanupAccum(long,boolean)|",
      "|java+method:///org/apache/spark/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1/org$apache$spark$ContextCleaner$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/$minus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2$$anonfun$apply$1/ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2$$anonfun$apply$1(org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2,org.apache.spark.CleanupTask)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$67/StagePage$$anonfun$67(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/ClientActor$$anonfun$1/apply(java.lang.String)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///akka/actor/ActorContext/system()|",
      "|java+method:///akka/actor/ActorContext/actorSelection(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/ClientActor/context()|",
      "|java+method:///org/apache/spark/deploy/master/Master$/toAkkaUrl(java.lang.String,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/write(scala.collection.Iterator)|",
    "called": "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/shuffleServerId()|",
      "|java+method:///org/apache/spark/ShuffleDependency/serializer()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter/ExternalSorter(scala.Option,scala.Option,scala.Option,scala.Option)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/getDataFile(int,int)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/writePartitionedFile(org.apache.spark.storage.BlockId,org.apache.spark.TaskContext,java.io.File)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/blockManager()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/mapStatus_$eq(org.apache.spark.scheduler.MapStatus)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/dep()|",
      "|java+method:///org/apache/spark/ShuffleDependency/keyOrdering()|",
      "|java+method:///org/apache/spark/scheduler/MapStatus$/apply(org.apache.spark.storage.BlockManagerId,long%5B%5D)|",
      "|java+method:///org/apache/spark/ShuffleDependency/aggregator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/insertAll(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter()|",
      "|java+method:///org/apache/spark/ShuffleDependency/mapSideCombine()|",
      "|java+constructor:///org/apache/spark/shuffle/sort/SortShuffleWriter$$anonfun$write$1/SortShuffleWriter$$anonfun$write$1(org.apache.spark.shuffle.sort.SortShuffleWriter)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/writeIndexFile(int,int,long%5B%5D)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter_$eq(org.apache.spark.util.collection.ExternalSorter)|",
      "|java+method:///org/apache/spark/ShuffleDependency/partitioner()|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockManager/consolidateId(int,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/shuffleServerId()|",
      "|java+method:///org/apache/spark/ShuffleDependency/serializer()|",
      "|java+constructor:///org/apache/spark/util/collection/ExternalSorter/ExternalSorter(scala.Option,scala.Option,scala.Option,scala.Option)|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/storage/ShuffleBlockId/ShuffleBlockId(int,int,int)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/blockManager()|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/mapStatus_$eq(org.apache.spark.scheduler.MapStatus)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockResolver/writeIndexFile(int,int,long%5B%5D)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/dep()|",
      "|java+method:///org/apache/spark/ShuffleDependency/keyOrdering()|",
      "|java+method:///org/apache/spark/ShuffleDependency/partitioner()|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockResolver/getDataFile(int,int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/writePartitionedFile(org.apache.spark.storage.BlockId,org.apache.spark.TaskContext,java.io.File)|",
      "|java+method:///org/apache/spark/shuffle/IndexShuffleBlockResolver$/NOOP_REDUCE_ID()|",
      "|java+method:///org/apache/spark/scheduler/MapStatus$/apply(org.apache.spark.storage.BlockManagerId,long%5B%5D)|",
      "|java+method:///org/apache/spark/ShuffleDependency/aggregator()|",
      "|java+method:///org/apache/spark/util/collection/ExternalSorter/insertAll(scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter()|",
      "|java+method:///org/apache/spark/ShuffleDependency/mapSideCombine()|",
      "|java+constructor:///org/apache/spark/shuffle/sort/SortShuffleWriter$$anonfun$write$1/SortShuffleWriter$$anonfun$write$1(org.apache.spark.shuffle.sort.SortShuffleWriter)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/shuffle/sort/SortShuffleWriter/sorter_$eq(org.apache.spark.util.collection.ExternalSorter)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage/AllJobsPage(org.apache.spark.ui.jobs.JobsTab)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/sc()|",
      "|java+method:///org/apache/spark/ui/jobs/JobsTab/listener()|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$3/AllJobsPage$$anonfun$3(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/WebUIPage/WebUIPage(java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/$scope()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/xml/Elem/toString()|",
      "|java+constructor:///org/apache/spark/ui/WebUIPage/WebUIPage(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/xml/Text/Text(java.lang.String)|",
      "|java+method:///scala/xml/NodeBuffer/$amp$plus(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///scala/xml/UnprefixedAttribute/UnprefixedAttribute(java.lang.String,scala.collection.Seq,scala.xml.MetaData)|",
      "|java+method:///scala/collection/immutable/StringOps/filter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$5/AllJobsPage$$anonfun$5(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///org/apache/spark/ui/jobs/AllJobsPage$$anonfun$4/AllJobsPage$$anonfun$4(org.apache.spark.ui.jobs.AllJobsPage)|",
      "|java+constructor:///scala/xml/Elem/Elem(java.lang.String,java.lang.String,scala.xml.MetaData,scala.xml.NamespaceBinding,boolean,scala.collection.Seq)|",
      "|java+constructor:///scala/xml/NodeBuffer/NodeBuffer()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/countByValueApprox(long,double,scala.math.Ordering)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$32/RDD$$anonfun$32(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/elementClassTag()|",
      "|java+method:///org/apache/spark/SparkContext/runApproximateJob(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/partial/GroupedCountEvaluator/GroupedCountEvaluator(int,double,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|",
      "|java+method:///scala/reflect/ClassTag/runtimeClass()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$countByValueApprox$1/RDD$$anonfun$countByValueApprox$1(org.apache.spark.rdd.RDD,long,double)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anon$13$$anonfun$run$19/apply(org.apache.spark.network.nio.ConnectionManager$MessageStatus)|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$8/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$8(org.apache.spark.network.nio.ConnectionManager$$anon$13$$anonfun$run$19)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$7/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$7(org.apache.spark.network.nio.ConnectionManager$$anon$13$$anonfun$run$19)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$ackTimeout()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/ref/WeakReference/get()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anon$13/org$apache$spark$network$nio$ConnectionManager$$anon$$$outer()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/concurrent/Promise/tryFailure(java.lang.Throwable)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$8/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$8(org.apache.spark.network.nio.ConnectionManager$$anon$13$$anonfun$run$19)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$7/ConnectionManager$$anon$13$$anonfun$run$19$$anonfun$apply$7(org.apache.spark.network.nio.ConnectionManager$$anon$13$$anonfun$run$19)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$ackTimeout()|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///java/lang/ref/WeakReference/get()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager$$anon$13/org$apache$spark$network$nio$ConnectionManager$$anon$$$outer()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/concurrent/Promise/tryFailure(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/ApplicationHistoryInfo$/ApplicationHistoryInfo$()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction7/AbstractFunction7()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction7/AbstractFunction7()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/reduceByKeyLocally(scala.Function2)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDD/reduce(scala.Function2)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$4/PairRDDFunctions$$anonfun$4(org.apache.spark.rdd.PairRDDFunctions,scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$3/PairRDDFunctions$$anonfun$3(org.apache.spark.rdd.PairRDDFunctions,scala.Function2)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/isArray()|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions(scala.Function1,boolean,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///scala/collection/JavaConversions$/mapAsScalaMap(java.util.Map)|",
      "|java+method:///org/apache/spark/rdd/RDD/mapPartitions$default$2()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$reduceByKeyLocally$1/PairRDDFunctions$$anonfun$reduceByKeyLocally$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function2)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/aggregate(java.lang.Object,scala.Function2,scala.Function2,scala.reflect.ClassTag)|",
    "called": "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/clean(java.lang.Object,boolean)|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.Function2,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/clean$default$2()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$26/RDD$$anonfun$26(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2,scala.Function2)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$27/RDD$$anonfun$27(org.apache.spark.rdd.RDD,scala.Function2,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/util/Utils$/clone(java.lang.Object,org.apache.spark.serializer.SerializerInstance,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/sc()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$aggregate$1/RDD$$anonfun$aggregate$1(org.apache.spark.rdd.RDD,java.lang.Object,scala.Function2,scala.Function2,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$55/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ExecutorAllocationManager/addExecutors(int)|",
    "called": "|java+method:///scala/math/package$/min(int,int)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$2/ExecutorAllocationManager$$anonfun$addExecutors$2(org.apache.spark.ExecutorAllocationManager,int,int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/targetNumExecutors()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/numExecutorsToAdd()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/testing()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/numExecutorsToAdd_$eq(int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$1/ExecutorAllocationManager$$anonfun$addExecutors$1(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$3/ExecutorAllocationManager$$anonfun$addExecutors$3(org.apache.spark.ExecutorAllocationManager,int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/updateNumExecutorsPending(int)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationClient/requestTotalExecutors(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsTarget()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/testing()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logDebug(scala.Function0)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsToAdd_$eq(int)|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$2/ExecutorAllocationManager$$anonfun$addExecutors$2(org.apache.spark.ExecutorAllocationManager,int,java.lang.String)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$executorIds()|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$1/ExecutorAllocationManager$$anonfun$addExecutors$1(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsTarget_$eq(int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/logInfo(scala.Function0)|",
      "|java+method:///scala/math/package$/max(int,int)|",
      "|java+method:///scala/collection/mutable/HashSet/size()|",
      "|java+constructor:///org/apache/spark/ExecutorAllocationManager$$anonfun$addExecutors$3/ExecutorAllocationManager$$anonfun$addExecutors$3(org.apache.spark.ExecutorAllocationManager)|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$numExecutorsToAdd()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$minNumExecutors()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/ExecutorAllocationClient/requestTotalExecutors(int)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/ExecutorAllocationManager/org$apache$spark$ExecutorAllocationManager$$maxNumExecutors()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1/apply$mcVI$sp(int)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/rdds()|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupPartition/CoGroupPartition(int,org.apache.spark.rdd.CoGroupSplitDep%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1(org.apache.spark.rdd.CoGroupedRDD$$anonfun$getPartitions$1,int)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/rdds()|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupPartition/CoGroupPartition(int,scala.Option%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1/CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1(org.apache.spark.rdd.CoGroupedRDD$$anonfun$getPartitions$1,int)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5/apply(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendMessageReliably(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/$plus$eq(scala.Tuple2)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$MessageStatus/ConnectionManager$MessageStatus(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Message,org.apache.spark.network.nio.ConnectionManagerId,scala.Function1)|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$ackTimeout()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendMessage(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///io/netty/util/HashedWheelTimer/newTimeout(io.netty.util.TimerTask,long,java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/collection/mutable/HashMap/$plus$eq(scala.Tuple2)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$messageStatuses()|",
      "|java+constructor:///java/lang/ref/WeakReference/WeakReference(java.lang.Object)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/ackTimeoutMonitor()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$14/ConnectionManager$$anonfun$14(org.apache.spark.network.nio.ConnectionManager,scala.concurrent.Promise,io.netty.util.Timeout)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13/ConnectionManager$$anon$13(org.apache.spark.network.nio.ConnectionManager,int,java.lang.ref.WeakReference)|",
      "|java+method:///org/apache/spark/network/nio/Message/id()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/concurrent/Promise$/apply()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$MessageStatus/ConnectionManager$MessageStatus(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Message,org.apache.spark.network.nio.ConnectionManagerId,scala.Function1)|",
      "|java+method:///scala/concurrent/Promise/future()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$ackTimeout()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendMessage(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///io/netty/util/HashedWheelTimer/newTimeout(io.netty.util.TimerTask,long,java.util.concurrent.TimeUnit)|",
      "|java+method:///scala/collection/mutable/HashMap/$plus$eq(scala.Tuple2)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$messageStatuses()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/ackTimeoutMonitor()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$13/ConnectionManager$$anon$13(org.apache.spark.network.nio.ConnectionManager,int,java.lang.ref.WeakReference)|",
      "|java+method:///org/apache/spark/network/nio/Message/id()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/concurrent/Promise$/apply()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$15/ConnectionManager$$anonfun$15(org.apache.spark.network.nio.ConnectionManager,scala.concurrent.Promise,io.netty.util.Timeout)|",
      "|java+constructor:///java/lang/ref/WeakReference/WeakReference(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$createTaskScheduler(org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$41/SparkContext$$anonfun$41()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$45/SparkContext$$anonfun$45()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.SparkConf,org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$8/FsHistoryProvider$$anonfun$8(org.apache.spark.deploy.history.FsHistoryProvider)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$6/apply$mcV$sp()|",
    "called": "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
    "v1Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addMasters(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///scala/collection/mutable/ListBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/delay(scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$6$$anonfun$apply$mcV$sp$2/FaultToleranceTest$$anonfun$6$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.FaultToleranceTest$$anonfun$6)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/assertValidClusterState()|",
      "|java+method:///scala/collection/mutable/ListBuffer/clear()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/workers()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/createClient()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/concurrent/duration/package$DurationInt/package$DurationInt(int)|",
      "|java+method:///scala/concurrent/duration/package$/DurationInt(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addMasters(int)|",
      "|java+method:///scala/collection/mutable/ListBuffer/clear()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$workers()|",
      "|java+method:///scala/collection/mutable/ListBuffer/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$delay(scala.concurrent.duration.Duration)|",
      "|java+constructor:///org/apache/spark/deploy/FaultToleranceTest$$anonfun$6$$anonfun$apply$mcV$sp$2/FaultToleranceTest$$anonfun$6$$anonfun$apply$mcV$sp$2(org.apache.spark.deploy.FaultToleranceTest$$anonfun$6)|",
      "|java+method:///scala/concurrent/duration/package$DurationInt/seconds()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$addWorkers(int)|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$killLeader()|",
      "|java+method:///org/apache/spark/deploy/FaultToleranceTest$/org$apache$spark$deploy$FaultToleranceTest$$createClient()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/apply()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/io/File/getName()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/apply()|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/apply()|",
      "|java+method:///org/apache/spark/storage/DiskStore$$anonfun$putBytes$2/apply$mcV$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/getCacheLocs(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$6/DAGScheduler$$anonfun$6(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/cacheLocs()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/storage/BlockManager$/blockIdsToBlockManagers(org.apache.spark.storage.BlockId%5B%5D,org.apache.spark.SparkEnv,org.apache.spark.storage.BlockManagerMaster)|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/indices()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$getCacheLocs$1/DAGScheduler$$anonfun$getCacheLocs$1(org.apache.spark.scheduler.DAGScheduler,scala.collection.immutable.Map)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$7/DAGScheduler$$anonfun$7(org.apache.spark.scheduler.DAGScheduler)|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$6/DAGScheduler$$anonfun$6(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/cacheLocs()|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/TraversableOnce/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/ArrayOps/indices()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/getLocations(org.apache.spark.storage.BlockId%5B%5D)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///scala/math/package$/max(double,double)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/OVERHEAD_FRACTION()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$$anonfun$calculateTotalMemory$1/MemoryUtils$$anonfun$calculateTotalMemory$1()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|"
    ],
    "v2Body": [
      "|java+method:///scala/math/package$/max(double,double)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/OVERHEAD_FRACTION()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/OVERHEAD_MINIMUM()|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/subtractByKey(org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1/PairRDDFunctions$$anonfun$subtractByKey$1(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/subtractByKey(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$subtractByKey$1/PairRDDFunctions$$anonfun$subtractByKey$1(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/renderJson(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/timeout()|",
      "|java+method:///akka/pattern/AskableActorRef$/$qmark$extension(akka.actor.ActorRef,java.lang.Object,akka.util.Timeout)|",
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/master()|",
      "|java+method:///akka/pattern/package$/ask(akka.actor.ActorRef)|",
      "|java+method:///akka/util/Timeout$/durationToTimeout(scala.concurrent.duration.FiniteDuration)|",
      "|java+method:///scala/concurrent/Await$/result(scala.concurrent.Awaitable,scala.concurrent.duration.Duration)|",
      "|java+method:///org/apache/spark/deploy/JsonProtocol$/writeMasterState(org.apache.spark.deploy.DeployMessages$MasterStateResponse)|",
      "|java+method:///scala/concurrent/Future/mapTo(scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/ui/MasterPage/getMasterState()|",
      "|java+method:///org/apache/spark/deploy/JsonProtocol$/writeMasterState(org.apache.spark.deploy.DeployMessages$MasterStateResponse)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/broadcast/TorrentBroadcast/org$apache$spark$broadcast$TorrentBroadcast$$setConf(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/io/CompressionCodec$/createCodec(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/broadcast/TorrentBroadcast/blockSize_$eq(int)|",
      "|java+method:///org/apache/spark/broadcast/TorrentBroadcast/org$apache$spark$broadcast$TorrentBroadcast$$compressionCodec_$eq(scala.Option)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/io/CompressionCodec$/createCodec(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/broadcast/TorrentBroadcast/blockSize_$eq(int)|",
      "|java+method:///org/apache/spark/broadcast/TorrentBroadcast/org$apache$spark$broadcast$TorrentBroadcast$$compressionCodec_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsKb(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$stageDependsOn(org.apache.spark.scheduler.Stage,org.apache.spark.scheduler.Stage)|",
    "called": "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
    "v1Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Stack/isEmpty()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$4(org.apache.spark.rdd.RDD,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+constructor:///scala/collection/mutable/Stack/Stack()|",
      "|java+method:///scala/collection/mutable/Stack/pop()|",
      "|java+method:///scala/collection/mutable/Stack/push(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$4(org.apache.spark.rdd.RDD,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///scala/collection/mutable/Stack/nonEmpty()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/mapValues(scala.Function1)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD/CoGroupedRDD(scala.collection.Seq,org.apache.spark.Partitioner)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$2/PairRDDFunctions$$anonfun$cogroup$2(org.apache.spark.rdd.PairRDDFunctions)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/runtime/ScalaRunTime$/arrayClass(java.lang.Class)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keyClass()|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/isArray()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$cogroup$2/PairRDDFunctions$$anonfun$cogroup$2(org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/Utils$/memoryStringToMb(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/util/JavaUtils/byteStringAsBytes(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$36/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$36/apply(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$36/apply(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$19/apply(org.apache.spark.ui.jobs.UIData$TaskUIData)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$19$$anonfun$apply$12/StagePage$$anonfun$19$$anonfun$apply$12(org.apache.spark.ui.jobs.StagePage$$anonfun$19)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$19$$anonfun$apply$2/StagePage$$anonfun$19$$anonfun$apply$2(org.apache.spark.ui.jobs.StagePage$$anonfun$19)|",
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/UIData$TaskUIData/taskMetrics()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/executorRunTime()|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/start()|",
    "called": "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
    "v1Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$10/SparkDeploySchedulerBackend$$anonfun$10(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/client_$eq(org.apache.spark.deploy.client.AppClient)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts(org.apache.spark.SparkConf,scala.Function1)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/waitForRegistration()|",
      "|java+constructor:///org/apache/spark/deploy/ApplicationDescription/ApplicationDescription(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient/AppClient(akka.actor.ActorSystem,java.lang.String%5B%5D,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.client.AppClientListener,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/client()|",
      "|java+method:///org/apache/spark/SparkContext/eventLogDir()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$11/SparkDeploySchedulerBackend$$anonfun$11(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$6/SparkDeploySchedulerBackend$$anonfun$6(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$7/SparkDeploySchedulerBackend$$anonfun$7(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$3/SparkDeploySchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$4/SparkDeploySchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$9/SparkDeploySchedulerBackend$$anonfun$9(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$5/SparkDeploySchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$8/SparkDeploySchedulerBackend$$anonfun$8(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///scala/sys/SystemProperties/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkContext/eventLogCodec()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/start()|",
      "|java+method:///scala/collection/mutable/ArrayOps/toSeq()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/actorSystem()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$10/SparkDeploySchedulerBackend$$anonfun$10(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$11/SparkDeploySchedulerBackend$$anonfun$11(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/client_$eq(org.apache.spark.deploy.client.AppClient)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///org/apache/spark/rpc/RpcAddress/RpcAddress(java.lang.String,int)|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/util/Utils$/sparkJavaOpts(org.apache.spark.SparkConf,scala.Function1)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/SparkContext/ui()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/uriOf(java.lang.String,org.apache.spark.rpc.RpcAddress,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/ApplicationDescription/ApplicationDescription(java.lang.String,scala.Option,int,org.apache.spark.deploy.Command,java.lang.String,scala.Option,scala.Option,scala.Option)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/waitForRegistration()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/rpcEnv()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient/AppClient(akka.actor.ActorSystem,java.lang.String%5B%5D,org.apache.spark.deploy.ApplicationDescription,org.apache.spark.deploy.client.AppClientListener,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+constructor:///org/apache/spark/deploy/Command/Command(java.lang.String,scala.collection.Seq,scala.collection.Map,scala.collection.Seq,scala.collection.Seq,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/client()|",
      "|java+method:///org/apache/spark/SparkContext/eventLogDir()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$6/SparkDeploySchedulerBackend$$anonfun$6(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$7/SparkDeploySchedulerBackend$$anonfun$7(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$3/SparkDeploySchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$12/SparkDeploySchedulerBackend$$anonfun$12(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$4/SparkDeploySchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$9/SparkDeploySchedulerBackend$$anonfun$9(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$5/SparkDeploySchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$8/SparkDeploySchedulerBackend$$anonfun$8(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///scala/collection/Seq/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///scala/sys/SystemProperties/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/eventLogCodec()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/start()|",
      "|java+method:///scala/collection/mutable/ArrayOps/toSeq()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/hashCode()|",
    "called": "|java+method:///scala/runtime/Statics/mix(int,int)|",
    "v1Body": [
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/tachyonSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/blockManagerId()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/diskSize()|",
      "|java+method:///scala/runtime/Statics/longHash(long)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/externalBlockStoreSize()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/storageLevel()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMessages$UpdateBlockInfo/memSize()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/intersection(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$1/RDD$$anonfun$intersection$1(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/cogroup(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$2/RDD$$anonfun$intersection$2(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$3/RDD$$anonfun$intersection$3(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keys()|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/filter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$intersection$2/RDD$$anonfun$intersection$2(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/parse(scala.collection.immutable.List)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/webUiPort_$eq(int)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/masters_$eq(java.lang.String%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/parse(scala.collection.immutable.List)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///org/apache/spark/deploy/worker/WorkerArguments$$anonfun$parse$1/WorkerArguments$$anonfun$parse$1(org.apache.spark.deploy.worker.WorkerArguments)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/cores_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/memory_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/port_$eq(int)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/masters()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/printUsageAndExit(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/host_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/util/MemoryParam$/unapply(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/workDir_$eq(java.lang.String)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/propertiesFile_$eq(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/cores_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/webUiPort_$eq(int)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/masters_$eq(java.lang.String%5B%5D)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/workDir_$eq(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/parseStandaloneMasterUrls(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/memory_$eq(int)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/port_$eq(int)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/masters()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/printUsageAndExit(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/host_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/util/MemoryParam$/unapply(java.lang.String)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/worker/WorkerArguments/propertiesFile_$eq(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/JobPage$$anonfun$3/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobPage$$anonfun$3/apply(org.apache.spark.scheduler.StageInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/JobPage$$anonfun$3/apply(char)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToChar(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/TestUtils$$anonfun$6/TestUtils$$anonfun$6()|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/runApproximateJob(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,org.apache.spark.util.CallSite,long,java.util.Properties)|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/scheduler/JobSubmitted/JobSubmitted(int,org.apache.spark.rdd.RDD,scala.Function2,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/getAndIncrement()|",
      "|java+method:///org/apache/spark/partial/ApproximateActionListener/awaitResult()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/partial/ApproximateActionListener/ApproximateActionListener(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///scala/collection/immutable/Range/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/nextJobId()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/scheduler/JobSubmitted/JobSubmitted(int,org.apache.spark.rdd.RDD,scala.Function2,int%5B%5D,boolean,org.apache.spark.util.CallSite,org.apache.spark.scheduler.JobListener,java.util.Properties)|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/getAndIncrement()|",
      "|java+method:///org/apache/spark/partial/ApproximateActionListener/awaitResult()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+constructor:///org/apache/spark/partial/ApproximateActionListener/ApproximateActionListener(org.apache.spark.rdd.RDD,scala.Function2,org.apache.spark.partial.ApproximateEvaluator,long)|",
      "|java+method:///org/apache/spark/scheduler/DAGSchedulerEventProcessLoop/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/eventProcessLoop()|",
      "|java+method:///scala/collection/immutable/Range/toArray(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/commons/lang3/SerializationUtils/clone(java.io.Serializable)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/nextJobId()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/reflect/ClassTag$/Int()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/Client$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/ClientArguments/ClientArguments(java.lang.String%5B%5D)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///org/apache/log4j/Level/isGreaterOrEqual(org.apache.log4j.Priority)|",
      "|java+method:///org/apache/spark/deploy/master/Master$/toAkkaUrl(java.lang.String,java.lang.String)|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///org/apache/log4j/Logger/getRootLogger()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/master()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/log4j/Logger/setLevel(org.apache.log4j.Level)|",
      "|java+method:///org/apache/log4j/Level/toString()|",
      "|java+method:///akka/actor/ActorSystem/awaitTermination()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/logLevel()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/ClientArguments/ClientArguments(java.lang.String%5B%5D)|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///org/apache/log4j/Level/isGreaterOrEqual(org.apache.log4j.Priority)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///org/apache/log4j/Logger/getRootLogger()|",
      "|java+method:///scala/sys/SystemProperties/contains(java.lang.String)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/masters()|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/mutable/ArrayOps/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/Client$$anonfun$main$1/Client$$anonfun$main$1(akka.actor.ActorSystem)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///java/lang/String/replace(java.lang.CharSequence,java.lang.CharSequence)|",
      "|java+method:///org/apache/log4j/Logger/setLevel(org.apache.log4j.Level)|",
      "|java+method:///org/apache/log4j/Level/toString()|",
      "|java+method:///akka/actor/ActorSystem/awaitTermination()|",
      "|java+method:///org/apache/spark/deploy/ClientArguments/logLevel()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagesTab/handleKillRequest(javax.servlet.http.HttpServletRequest)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/listener()|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRemoteUser()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/cancelStage(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/SparkUI/securityManager()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/sc()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/checkModifyPermissions(java.lang.String)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeStages()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$2/StagesTab$$anonfun$2(org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$1/StagesTab$$anonfun$1(org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/killEnabled()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getRemoteUser()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/SparkContext/cancelStage(int)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/progressListener()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/ui/SparkUI/securityManager()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///javax/servlet/http/HttpServletRequest/getParameter(java.lang.String)|",
      "|java+method:///org/apache/spark/ui/jobs/StagesTab/sc()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SecurityManager/checkModifyPermissions(java.lang.String)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///org/apache/spark/ui/jobs/JobProgressListener/activeStages()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$2/StagesTab$$anonfun$2(org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///org/apache/spark/ui/jobs/StagesTab$$anonfun$1/StagesTab$$anonfun$1(org.apache.spark.ui.jobs.StagesTab)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countApproxDistinctByKey(double,org.apache.spark.Partitioner)|",
    "called": "|java+method:///scala/math/package$/log(double)|",
    "v1Body": [
      "|java+method:///scala/math/package$/ceil(double)|",
      "|java+method:///scala/Predef$/assert(boolean)|",
      "|java+method:///scala/Predef$/require(boolean,scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$5/PairRDDFunctions$$anonfun$countApproxDistinctByKey$5(org.apache.spark.rdd.PairRDDFunctions,double)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/countApproxDistinctByKey(int,int,org.apache.spark.Partitioner)|",
      "|java+method:///scala/math/package$/log(double)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2/PairRDDFunctions$$anonfun$countApproxDistinctByKey$2(org.apache.spark.rdd.PairRDDFunctions,double,org.apache.spark.Partitioner)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/apply(org.apache.spark.deploy.master.ApplicationInfo)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$2/apply(org.apache.spark.deploy.master.WorkerInfo)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/start()|",
    "called": "|java+method:///scala/concurrent/duration/package$DurationLong/milliseconds()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend/start()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/SPECULATION_INTERVAL()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///akka/actor/ActorSystem/dispatcher()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/backend()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/sc()|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/milliseconds()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/conf()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$start$1/TaskSchedulerImpl$$anonfun$start$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$start$2/TaskSchedulerImpl$$anonfun$start$2(org.apache.spark.scheduler.TaskSchedulerImpl)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/SchedulerBackend/start()|",
      "|java+constructor:///scala/concurrent/duration/package$DurationLong/package$DurationLong(long)|",
      "|java+method:///akka/actor/Scheduler/schedule(scala.concurrent.duration.FiniteDuration,scala.concurrent.duration.FiniteDuration,scala.Function0,scala.concurrent.ExecutionContext)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///akka/actor/ActorSystem/dispatcher()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/backend()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/logInfo(scala.Function0)|",
      "|java+method:///akka/actor/ActorSystem/scheduler()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/sc()|",
      "|java+method:///scala/concurrent/duration/package$DurationLong/milliseconds()|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/SPECULATION_INTERVAL_MS()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/conf()|",
      "|java+method:///scala/concurrent/duration/package$/DurationLong(long)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$start$1/TaskSchedulerImpl$$anonfun$start$1(org.apache.spark.scheduler.TaskSchedulerImpl)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl$$anonfun$start$2/TaskSchedulerImpl$$anonfun$start$2(org.apache.spark.scheduler.TaskSchedulerImpl)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory_$eq(long)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$remove$1/MemoryStore$$anonfun$remove$1(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,org.apache.spark.storage.MemoryEntry)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/MemoryEntry/size()|",
      "|java+method:///java/util/LinkedHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$entries()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory_$eq(long)|",
      "|java+constructor:///org/apache/spark/storage/MemoryStore$$anonfun$remove$1/MemoryStore$$anonfun$remove$1(org.apache.spark.storage.MemoryStore,org.apache.spark.storage.BlockId,org.apache.spark.storage.MemoryEntry)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$currentMemory()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToBoolean(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryEntry/size()|",
      "|java+method:///java/util/LinkedHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$entries()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$17/StagePage$$anonfun$17(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext/union(org.apache.spark.rdd.RDD,scala.collection.Seq,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/collection/Seq$/canBuildFrom()|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext/union(scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/$plus$plus(scala.collection.GenTraversableOnce,scala.collection.generic.CanBuildFrom)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$union$2/SparkContext$$anonfun$union$2(org.apache.spark.SparkContext,org.apache.spark.rdd.RDD,scala.collection.Seq,scala.reflect.ClassTag)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$countByKey$1/PairRDDFunctions$$anonfun$countByKey$1(org.apache.spark.rdd.PairRDDFunctions)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction2$mcJJJ$sp/AbstractFunction2$mcJJJ$sp()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction2$mcJJJ$sp/AbstractFunction2$mcJJJ$sp()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/TaskSetManager/org$apache$spark$scheduler$TaskSetManager$$getLocalityWait(scala.Enumeration$Value)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/conf()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/PROCESS_LOCAL()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/RACK_LOCAL()|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/NODE_LOCAL()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/TaskSetManager/conf()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/PROCESS_LOCAL()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/RACK_LOCAL()|",
      "|java+method:///org/apache/spark/scheduler/TaskLocality$/NODE_LOCAL()|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsMs(java.lang.String,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$$anonfun$validateSettings$6/apply(java.lang.String)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$6/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$6(org.apache.spark.SparkConf$$anonfun$validateSettings$6,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7(org.apache.spark.SparkConf$$anonfun$validateSettings$6,java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/logWarning(scala.Function0)|",
      "|java+method:///scala/collection/IterableLike/foreach(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/stripMargin()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$8/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$8(org.apache.spark.SparkConf$$anonfun$validateSettings$6,java.lang.String)|",
      "|java+method:///scala/collection/Seq$/apply(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7/SparkConf$$anonfun$validateSettings$6$$anonfun$apply$7(org.apache.spark.SparkConf$$anonfun$validateSettings$6,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
    "called": "|java+method:///scala/runtime/NonLocalReturnControl/value$mcD$sp()|",
    "v1Body": [
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcD$sp()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$getResource$2/MesosSchedulerBackend$$anonfun$getResource$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,java.lang.Object)|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$getResource$1/MesosSchedulerBackend$$anonfun$getResource$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,java.lang.String)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils$class/getResource(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerUtils,java.util.List,java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1/applyOrElse(java.lang.Object,scala.Function1)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster(akka.actor.Address)|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///akka/remote/AssociationErrorEvent/remoteAddress()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/alreadyDisconnected_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/exitStatus()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$MasterChangeAcknowledged/DeployMessages$MasterChangeAcknowledged(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/masterAddress()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDisconnected()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/context()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/registered_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/workerId()|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/executorAdded(java.lang.String,java.lang.String,java.lang.String,int,int)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDead(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$3/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$3(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/message()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/self()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$2/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/id()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/changeMaster(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/connected(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+method:///akka/remote/AssociationErrorEvent/cause()|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/id()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/appId()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/RUNNING()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/memory()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.Throwable,akka.actor.Address)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/sender()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/state()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ApplicationRemoved/message()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/masterUrl()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.String,java.lang.String,java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/executorRemoved(java.lang.String,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/hostPort()|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterUrl()|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///akka/actor/ActorContext/stop(akka.actor.ActorRef)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/cores()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/appId_$eq(java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/master()|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$isPossibleMaster(akka.actor.Address)|",
      "|java+method:///akka/actor/ActorSelection$/toScala(akka.actor.ActorSelection)|",
      "|java+method:///akka/remote/AssociationErrorEvent/remoteAddress()|",
      "|java+method:///akka/actor/ScalaActorRef/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$appId()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/alreadyDisconnected_$eq(boolean)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/appId()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/exitStatus()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDisconnected()|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$MasterChangeAcknowledged/DeployMessages$MasterChangeAcknowledged(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$appId_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/context()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/workerId()|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/executorAdded(java.lang.String,java.lang.String,java.lang.String,int,int)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/markDead(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$3/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$3(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,scala.Enumeration$Value,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/message()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$3(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/self()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$2/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$2(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/id()|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/changeMaster(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/connected(java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/org$apache$spark$deploy$client$AppClient$ClientActor$$$outer()|",
      "|java+method:///akka/actor/package$/actorRef2Scala(akka.actor.ActorRef)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$UnregisterApplication/DeployMessages$UnregisterApplication(java.lang.String)|",
      "|java+method:///akka/remote/AssociationErrorEvent/cause()|",
      "|java+method:///akka/actor/ScalaActorSelection/$bang(java.lang.Object,akka.actor.ActorRef)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/id()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/RUNNING()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/memory()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$6(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.Throwable,akka.actor.Address)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$masterAddress()|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$5(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,akka.actor.Address)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/sender()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorUpdated/state()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ApplicationRemoved/message()|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$RegisteredApplication/masterUrl()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient/org$apache$spark$deploy$client$AppClient$$registered_$eq(boolean)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$1(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.String,java.lang.String,java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/client/AppClientListener/executorRemoved(java.lang.String,java.lang.String,scala.Option)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/hostPort()|",
      "|java+method:///scala/Function1/apply(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$MasterChanged/masterUrl()|",
      "|java+method:///akka/remote/DisassociatedEvent/remoteAddress()|",
      "|java+method:///org/apache/spark/deploy/ExecutorState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///akka/actor/ActorContext/stop(akka.actor.ActorRef)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/DeployMessages$ExecutorStateChanged/DeployMessages$ExecutorStateChanged(java.lang.String,int,scala.Enumeration$Value,scala.Option,scala.Option)|",
      "|java+constructor:///org/apache/spark/deploy/client/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4/AppClient$ClientActor$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$4(org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1,java.lang.String)|",
      "|java+method:///org/apache/spark/deploy/DeployMessages$ExecutorAdded/cores()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/deploy/client/AppClient$ClientActor/master()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/DriverWrapper$/main(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///akka/actor/ActorSystem/shutdown()|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///java/lang/Class/getMethod(java.lang.String,java.lang.Class%5B%5D)|",
      "|java+constructor:///org/apache/spark/util/ChildFirstURLClassLoader/ChildFirstURLClassLoader(java.net.URL%5B%5D,java.lang.ClassLoader)|",
      "|java+method:///scala/sys/SystemProperties/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverWrapper$$anonfun$1/DriverWrapper$$anonfun$1()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///scala/collection/immutable/List/toArray(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///akka/actor/ActorSystem/actorOf(akka.actor.Props,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+constructor:///org/apache/spark/util/MutableURLClassLoader/MutableURLClassLoader(java.net.URL%5B%5D,java.lang.ClassLoader)|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+method:///akka/actor/Props$/apply(java.lang.Class,scala.collection.Seq)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/shutdown()|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///java/lang/Class/getMethod(java.lang.String,java.lang.Class%5B%5D)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/sys/SystemProperties/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/collection/mutable/ArrayOps/toList()|",
      "|java+method:///java/lang/Class/forName(java.lang.String,boolean,java.lang.ClassLoader)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/worker/DriverWrapper$$anonfun$1/DriverWrapper$$anonfun$1()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///scala/collection/immutable/List/toArray(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/deploy/worker/WorkerWatcher/WorkerWatcher(org.apache.spark.rpc.RpcEnv,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/toBoolean()|",
      "|java+method:///scala/sys/package$/props()|",
      "|java+method:///java/io/PrintStream/println(java.lang.String)|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///java/net/URI/toURL()|",
      "|java+constructor:///org/apache/spark/util/ChildFirstURLClassLoader/ChildFirstURLClassLoader(java.net.URL%5B%5D,java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv$/create(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///java/lang/System/exit(int)|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///java/io/File/toURI()|",
      "|java+constructor:///org/apache/spark/util/MutableURLClassLoader/MutableURLClassLoader(java.net.URL%5B%5D,java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/setupEndpoint(java.lang.String,org.apache.spark.rpc.RpcEndpoint)|",
      "|java+method:///java/lang/reflect/Method/invoke(java.lang.Object,java.lang.Object%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$83/StagePage$$anonfun$83(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$20/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/MasterArguments/parse(scala.collection.immutable.List)|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/port_$eq(int)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/webUiPort_$eq(int)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/parse(scala.collection.immutable.List)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/host_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/printUsageAndExit(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/propertiesFile_$eq(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/port_$eq(int)|",
      "|java+method:///scala/collection/immutable/$colon$colon/tl$1()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/webUiPort_$eq(int)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/host_$eq(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/printUsageAndExit(int)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/$colon$colon/hd$1()|",
      "|java+method:///org/apache/spark/util/Utils$/checkHost(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/IntParam$/unapply(java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/deploy/master/MasterArguments/propertiesFile_$eq(java.lang.String)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$4/getValue()|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$4/getValue()|",
      "|java+method:///org/apache/spark/executor/Executor/threadPool()|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getPoolSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/executor/ExecutorSource/executor()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ExecutorSource$$anon$4/getValue()|",
      "|java+method:///java/util/concurrent/ThreadPoolExecutor/getPoolSize()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/productElement(int)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/version()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/_newName()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/deprecationMessage()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/oldName()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/version()|",
      "|java+constructor:///java/lang/IndexOutOfBoundsException/IndexOutOfBoundsException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/key()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkConf$DeprecatedConfig/deprecationMessage()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$52/apply(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/collection/immutable/List$/canBuildFrom()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class,scala.reflect.Manifest,scala.collection.Seq)|",
      "|java+method:///scala/collection/TraversableLike/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$52$$anonfun$apply$11/JsonProtocol$$anonfun$52$$anonfun$apply$11(org.apache.spark.util.JsonProtocol$$anonfun$52)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/Option/map(scala.Function1)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/conf()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$2/SparkDeploySchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$1/SparkDeploySchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,akka.actor.ActorSystem)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/CoarseGrainedSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/conf()|",
      "|java+constructor:///java/util/concurrent/Semaphore/Semaphore(int)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$2/SparkDeploySchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend$$anonfun$1/SparkDeploySchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$/setActiveContext(org.apache.spark.SparkContext,boolean)|",
    "called": "|java+constructor:///scala/Some/Some(java.lang.Object)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext$/assertNoOtherContextIsRunning(org.apache.spark.SparkContext,boolean)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$activeContext_$eq(scala.Option)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkContext$/SPARK_CONTEXT_CONSTRUCTOR_LOCK()|",
      "|java+method:///org/apache/spark/SparkContext$/assertNoOtherContextIsRunning(org.apache.spark.SparkContext,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/contextBeingConstructed_$eq(scala.Option)|",
      "|java+method:///java/util/concurrent/atomic/AtomicReference/set(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$activeContext()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/ZippedWithIndexRDD/ZippedWithIndexRDD(org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/scanLeft(java.lang.Object,scala.Function2,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedWithIndexRDD$$anonfun$2/ZippedWithIndexRDD$$anonfun$2(org.apache.spark.rdd.ZippedWithIndexRDD)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedWithIndexRDD$$anonfun$1/ZippedWithIndexRDD$$anonfun$1(org.apache.spark.rdd.ZippedWithIndexRDD)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/Long()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function1,scala.collection.Seq,boolean,scala.reflect.ClassTag)|",
      "|java+method:///scala/Array$/apply(scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.rdd.RDD,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/scanLeft(java.lang.Object,scala.Function2,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedWithIndexRDD$$anonfun$2/ZippedWithIndexRDD$$anonfun$2(org.apache.spark.rdd.ZippedWithIndexRDD)|",
      "|java+constructor:///org/apache/spark/rdd/ZippedWithIndexRDD$$anonfun$1/ZippedWithIndexRDD$$anonfun$1(org.apache.spark.rdd.ZippedWithIndexRDD)|",
      "|java+method:///scala/reflect/ClassTag$/Long()|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Predef$/longArrayOps(long%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$7/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$7/apply(org.apache.spark.scheduler.Stage)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/DAGScheduler$$anonfun$7/apply(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$80/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$80/apply(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/ui/jobs/StagePage$$anonfun$80/apply(org.apache.spark.executor.ShuffleReadMetrics)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/serializer/KryoSerializer/KryoSerializer(org.apache.spark.SparkConf)|",
    "called": "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getDouble(java.lang.String,double)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/serializer/KryoSerializer$$anonfun$1/KryoSerializer$$anonfun$1(org.apache.spark.serializer.KryoSerializer)|",
      "|java+constructor:///org/apache/spark/serializer/Serializer/Serializer()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/network/util/ByteUnit/toKiB(long)|",
      "|java+method:///org/apache/spark/serializer/KryoSerializer/maxBufferSizeMb()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/network/util/ByteUnit/toBytes(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsKb(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///org/apache/spark/serializer/KryoSerializer/bufferSizeKb()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/network/util/ByteUnit/toMiB(long)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getSizeAsMb(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/serializer/KryoSerializer$$anonfun$1/KryoSerializer$$anonfun$1(org.apache.spark.serializer.KryoSerializer)|",
      "|java+constructor:///org/apache/spark/serializer/Serializer/Serializer()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$14/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|",
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$14/apply(org.apache.spark.deploy.master.WorkerInfo)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/master/Master$$anonfun$14/apply(org.apache.spark.deploy.master.DriverInfo)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToBoolean(boolean)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/debugSelf$1(org.apache.spark.rdd.RDD)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$39/RDD$$anonfun$39(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$DummyImplicit$/dummyImplicit()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkContext/getRDDStorageInfo()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$40/RDD$$anonfun$40(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/description()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/$plus$colon(java.lang.Object,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$35/RDD$$anonfun$35(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkContext/getRDDStorageInfo()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/NONE()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/storageLevel()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$36/RDD$$anonfun$36(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$DummyImplicit$/dummyImplicit()|",
      "|java+method:///scala/Array$/fallbackCanBuildFrom(scala.Predef$DummyImplicit)|",
      "|java+method:///org/apache/spark/storage/StorageLevel/description()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/ArrayOps/filter(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$2/PartitionerAwareUnionRDD$$anonfun$2(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PartitionerAwareUnionRDD$$anonfun$4/PartitionerAwareUnionRDD$$anonfun$4(org.apache.spark.rdd.PartitionerAwareUnionRDD)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/history/HistoryServer$/main(java.lang.String%5B%5D)|",
    "called": "|java+method:///scala/Option/getOrElse(scala.Function0)|",
    "v1Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Runtime/addShutdownHook(java.lang.Thread)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$2/HistoryServer$$anon$2(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///org/apache/spark/util/SignalLogger$/register(org.slf4j.Logger)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServerArguments/HistoryServerArguments(org.apache.spark.SparkConf,java.lang.String%5B%5D)|",
      "|java+method:///java/lang/Runtime/getRuntime()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/conf()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/bind()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer/HistoryServer(org.apache.spark.SparkConf,org.apache.spark.deploy.history.ApplicationHistoryProvider,org.apache.spark.SecurityManager,int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/initSecurity()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anonfun$3/HistoryServer$$anonfun$3()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/log()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anonfun$main$1/HistoryServer$$anonfun$main$1(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/conf()|",
      "|java+method:///org/apache/spark/util/Utils$/addShutdownHook(scala.Function0)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///org/apache/spark/util/SignalLogger$/register(org.slf4j.Logger)|",
      "|java+method:///java/lang/Thread/sleep(long)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServerArguments/HistoryServerArguments(org.apache.spark.SparkConf,java.lang.String%5B%5D)|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/bind()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer/HistoryServer(org.apache.spark.SparkConf,org.apache.spark.deploy.history.ApplicationHistoryProvider,org.apache.spark.SecurityManager,int)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/initSecurity()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anonfun$3/HistoryServer$$anonfun$3()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer$/log()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/ui/jobs/StagePage$$anonfun$8/StagePage$$anonfun$8(org.apache.spark.ui.jobs.StagePage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0$mcJ$sp/AbstractFunction0$mcJ$sp()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/distinct()|",
    "called": "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/distinct$default$2(int)|",
      "|java+method:///org/apache/spark/rdd/RDD/distinct(int,scala.math.Ordering)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$distinct$2/RDD$$anonfun$distinct$2(org.apache.spark.rdd.RDD)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$10/MasterPage$$anonfun$10(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/visit$3(org.apache.spark.rdd.RDD,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
    "called": "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getCacheLocs(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$visit$3$1/DAGScheduler$$anonfun$visit$3$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+method:///scala/collection/mutable/HashSet/apply(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/getCacheLocs(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/RDD/dependencies()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$visit$3$1/DAGScheduler$$anonfun$visit$3$1(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage,scala.collection.mutable.HashSet,scala.collection.mutable.Stack)|",
      "|java+method:///scala/collection/mutable/HashSet/apply(java.lang.Object)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$flatMapValues$1/PairRDDFunctions$$anonfun$flatMapValues$1(org.apache.spark.rdd.PairRDDFunctions,scala.Function1)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction3/AbstractFunction3()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager$/testSequentialSending(org.apache.spark.network.nio.ConnectionManager)|",
    "called": "|java+method:///scala/Predef$/println(java.lang.Object)|",
    "v1Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$15/ConnectionManager$$anonfun$15()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testSequentialSending$1/ConnectionManager$$anonfun$testSequentialSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|"
    ],
    "v2Body": [
      "|java+method:///java/nio/ByteBuffer/allocate(int)|",
      "|java+method:///java/nio/ByteBuffer/flip()|",
      "|java+method:///scala/collection/immutable/Range/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/immutable/IndexedSeq$/canBuildFrom()|",
      "|java+method:///scala/Predef$/println()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$16/ConnectionManager$$anonfun$16()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$testSequentialSending$1/ConnectionManager$$anonfun$testSequentialSending$1(org.apache.spark.network.nio.ConnectionManager,java.nio.ByteBuffer)|",
      "|java+method:///scala/Predef$/println(java.lang.Object)|",
      "|java+method:///java/nio/ByteBuffer/put(byte%5B%5D)|",
      "|java+method:///scala/runtime/RichInt$/until$extension0(int,int)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/tabulate(int,scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///scala/reflect/ClassTag$/Byte()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDD/subtract(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.math.Ordering)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anon$2/RDD$$anon$2(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$1/RDD$$anonfun$subtract$1(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$2/RDD$$anonfun$subtract$2(org.apache.spark.rdd.RDD)|",
      "|java+method:///scala/reflect/ClassTag$/Null()|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$3/RDD$$anonfun$subtract$3(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$4/RDD$$anonfun$subtract$4(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/keys()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/map(scala.Function1,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD$/rddToPairRDDFunctions(org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitioner()|",
      "|java+method:///org/apache/spark/rdd/PairRDDFunctions/subtractByKey(org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.reflect.ClassTag)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD$$anonfun$subtract$3/RDD$$anonfun$subtract$3(org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,org.apache.spark.Partitioner,scala.math.Ordering)|",
      "|java+method:///org/apache/spark/rdd/RDD/withScope(scala.Function0)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/org$apache$spark$scheduler$DAGScheduler$$getShuffleMapStage(org.apache.spark.ShuffleDependency,int)|",
    "called": "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newOrUsedStage(org.apache.spark.rdd.RDD,int,org.apache.spark.ShuffleDependency,int,org.apache.spark.util.CallSite)|",
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/creationSite()|",
      "|java+method:///org/apache/spark/ShuffleDependency/rdd()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/registerShuffleDependencies(org.apache.spark.ShuffleDependency,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/shuffleToMapStage()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/registerShuffleDependencies(org.apache.spark.ShuffleDependency,int)|",
      "|java+method:///org/apache/spark/ShuffleDependency/shuffleId()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/newOrUsedShuffleStage(org.apache.spark.ShuffleDependency,int)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$5/BlockManager$$anonfun$5(org.apache.spark.storage.BlockManager)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/getPos$mcI$sp(int)|",
    "called": "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash$mcI$sp(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/_data()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/hasher()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|",
      "|java+method:///scala/Predef$/genericArrayOps(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$_mask()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$_mask()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$Hasher/hash$mcI$sp(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/_data()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$_bitset()|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/hasher()|",
      "|java+method:///org/apache/spark/util/collection/BitSet/get(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$mcI$sp/org$apache$spark$util$collection$OpenHashSet$$hashcode(int)|",
      "|java+method:///org/apache/spark/util/collection/OpenHashSet$/INVALID_POS()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$/accumulableInfoFromJson(org.json4s.JsonAST$JValue)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
    "v1Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$55/JsonProtocol$$anonfun$55()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|"
    ],
    "v2Body": [
      "|java+method:///scala/runtime/BoxesRunTime/unboxToLong(java.lang.Object)|",
      "|java+method:///scala/reflect/ManifestFactory$/classType(java.lang.Class)|",
      "|java+method:///scala/reflect/ManifestFactory$/Long()|",
      "|java+method:///org/json4s/ExtractableJsonAstNode/extract(org.json4s.Formats,scala.reflect.Manifest)|",
      "|java+method:///org/apache/spark/util/Utils$/jsonOption(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/json4s/package$/jvalue2monadic(org.json4s.JsonAST$JValue)|",
      "|java+constructor:///org/apache/spark/util/JsonProtocol$$anonfun$60/JsonProtocol$$anonfun$60()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+method:///org/json4s/MonadicJValue/$bslash(java.lang.String)|",
      "|java+method:///org/json4s/package$/jvalue2extractable(org.json4s.JsonAST$JValue)|",
      "|java+method:///org/apache/spark/scheduler/AccumulableInfo$/apply(long,java.lang.String,scala.Option,java.lang.String)|",
      "|java+method:///org/apache/spark/util/JsonProtocol$/org$apache$spark$util$JsonProtocol$$format()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/SparkContext$$anonfun$15/SparkContext$$anonfun$15(org.apache.spark.SparkContext)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/apply()|",
    "called": "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/apply()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/deploy/worker/Worker$$anonfun$receiveWithLogging$1$$anonfun$applyOrElse$7/apply()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/CoGroupedRDD/compute(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
    "called": "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$1/CoGroupedRDD$$anonfun$1(org.apache.spark.rdd.CoGroupedRDD,int)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/diskBytesSpilled()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/createExternalMap(int)|",
      "|java+method:///org/apache/spark/rdd/CoGroupPartition/deps()|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$5/CoGroupedRDD$$anonfun$compute$5(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.util.collection.ExternalAppendOnlyMap)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incDiskBytesSpilled(long)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$1/CoGroupedRDD$$anonfun$compute$1(org.apache.spark.rdd.CoGroupedRDD)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+constructor:///org/apache/spark/InterruptibleIterator/InterruptibleIterator(org.apache.spark.TaskContext,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$2/CoGroupedRDD$$anonfun$compute$2(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.TaskContext,org.apache.spark.rdd.CoGroupPartition,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/memoryBytesSpilled()|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/iterator()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///org/apache/spark/util/collection/AppendOnlyMap/AppendOnlyMap(int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap$/$lessinit$greater$default$1()|",
      "|java+method:///scala/collection/mutable/ArrayOps/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$3/CoGroupedRDD$$anonfun$compute$3(org.apache.spark.rdd.CoGroupedRDD,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$2/CoGroupedRDD$$anonfun$2(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.util.collection.AppendOnlyMap,scala.Function2)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/ArrayOps/withFilter(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$4/CoGroupedRDD$$anonfun$compute$4(org.apache.spark.rdd.CoGroupedRDD)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incMemoryBytesSpilled(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/iterator()|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/Seq/zipWithIndex(scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$1/CoGroupedRDD$$anonfun$1(org.apache.spark.rdd.CoGroupedRDD,int)|",
      "|java+method:///scala/collection/TraversableLike/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/diskBytesSpilled()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/createExternalMap(int)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$5/CoGroupedRDD$$anonfun$compute$5(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.util.collection.ExternalAppendOnlyMap)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incDiskBytesSpilled(long)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$1/CoGroupedRDD$$anonfun$compute$1(org.apache.spark.rdd.CoGroupedRDD)|",
      "|java+constructor:///org/apache/spark/InterruptibleIterator/InterruptibleIterator(org.apache.spark.TaskContext,scala.collection.Iterator)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$2/CoGroupedRDD$$anonfun$compute$2(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.TaskContext,org.apache.spark.rdd.CoGroupPartition,scala.collection.mutable.ArrayBuffer)|",
      "|java+method:///scala/collection/Seq$/canBuildFrom()|",
      "|java+method:///org/apache/spark/rdd/CoGroupedRDD/dependencies()|",
      "|java+method:///org/apache/spark/SparkEnv$/get()|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/memoryBytesSpilled()|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap/iterator()|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+constructor:///org/apache/spark/util/collection/AppendOnlyMap/AppendOnlyMap(int)|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/withFilter(scala.Function1)|",
      "|java+method:///org/apache/spark/util/collection/AppendOnlyMap$/$lessinit$greater$default$1()|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$3/CoGroupedRDD$$anonfun$compute$3(org.apache.spark.rdd.CoGroupedRDD,scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$2/CoGroupedRDD$$anonfun$2(org.apache.spark.rdd.CoGroupedRDD,org.apache.spark.util.collection.AppendOnlyMap,scala.Function2)|",
      "|java+method:///org/apache/spark/SparkEnv/conf()|",
      "|java+method:///scala/collection/mutable/ArrayBuffer/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/rdd/CoGroupedRDD$$anonfun$compute$4/CoGroupedRDD$$anonfun$compute$4(org.apache.spark.rdd.CoGroupedRDD)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/incMemoryBytesSpilled(long)|",
      "|java+method:///org/apache/spark/util/collection/ExternalAppendOnlyMap/iterator()|",
      "|java+method:///scala/collection/Seq/length()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/rdd/RDDCheckpointData/doCheckpoint()|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpFile_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkContext/checkpointDir()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/MarkedForCheckpoint()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SerializableWritable/SerializableWritable(org.apache.hadoop.io.Writable)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/logInfo(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/spark/rdd/RDD/markCheckpointed(org.apache.spark.rdd.RDD)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpRDD_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD/CheckpointRDD(org.apache.spark.SparkContext,java.lang.String,scala.reflect.ClassTag)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/reflect/ClassTag$/Unit()|",
      "|java+constructor:///org/apache/hadoop/fs/Path/Path(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/writeToFile$default$3()|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpState()|",
      "|java+constructor:///org/apache/spark/rdd/RDDCheckpointData$$anonfun$doCheckpoint$2/RDDCheckpointData$$anonfun$doCheckpoint$2(org.apache.spark.rdd.RDDCheckpointData,org.apache.hadoop.fs.Path,org.apache.spark.rdd.CheckpointRDD)|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/Checkpointed()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/CheckpointingInProgress()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+constructor:///org/apache/spark/rdd/RDDCheckpointData$$anonfun$doCheckpoint$1/RDDCheckpointData$$anonfun$doCheckpoint$1(org.apache.spark.rdd.RDDCheckpointData,org.apache.spark.broadcast.Broadcast,java.lang.String,int)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpState_$eq(scala.Enumeration$Value)|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/mkdirs(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Unit()|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpFile_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/SparkContext/broadcast(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/rdd/RDDCheckpointData$$anonfun$doCheckpoint$1/RDDCheckpointData$$anonfun$doCheckpoint$1(org.apache.spark.rdd.RDDCheckpointData,org.apache.spark.rdd.CheckpointRDD)|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/Checkpointed()|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/MarkedForCheckpoint()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SerializableWritable/SerializableWritable(org.apache.hadoop.io.Writable)|",
      "|java+method:///org/apache/spark/SparkContext/hadoopConfiguration()|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpState_$eq(scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/rdd/RDD/conf()|",
      "|java+method:///org/apache/hadoop/fs/Path/toString()|",
      "|java+method:///org/apache/spark/rdd/RDD/markCheckpointed(org.apache.spark.rdd.RDD)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpRDD_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/rdd/CheckpointRDD/CheckpointRDD(org.apache.spark.SparkContext,java.lang.String,scala.reflect.ClassTag)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/context()|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD$/writeToFile$default$3()|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData/cpState()|",
      "|java+constructor:///org/apache/spark/rdd/RDDCheckpointData$$anonfun$doCheckpoint$3/RDDCheckpointData$$anonfun$doCheckpoint$3(org.apache.spark.rdd.RDDCheckpointData,org.apache.hadoop.fs.Path,org.apache.spark.rdd.CheckpointRDD)|",
      "|java+method:///org/apache/spark/rdd/RDDCheckpointData$/rddCheckpointDataPath(org.apache.spark.SparkContext,int)|",
      "|java+method:///org/apache/spark/rdd/CheckpointRDD/partitions()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkContext/runJob(org.apache.spark.rdd.RDD,scala.Function2,scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/CheckpointState$/CheckpointingInProgress()|",
      "|java+method:///org/apache/spark/rdd/RDD/id()|",
      "|java+constructor:///org/apache/spark/rdd/RDDCheckpointData$$anonfun$doCheckpoint$2/RDDCheckpointData$$anonfun$doCheckpoint$2(org.apache.spark.rdd.RDDCheckpointData,org.apache.spark.broadcast.Broadcast,java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkContext/cleaner()|",
      "|java+method:///org/apache/hadoop/fs/FileSystem/mkdirs(org.apache.hadoop.fs.Path)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$40/apply(java.lang.Object)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$40/apply(org.json4s.JsonAST$JValue)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/util/JsonProtocol$$anonfun$40/apply(int)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/deploy/master/ui/MasterPage$$anonfun$9/MasterPage$$anonfun$9(org.apache.spark.deploy.master.ui.MasterPage)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$1/apply()|",
    "called": "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore/org$apache$spark$storage$MemoryStore$$unrollMemoryThreshold()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$1/apply()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/util/Utils$/bytesToString(long)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$1/apply()|",
      "|java+method:///org/apache/spark/storage/MemoryStore$$anonfun$1/apply$mcJ$sp()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/abortStage(org.apache.spark.scheduler.Stage,java.lang.String)|",
    "called": "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
    "v1Body": [
      "|java+method:///scala/collection/SetLike/toSeq()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$abortStage$1/DAGScheduler$$anonfun$abortStage$1(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$17/DAGScheduler$$anonfun$17(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$abortStage$2/DAGScheduler$$anonfun$abortStage$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime_$eq(scala.Option)|"
    ],
    "v2Body": [
      "|java+method:///scala/collection/SetLike/toSeq()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///scala/collection/Seq/isEmpty()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$abortStage$1/DAGScheduler$$anonfun$abortStage$1(org.apache.spark.scheduler.DAGScheduler,java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/collection/mutable/HashSet/filter(scala.Function1)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/latestInfo()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$19/DAGScheduler$$anonfun$19(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$abortStage$2/DAGScheduler$$anonfun$abortStage$2(org.apache.spark.scheduler.DAGScheduler,org.apache.spark.scheduler.Stage)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/activeJobs()|",
      "|java+method:///org/apache/spark/scheduler/StageInfo/completionTime_$eq(scala.Option)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/network/nio/ConnectionManager/ConnectionManager(int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager,java.lang.String)|",
    "called": "|java+constructor:///scala/collection/mutable/SynchronizedQueue/SynchronizedQueue()|",
    "v1Body": [
      "|java+method:///java/nio/channels/ServerSocketChannel/configureBlocking(boolean)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/nio/channels/ServerSocketChannel/socket()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$1/ConnectionManager$$anon$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$3/ConnectionManager$$anon$3(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/util/Utils$/namedThreadFactory(java.lang.String)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$4/ConnectionManager$$anon$4(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+constructor:///scala/collection/mutable/SynchronizedQueue/SynchronizedQueue()|",
      "|java+method:///org/apache/spark/util/Utils$/startServiceOnPort(int,scala.Function1,org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///java/net/ServerSocket/setReceiveBufferSize(int)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/selectorThread()|",
      "|java+method:///java/nio/channels/spi/SelectorProvider/openSelector()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$serverChannel()|",
      "|java+method:///org/apache/spark/util/Utils$/newDaemonCachedThreadPool(java.lang.String)|",
      "|java+method:///java/net/ServerSocket/getLocalPort()|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$selector()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+constructor:///io/netty/util/HashedWheelTimer/HashedWheelTimer(java.util.concurrent.ThreadFactory)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$2/ConnectionManager$$anon$2(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///scala/concurrent/ExecutionContext$/fromExecutor(java.util.concurrent.Executor)|",
      "|java+method:///java/nio/channels/spi/SelectorProvider/provider()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$5/ConnectionManager$$anon$5(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$6/ConnectionManager$$anon$6(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/net/ServerSocket/setReuseAddress(boolean)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManagerId/ConnectionManagerId(java.lang.String,int)|",
      "|java+method:///java/nio/channels/ServerSocketChannel/register(java.nio.channels.Selector,int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$7/ConnectionManager$$anon$7(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///java/nio/channels/ServerSocketChannel/open()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$3/ConnectionManager$$anonfun$3(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$2/ConnectionManager$$anonfun$2(org.apache.spark.network.nio.ConnectionManager)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/nio/channels/ServerSocketChannel/socket()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$1/ConnectionManager$$anon$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$4/ConnectionManager$$anon$4(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicInteger/AtomicInteger(int)|",
      "|java+constructor:///scala/collection/mutable/SynchronizedQueue/SynchronizedQueue()|",
      "|java+method:///java/nio/channels/ServerSocketChannel/configureBlocking(boolean)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/startServiceOnPort(int,scala.Function1,org.apache.spark.SparkConf,java.lang.String)|",
      "|java+method:///org/apache/spark/util/Utils$/localHostName()|",
      "|java+method:///java/net/ServerSocket/setReceiveBufferSize(int)|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/selectorThread()|",
      "|java+method:///java/nio/channels/spi/SelectorProvider/openSelector()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$serverChannel()|",
      "|java+method:///java/net/ServerSocket/getLocalPort()|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/namedThreadFactory(java.lang.String)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/org$apache$spark$network$nio$ConnectionManager$$selector()|",
      "|java+method:///org/apache/spark/SecurityManager/isAuthenticationEnabled()|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+constructor:///io/netty/util/HashedWheelTimer/HashedWheelTimer(java.util.concurrent.ThreadFactory)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$2/ConnectionManager$$anon$2(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///scala/concurrent/ExecutionContext$/fromExecutor(java.util.concurrent.Executor)|",
      "|java+method:///java/nio/channels/spi/SelectorProvider/provider()|",
      "|java+method:///org/apache/spark/util/ThreadUtils$/newDaemonCachedThreadPool(java.lang.String)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$3/ConnectionManager$$anon$3(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$5/ConnectionManager$$anon$5(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$6/ConnectionManager$$anon$6(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///java/net/ServerSocket/setReuseAddress(boolean)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManagerId/ConnectionManagerId(java.lang.String,int)|",
      "|java+method:///java/nio/channels/ServerSocketChannel/register(java.nio.channels.Selector,int)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anon$7/ConnectionManager$$anon$7(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+method:///java/nio/channels/ServerSocketChannel/open()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$3/ConnectionManager$$anonfun$3(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$2/ConnectionManager$$anonfun$2(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/SparkConf/getTimeAsSeconds(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/lang/Object/Object()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hashCode()|",
    "called": "|java+method:///scala/runtime/Statics/mix(int,int)|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/logUrls()|",
      "|java+method:///scala/runtime/Statics/finalizeHash(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/cores()|",
      "|java+method:///scala/runtime/Statics/mix(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/hostPort()|",
      "|java+method:///scala/runtime/Statics/anyHash(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessages$RegisterExecutor/executorRef()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1/apply(org.apache.spark.SparkContext)|",
    "called": "|java+method:///scala/Option/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$9/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$9(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$37/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$37(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$creationSite()|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$10/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$10(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$38/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$38(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$activeContext()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$17/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$17(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$41/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$41(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$42/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$42(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///java/util/concurrent/atomic/AtomicReference/get()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext/org$apache$spark$SparkContext$$creationSite()|",
      "|java+method:///org/apache/spark/util/CallSite/longForm()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$16/SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$16(org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1,java.lang.String)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$activeContext()|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/PairRDDFunctions$$anonfun$lookup$1/PairRDDFunctions$$anonfun$lookup$1(org.apache.spark.rdd.PairRDDFunctions,java.lang.Object)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/storage/ShuffleBlockFetcherIterator/ShuffleBlockFetcherIterator(org.apache.spark.TaskContext,org.apache.spark.network.shuffle.ShuffleClient,org.apache.spark.storage.BlockManager,scala.collection.Seq,org.apache.spark.serializer.Serializer,long)|",
    "called": "|java+constructor:///scala/collection/mutable/Queue/Queue()|",
    "v1Body": [
      "|java+constructor:///java/util/concurrent/LinkedBlockingQueue/LinkedBlockingQueue()|",
      "|java+constructor:///scala/collection/mutable/Queue/Queue()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockFetcherIterator/initialize()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/GenTraversableOnce$class/$init$(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/Iterator$class/$init$(scala.collection.Iterator)|",
      "|java+method:///scala/collection/TraversableOnce$class/$init$(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/createShuffleReadMetricsForDependency()|"
    ],
    "v2Body": [
      "|java+constructor:///java/util/concurrent/LinkedBlockingQueue/LinkedBlockingQueue()|",
      "|java+constructor:///scala/collection/mutable/Queue/Queue()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///scala/collection/mutable/HashSet/HashSet()|",
      "|java+method:///org/apache/spark/TaskContext/taskMetrics()|",
      "|java+constructor:///scala/collection/mutable/ArrayBuffer/ArrayBuffer()|",
      "|java+method:///org/apache/spark/storage/ShuffleBlockFetcherIterator/initialize()|",
      "|java+method:///org/apache/spark/Logging$class/$init$(org.apache.spark.Logging)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/collection/GenTraversableOnce$class/$init$(scala.collection.GenTraversableOnce)|",
      "|java+method:///scala/collection/Iterator$class/$init$(scala.collection.Iterator)|",
      "|java+method:///scala/collection/TraversableOnce$class/$init$(scala.collection.TraversableOnce)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/createShuffleReadMetricsForDependency()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/rdd/CartesianRDD/CartesianRDD(org.apache.spark.SparkContext,org.apache.spark.rdd.RDD,org.apache.spark.rdd.RDD,scala.reflect.ClassTag,scala.reflect.ClassTag)|",
    "called": "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd2()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/collection/mutable/ArrayOps/size()|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+constructor:///org/apache/spark/rdd/RDD/RDD(org.apache.spark.SparkContext,scala.collection.Seq,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/CartesianRDD/rdd2()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$8/BlockManager$$anonfun$8(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
    "called": "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
    "v1Body": [
      "|java+constructor:///scala/runtime/AbstractFunction1/AbstractFunction1()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "v2Body": [
      "|java+constructor:///scala/runtime/AbstractFunction0/AbstractFunction0()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/SparkEnv/stop()|",
    "called": "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///akka/actor/ActorSystem/shutdown()|",
      "|java+method:///org/apache/spark/MapOutputTracker/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/stop()|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/SparkEnv/httpFileServer()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/pythonWorkers()|",
      "|java+method:///org/apache/spark/SparkEnv/isStopped_$eq(boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/stop()|",
      "|java+method:///org/apache/spark/storage/BlockManager/stop()|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/stop()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$stop$1/SparkEnv$$anonfun$stop$1(org.apache.spark.SparkEnv)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$stop$2/SparkEnv$$anonfun$stop$2(org.apache.spark.SparkEnv)|",
      "|java+method:///org/apache/spark/SparkEnv/broadcastManager()|",
      "|java+method:///org/apache/spark/SparkEnv/outputCommitCoordinator()|"
    ],
    "v2Body": [
      "|java+method:///scala/Some/x()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///org/apache/spark/MapOutputTracker/stop()|",
      "|java+method:///org/apache/spark/broadcast/BroadcastManager/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+method:///org/apache/spark/SparkEnv/metricsSystem()|",
      "|java+method:///org/apache/spark/SparkEnv/httpFileServer()|",
      "|java+method:///org/apache/spark/SparkEnv/pythonWorkers()|",
      "|java+method:///org/apache/spark/util/Utils$/deleteRecursively(java.io.File)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/shutdown()|",
      "|java+method:///org/apache/spark/SparkEnv/isStopped_$eq(boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleManager()|",
      "|java+method:///org/apache/spark/SparkEnv/logWarning(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster/stop()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$stop$3/SparkEnv$$anonfun$stop$3(org.apache.spark.SparkEnv,java.lang.String)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/stop()|",
      "|java+method:///org/apache/spark/storage/BlockManager/master()|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+constructor:///java/io/File/File(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/stop()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$stop$1/SparkEnv$$anonfun$stop$1(org.apache.spark.SparkEnv)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$stop$2/SparkEnv$$anonfun$stop$2(org.apache.spark.SparkEnv)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/org$apache$spark$SparkEnv$$driverTmpDirToDelete()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/stop()|",
      "|java+method:///org/apache/spark/SparkEnv/rpcEnv()|",
      "|java+method:///org/apache/spark/SparkEnv/broadcastManager()|",
      "|java+method:///org/apache/spark/SparkEnv/outputCommitCoordinator()|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.4.0",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.3.1",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/removeBlock(org.apache.spark.storage.BlockId,boolean)|",
    "called": "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$1/BlockManager$$anonfun$removeBlock$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/DiskStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/tellMaster()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$2/BlockManager$$anonfun$removeBlock$2(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$3/BlockManager$$anonfun$removeBlock$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/tachyonStore()|",
      "|java+method:///org/apache/spark/storage/TachyonStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/tachyonInitialized()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Predef$/conforms()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$1/BlockManager$$anonfun$removeBlock$1(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus$default$4()|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskStore()|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/DiskStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/storage/BlockManager/reportBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo,org.apache.spark.storage.BlockStatus,long)|",
      "|java+method:///org/apache/spark/storage/BlockInfo/tellMaster()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$2/BlockManager$$anonfun$removeBlock$2(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$blockInfo()|",
      "|java+method:///org/apache/spark/storage/ExternalBlockStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(org.apache.spark.storage.BlockId,org.apache.spark.storage.BlockInfo)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$removeBlock$3/BlockManager$$anonfun$removeBlock$3(org.apache.spark.storage.BlockManager,org.apache.spark.storage.BlockId)|",
      "|java+method:///org/apache/spark/storage/BlockManager/externalBlockStore()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/remove(org.apache.spark.storage.BlockId)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/storage/BlockManager/externalBlockStoreInitialized()|",
      "|java+method:///org/apache/spark/util/TimeStampedHashMap/remove(java.lang.Object)|"
    ],
    "affectedLib": "org.scala-lang:scala-library:2.10.4",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/DAGScheduler/runLocallyWithinThread(org.apache.spark.scheduler.ActiveJob)|",
    "called": "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
    "v1Body": [
      "|java+method:///org/apache/spark/TaskContextImpl$/$lessinit$greater$default$6()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/TaskContextHelper$/unset()|",
      "|java+constructor:///org/apache/spark/TaskContextImpl/TaskContextImpl(int,int,long,int,boolean,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///org/apache/spark/TaskContextHelper$/setTaskContext(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///org/apache/spark/scheduler/Stage/id()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///org/apache/spark/TaskContextImpl/markTaskCompleted()|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/partitions()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/Stage/rdd()|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/ActiveJob/listener()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListenerJobEnd/SparkListenerJobEnd(int,long,org.apache.spark.scheduler.JobResult)|",
      "|java+constructor:///org/apache/spark/scheduler/JobFailed/JobFailed(java.lang.Exception)|",
      "|java+method:///org/apache/spark/scheduler/JobListener/jobFailed(java.lang.Exception)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/logError(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/DAGScheduler$$anonfun$runLocallyWithinThread$1/DAGScheduler$$anonfun$runLocallyWithinThread$1(org.apache.spark.scheduler.DAGScheduler,long)|",
      "|java+method:///org/apache/spark/util/Clock/getTimeMillis()|",
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/id()|",
      "|java+method:///org/apache/spark/TaskContextImpl$/$lessinit$greater$default$7()|",
      "|java+method:///org/apache/spark/scheduler/ResultStage/rdd()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/TaskContextImpl/markTaskCompleted()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/TaskMemoryManager/TaskMemoryManager(org.apache.spark.unsafe.memory.ExecutorMemoryManager)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/stageIdToStage()|",
      "|java+constructor:///org/apache/spark/SparkDriverExecutionException/SparkDriverExecutionException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/jobIdToStageIds()|",
      "|java+method:///org/apache/spark/rdd/RDD/partitions()|",
      "|java+method:///org/apache/spark/TaskContext$/setTaskContext(org.apache.spark.TaskContext)|",
      "|java+method:///org/apache/spark/scheduler/DAGScheduler/sc()|",
      "|java+method:///org/apache/spark/scheduler/JobListener/taskSucceeded(int,java.lang.Object)|",
      "|java+method:///org/apache/spark/rdd/RDD/iterator(org.apache.spark.Partition,org.apache.spark.TaskContext)|",
      "|java+constructor:///org/apache/spark/TaskContextImpl/TaskContextImpl(int,int,long,int,org.apache.spark.unsafe.memory.TaskMemoryManager,boolean,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///scala/Function2/apply(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/LiveListenerBus/post(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/func()|",
      "|java+method:///org/apache/spark/TaskContext$/unset()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/finalStage()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/partitions()|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv/executorMemoryManager()|",
      "|java+method:///org/apache/spark/scheduler/ActiveJob/jobId()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.10:1.4.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/SparkEnv$/create(org.apache.spark.SparkConf,java.lang.String,java.lang.String,int,boolean,boolean,org.apache.spark.scheduler.LiveListenerBus,int,scala.Option)|",
    "called": "|java+constructor:///org/apache/spark/unsafe/memory/ExecutorMemoryManager/ExecutorMemoryManager(org.apache.spark.unsafe.memory.MemoryAllocator)|",
    "v1Body": [
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster/BlockManagerMaster(akka.actor.ActorRef,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir(java.lang.String,java.lang.String)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/registerOrLookup$1(java.lang.String,scala.Function0,org.apache.spark.SparkConf,boolean,akka.actor.ActorSystem)|",
      "|java+method:///scala/Tuple2/_2$mcI$sp()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/createActorSystem(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$2/SparkEnv$$anonfun$create$2(org.apache.spark.serializer.Serializer)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/HttpFileServer/serverUri()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$1/SparkEnv$$anonfun$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/broadcast/BroadcastManager/BroadcastManager(boolean,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/spark/SparkEnv$/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$4/SparkEnv$$anonfun$create$4()|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorActor_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$1/SparkEnv$$anonfun$create$1()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///org/apache/spark/HttpFileServer/initialize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+constructor:///org/apache/spark/network/nio/NioBlockTransferService/NioBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$2/SparkEnv$$anonfun$2(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus)|",
      "|java+method:///org/apache/spark/SparkConf/contains(java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker/trackerActor_$eq(akka.actor.ActorRef)|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerMaster/MapOutputTrackerMaster(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerWorker/MapOutputTrackerWorker(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClass$1(java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+constructor:///org/apache/spark/HttpFileServer/HttpFileServer(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/CacheManager/CacheManager(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$4/SparkEnv$$anonfun$4(org.apache.spark.scheduler.OutputCommitCoordinator)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClassFromConf$1(java.lang.String,java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$3/SparkEnv$$anonfun$3(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$3/SparkEnv$$anonfun$create$3(org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker)|",
      "|java+constructor:///org/apache/spark/SparkEnv/SparkEnv(java.lang.String,akka.actor.ActorSystem,org.apache.spark.serializer.Serializer,org.apache.spark.serializer.Serializer,org.apache.spark.CacheManager,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.broadcast.BroadcastManager,org.apache.spark.network.BlockTransferService,org.apache.spark.storage.BlockManager,org.apache.spark.SecurityManager,org.apache.spark.HttpFileServer,java.lang.String,org.apache.spark.metrics.MetricsSystem,org.apache.spark.shuffle.ShuffleMemoryManager,org.apache.spark.scheduler.OutputCommitCoordinator,org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager/BlockManager(java.lang.String,akka.actor.ActorSystem,org.apache.spark.storage.BlockManagerMaster,org.apache.spark.serializer.Serializer,org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.network.BlockTransferService,org.apache.spark.SecurityManager,int)|",
      "|java+constructor:///org/apache/spark/shuffle/ShuffleMemoryManager/ShuffleMemoryManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/logWarning(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService/NettyBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/Predef$/Map()|",
      "|java+method:///org/apache/spark/rpc/RpcAddress/port()|",
      "|java+method:///scala/collection/immutable/Map/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/ExecutorMemoryManager/ExecutorMemoryManager(org.apache.spark.unsafe.memory.MemoryAllocator)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService/NettyBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///org/apache/spark/SparkEnv$/registerOrLookupEndpoint$1(java.lang.String,scala.Function0,org.apache.spark.SparkConf,boolean,org.apache.spark.rpc.RpcEnv)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$2/SparkEnv$$anonfun$2(org.apache.spark.SparkConf,boolean,org.apache.spark.scheduler.LiveListenerBus,org.apache.spark.rpc.RpcEnv)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/MapOutputTracker$/ENDPOINT_NAME()|",
      "|java+method:///scala/collection/immutable/Map$/apply(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/util/Utils$/getLocalDir(org.apache.spark.SparkConf)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$2/SparkEnv$$anonfun$create$2(org.apache.spark.serializer.Serializer)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockManagerMaster$/DRIVER_ENDPOINT_NAME()|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/Predef$/assert(boolean,scala.Function0)|",
      "|java+method:///org/apache/spark/HttpFileServer/serverUri()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$1/SparkEnv$$anonfun$1(java.lang.String)|",
      "|java+constructor:///org/apache/spark/broadcast/BroadcastManager/BroadcastManager(boolean,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/scheduler/OutputCommitCoordinator/coordinatorRef_$eq(scala.Option)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/spark/SparkEnv$/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$1/SparkEnv$$anonfun$create$1()|",
      "|java+constructor:///org/apache/spark/SecurityManager/SecurityManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkEnv/org$apache$spark$SparkEnv$$driverTmpDirToDelete_$eq(scala.Option)|",
      "|java+method:///org/apache/spark/HttpFileServer/initialize()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem/start()|",
      "|java+constructor:///org/apache/spark/network/nio/NioBlockTransferService/NioBlockTransferService(org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$create$3/SparkEnv$$anonfun$create$3(org.apache.spark.SparkConf,org.apache.spark.rpc.RpcEnv,org.apache.spark.MapOutputTracker)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerMaster/MapOutputTrackerMaster(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv$/create(java.lang.String,java.lang.String,int,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+constructor:///org/apache/spark/MapOutputTrackerWorker/MapOutputTrackerWorker(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClass$1(java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///org/apache/spark/MapOutputTracker/trackerEndpoint_$eq(org.apache.spark.rpc.RpcEndpointRef)|",
      "|java+constructor:///org/apache/spark/HttpFileServer/HttpFileServer(org.apache.spark.SparkConf,org.apache.spark.SecurityManager,int)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager/BlockManager(java.lang.String,org.apache.spark.rpc.RpcEnv,org.apache.spark.storage.BlockManagerMaster,org.apache.spark.serializer.Serializer,org.apache.spark.SparkConf,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.network.BlockTransferService,org.apache.spark.SecurityManager,int)|",
      "|java+constructor:///org/apache/spark/CacheManager/CacheManager(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/SparkEnv$/instantiateClassFromConf$1(java.lang.String,java.lang.String,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/spark/SparkEnv$/executorActorSystemName()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/rpc/akka/AkkaRpcEnv/actorSystem()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$3/SparkEnv$$anonfun$3(org.apache.spark.SparkConf,boolean)|",
      "|java+constructor:///org/apache/spark/shuffle/ShuffleMemoryManager/ShuffleMemoryManager(org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/metrics/MetricsSystem$/createMetricsSystem(java.lang.String,org.apache.spark.SparkConf,org.apache.spark.SecurityManager)|",
      "|java+method:///org/apache/spark/util/Utils$/createTempDir(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkEnv/SparkEnv(java.lang.String,org.apache.spark.rpc.RpcEnv,org.apache.spark.serializer.Serializer,org.apache.spark.serializer.Serializer,org.apache.spark.CacheManager,org.apache.spark.MapOutputTracker,org.apache.spark.shuffle.ShuffleManager,org.apache.spark.broadcast.BroadcastManager,org.apache.spark.network.BlockTransferService,org.apache.spark.storage.BlockManager,org.apache.spark.SecurityManager,org.apache.spark.HttpFileServer,java.lang.String,org.apache.spark.metrics.MetricsSystem,org.apache.spark.shuffle.ShuffleMemoryManager,org.apache.spark.unsafe.memory.ExecutorMemoryManager,org.apache.spark.scheduler.OutputCommitCoordinator,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/rpc/RpcEnv/address()|",
      "|java+constructor:///org/apache/spark/storage/BlockManagerMaster/BlockManagerMaster(org.apache.spark.rpc.RpcEndpointRef,org.apache.spark.SparkConf,boolean)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+constructor:///org/apache/spark/SparkEnv$$anonfun$4/SparkEnv$$anonfun$4(org.apache.spark.rpc.RpcEnv,org.apache.spark.scheduler.OutputCommitCoordinator)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.10:1.4.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/executor/Executor$TaskRunner/run()|",
    "called": "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
    "v1Body": [
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$maxResultSize()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/startGCTime_$eq(long)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$4/Executor$TaskRunner$$anonfun$4(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$5/Executor$TaskRunner$$anonfun$5(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$6/Executor$TaskRunner$$anonfun$6(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/releaseMemoryForThisThread()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/shuffle/FetchFailedException/toTaskEndReason()|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/IndirectTaskResult/IndirectTaskResult(org.apache.spark.storage.BlockId,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$1/Executor$TaskRunner$$anonfun$run$1(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleMemoryManager()|",
      "|java+constructor:///org/apache/spark/TaskKilledException/TaskKilledException()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$5/Executor$TaskRunner$$anonfun$run$5(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptedTask_$eq(scala.Option)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$4/Executor$TaskRunner$$anonfun$run$4(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/Executor$TaskRunner$$anonfun$run$2(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$7/Executor$TaskRunner$$anonfun$7(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread$default$1()|",
      "|java+method:///org/apache/spark/scheduler/Task/killed()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/reservedSizeBytes()|",
      "|java+method:///org/apache/spark/TaskState$/FAILED()|",
      "|java+method:///org/apache/spark/TaskState$/KILLED()|",
      "|java+constructor:///org/apache/spark/storage/TaskResultBlockId/TaskResultBlockId(long)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/Accumulators$/clear()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$6/Executor$TaskRunner$$anonfun$run$6(org.apache.spark.executor.Executor$TaskRunner,long)|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/org$apache$spark$executor$Executor$TaskRunner$$$outer()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.Throwable,scala.Option)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult/DirectTaskResult(java.nio.ByteBuffer,scala.collection.mutable.Map,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_AND_DISK_SER()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$EMPTY_BYTE_BUFFER()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptedTask()|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/Task/metrics()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$3/Executor$TaskRunner$$anonfun$run$3(org.apache.spark.executor.Executor$TaskRunner,long,scala.runtime.LongRef,long,long,long)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/MapOutputTracker/updateEpoch(long)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$gcTime()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/killed()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptNumber()|",
      "|java+method:///org/apache/spark/executor/CommitDeniedException/toTaskEndReason()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$4()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel,boolean,scala.Option)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$5()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/util/Utils$/isFatalError(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/util/SparkUncaughtExceptionHandler$/uncaughtException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/executor/ExecutorBackend/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$akkaFrameSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$runningTasks()|",
      "|java+method:///org/apache/spark/scheduler/Task/run(long,int)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task_$eq(org.apache.spark.scheduler.Task)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/Task$/deserializeWithDependencies(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$updateDependencies(scala.collection.mutable.HashMap,scala.collection.mutable.HashMap)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///org/apache/spark/Accumulators$/values()|"
    ],
    "v2Body": [
      "|java+method:///scala/Tuple3/_2()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$maxResultSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$conf()|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/reflect/ClassTag$/Any()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$4/Executor$TaskRunner$$anonfun$4(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$5/Executor$TaskRunner$$anonfun$5(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$6/Executor$TaskRunner$$anonfun$6(org.apache.spark.executor.Executor$TaskRunner,int)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$computeTotalGcTime()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleMemoryManager/releaseMemoryForThisThread()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/shuffle/FetchFailedException/toTaskEndReason()|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkEnv/serializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logDebug(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/IndirectTaskResult/IndirectTaskResult(org.apache.spark.storage.BlockId,int)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread$default$1()|",
      "|java+method:///org/apache/spark/SparkEnv/shuffleMemoryManager()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$6/Executor$TaskRunner$$anonfun$run$6(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/TaskKilledException/TaskKilledException()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$5/Executor$TaskRunner$$anonfun$run$5(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$3/Executor$TaskRunner$$anonfun$run$3(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$2/Executor$TaskRunner$$anonfun$run$2(org.apache.spark.executor.Executor$TaskRunner)|",
      "|java+method:///org/apache/spark/scheduler/Task/killed()|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/reservedSizeBytes()|",
      "|java+method:///org/apache/spark/TaskState$/FAILED()|",
      "|java+method:///org/apache/spark/TaskState$/KILLED()|",
      "|java+constructor:///org/apache/spark/unsafe/memory/TaskMemoryManager/TaskMemoryManager(org.apache.spark.unsafe.memory.ExecutorMemoryManager)|",
      "|java+constructor:///org/apache/spark/storage/TaskResultBlockId/TaskResultBlockId(long)|",
      "|java+constructor:///scala/runtime/LongRef/LongRef(long)|",
      "|java+method:///org/apache/spark/Accumulators$/clear()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$replClassLoader()|",
      "|java+method:///org/apache/spark/serializer/Serializer/newInstance()|",
      "|java+method:///java/lang/Thread/setContextClassLoader(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/org$apache$spark$executor$Executor$TaskRunner$$$outer()|",
      "|java+method:///scala/Option/flatMap(scala.Function1)|",
      "|java+method:///org/apache/spark/storage/BlockManager/memoryStore()|",
      "|java+method:///scala/Tuple3/_1()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/ExceptionFailure/ExceptionFailure(java.lang.Throwable,scala.Option)|",
      "|java+method:///scala/Tuple3/_3()|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/serialize(java.lang.Object,scala.reflect.ClassTag)|",
      "|java+method:///org/apache/spark/SparkEnv/mapOutputTracker()|",
      "|java+constructor:///org/apache/spark/scheduler/DirectTaskResult/DirectTaskResult(java.nio.ByteBuffer,scala.collection.mutable.Map,org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/TaskState$/RUNNING()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0,java.lang.Throwable)|",
      "|java+method:///scala/Option$/apply(java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/StorageLevel$/MEMORY_AND_DISK_SER()|",
      "|java+method:///org/apache/spark/executor/Executor/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/unsafe/memory/TaskMemoryManager/cleanUpAllAllocatedMemory()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$EMPTY_BYTE_BUFFER()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///scala/Option/orNull(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkEnv/blockManager()|",
      "|java+method:///org/apache/spark/scheduler/Task/metrics()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$run$4/Executor$TaskRunner$$anonfun$run$4(org.apache.spark.executor.Executor$TaskRunner,long,scala.runtime.LongRef,long,long,long)|",
      "|java+method:///org/apache/spark/scheduler/Task/setTaskMemoryManager(org.apache.spark.unsafe.memory.TaskMemoryManager)|",
      "|java+method:///org/apache/spark/SparkEnv/closureSerializer()|",
      "|java+method:///org/apache/spark/executor/Executor/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/MapOutputTracker/updateEpoch(long)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/killed()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/attemptNumber()|",
      "|java+method:///org/apache/spark/executor/CommitDeniedException/toTaskEndReason()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Tuple3/Tuple3(java.lang.Object,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$4()|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/taskId()|",
      "|java+method:///org/apache/spark/scheduler/Task/epoch()|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes(org.apache.spark.storage.BlockId,java.nio.ByteBuffer,org.apache.spark.storage.StorageLevel,boolean,scala.Option)|",
      "|java+method:///org/apache/spark/storage/BlockManager/putBytes$default$5()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$7/Executor$TaskRunner$$anonfun$7(org.apache.spark.executor.Executor$TaskRunner,scala.runtime.LongRef)|",
      "|java+method:///org/apache/spark/serializer/SerializerInstance/deserialize(java.nio.ByteBuffer,java.lang.ClassLoader,scala.reflect.ClassTag)|",
      "|java+method:///java/nio/ByteBuffer/limit()|",
      "|java+method:///org/apache/spark/util/Utils$/isFatalError(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/util/SparkUncaughtExceptionHandler$/uncaughtException(java.lang.Throwable)|",
      "|java+method:///org/apache/spark/executor/ExecutorBackend/statusUpdate(long,scala.Enumeration$Value,java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$akkaFrameSize()|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$runningTasks()|",
      "|java+method:///org/apache/spark/scheduler/Task/run(long,int)|",
      "|java+method:///java/lang/System/currentTimeMillis()|",
      "|java+method:///org/apache/spark/executor/Executor/logWarning(scala.Function0)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task_$eq(org.apache.spark.scheduler.Task)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/TaskState$/FINISHED()|",
      "|java+method:///org/apache/spark/scheduler/Task$/deserializeWithDependencies(java.nio.ByteBuffer)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/task()|",
      "|java+method:///java/util/concurrent/ConcurrentHashMap/remove(java.lang.Object)|",
      "|java+method:///org/apache/spark/executor/Executor/org$apache$spark$executor$Executor$$updateDependencies(scala.collection.mutable.HashMap,scala.collection.mutable.HashMap)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+method:///org/apache/spark/SparkEnv/executorMemoryManager()|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/storage/MemoryStore/releaseUnrollMemoryForThisThread(long)|",
      "|java+method:///org/apache/spark/Accumulators$/values()|",
      "|java+constructor:///org/apache/spark/executor/Executor$TaskRunner$$anonfun$3/Executor$TaskRunner$$anonfun$3(org.apache.spark.executor.Executor$TaskRunner,java.lang.String)|",
      "|java+method:///org/apache/spark/executor/Executor$TaskRunner/startGCTime_$eq(long)|"
    ],
    "affectedLib": "org.apache.spark:spark-unsafe_2.10:1.4.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/handleServerAuthentication(org.apache.spark.network.nio.Connection,org.apache.spark.network.nio.SecurityMessage,org.apache.spark.network.nio.ConnectionId)|",
    "called": "|java+method:///org/apache/spark/network/sasl/SparkSaslServer/response(byte%5B%5D)|",
    "v1Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$1/ConnectionManager$$anonfun$handleServerAuthentication$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$2/ConnectionManager$$anonfun$handleServerAuthentication$2(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$3/ConnectionManager$$anonfun$handleServerAuthentication$3(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection,org.apache.spark.network.nio.ConnectionId)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$4/ConnectionManager$$anonfun$handleServerAuthentication$4(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection,org.apache.spark.network.nio.ConnectionId)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendSecurityMessage(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/getToken()|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage$/fromResponse(byte%5B%5D,java.lang.String)|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslServer/SparkSaslServer(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///org/apache/spark/network/nio/Connection/isSaslComplete()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0)|",
      "|java+method:///org/apache/spark/network/nio/Connection/getRemoteConnectionManagerId()|",
      "|java+method:///org/apache/spark/network/nio/Connection/sparkSaslServer()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$6/ConnectionManager$$anonfun$handleServerAuthentication$6(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection)|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/toBufferMessage()|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/getConnectionId()|",
      "|java+method:///org/apache/spark/network/nio/Connection/close()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/network/nio/Connection/sparkSaslServer_$eq(org.apache.spark.network.sasl.SparkSaslServer)|",
      "|java+method:///org/apache/spark/network/sasl/SparkSaslServer/response(byte%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$5/ConnectionManager$$anonfun$handleServerAuthentication$5(org.apache.spark.network.nio.ConnectionManager,java.lang.Exception)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$1/ConnectionManager$$anonfun$handleServerAuthentication$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$2/ConnectionManager$$anonfun$handleServerAuthentication$2(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$3/ConnectionManager$$anonfun$handleServerAuthentication$3(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection,org.apache.spark.network.nio.ConnectionId)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$4/ConnectionManager$$anonfun$handleServerAuthentication$4(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection,org.apache.spark.network.nio.ConnectionId)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/sendSecurityMessage(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.Message)|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/getToken()|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage$/fromResponse(byte%5B%5D,java.lang.String)|",
      "|java+method:///org/apache/spark/network/nio/Connection/isSaslComplete()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logError(scala.Function0)|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslServer/SparkSaslServer(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+method:///org/apache/spark/network/nio/Connection/getRemoteConnectionManagerId()|",
      "|java+method:///org/apache/spark/network/nio/Connection/sparkSaslServer()|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$6/ConnectionManager$$anonfun$handleServerAuthentication$6(org.apache.spark.network.nio.ConnectionManager,org.apache.spark.network.nio.Connection)|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/toBufferMessage()|",
      "|java+method:///org/apache/spark/network/nio/SecurityMessage/getConnectionId()|",
      "|java+method:///org/apache/spark/network/nio/Connection/close()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+method:///org/apache/spark/network/nio/Connection/sparkSaslServer_$eq(org.apache.spark.network.sasl.SparkSaslServer)|",
      "|java+method:///org/apache/spark/network/sasl/SparkSaslServer/response(byte%5B%5D)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+constructor:///java/lang/Exception/Exception(java.lang.String)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$handleServerAuthentication$5/ConnectionManager$$anonfun$handleServerAuthentication$5(org.apache.spark.network.nio.ConnectionManager,java.lang.Exception)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/util/Utils$/memoryStringToMb(java.lang.String)|",
    "called": "|java+method:///org/apache/spark/network/util/JavaUtils/byteStringAsBytes(java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///java/lang/String/length()|",
      "|java+method:///java/lang/String/substring(int,int)|",
      "|java+method:///scala/collection/immutable/StringOps/toLong()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/util/JavaUtils/byteStringAsBytes(java.lang.String)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/init(org.apache.spark.network.BlockDataManager)|",
    "called": "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+method:///scala/Option/toList()|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslRpcHandler/SaslRpcHandler(org.apache.spark.network.server.RpcHandler,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|",
      "|java+method:///org/apache/spark/network/TransportContext/createServer(int)|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/spark/network/sasl/SaslServerBootstrap/SaslServerBootstrap(org.apache.spark.network.util.TransportConf,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///scala/Option/toList()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockTransferService$$anonfun$init$1/NettyBlockTransferService$$anonfun$init$1(org.apache.spark.network.netty.NettyBlockTransferService)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/authEnabled()|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/createServer(scala.collection.immutable.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/serializer()|",
      "|java+constructor:///scala/Some/Some(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/sasl/SaslClientBootstrap/SaslClientBootstrap(org.apache.spark.network.util.TransportConf,java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+constructor:///org/apache/spark/network/TransportContext/TransportContext(org.apache.spark.network.util.TransportConf,org.apache.spark.network.server.RpcHandler)|",
      "|java+method:///org/apache/spark/SecurityManager/isSaslEncryptionEnabled()|",
      "|java+constructor:///org/apache/spark/network/netty/NettyBlockRpcServer/NettyBlockRpcServer(org.apache.spark.serializer.Serializer,org.apache.spark.network.BlockDataManager)|",
      "|java+method:///org/apache/spark/network/TransportContext/createClientFactory(java.util.List)|",
      "|java+method:///org/apache/spark/network/netty/NettyBlockTransferService/transportConf()|",
      "|java+method:///scala/collection/JavaConversions$/seqAsJavaList(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryServer/HistoryServer(org.apache.spark.SparkConf,org.apache.spark.deploy.history.ApplicationHistoryProvider,org.apache.spark.SecurityManager,int)|",
    "called": "|java+method:///org/spark-project/guava/cache/CacheBuilder/build(org.spark-project.guava.cache.CacheLoader)|",
    "v1Body": [
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/ui/WebUI/WebUI(org.apache.spark.SecurityManager,int,org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$5()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/retainedApplications()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$3/HistoryServer$$anon$3(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/build(org.spark-project.guava.cache.CacheLoader)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$4/HistoryServer$$anon$4(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/maximumSize(long)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/initialize()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/appLoader()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1/HistoryServer$$anon$1(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/removalListener(org.spark-project.guava.cache.RemovalListener)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/newBuilder()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/status/api/v1/UIRoot$class/$init$(org.apache.spark.status.api.v1.UIRoot)|",
      "|java+method:///org/apache/spark/SparkConf/getInt(java.lang.String,int)|",
      "|java+constructor:///org/apache/spark/ui/WebUI/WebUI(org.apache.spark.SecurityManager,int,org.apache.spark.SparkConf,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$4()|",
      "|java+method:///org/apache/spark/ui/WebUI$/$lessinit$greater$default$5()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/retainedApplications()|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/maximumSize(long)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$3/HistoryServer$$anon$3(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/build(org.spark-project.guava.cache.CacheLoader)|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$2/HistoryServer$$anon$2(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/initialize()|",
      "|java+method:///org/apache/spark/deploy/history/HistoryServer/appLoader()|",
      "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$1/HistoryServer$$anon$1(org.apache.spark.deploy.history.HistoryServer)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/removalListener(org.spark-project.guava.cache.RemovalListener)|",
      "|java+method:///org/spark-project/guava/cache/CacheBuilder/newBuilder()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+constructor:///org/apache/spark/deploy/history/HistoryServer$$anon$2/HistoryServer$$anon$2(org.apache.spark.deploy.history.HistoryServer)|",
    "called": "|java+constructor:///org/spark-project/guava/cache/CacheLoader/CacheLoader()|",
    "v1Body": [
      "|java+constructor:///java/lang/Thread/Thread(java.lang.String)|"
    ],
    "v2Body": [
      "|java+constructor:///org/spark-project/guava/cache/CacheLoader/CacheLoader()|",
      "|java+constructor:///java/lang/NullPointerException/NullPointerException()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/getBlockData(org.apache.spark.storage.BlockId)|",
    "called": "|java+constructor:///org/apache/spark/network/buffer/NioManagedBuffer/NioManagedBuffer(java.nio.ByteBuffer)|",
    "v1Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockManager/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+constructor:///org/apache/spark/storage/BlockNotFoundException/BlockNotFoundException(java.lang.String)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockManager()|",
      "|java+constructor:///org/apache/spark/network/buffer/NioManagedBuffer/NioManagedBuffer(java.nio.ByteBuffer)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/storage/BlockManager/doGetLocal(org.apache.spark.storage.BlockId,boolean)|",
      "|java+method:///org/apache/spark/storage/BlockId/isShuffle()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/spark/storage/BlockNotFoundException/BlockNotFoundException(java.lang.String)|",
      "|java+method:///org/apache/spark/shuffle/ShuffleManager/shuffleBlockResolver()|",
      "|java+constructor:///org/apache/spark/network/buffer/NioManagedBuffer/NioManagedBuffer(java.nio.ByteBuffer)|",
      "|java+method:///scala/Option/get()|",
      "|java+method:///org/apache/spark/shuffle/ShuffleBlockResolver/getBlockData(org.apache.spark.storage.ShuffleBlockId)|",
      "|java+method:///org/apache/spark/storage/BlockId/toString()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/network/nio/ConnectionManager/checkSendAuthFirst(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection)|",
    "called": "|java+constructor:///org/apache/spark/network/sasl/SparkSaslClient/SparkSaslClient(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
    "v1Body": [
      "|java+method:///org/apache/spark/network/nio/SendingConnection/isSaslComplete()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$checkSendAuthFirst$1/ConnectionManager$$anonfun$checkSendAuthFirst$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/liftedTree1$1(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection,scala.runtime.ObjectRef)|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslClient/SparkSaslClient(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient_$eq(org.apache.spark.network.sasl.SparkSaslClient)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/network/nio/SendingConnection/isSaslComplete()|",
      "|java+constructor:///org/apache/spark/network/sasl/SparkSaslClient/SparkSaslClient(java.lang.String,org.apache.spark.network.sasl.SecretKeyHolder,boolean)|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/logDebug(scala.Function0)|",
      "|java+constructor:///scala/runtime/ObjectRef/ObjectRef(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/network/nio/ConnectionManager$$anonfun$checkSendAuthFirst$1/ConnectionManager$$anonfun$checkSendAuthFirst$1(org.apache.spark.network.nio.ConnectionManager)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient()|",
      "|java+method:///org/apache/spark/network/nio/ConnectionManager/liftedTree1$1(org.apache.spark.network.nio.ConnectionManagerId,org.apache.spark.network.nio.SendingConnection,scala.runtime.ObjectRef)|",
      "|java+method:///org/apache/spark/network/nio/SendingConnection/sparkSaslClient_$eq(org.apache.spark.network.sasl.SparkSaslClient)|",
      "|java+method:///org/apache/spark/SparkConf/getAppId()|"
    ],
    "affectedLib": "org.apache.spark:spark-network-common_2.10:1.4.0",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/start()|",
    "called": "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/build()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anon$1/CoarseMesosSchedulerBackend$$anon$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/waitForRegister()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anon$1/start()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/start()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/startScheduler(java.lang.String,org.apache.mesos.Scheduler,org.apache.mesos.Protos$FrameworkInfo)|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/setUser(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo/newBuilder()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
    "called": "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ACTOR_NAME()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/spark/SparkEnv/actorSystem()|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId()|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/env()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/build()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/address(java.lang.String,java.lang.String,java.lang.String,java.lang.Object,java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$1/CoarseMesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$2/CoarseMesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$3/CoarseMesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$4/CoarseMesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$5/CoarseMesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/conf()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/util/AkkaUtils$/protocol(akka.actor.ActorSystem)|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend$/ENDPOINT_NAME()|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String)|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$1/CoarseMesosSchedulerBackend$$anonfun$createCommand$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$createCommand$2/CoarseMesosSchedulerBackend$$anonfun$createCommand$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/spark/SparkEnv$/driverActorSystemName()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/stop()|",
    "called": "|java+method:///org/apache/mesos/MesosSchedulerDriver/stop()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/driver()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/stop()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stop()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/stop()|",
      "|java+method:///org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend/stop()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosDriver()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/registered(org.apache.mesos.SchedulerDriver,org.apache.mesos.Protos$FrameworkID,org.apache.mesos.Protos$MasterInfo)|",
    "called": "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/registeredLock()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$registered$1/CoarseMesosSchedulerBackend$$anonfun$registered$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId_$eq(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/isRegistered_$eq(boolean)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/markRegistered()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$registered$1/CoarseMesosSchedulerBackend$$anonfun$registered$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/appId_$eq(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/Collections/singletonList(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///java/util/Collections/emptyList()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$createResource(java.lang.String,double)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///java/util/Collections/singletonList(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/extraCoresPerSlave()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/newMesosTaskId()|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/totalCoresAcquired_$eq(int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+method:///scala/collection/mutable/HashSet/$plus$eq(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2/CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend$$anonfun$resourceOffers$1,org.apache.mesos.Protos$TaskInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setSlaveId(org.apache.mesos.Protos$SlaveID)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo)|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///java/util/Collections/emptyList()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/org$apache$spark$scheduler$cluster$mesos$CoarseMesosSchedulerBackend$$createResource(java.lang.String,double)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setName(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/maxCores()|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$TaskInfo$Builder/setTaskId(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/toString()|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+method:///scala/math/package$/min(int,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/createCommand(org.apache.mesos.Protos$Offer,int)|",
      "|java+method:///java/util/Collections/singleton(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/mesos/SchedulerDriver/launchTasks(java.util.Collection,java.util.Collection,org.apache.mesos.Protos$Filters)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/scheduler/WorkerOffer/WorkerOffer(java.lang.String,java.lang.String,int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/start()|",
    "called": "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/build()|",
    "v1Body": [
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/classLoader_$eq(java.lang.ClassLoader)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anon$1/MesosSchedulerBackend$$anon$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/waitForRegister()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anon$1/start()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+method:///org/apache/spark/SparkContext/sparkUser()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/startScheduler(java.lang.String,org.apache.mesos.Scheduler,org.apache.mesos.Protos$FrameworkInfo)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/classLoader_$eq(java.lang.ClassLoader)|",
      "|java+method:///org/apache/spark/SparkContext/appName()|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/setUser(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$FrameworkInfo/newBuilder()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecutorInfo(java.lang.String)|",
    "called": "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/CPUS_PER_TASK()|",
      "|java+method:///org/apache/spark/SparkConf/get(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/setValue(double)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setCommand(org.apache.mesos.Protos$CommandInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Environment$Builder/addVariables(org.apache.mesos.Protos$Environment$Variable)|",
      "|java+method:///org/apache/spark/SparkContext/executorEnvs()|",
      "|java+method:///org/apache/mesos/protobuf/ByteString/copyFrom(byte%5B%5D)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+method:///scala/Option/orElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI$Builder/setValue(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$3/MesosSchedulerBackend$$anonfun$createExecutorInfo$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$ExecutorInfo$Builder)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/addResources(org.apache.mesos.Protos$Resource)|",
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar$Builder/build()|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setExecutorId(org.apache.mesos.Protos$ExecutorID)|",
      "|java+method:///org/apache/mesos/Protos$Environment/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource/newBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/getOption(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setName(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setName(java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo$Builder/setData(org.apache.mesos.protobuf.ByteString)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/createExecArg()|",
      "|java+method:///scala/Option/map(scala.Function1)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/addUris(org.apache.mesos.Protos$CommandInfo$URI$Builder)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/build()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$1/MesosSchedulerBackend$$anonfun$createExecutorInfo$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/mesos/Protos$ExecutorInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setEnvironment(org.apache.mesos.Protos$Environment$Builder)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+method:///org/apache/mesos/Protos$Value$Scalar/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$createExecutorInfo$2/MesosSchedulerBackend$$anonfun$createExecutorInfo$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend,org.apache.mesos.Protos$Environment$Builder)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$1/MesosSchedulerBackend$$anonfun$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$2/MesosSchedulerBackend$$anonfun$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$3/MesosSchedulerBackend$$anonfun$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$4/MesosSchedulerBackend$$anonfun$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$5/MesosSchedulerBackend$$anonfun$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$6/MesosSchedulerBackend$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend)|",
      "|java+method:///scala/collection/mutable/ArrayOps/last()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo$URI/newBuilder()|",
      "|java+method:///java/io/File/getCanonicalPath()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MemoryUtils$/calculateTotalMemory(org.apache.spark.SparkContext)|",
      "|java+method:///scala/collection/immutable/StringOps/split(char)|",
      "|java+method:///scala/Option/getOrElse(scala.Function0)|",
      "|java+method:///org/apache/mesos/Protos$ExecutorID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setType(org.apache.mesos.Protos$Value$Type)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///org/apache/mesos/Protos$Environment$Variable$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$CommandInfo/newBuilder()|",
      "|java+method:///org/apache/mesos/Protos$Resource$Builder/setScalar(org.apache.mesos.Protos$Value$Scalar)|",
      "|java+method:///scala/collection/mutable/ArrayOps/head()|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$registered$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/registeredLock()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/appId_$eq(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/isRegistered_$eq(boolean)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$registered$1$$anonfun$apply$mcV$sp$1/MesosSchedulerBackend$$anonfun$registered$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$registered$1)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/markRegistered()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/appId_$eq(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$registered$1$$anonfun$apply$mcV$sp$1/MesosSchedulerBackend$$anonfun$registered$1$$anonfun$apply$mcV$sp$1(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$registered$1)|",
      "|java+method:///org/apache/mesos/Protos$FrameworkID/getValue()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/SparkContext$/org$apache$spark$SparkContext$$createTaskScheduler(org.apache.spark.SparkContext,java.lang.String)|",
    "called": "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
    "v1Body": [
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$41/SparkContext$$anonfun$41()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/shutdownCallback_$eq(scala.Function1)|",
      "|java+method:///scala/Option/isEmpty()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SimrSchedulerBackend/SimrSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/SparkDeploySchedulerBackend/SparkDeploySchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String%5B%5D)|",
      "|java+constructor:///scala/StringContext/StringContext(scala.collection.Seq)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/initialize(org.apache.spark.scheduler.SchedulerBackend)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$1()|",
      "|java+method:///scala/collection/LinearSeqOptimized/lengthCompare(int)|",
      "|java+method:///scala/collection/immutable/StringOps/stripPrefix(java.lang.String)|",
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///java/lang/Class/forName(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/getConf()|",
      "|java+method:///java/lang/reflect/Constructor/newInstance(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkException/SparkException(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkConf/getBoolean(java.lang.String,boolean)|",
      "|java+method:///org/apache/spark/SparkContext/executorMemory()|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1(org.apache.spark.deploy.LocalSparkCluster)|",
      "|java+method:///org/apache/mesos/MesosNativeLibrary/load()|",
      "|java+method:///java/lang/Object/equals(java.lang.Object)|",
      "|java+method:///scala/collection/LinearSeqOptimized/apply(int)|",
      "|java+method:///scala/util/matching/Regex/unapplySeq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$45/SparkContext$$anonfun$45()|",
      "|java+constructor:///org/apache/spark/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2/SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/CoarseMesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/collection/immutable/StringOps/r()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/MesosSchedulerBackend(org.apache.spark.scheduler.TaskSchedulerImpl,org.apache.spark.SparkContext,java.lang.String)|",
      "|java+method:///scala/Predef$/wrapRefArray(java.lang.Object%5B%5D)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+constructor:///org/apache/spark/scheduler/local/LocalBackend/LocalBackend(org.apache.spark.SparkConf,org.apache.spark.scheduler.TaskSchedulerImpl,int)|",
      "|java+constructor:///org/apache/spark/deploy/LocalSparkCluster/LocalSparkCluster(int,int,int,org.apache.spark.SparkConf)|",
      "|java+method:///org/apache/spark/SparkContext/conf()|",
      "|java+constructor:///scala/collection/mutable/StringBuilder/StringBuilder()|",
      "|java+method:///scala/Predef$/genericWrapArray(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkContext$/localCpuCount$2()|",
      "|java+method:///org/apache/spark/deploy/LocalSparkCluster/start()|",
      "|java+method:///java/lang/Class/getConstructor(java.lang.Class%5B%5D)|",
      "|java+method:///scala/collection/mutable/StringBuilder/append(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext)|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/TaskSchedulerImpl/TaskSchedulerImpl(org.apache.spark.SparkContext,int,boolean)|",
      "|java+method:///org/apache/spark/SparkContext$/logWarning(scala.Function0)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+method:///scala/StringContext/s(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/StringBuilder/toString()|",
      "|java+method:///scala/collection/immutable/StringOps/format(scala.collection.Seq)|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/statusUpdate(org.apache.mesos.SchedulerDriver,org.apache.mesos.Protos$TaskStatus)|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
    "v1Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/driver()|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/reviveOffers()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|"
    ],
    "v2Body": [
      "|java+method:///scala/Option/foreach(scala.Function1)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/failuresBySlaveId()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$1(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/MAX_SLAVE_FAILURES()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/logInfo(scala.Function0)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$4(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,java.lang.String)|",
      "|java+method:///org/apache/spark/TaskState$/isFinished(scala.Enumeration$Value)|",
      "|java+method:///scala/collection/mutable/HashMap/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/runtime/BoxesRunTime/unboxToInt(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/coresByTaskId()|",
      "|java+method:///scala/collection/mutable/HashSet/$minus$eq(java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/update(java.lang.Object,java.lang.Object)|",
      "|java+method:///scala/collection/mutable/HashMap/getOrElse(java.lang.Object,scala.Function0)|",
      "|java+method:///scala/Predef$/augmentString(java.lang.String)|",
      "|java+method:///scala/collection/mutable/HashMap/apply(java.lang.Object)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$3(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/taskIdToSlaveId()|",
      "|java+method:///org/apache/spark/TaskState$/isFailed(scala.Enumeration$Value)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getTaskId()|",
      "|java+method:///scala/collection/mutable/HashMap/get(java.lang.Object)|",
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/reviveOffers()|",
      "|java+method:///scala/collection/immutable/StringOps/toInt()|",
      "|java+method:///org/apache/spark/TaskState$/fromMesos(org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToInteger(int)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/getValue()|",
      "|java+constructor:///scala/collection/immutable/StringOps/StringOps(java.lang.String)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend/mesosDriver()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2/CoarseMesosSchedulerBackend$$anonfun$statusUpdate$2(org.apache.spark.scheduler.cluster.mesos.CoarseMesosSchedulerBackend,int,org.apache.mesos.Protos$TaskState)|",
      "|java+method:///org/apache/mesos/Protos$TaskStatus/getState()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/apply$mcV$sp()|",
    "called": "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/setRefuseSeconds(double)|",
      "|java+method:///scala/collection/mutable/HashMap/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/HashSet$/apply(scala.collection.Seq)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///scala/collection/JavaConversions$/asScalaBuffer(java.util.List)|",
      "|java+method:///scala/collection/TraversableOnce/toMap(scala.Predef$$less$colon$less)|",
      "|java+constructor:///scala/MatchError/MatchError(java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Filters$Builder/build()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$5(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///scala/collection/mutable/Buffer$/canBuildFrom()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$10(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/Seq/filter(scala.Function1)|",
      "|java+method:///scala/collection/Seq/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$4(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$11/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$11(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/collection/mutable/Buffer/foreach(scala.Function1)|",
      "|java+method:///scala/collection/mutable/Buffer/partition(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$2(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.mutable.HashMap,scala.collection.mutable.HashSet)|",
      "|java+method:///scala/collection/generic/FilterMonadic/foreach(scala.Function1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$9(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$7(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///org/apache/mesos/Protos$Filters/newBuilder()|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$3(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1,scala.collection.immutable.Map,scala.collection.immutable.Map,org.apache.mesos.Protos$Filters)|",
      "|java+constructor:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$apply$mcV$sp$6(org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend$$anonfun$resourceOffers$1)|",
      "|java+method:///scala/Predef$/conforms()|",
      "|java+constructor:///scala/collection/mutable/HashMap/HashMap()|",
      "|java+constructor:///scala/Tuple2/Tuple2(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/TaskSchedulerImpl/resourceOffers(scala.collection.Seq)|",
      "|java+method:///scala/collection/mutable/Buffer/withFilter(scala.Function1)|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/stop()|",
    "called": "|java+method:///org/apache/mesos/MesosSchedulerDriver/stop()|",
    "v1Body": [
      "|java+method:///org/apache/mesos/SchedulerDriver/stop()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/driver()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/stop()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosDriver()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1$$anonfun$8/apply(org.apache.mesos.Protos$Offer)|",
    "called": "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///scala/Predef$/any2ArrowAssoc(java.lang.Object)|",
      "|java+method:///scala/Predef$ArrowAssoc$/$minus$greater$extension(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$SlaveID/getValue()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend$$anonfun$resourceOffers$1/org$apache$spark$scheduler$cluster$mesos$MesosSchedulerBackend$$anonfun$$$outer()|",
      "|java+constructor:///org/apache/spark/scheduler/WorkerOffer/WorkerOffer(java.lang.String,java.lang.String,int)|",
      "|java+method:///scala/collection/mutable/HashSet/contains(java.lang.Object)|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosExecutorCores()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/slaveIdsWithExecutors()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getSlaveId()|",
      "|java+method:///org/apache/mesos/Protos$Offer/getHostname()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/getResource(java.util.List,java.lang.String)|",
      "|java+method:///org/apache/mesos/Protos$Offer/getResourcesList()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/killTask(long,java.lang.String,boolean)|",
    "called": "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
    "v1Body": [
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/driver()|",
      "|java+method:///org/apache/mesos/SchedulerDriver/killTask(org.apache.mesos.Protos$TaskID)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/build()|",
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/spark/scheduler/cluster/mesos/MesosSchedulerBackend/mesosDriver()|",
      "|java+method:///org/apache/mesos/Protos$TaskID$Builder/setValue(java.lang.String)|",
      "|java+method:///org/apache/mesos/MesosSchedulerDriver/killTask(org.apache.mesos.Protos$TaskID)|",
      "|java+method:///scala/runtime/BoxesRunTime/boxToLong(long)|",
      "|java+method:///org/apache/mesos/Protos$TaskID/newBuilder()|"
    ],
    "affectedLib": "org.apache.mesos:mesos:0.21.1",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.spark:spark-core_2.10:1.3.1",
    "coordinatesV2": "org.apache.spark:spark-core_2.10:1.4.0",
    "caller": "|java+method:///org/apache/spark/storage/BlockManager/registerWithExternalShuffleServer()|",
    "called": "|java+constructor:///org/apache/spark/network/shuffle/protocol/ExecutorShuffleInfo/ExecutorShuffleInfo(java.lang.String%5B%5D,int,java.lang.String)|",
    "v1Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$1/BlockManager$$anonfun$registerWithExternalShuffleServer$1(org.apache.spark.storage.BlockManager,org.apache.spark.network.shuffle.protocol.ExecutorShuffleInfo,int,int,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/localDirs()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/ExecutorShuffleInfo/ExecutorShuffleInfo(java.lang.String%5B%5D,int,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirsPerLocalDir()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$2/BlockManager$$anonfun$registerWithExternalShuffleServer$2(org.apache.spark.storage.BlockManager)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$6/BlockManager$$anonfun$6(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "v2Body": [
      "|java+method:///scala/reflect/ClassTag$/apply(java.lang.Class)|",
      "|java+method:///scala/Predef$/intWrapper(int)|",
      "|java+method:///scala/Array$/canBuildFrom(scala.reflect.ClassTag)|",
      "|java+method:///scala/collection/mutable/ArrayOps/map(scala.Function1,scala.collection.generic.CanBuildFrom)|",
      "|java+method:///org/apache/spark/storage/BlockManager/diskBlockManager()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$1/BlockManager$$anonfun$registerWithExternalShuffleServer$1(org.apache.spark.storage.BlockManager,org.apache.spark.network.shuffle.protocol.ExecutorShuffleInfo,int,int,java.lang.Object)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/value$mcV$sp()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/localDirs()|",
      "|java+method:///scala/collection/immutable/Range$Inclusive/foreach$mVc$sp(scala.Function1)|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$5/BlockManager$$anonfun$5(org.apache.spark.storage.BlockManager)|",
      "|java+method:///scala/Predef$/refArrayOps(java.lang.Object%5B%5D)|",
      "|java+constructor:///org/apache/spark/network/shuffle/protocol/ExecutorShuffleInfo/ExecutorShuffleInfo(java.lang.String%5B%5D,int,java.lang.String)|",
      "|java+method:///org/apache/spark/storage/DiskBlockManager/subDirsPerLocalDir()|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+constructor:///org/apache/spark/storage/BlockManager$$anonfun$registerWithExternalShuffleServer$2/BlockManager$$anonfun$registerWithExternalShuffleServer$2(org.apache.spark.storage.BlockManager)|",
      "|java+method:///org/apache/spark/storage/BlockManager/logInfo(scala.Function0)|",
      "|java+method:///scala/runtime/NonLocalReturnControl/key()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///scala/runtime/RichInt$/to$extension0(int,int)|"
    ],
    "affectedLib": "org.apache.spark:spark-network-shuffle_2.10:1.4.0",
    "change": "UPDATED"
  }
]