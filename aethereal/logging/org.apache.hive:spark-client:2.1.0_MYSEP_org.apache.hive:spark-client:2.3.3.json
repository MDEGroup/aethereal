[
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+constructor:///org/apache/hive/spark/client/RemoteDriver/RemoteDriver(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListener)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "v2Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListenerInterface)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBlocksFetched()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(int,int,long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBytesRead()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/fetchWaitTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBlocksFetched()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(long,long,long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBytesRead()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/fetchWaitTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+method:///org/apache/hive/spark/client/SparkClientImpl/startDriver(org.apache.hive.spark.client.rpc.RpcServer,java.lang.String,java.lang.String)|",
    "called": "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///com/google/common/collect/Lists/newArrayList()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClientMode(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/getSparkJobCredentialProviderPassword()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/List/addAll(java.util.Collection)|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/get(java.lang.String)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/commons/lang3/StringUtils/isNotBlank(java.lang.CharSequence)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClusterMode(java.lang.String,java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///com/google/common/base/Strings/emptyToNull(java.lang.String)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+method:///org/apache/hive/spark/client/metrics/Metrics/optionalShuffleReadMetric(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
    "v1Body": [
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/hive/spark/client/metrics/DataReadMethod/valueOf(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.hive.spark.client.metrics.DataReadMethod,long)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/readMethod()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(long)|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
    "v1Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleBytesWritten()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleBytesWritten()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver)|",
    "called": "|java+constructor:///org/apache/spark/JavaSparkListener/JavaSparkListener()|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+constructor:///org/apache/spark/JavaSparkListener/JavaSparkListener()|"
    ],
    "v2Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListener/SparkListener()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.3.3",
    "coordinatesV2": "org.apache.hive:spark-client:2.1.0",
    "caller": "|java+method:///org/apache/hive/spark/client/metrics/Metrics/optionalInputMetric(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
    "v1Body": [
      "|java+method:///scala/Option/isDefined()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.spark.executor.TaskMetrics)|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.10:1.6.0",
    "change": "REMOVED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/RemoteDriver/RemoteDriver(java.lang.String%5B%5D)|",
    "called": "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListenerInterface)|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListener)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "v2Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListenerInterface)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
    "v1Body": [
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBlocksFetched()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(int,int,long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBytesRead()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/fetchWaitTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBlocksFetched()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/localBlocksFetched()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleReadMetrics/ShuffleReadMetrics(long,long,long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/remoteBytesRead()|",
      "|java+method:///org/apache/spark/executor/ShuffleReadMetrics/fetchWaitTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleReadMetrics()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+method:///org/apache/hive/spark/client/SparkClientImpl/startDriver(org.apache.hive.spark.client.rpc.RpcServer,java.lang.String,java.lang.String)|",
    "called": "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///com/google/common/collect/Lists/newArrayList()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClientMode(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/getSparkJobCredentialProviderPassword()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/List/addAll(java.util.Collection)|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/get(java.lang.String)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/commons/lang3/StringUtils/isNotBlank(java.lang.CharSequence)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClusterMode(java.lang.String,java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///com/google/common/base/Strings/emptyToNull(java.lang.String)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
    "v1Body": [
      "|java+method:///java/lang/Object/toString()|",
      "|java+method:///org/apache/hive/spark/client/metrics/DataReadMethod/valueOf(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(org.apache.hive.spark.client.metrics.DataReadMethod,long)|",
      "|java+method:///org/apache/spark/executor/InputMetrics/readMethod()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///org/apache/spark/executor/TaskMetrics/inputMetrics()|",
      "|java+method:///org/apache/spark/executor/InputMetrics/bytesRead()|",
      "|java+constructor:///org/apache/hive/spark/client/metrics/InputMetrics/InputMetrics(long)|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(org.apache.spark.executor.TaskMetrics)|",
    "called": "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
    "v1Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleBytesWritten()|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hive/spark/client/metrics/ShuffleWriteMetrics/ShuffleWriteMetrics(long,long)|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleWriteTime()|",
      "|java+method:///org/apache/spark/executor/TaskMetrics/shuffleWriteMetrics()|",
      "|java+method:///org/apache/spark/executor/ShuffleWriteMetrics/shuffleBytesWritten()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver)|",
    "called": "|java+constructor:///org/apache/spark/scheduler/SparkListener/SparkListener()|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+constructor:///org/apache/spark/JavaSparkListener/JavaSparkListener()|"
    ],
    "v2Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+constructor:///org/apache/spark/scheduler/SparkListener/SparkListener()|"
    ],
    "affectedLib": "org.apache.spark:spark-core_2.11:2.0.0",
    "change": "ADDED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/RemoteDriver/RemoteDriver(java.lang.String%5B%5D)|",
    "called": "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
    "v1Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListener)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "v2Body": [
      "|java+method:///com/google/common/collect/Maps/newHashMap()|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object,java.lang.Object)|",
      "|java+method:///org/apache/spark/api/java/JavaSparkContext/sc()|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///org/apache/spark/SparkConf/getAll()|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///org/slf4j/Logger/debug(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver$JobWrapper/submit()|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///java/lang/String/split(java.lang.String,int)|",
      "|java+method:///org/apache/spark/SparkContext/addSparkListener(org.apache.spark.scheduler.SparkListenerInterface)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/getArg(java.lang.String%5B%5D,int)|",
      "|java+constructor:///org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)|",
      "|java+method:///scala/Tuple2/_1()|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+method:///scala/Tuple2/_2()|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///org/apache/spark/SparkConf/SparkConf()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/JobContextImpl/JobContextImpl(org.apache.spark.api.java.JavaSparkContext,java.io.File)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$DriverProtocol/RemoteDriver$DriverProtocol(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/addListener(org.apache.hive.spark.client.rpc.Rpc$Listener)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$ClientListener/RemoteDriver$ClientListener(org.apache.hive.spark.client.RemoteDriver,org.apache.hive.spark.client.RemoteDriver$1)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/RemoteDriver/shutdown(java.lang.Throwable)|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/io/Files/createTempDir()|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/spark/SparkConf/set(java.lang.String,java.lang.String)|",
      "|java+method:///org/slf4j/Logger/error(java.lang.String,java.lang.Throwable)|",
      "|java+constructor:///org/apache/hive/spark/client/RemoteDriver$1/RemoteDriver$1(org.apache.hive.spark.client.RemoteDriver)|",
      "|java+method:///java/lang/Object/notifyAll()|",
      "|java+method:///java/lang/Integer/parseInt(java.lang.String)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+constructor:///java/lang/IllegalArgumentException/IllegalArgumentException(java.lang.String)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+method:///io/netty/util/concurrent/Promise/get()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///java/util/List/iterator()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+method:///java/util/concurrent/Executors/newCachedThreadPool()|"
    ],
    "affectedLib": "io.netty:netty-all:4.0.52.Final",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+method:///org/apache/hive/spark/client/rpc/Rpc/createClient(java.util.Map,io.netty.channel.nio.NioEventLoopGroup,java.lang.String,int,java.lang.String,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher)|",
    "called": "|java+constructor:///io/netty/bootstrap/Bootstrap/Bootstrap()|",
    "v1Body": [
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$4/Rpc$4(io.netty.channel.ChannelFuture)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$1/Rpc$1()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/group(io.netty.channel.EventLoopGroup)|",
      "|java+method:///io/netty/channel/nio/NioEventLoopGroup/next()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getServerConnectTimeoutMs()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicReference/AtomicReference()|",
      "|java+method:///io/netty/channel/EventLoop/newPromise()|",
      "|java+method:///io/netty/util/concurrent/Promise/addListener(io.netty.util.concurrent.GenericFutureListener)|",
      "|java+method:///io/netty/bootstrap/Bootstrap/handler(io.netty.channel.ChannelHandler)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///io/netty/bootstrap/Bootstrap/channel(java.lang.Class)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getConnectTimeoutMs()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/connect(java.lang.String,int)|",
      "|java+method:///io/netty/channel/nio/NioEventLoopGroup/schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$2/Rpc$2(io.netty.util.concurrent.Promise)|",
      "|java+method:///java/lang/Boolean/valueOf(boolean)|",
      "|java+method:///io/netty/channel/ChannelFuture/addListener(io.netty.util.concurrent.GenericFutureListener)|",
      "|java+constructor:///io/netty/bootstrap/Bootstrap/Bootstrap()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/option(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$3/Rpc$3(org.apache.hive.spark.client.rpc.RpcConfiguration,java.lang.String,io.netty.util.concurrent.Promise,io.netty.util.concurrent.ScheduledFuture,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher,io.netty.channel.nio.NioEventLoopGroup)|"
    ],
    "v2Body": [
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$4/Rpc$4(io.netty.channel.ChannelFuture)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$1/Rpc$1()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/group(io.netty.channel.EventLoopGroup)|",
      "|java+method:///io/netty/channel/nio/NioEventLoopGroup/next()|",
      "|java+constructor:///java/util/concurrent/atomic/AtomicReference/AtomicReference()|",
      "|java+method:///io/netty/channel/EventLoop/newPromise()|",
      "|java+method:///io/netty/util/concurrent/Promise/addListener(io.netty.util.concurrent.GenericFutureListener)|",
      "|java+method:///io/netty/bootstrap/Bootstrap/handler(io.netty.channel.ChannelHandler)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///io/netty/bootstrap/Bootstrap/channel(java.lang.Class)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getConnectTimeoutMs()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/connect(java.lang.String,int)|",
      "|java+method:///io/netty/channel/nio/NioEventLoopGroup/schedule(java.lang.Runnable,long,java.util.concurrent.TimeUnit)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$2/Rpc$2(io.netty.util.concurrent.Promise)|",
      "|java+method:///java/lang/Boolean/valueOf(boolean)|",
      "|java+method:///io/netty/channel/ChannelFuture/addListener(io.netty.util.concurrent.GenericFutureListener)|",
      "|java+constructor:///io/netty/bootstrap/Bootstrap/Bootstrap()|",
      "|java+method:///io/netty/bootstrap/Bootstrap/option(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/Rpc$3/Rpc$3(org.apache.hive.spark.client.rpc.RpcConfiguration,java.lang.String,io.netty.util.concurrent.Promise,io.netty.util.concurrent.ScheduledFuture,java.lang.String,org.apache.hive.spark.client.rpc.RpcDispatcher,io.netty.channel.nio.NioEventLoopGroup)|"
    ],
    "affectedLib": "io.netty:netty-all:4.0.52.Final",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+method:///org/apache/hive/spark/client/rpc/Rpc$5/channelInactive(io.netty.channel.ChannelHandlerContext)|",
    "called": "|java+method:///io/netty/channel/ChannelInboundHandlerAdapter/channelInactive(io.netty.channel.ChannelHandlerContext)|",
    "v1Body": [
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/close()|"
    ],
    "v2Body": [
      "|java+method:///io/netty/channel/ChannelInboundHandlerAdapter/channelInactive(io.netty.channel.ChannelHandlerContext)|",
      "|java+method:///org/apache/hive/spark/client/rpc/Rpc/close()|"
    ],
    "affectedLib": "io.netty:netty-all:4.0.52.Final",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+constructor:///org/apache/hive/spark/client/rpc/RpcServer/RpcServer(java.util.Map)|",
    "called": "|java+method:///io/netty/bootstrap/ServerBootstrap/childOption(io.netty.channel.ChannelOption,java.lang.Object)|",
    "v1Body": [
      "|java+method:///io/netty/channel/ChannelFuture/sync()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/bind(int)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/group(io.netty.channel.EventLoopGroup)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///io/netty/bootstrap/ServerBootstrap/ServerBootstrap()|",
      "|java+method:///io/netty/channel/ChannelFuture/channel()|",
      "|java+method:///io/netty/channel/Channel/localAddress()|",
      "|java+method:///java/lang/Boolean/valueOf(boolean)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getServerAddress()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/channel(java.lang.Class)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/childOption(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+method:///java/net/InetSocketAddress/getPort()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcServer$1/RpcServer$1(org.apache.hive.spark.client.rpc.RpcServer)|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/option(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/childHandler(io.netty.channel.ChannelHandler)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|"
    ],
    "v2Body": [
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getRpcThreadCount()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/group(io.netty.channel.EventLoopGroup)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setNameFormat(java.lang.String)|",
      "|java+constructor:///io/netty/bootstrap/ServerBootstrap/ServerBootstrap()|",
      "|java+method:///io/netty/channel/ChannelFuture/channel()|",
      "|java+method:///io/netty/channel/Channel/localAddress()|",
      "|java+method:///java/lang/Boolean/valueOf(boolean)|",
      "|java+constructor:///io/netty/channel/nio/NioEventLoopGroup/NioEventLoopGroup(int,java.util.concurrent.ThreadFactory)|",
      "|java+constructor:///java/lang/Object/Object()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getServerAddress()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/channel(java.lang.Class)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/bindServerPort(io.netty.bootstrap.ServerBootstrap)|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/setDaemon(boolean)|",
      "|java+constructor:///com/google/common/util/concurrent/ThreadFactoryBuilder/ThreadFactoryBuilder()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/childOption(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+method:///java/net/InetSocketAddress/getPort()|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcServer$1/RpcServer$1(org.apache.hive.spark.client.rpc.RpcServer)|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/option(io.netty.channel.ChannelOption,java.lang.Object)|",
      "|java+method:///java/lang/Integer/valueOf(int)|",
      "|java+method:///com/google/common/collect/Maps/newConcurrentMap()|",
      "|java+method:///com/google/common/util/concurrent/ThreadFactoryBuilder/build()|",
      "|java+method:///io/netty/bootstrap/ServerBootstrap/childHandler(io.netty.channel.ChannelHandler)|",
      "|java+constructor:///org/apache/hive/spark/client/rpc/RpcConfiguration/RpcConfiguration(java.util.Map)|"
    ],
    "affectedLib": "io.netty:netty-all:4.0.52.Final",
    "change": "UPDATED"
  },
  {
    "coordinatesV1": "org.apache.hive:spark-client:2.1.0",
    "coordinatesV2": "org.apache.hive:spark-client:2.3.3",
    "caller": "|java+method:///org/apache/hive/spark/client/SparkClientImpl/startDriver(org.apache.hive.spark.client.rpc.RpcServer,java.lang.String,java.lang.String)|",
    "called": "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
    "v1Body": [
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///com/google/common/collect/Lists/newArrayList()|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "v2Body": [
      "|java+method:///java/util/Properties/get(java.lang.Object)|",
      "|java+method:///java/io/File/setReadable(boolean)|",
      "|java+method:///java/util/Map/containsKey(java.lang.Object)|",
      "|java+method:///org/apache/hadoop/security/SecurityUtil/getServerPrincipal(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getErrorStream()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClientMode(java.lang.String,java.lang.String)|",
      "|java+method:///java/lang/Process/getInputStream()|",
      "|java+method:///java/util/concurrent/atomic/AtomicInteger/incrementAndGet()|",
      "|java+method:///java/lang/String/equalsIgnoreCase(java.lang.String)|",
      "|java+method:///java/util/Map/put(java.lang.Object,java.lang.Object)|",
      "|java+constructor:///java/util/ArrayList/ArrayList()|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/getSparkJobCredentialProviderPassword()|",
      "|java+method:///java/lang/ClassLoader/getResource(java.lang.String)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream,java.util.List)|",
      "|java+constructor:///java/lang/IllegalStateException/IllegalStateException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/lang/String/split(java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Object,java.lang.Object,java.lang.Object%5B%5D)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String)|",
      "|java+method:///org/slf4j/Logger/warn(java.lang.String)|",
      "|java+constructor:///java/io/IOException/IOException(java.lang.String,java.lang.Throwable)|",
      "|java+method:///java/util/Properties/store(java.io.Writer,java.lang.String)|",
      "|java+method:///java/util/Iterator/hasNext()|",
      "|java+method:///java/lang/String/toLowerCase()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$Redirector/SparkClientImpl$Redirector(org.apache.hive.spark.client.SparkClientImpl,java.io.InputStream)|",
      "|java+method:///com/google/common/io/Resources/toByteArray(java.net.URL)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.String)|",
      "|java+method:///java/util/Map$Entry/getKey()|",
      "|java+method:///java/lang/String/trim()|",
      "|java+method:///scala/Option/isDefined()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcConfiguration/getValue(org.apache.hadoop.hive.conf.HiveConf,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientImpl/redirect(java.lang.String,org.apache.hive.spark.client.SparkClientImpl$Redirector)|",
      "|java+method:///java/lang/StringBuilder/append(int)|",
      "|java+method:///com/google/common/base/Joiner/on(java.lang.String)|",
      "|java+method:///java/lang/Thread/start()|",
      "|java+constructor:///java/io/OutputStreamWriter/OutputStreamWriter(java.io.OutputStream,java.nio.charset.Charset)|",
      "|java+constructor:///java/io/ByteArrayInputStream/ByteArrayInputStream(byte%5B%5D)|",
      "|java+method:///java/util/Map/get(java.lang.Object)|",
      "|java+method:///java/lang/Thread/currentThread()|",
      "|java+constructor:///java/lang/Thread/Thread(java.lang.Runnable)|",
      "|java+method:///org/apache/spark/SparkContext/jarOfClass(java.lang.Class)|",
      "|java+method:///java/util/Properties/put(java.lang.Object,java.lang.Object)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String)|",
      "|java+method:///java/lang/String/format(java.lang.String,java.lang.Object%5B%5D)|",
      "|java+method:///java/lang/ProcessBuilder/start()|",
      "|java+method:///java/io/File/setReadable(boolean,boolean)|",
      "|java+method:///java/lang/Thread/setDaemon(boolean)|",
      "|java+method:///java/util/List/addAll(java.util.Collection)|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/get(java.lang.String)|",
      "|java+method:///java/util/Iterator/next()|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$3/SparkClientImpl$3(org.apache.hive.spark.client.SparkClientImpl,java.lang.Process,java.util.List,org.apache.hive.spark.client.rpc.RpcServer,java.lang.String)|",
      "|java+method:///java/lang/Thread/setName(java.lang.String)|",
      "|java+method:///com/google/common/base/Strings/nullToEmpty(java.lang.String)|",
      "|java+method:///java/io/Writer/close()|",
      "|java+method:///org/apache/hadoop/security/UserGroupInformation/getShortUserName()|",
      "|java+method:///java/lang/String/equals(java.lang.Object)|",
      "|java+constructor:///java/io/File/File(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/commons/lang3/StringUtils/isNotBlank(java.lang.CharSequence)|",
      "|java+constructor:///java/util/Properties/Properties()|",
      "|java+method:///java/lang/Class/getName()|",
      "|java+method:///com/google/common/base/Preconditions/checkArgument(boolean,java.lang.Object)|",
      "|java+method:///org/apache/hive/spark/client/SparkClientUtilities/isYarnClusterMode(java.lang.String,java.lang.String)|",
      "|java+method:///com/google/common/base/Joiner/skipNulls()|",
      "|java+method:///java/lang/String/isEmpty()|",
      "|java+method:///java/lang/System/getProperty(java.lang.String)|",
      "|java+constructor:///java/lang/StringBuilder/StringBuilder()|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getAddress()|",
      "|java+method:///com/google/common/base/Joiner/join(java.lang.Iterable)|",
      "|java+method:///java/io/File/getAbsolutePath()|",
      "|java+method:///com/google/common/base/Strings/emptyToNull(java.lang.String)|",
      "|java+method:///java/util/Set/iterator()|",
      "|java+method:///java/util/List/add(java.lang.Object)|",
      "|java+constructor:///org/apache/hive/spark/client/SparkClientImpl$2/SparkClientImpl$2(org.apache.hive.spark.client.SparkClientImpl,java.lang.String,java.lang.String,java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hive/spark/client/rpc/RpcServer/getPort()|",
      "|java+constructor:///java/lang/ProcessBuilder/ProcessBuilder(java.lang.String%5B%5D)|",
      "|java+method:///com/google/common/collect/ImmutableSet/iterator()|",
      "|java+method:///com/google/common/collect/Lists/newLinkedList()|",
      "|java+method:///java/lang/String/startsWith(java.lang.String)|",
      "|java+method:///java/lang/StringBuilder/append(java.lang.Object)|",
      "|java+method:///java/lang/Object/getClass()|",
      "|java+method:///java/lang/System/getenv(java.lang.String)|",
      "|java+method:///java/lang/String/contains(java.lang.CharSequence)|",
      "|java+method:///java/util/Properties/load(java.io.InputStream)|",
      "|java+method:///org/slf4j/Logger/info(java.lang.String,java.lang.Object)|",
      "|java+method:///java/lang/Thread/getContextClassLoader()|",
      "|java+method:///java/io/File/createTempFile(java.lang.String,java.lang.String)|",
      "|java+method:///org/apache/hadoop/hive/shims/Utils/getUGI()|",
      "|java+method:///java/io/File/deleteOnExit()|",
      "|java+method:///java/util/Map/entrySet()|",
      "|java+method:///org/apache/hadoop/hive/conf/HiveConf/getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars)|",
      "|java+method:///java/lang/ProcessBuilder/environment()|",
      "|java+method:///java/util/Map/remove(java.lang.Object)|",
      "|java+constructor:///java/io/FileOutputStream/FileOutputStream(java.io.File)|",
      "|java+method:///java/lang/StringBuilder/toString()|",
      "|java+method:///java/lang/String/valueOf(int)|",
      "|java+method:///java/lang/String/endsWith(java.lang.String)|",
      "|java+method:///scala/Option/get()|"
    ],
    "affectedLib": "org.apache.hive:hive-common:2.3.3",
    "change": "UPDATED"
  }
]